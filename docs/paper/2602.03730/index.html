<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Efficient Variance-reduced Estimation from Generative EHR Models: The SCOPE and REACH Estimators - Paper Tracker</title>
    <meta name="description" content="Daily arXiv paper tracking with AI-powered analysis">
    <link rel="stylesheet" href="/static/css/style.css">
    
</head>
<body>
    <nav class="navbar">
        <div class="nav-container">
            <a href="/" class="nav-brand">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path>
                    <path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path>
                </svg>
                <span>Paper Tracker</span>
            </a>
            <div class="nav-links">
                
                <a href="/category/memory/" class="nav-link ">
                    LLM Memory &amp; RAG
                </a>
                
                <a href="/category/agent/" class="nav-link ">
                    AI Agents
                </a>
                
                <a href="/category/reasoning/" class="nav-link ">
                    LLM Reasoning
                </a>
                
            </div>
            <div class="nav-search">
                <input type="text" id="search-input" placeholder="搜索论文..." autocomplete="off">
                <div id="search-results" class="search-dropdown"></div>
            </div>
        </div>
    </nav>

    <main class="main-content">
        
<div class="container">
    <article class="paper-detail">
        <nav class="breadcrumb">
            <a href="/">首页</a>
            <span>/</span>
            <a href="/category/reasoning/">LLM Reasoning</a>
            <span>/</span>
            <span>2602.03730v1</span>
        </nav>

        <header class="paper-detail-header">
            <div class="paper-detail-meta">
                <span class="paper-category-badge">LLM Reasoning</span>
                <span class="paper-score score-medium">
                    相关度: 7/10
                </span>
            </div>
            <h1 class="paper-detail-title">Efficient Variance-reduced Estimation from Generative EHR Models: The SCOPE and REACH Estimators</h1>
            <div class="paper-detail-authors">
                
                <span class="author">Luke Solo</span>, 
                
                <span class="author">Matthew B. A. McDermott</span>, 
                
                <span class="author">William F. Parker</span>, 
                
                <span class="author">Bashar Ramadan</span>, 
                
                <span class="author">Michael C. Burkhart</span>, 
                
                <span class="author">Brett K. Beaulieu-Jones</span>
                
            </div>
            <div class="paper-detail-info">
                <span>arXiv: 2602.03730v1</span>
                <span>发布: 2026-02-03</span>
                <span>更新: 2026-02-03</span>
            </div>
            <div class="paper-detail-actions">
                <a href="https://arxiv.org/pdf/2602.03730v1" class="btn btn-primary" target="_blank" rel="noopener">
                    <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"></path>
                        <polyline points="7 10 12 15 17 10"></polyline>
                        <line x1="12" y1="15" x2="12" y2="3"></line>
                    </svg>
                    下载 PDF
                </a>
                <a href="http://arxiv.org/abs/2602.03730v1" class="btn btn-outline" target="_blank" rel="noopener">
                    <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path>
                        <polyline points="15 3 21 3 21 9"></polyline>
                        <line x1="10" y1="14" x2="21" y2="3"></line>
                    </svg>
                    arXiv 页面
                </a>
            </div>
        </header>

        <section class="paper-section">
            <h2>AI 摘要</h2>
            <div class="summary-box">
                <p>提出了SCOPE和REACH两种新的EHR生成模型估计器，显著降低了计算成本和抽样方差。</p>
            </div>
        </section>

        <section class="paper-section">
            <h2>主要贡献</h2>
            <ul class="contributions-list">
                
                <li>提出了SCOPE和REACH两种新的无偏估计器</li>
                
                <li>证明了REACH保证了方差缩减</li>
                
                <li>在MIMIC-IV数据集上验证了方法的有效性，显著降低了推理成本</li>
                
            </ul>
        </section>

        <section class="paper-section">
            <h2>方法论</h2>
            <p>利用生成模型中被丢弃的next-token概率分布，设计了SCOPE和REACH估计器，并进行了理论分析和实验验证。</p>
        </section>

        <section class="paper-section">
            <h2>原文摘要</h2>
            <div class="abstract-box">
                <p>Generative models trained using self-supervision of tokenized electronic health record (EHR) timelines show promise for clinical outcome prediction. This is typically done using Monte Carlo simulation for future patient trajectories. However, existing approaches suffer from three key limitations: sparse estimate distributions that poorly differentiate patient risk levels, extreme computational costs, and high sampling variance. We propose two new estimators: the Sum of Conditional Outcome Probability Estimator (SCOPE) and Risk Estimation from Anticipated Conditional Hazards (REACH), that leverage next-token probability distributions discarded by standard Monte Carlo. We prove both estimators are unbiased and that REACH guarantees variance reduction over Monte Carlo sampling for any model and outcome. Empirically, on hospital mortality prediction in MIMIC-IV using the ETHOS-ARES framework, SCOPE and REACH match 100-sample Monte Carlo performance using only 10-11 samples (95% CI: [9,11]), representing a ~10x reduction in inference cost without degrading calibration. For ICU admission prediction, efficiency gains are more modest (~1.2x), which we attribute to the outcome&#39;s lower &#34;spontaneity,&#34; a property we characterize theoretically and empirically. These methods substantially improve the feasibility of deploying generative EHR models in resource-constrained clinical settings.</p>
            </div>
        </section>

        <section class="paper-section">
            <h2>标签</h2>
            <div class="paper-tags">
                
                <span class="tag">EHR</span>
                
                <span class="tag">生成模型</span>
                
                <span class="tag">临床预测</span>
                
                <span class="tag">方差缩减</span>
                
                <span class="tag">自监督学习</span>
                
            </div>
        </section>

        <section class="paper-section">
            <h2>arXiv 分类</h2>
            <div class="paper-tags">
                
                <span class="tag tag-secondary">stat.ML</span>
                
                <span class="tag tag-secondary">cs.LG</span>
                
            </div>
        </section>

        <footer class="paper-detail-footer">
            <p class="analysis-info">
                分析模型: gemini / gemini-2.0-flash
                · 分析时间: 2026-02-04 20:42
            </p>
            <p class="relevance-reason">
                <strong>相关度评分原因:</strong> 论文研究降低计算成本，侧重推理效率，与推理相关。
            </p>
        </footer>
    </article>
</div>

    </main>

    <footer class="footer">
        <div class="footer-container">
            <p>Generated at 2026-02-04 20:44 · Powered by arXiv API</p>
        </div>
    </footer>

    <script src="/static/js/main.js"></script>
    
</body>
</html>