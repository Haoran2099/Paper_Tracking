<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>When Single Answer Is Not Enough: Rethinking Single-Step Retrosynthesis Benchmarks for LLMs - Paper Tracker</title>
    <meta name="description" content="Daily arXiv paper tracking with AI-powered analysis">
    <link rel="stylesheet" href="/static/css/style.css">
    
</head>
<body>
    <nav class="navbar">
        <div class="nav-container">
            <a href="/" class="nav-brand">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path>
                    <path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path>
                </svg>
                <span>Paper Tracker</span>
            </a>
            <div class="nav-links">
                
                <a href="/category/memory/" class="nav-link ">
                    LLM Memory &amp; RAG
                </a>
                
                <a href="/category/agent/" class="nav-link ">
                    AI Agents
                </a>
                
                <a href="/category/reasoning/" class="nav-link ">
                    LLM Reasoning
                </a>
                
            </div>
            <div class="nav-search">
                <input type="text" id="search-input" placeholder="搜索论文..." autocomplete="off">
                <div id="search-results" class="search-dropdown"></div>
            </div>
        </div>
    </nav>

    <main class="main-content">
        
<div class="container">
    <article class="paper-detail">
        <nav class="breadcrumb">
            <a href="/">首页</a>
            <span>/</span>
            <a href="/category/reasoning/">LLM Reasoning</a>
            <span>/</span>
            <span>2602.03554v1</span>
        </nav>

        <header class="paper-detail-header">
            <div class="paper-detail-meta">
                <span class="paper-category-badge">LLM Reasoning</span>
                <span class="paper-score score-high">
                    相关度: 8/10
                </span>
            </div>
            <h1 class="paper-detail-title">When Single Answer Is Not Enough: Rethinking Single-Step Retrosynthesis Benchmarks for LLMs</h1>
            <div class="paper-detail-authors">
                
                <span class="author">Bogdan Zagribelnyy</span>, 
                
                <span class="author">Ivan Ilin</span>, 
                
                <span class="author">Maksim Kuznetsov</span>, 
                
                <span class="author">Nikita Bondarev</span>, 
                
                <span class="author">Roman Schutski</span>, 
                
                <span class="author">Thomas MacDougall</span>, 
                
                <span class="author">Rim Shayakhmetov</span>, 
                
                <span class="author">Zulfat Miftakhutdinov</span>, 
                
                <span class="author">Mikolaj Mizera</span>, 
                
                <span class="author">Vladimir Aladinskiy</span>, 
                
                <span class="author">Alex Aliper</span>, 
                
                <span class="author">Alex Zhavoronkov</span>
                
            </div>
            <div class="paper-detail-info">
                <span>arXiv: 2602.03554v1</span>
                <span>发布: 2026-02-03</span>
                <span>更新: 2026-02-03</span>
            </div>
            <div class="paper-detail-actions">
                <a href="https://arxiv.org/pdf/2602.03554v1" class="btn btn-primary" target="_blank" rel="noopener">
                    <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"></path>
                        <polyline points="7 10 12 15 17 10"></polyline>
                        <line x1="12" y1="15" x2="12" y2="3"></line>
                    </svg>
                    下载 PDF
                </a>
                <a href="http://arxiv.org/abs/2602.03554v1" class="btn btn-outline" target="_blank" rel="noopener">
                    <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path>
                        <polyline points="15 3 21 3 21 9"></polyline>
                        <line x1="10" y1="14" x2="21" y2="3"></line>
                    </svg>
                    arXiv 页面
                </a>
            </div>
        </header>

        <section class="paper-section">
            <h2>AI 摘要</h2>
            <div class="summary-box">
                <p>论文提出一种新的单步逆合成基准测试框架，并使用化学合理性指标ChemCensor评估LLM的性能。</p>
            </div>
        </section>

        <section class="paper-section">
            <h2>主要贡献</h2>
            <ul class="contributions-list">
                
                <li>提出了新的逆合成基准测试框架</li>
                
                <li>引入了化学合理性指标ChemCensor</li>
                
                <li>构建了大规模数据集CREED用于LLM训练</li>
                
            </ul>
        </section>

        <section class="paper-section">
            <h2>方法论</h2>
            <p>使用ChemCensor评估LLM生成的逆合成反应的化学合理性，并使用CREED数据集训练LLM。</p>
        </section>

        <section class="paper-section">
            <h2>原文摘要</h2>
            <div class="abstract-box">
                <p>Recent progress has expanded the use of large language models (LLMs) in drug discovery, including synthesis planning. However, objective evaluation of retrosynthesis performance remains limited. Existing benchmarks and metrics typically rely on published synthetic procedures and Top-K accuracy based on single ground-truth, which does not capture the open-ended nature of real-world synthesis planning. We propose a new benchmarking framework for single-step retrosynthesis that evaluates both general-purpose and chemistry-specialized LLMs using ChemCensor, a novel metric for chemical plausibility. By emphasizing plausibility over exact match, this approach better aligns with human synthesis planning practices. We also introduce CREED, a novel dataset comprising millions of ChemCensor-validated reaction records for LLM training, and use it to train a model that improves over the LLM baselines under this benchmark.</p>
            </div>
        </section>

        <section class="paper-section">
            <h2>标签</h2>
            <div class="paper-tags">
                
                <span class="tag">LLM</span>
                
                <span class="tag">逆合成</span>
                
                <span class="tag">药物发现</span>
                
                <span class="tag">基准测试</span>
                
                <span class="tag">化学信息学</span>
                
            </div>
        </section>

        <section class="paper-section">
            <h2>arXiv 分类</h2>
            <div class="paper-tags">
                
                <span class="tag tag-secondary">cs.LG</span>
                
                <span class="tag tag-secondary">cs.AI</span>
                
                <span class="tag tag-secondary">cs.CE</span>
                
                <span class="tag tag-secondary">cs.CL</span>
                
            </div>
        </section>

        <footer class="paper-detail-footer">
            <p class="analysis-info">
                分析模型: gemini / gemini-2.0-flash
                · 分析时间: 2026-02-04 20:43
            </p>
            <p class="relevance-reason">
                <strong>相关度评分原因:</strong> 涉及LLM在特定领域的推理能力评估，并提出新评估方法。
            </p>
        </footer>
    </article>
</div>

    </main>

    <footer class="footer">
        <div class="footer-container">
            <p>Generated at 2026-02-04 20:44 · Powered by arXiv API</p>
        </div>
    </footer>

    <script src="/static/js/main.js"></script>
    
</body>
</html>