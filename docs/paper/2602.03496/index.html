<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lookahead Path Likelihood Optimization for Diffusion LLMs - Paper Tracker</title>
    <meta name="description" content="Daily arXiv paper tracking with AI-powered analysis">
    <link rel="stylesheet" href="/Paper_Tracking/static/css/style.css">
    <script>window.SITE_BASE_URL = "/Paper_Tracking";</script>
    
</head>
<body>
    <nav class="navbar">
        <div class="nav-container">
            <a href="/Paper_Tracking/" class="nav-brand">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path>
                    <path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path>
                </svg>
                <span>Paper Tracker</span>
            </a>
            <div class="nav-links">
                
                <a href="/Paper_Tracking/category/memory/" class="nav-link ">
                    LLM Memory &amp; RAG
                </a>
                
                <a href="/Paper_Tracking/category/agent/" class="nav-link ">
                    AI Agents
                </a>
                
                <a href="/Paper_Tracking/category/reasoning/" class="nav-link ">
                    LLM Reasoning
                </a>
                
            </div>
            <div class="nav-search">
                <input type="text" id="search-input" placeholder="搜索论文..." autocomplete="off">
                <div id="search-results" class="search-dropdown"></div>
            </div>
        </div>
    </nav>

    <main class="main-content">
        
<div class="container">
    <article class="paper-detail">
        <nav class="breadcrumb">
            <a href="/Paper_Tracking/">首页</a>
            <span>/</span>
            <a href="/Paper_Tracking/category/reasoning/">LLM Reasoning</a>
            <span>/</span>
            <span>2602.03496v1</span>
        </nav>

        <header class="paper-detail-header">
            <div class="paper-detail-meta">
                <span class="paper-category-badge">LLM Reasoning</span>
                <span class="paper-score score-high">
                    相关度: 9/10
                </span>
            </div>
            <h1 class="paper-detail-title">Lookahead Path Likelihood Optimization for Diffusion LLMs</h1>
            <div class="paper-detail-authors">
                
                <span class="author">Xuejie Liu</span>, 
                
                <span class="author">Yap Vit Chun</span>, 
                
                <span class="author">Yitao Liang</span>, 
                
                <span class="author">Anji Liu</span>
                
            </div>
            <div class="paper-detail-info">
                <span>arXiv: 2602.03496v1</span>
                <span>发布: 2026-02-03</span>
                <span>更新: 2026-02-03</span>
            </div>
            <div class="paper-detail-actions">
                <a href="https://arxiv.org/pdf/2602.03496v1" class="btn btn-primary" target="_blank" rel="noopener">
                    <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"></path>
                        <polyline points="7 10 12 15 17 10"></polyline>
                        <line x1="12" y1="15" x2="12" y2="3"></line>
                    </svg>
                    下载 PDF
                </a>
                <a href="http://arxiv.org/abs/2602.03496v1" class="btn btn-outline" target="_blank" rel="noopener">
                    <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path>
                        <polyline points="15 3 21 3 21 9"></polyline>
                        <line x1="10" y1="14" x2="21" y2="3"></line>
                    </svg>
                    arXiv 页面
                </a>
            </div>
        </header>

        <section class="paper-section">
            <h2>AI 摘要</h2>
            <div class="summary-box">
                <p>提出了一种基于路径似然优化的扩散LLM解码方法，提升推理准确性。</p>
            </div>
        </section>

        <section class="paper-section">
            <h2>主要贡献</h2>
            <ul class="contributions-list">
                
                <li>提出了路径对数似然(Path LL)目标</li>
                
                <li>设计了高效的值估计器POKE</li>
                
                <li>提出了基于POKE的序列蒙特卡洛搜索框架POKE-SMC</li>
                
            </ul>
        </section>

        <section class="paper-section">
            <h2>方法论</h2>
            <p>引入路径似然作为优化目标，通过值估计器预测未来路径似然，并利用蒙特卡洛搜索寻找最优解码路径。</p>
        </section>

        <section class="paper-section">
            <h2>原文摘要</h2>
            <div class="abstract-box">
                <p>Diffusion Large Language Models (dLLMs) support arbitrary-order generation, yet their inference performance critically depends on the unmasking order. Existing strategies rely on heuristics that greedily optimize local confidence, offering limited guidance for identifying unmasking paths that are globally consistent and accurate. To bridge this gap, we introduce path log-likelihood (Path LL), a trajectory-conditioned objective that strongly correlates with downstream accuracy and enables principled selection of unmasking paths. To optimize Path LL at inference time, we propose POKE, an efficient value estimator that predicts the expected future Path LL of a partial decoding trajectory. We then integrate this lookahead signal into POKE-SMC, a Sequential Monte Carlo-based search framework for dynamically identifying optimal unmasking paths. Extensive experiments across 6 reasoning tasks show that POKE-SMC consistently improves accuracy, achieving 2%--3% average gains over strong decoding-time scaling baselines at comparable inference overhead on LLaDA models and advancing the accuracy--compute Pareto frontier.</p>
            </div>
        </section>

        <section class="paper-section">
            <h2>标签</h2>
            <div class="paper-tags">
                
                <span class="tag">Diffusion LLM</span>
                
                <span class="tag">Inference</span>
                
                <span class="tag">Unmasking Order</span>
                
                <span class="tag">Lookahead Search</span>
                
            </div>
        </section>

        <section class="paper-section">
            <h2>arXiv 分类</h2>
            <div class="paper-tags">
                
                <span class="tag tag-secondary">cs.LG</span>
                
            </div>
        </section>

        <footer class="paper-detail-footer">
            <p class="analysis-info">
                分析模型: gemini / gemini-2.0-flash
                · 分析时间: 2026-02-04 20:44
            </p>
            <p class="relevance-reason">
                <strong>相关度评分原因:</strong> 论文核心关注LLM的推理和解码过程优化，属于推理领域关键问题。
            </p>
        </footer>
    </article>
</div>

    </main>

    <footer class="footer">
        <div class="footer-container">
            <p>Generated at 2026-02-05 01:08 · Powered by arXiv API</p>
        </div>
    </footer>

    <script src="/Paper_Tracking/static/js/main.js"></script>
    
</body>
</html>