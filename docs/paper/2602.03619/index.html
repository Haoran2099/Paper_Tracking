<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Learning Query-Specific Rubrics from Human Preferences for DeepResearch Report Generation - Paper Tracker</title>
    <meta name="description" content="Daily arXiv paper tracking with AI-powered analysis">
    <link rel="stylesheet" href="/Paper_Tracking/static/css/style.css">
    <script>window.SITE_BASE_URL = "/Paper_Tracking";</script>
    
</head>
<body>
    <nav class="navbar">
        <div class="nav-container">
            <a href="/Paper_Tracking/" class="nav-brand">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path>
                    <path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path>
                </svg>
                <span>Paper Tracker</span>
            </a>
            <div class="nav-links">
                
                <a href="/Paper_Tracking/category/memory/" class="nav-link ">
                    LLM Memory &amp; RAG
                </a>
                
                <a href="/Paper_Tracking/category/agent/" class="nav-link ">
                    AI Agents
                </a>
                
                <a href="/Paper_Tracking/category/reasoning/" class="nav-link ">
                    LLM Reasoning
                </a>
                
            </div>
            <div class="nav-search">
                <input type="text" id="search-input" placeholder="搜索论文..." autocomplete="off">
                <div id="search-results" class="search-dropdown"></div>
            </div>
        </div>
    </nav>

    <main class="main-content">
        
<div class="container">
    <article class="paper-detail">
        <nav class="breadcrumb">
            <a href="/Paper_Tracking/">首页</a>
            <span>/</span>
            <a href="/Paper_Tracking/category/agent/">AI Agents</a>
            <span>/</span>
            <span>2602.03619v1</span>
        </nav>

        <header class="paper-detail-header">
            <div class="paper-detail-meta">
                <span class="paper-category-badge">AI Agents</span>
                <span class="paper-score score-high">
                    相关度: 8/10
                </span>
            </div>
            <h1 class="paper-detail-title">Learning Query-Specific Rubrics from Human Preferences for DeepResearch Report Generation</h1>
            <div class="paper-detail-authors">
                
                <span class="author">Changze Lv</span>, 
                
                <span class="author">Jie Zhou</span>, 
                
                <span class="author">Wentao Zhao</span>, 
                
                <span class="author">Jingwen Xu</span>, 
                
                <span class="author">Zisu Huang</span>, 
                
                <span class="author">Muzhao Tian</span>, 
                
                <span class="author">Shihan Dou</span>, 
                
                <span class="author">Tao Gui</span>, 
                
                <span class="author">Le Tian</span>, 
                
                <span class="author">Xiao Zhou</span>, 
                
                <span class="author">Xiaoqing Zheng</span>, 
                
                <span class="author">Xuanjing Huang</span>, 
                
                <span class="author">Jie Zhou</span>
                
            </div>
            <div class="paper-detail-info">
                <span>arXiv: 2602.03619v1</span>
                <span>发布: 2026-02-03</span>
                <span>更新: 2026-02-03</span>
            </div>
            <div class="paper-detail-actions">
                <a href="https://arxiv.org/pdf/2602.03619v1" class="btn btn-primary" target="_blank" rel="noopener">
                    <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"></path>
                        <polyline points="7 10 12 15 17 10"></polyline>
                        <line x1="12" y1="15" x2="12" y2="3"></line>
                    </svg>
                    下载 PDF
                </a>
                <a href="http://arxiv.org/abs/2602.03619v1" class="btn btn-outline" target="_blank" rel="noopener">
                    <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path>
                        <polyline points="15 3 21 3 21 9"></polyline>
                        <line x1="10" y1="14" x2="21" y2="3"></line>
                    </svg>
                    arXiv 页面
                </a>
            </div>
        </header>

        <section class="paper-section">
            <h2>AI 摘要</h2>
            <div class="summary-box">
                <p>提出一种基于人类偏好的查询特定评估标准生成方法，用于提升深度研究报告的生成质量。</p>
            </div>
        </section>

        <section class="paper-section">
            <h2>主要贡献</h2>
            <ul class="contributions-list">
                
                <li>构建了深度研究风格查询及人类偏好标注的数据集</li>
                
                <li>提出使用混合奖励强化学习训练评估标准生成器</li>
                
                <li>引入多智能体马尔可夫状态工作流(MaMs)提升报告生成效果</li>
                
            </ul>
        </section>

        <section class="paper-section">
            <h2>方法论</h2>
            <p>通过强化学习训练评估标准生成器，结合人类偏好监督和LLM评估，并采用MaMs工作流优化长程推理。</p>
        </section>

        <section class="paper-section">
            <h2>原文摘要</h2>
            <div class="abstract-box">
                <p>Nowadays, training and evaluating DeepResearch-generated reports remain challenging due to the lack of verifiable reward signals. Accordingly, rubric-based evaluation has become a common practice. However, existing approaches either rely on coarse, pre-defined rubrics that lack sufficient granularity, or depend on manually constructed query-specific rubrics that are costly and difficult to scale. In this paper, we propose a pipeline to train human-preference-aligned query-specific rubric generators tailored for DeepResearch report generation. We first construct a dataset of DeepResearch-style queries annotated with human preferences over paired reports, and train rubric generators via reinforcement learning with a hybrid reward combining human preference supervision and LLM-based rubric evaluation. To better handle long-horizon reasoning, we further introduce a Multi-agent Markov-state (MaMs) workflow for report generation. We empirically show that our proposed rubric generators deliver more discriminative and better human-aligned supervision than existing rubric design strategies. Moreover, when integrated into the MaMs training framework, DeepResearch systems equipped with our rubric generators consistently outperform all open-source baselines on the DeepResearch Bench and achieve performance comparable to that of leading closed-source models.</p>
            </div>
        </section>

        <section class="paper-section">
            <h2>标签</h2>
            <div class="paper-tags">
                
                <span class="tag">深度研究报告</span>
                
                <span class="tag">评估标准生成</span>
                
                <span class="tag">强化学习</span>
                
                <span class="tag">人类偏好</span>
                
                <span class="tag">多智能体</span>
                
            </div>
        </section>

        <section class="paper-section">
            <h2>arXiv 分类</h2>
            <div class="paper-tags">
                
                <span class="tag tag-secondary">cs.CL</span>
                
            </div>
        </section>

        <footer class="paper-detail-footer">
            <p class="analysis-info">
                分析模型: gemini / gemini-2.0-flash
                · 分析时间: 2026-02-04 20:43
            </p>
            <p class="relevance-reason">
                <strong>相关度评分原因:</strong> 涉及多智能体和AI Agent驱动的研究报告生成，密切相关。
            </p>
        </footer>
    </article>
</div>

    </main>

    <footer class="footer">
        <div class="footer-container">
            <p>Generated at 2026-02-05 01:08 · Powered by arXiv API</p>
        </div>
    </footer>

    <script src="/Paper_Tracking/static/js/main.js"></script>
    
</body>
</html>