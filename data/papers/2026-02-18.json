{
  "date": "2026-02-18",
  "papers": [
    {
      "arxiv_id": "2602.15827v1",
      "title": "Perceptive Humanoid Parkour: Chaining Dynamic Human Skills via Motion Matching",
      "abstract": "While recent advances in humanoid locomotion have achieved stable walking on varied terrains, capturing the agility and adaptivity of highly dynamic human motions remains an open challenge. In particular, agile parkour in complex environments demands not only low-level robustness, but also human-like motion expressiveness, long-horizon skill composition, and perception-driven decision-making. In this paper, we present Perceptive Humanoid Parkour (PHP), a modular framework that enables humanoid robots to autonomously perform long-horizon, vision-based parkour across challenging obstacle courses. Our approach first leverages motion matching, formulated as nearest-neighbor search in a feature space, to compose retargeted atomic human skills into long-horizon kinematic trajectories. This framework enables the flexible composition and smooth transition of complex skill chains while preserving the elegance and fluidity of dynamic human motions. Next, we train motion-tracking reinforcement learning (RL) expert policies for these composed motions, and distill them into a single depth-based, multi-skill student policy, using a combination of DAgger and RL. Crucially, the combination of perception and skill composition enables autonomous, context-aware decision-making: using only onboard depth sensing and a discrete 2D velocity command, the robot selects and executes whether to step over, climb onto, vault or roll off obstacles of varying geometries and heights. We validate our framework with extensive real-world experiments on a Unitree G1 humanoid robot, demonstrating highly dynamic parkour skills such as climbing tall obstacles up to 1.25m (96% robot height), as well as long-horizon multi-obstacle traversal with closed-loop adaptation to real-time obstacle perturbations.",
      "authors": [
        "Zhen Wu",
        "Xiaoyu Huang",
        "Lujie Yang",
        "Yuanhang Zhang",
        "Koushil Sreenath",
        "Xi Chen",
        "Pieter Abbeel",
        "Rocky Duan",
        "Angjoo Kanazawa",
        "Carmelo Sferrazza",
        "Guanya Shi",
        "C. Karen Liu"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "published": "2026-02-17T18:59:11Z",
      "updated": "2026-02-17T18:59:11Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15827v1",
      "abs_url": "http://arxiv.org/abs/2602.15827v1",
      "summary": "该论文提出了一种感知人形机器人跑酷框架，实现了复杂环境下的自主跑酷。",
      "key_contributions": [
        "提出Perceptive Humanoid Parkour (PHP)框架",
        "结合运动匹配和强化学习实现技能链的生成",
        "通过深度信息实现感知驱动的决策"
      ],
      "methodology": "利用运动匹配生成轨迹，训练强化学习策略，并通过深度信息进行感知决策，实现自主跑酷。",
      "tags": [
        "人形机器人",
        "跑酷",
        "运动匹配",
        "强化学习",
        "深度感知"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "研究机器人自主完成复杂任务，涉及智能体决策和控制。",
      "analyzed_at": "2026-02-18T07:00:20.935723",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15814v1",
      "title": "Avey-B",
      "abstract": "Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute and memory budgets. Their effectiveness stems from self-attention's ability to deliver high-quality bidirectional contextualization with sequence-level parallelism, as popularized by BERT-style architectures. Recently, Avey was introduced as an autoregressive, attention-free alternative that naturally admits an encoder-only adaptation. In this paper, we reformulate Avey for the encoder-only paradigm and propose several innovations to its architecture, including decoupled static and dynamic parameterizations, stability-oriented normalization, and neural compression. Results show that this reformulated architecture compares favorably to four widely used Transformer-based encoders, consistently outperforming them on standard token-classification and information-retrieval benchmarks while scaling more efficiently to long contexts.",
      "authors": [
        "Devang Acharya",
        "Mohammad Hammoud"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-17T18:50:40Z",
      "updated": "2026-02-17T18:50:40Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15814v1",
      "abs_url": "http://arxiv.org/abs/2602.15814v1",
      "summary": "Avey模型的encoder-only改进版，性能超越Transformer，更高效处理长文本。",
      "key_contributions": [
        "Avey模型的encoder-only重构",
        "解耦静态和动态参数化",
        "稳定导向的标准化",
        "神经压缩"
      ],
      "methodology": "对Avey模型进行改造，提出解耦参数、稳定性标准化和神经压缩等创新，并在token分类和信息检索任务上进行评估。",
      "tags": [
        "自然语言处理",
        "Transformer",
        "自注意力",
        "编码器",
        "长文本"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 7,
      "relevance_reason": "涉及模型结构改进，提升处理长文本推理的能力。",
      "analyzed_at": "2026-02-18T07:00:26.257394",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15785v1",
      "title": "This human study did not involve human subjects: Validating LLM simulations as behavioral evidence",
      "abstract": "A growing literature uses large language models (LLMs) as synthetic participants to generate cost-effective and nearly instantaneous responses in social science experiments. However, there is limited guidance on when such simulations support valid inference about human behavior. We contrast two strategies for obtaining valid estimates of causal effects and clarify the assumptions under which each is suitable for exploratory versus confirmatory research. Heuristic approaches seek to establish that simulated and observed human behavior are interchangeable through prompt engineering, model fine-tuning, and other repair strategies designed to reduce LLM-induced inaccuracies. While useful for many exploratory tasks, heuristic approaches lack the formal statistical guarantees typically required for confirmatory research. In contrast, statistical calibration combines auxiliary human data with statistical adjustments to account for discrepancies between observed and simulated responses. Under explicit assumptions, statistical calibration preserves validity and provides more precise estimates of causal effects at lower cost than experiments that rely solely on human participants. Yet the potential of both approaches depends on how well LLMs approximate the relevant populations. We consider what opportunities are overlooked when researchers focus myopically on substituting LLMs for human participants in a study.",
      "authors": [
        "Jessica Hullman",
        "David Broska",
        "Huaman Sun",
        "Aaron Shaw"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-17T18:18:38Z",
      "updated": "2026-02-17T18:18:38Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15785v1",
      "abs_url": "http://arxiv.org/abs/2602.15785v1",
      "summary": "该论文探讨了使用LLM模拟人类行为的有效性，提出了启发式方法和统计校准两种策略。",
      "key_contributions": [
        "对比了启发式方法和统计校准两种LLM模拟策略",
        "阐明了不同策略在探索性研究和验证性研究中的适用性",
        "强调了评估LLM近似真实人群能力的重要性"
      ],
      "methodology": "论文对比了两种LLM模拟策略：启发式方法（prompt工程等）和统计校准（结合辅助人类数据）。",
      "tags": [
        "LLM",
        "simulation",
        "behavioral science",
        "statistical calibration",
        "heuristic approach"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "论文讨论了LLM在模拟人类行为和推理中的应用，并探讨了不同策略的优缺点。",
      "analyzed_at": "2026-02-18T07:00:32.125552",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15782v1",
      "title": "Meteorological data and Sky Images meets Neural Models for Photovoltaic Power Forecasting",
      "abstract": "Due to the rise in the use of renewable energies as an alternative to traditional ones, and especially solar energy, there is increasing interest in studying how to address photovoltaic forecasting in the face of the challenge of variability in photovoltaic energy production, using different methodologies. This work develops a hybrid approach for short and long-term forecasting based on two studies with the same purpose. A multimodal approach that combines images of the sky and photovoltaic energy history with meteorological data is proposed. The main goal is to improve the accuracy of ramp event prediction, increase the robustness of forecasts in cloudy conditions, and extend capabilities beyond nowcasting, to support more efficient operation of the power grid and better management of solar variability. Deep neural models are used for both nowcasting and forecasting solutions, incorporating individual and multiple meteorological variables, as well as an analytical solar position. The results demonstrate that the inclusion of meteorological data, particularly the surface long-wave, radiation downwards, and the combination of wind and solar position, significantly improves current predictions in both nowcasting and forecasting tasks, especially on cloudy days. This study highlights the importance of integrating diverse data sources to improve the reliability and interpretability of solar energy prediction models.",
      "authors": [
        "Ines Montoya-Espinagosa",
        "Antonio Agudo"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-17T18:14:15Z",
      "updated": "2026-02-17T18:14:15Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15782v1",
      "abs_url": "http://arxiv.org/abs/2602.15782v1",
      "summary": "论文提出了一种结合气象数据、天空图像和光伏历史数据的混合深度学习光伏功率预测方法。",
      "key_contributions": [
        "提出了一种结合天空图像、气象数据和光伏历史数据的多模态光伏功率预测方法",
        "验证了气象数据(尤其是长波辐射)对光伏功率预测的有效性",
        "使用深度学习模型进行短期和长期光伏功率预测"
      ],
      "methodology": "使用深度学习模型，结合天空图像、光伏能量历史数据和气象数据，进行短期和长期光伏功率预测。",
      "tags": [
        "光伏功率预测",
        "多模态学习",
        "深度学习",
        "气象数据",
        "天空图像"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 8,
      "relevance_reason": "论文使用了多种模态的数据（图像、气象数据、时间序列数据）进行预测任务。",
      "analyzed_at": "2026-02-18T07:00:34.133829",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15769v1",
      "title": "ViTaB-A: Evaluating Multimodal Large Language Models on Visual Table Attribution",
      "abstract": "Multimodal Large Language Models (mLLMs) are often used to answer questions in structured data such as tables in Markdown, JSON, and images. While these models can often give correct answers, users also need to know where those answers come from. In this work, we study structured data attribution/citation, which is the ability of the models to point to the specific rows and columns that support an answer. We evaluate several mLLMs across different table formats and prompting strategies. Our results show a clear gap between question answering and evidence attribution. Although question answering accuracy remains moderate, attribution accuracy is much lower, near random for JSON inputs, across all models. We also find that models are more reliable at citing rows than columns, and struggle more with textual formats than images. Finally, we observe notable differences across model families. Overall, our findings show that current mLLMs are unreliable at providing fine-grained, trustworthy attribution for structured data, which limits their usage in applications requiring transparency and traceability.",
      "authors": [
        "Yahia Alqurnawi",
        "Preetom Biswas",
        "Anmol Rao",
        "Tejas Anvekar",
        "Chitta Baral",
        "Vivek Gupta"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-17T18:01:35Z",
      "updated": "2026-02-17T18:01:35Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15769v1",
      "abs_url": "http://arxiv.org/abs/2602.15769v1",
      "summary": "该论文评估了多模态大语言模型在视觉表格属性归因任务上的表现，发现其归因能力远低于问答能力。",
      "key_contributions": [
        "提出了视觉表格属性归因（ViTaB-A）的评估任务",
        "评估了不同模型在不同表格格式和提示策略下的归因能力",
        "发现现有模型在细粒度属性归因方面存在不足"
      ],
      "methodology": "构建ViTaB-A数据集，设计不同的表格格式和提示策略，评估多个多模态大语言模型在归因任务上的表现。",
      "tags": [
        "多模态",
        "大语言模型",
        "表格",
        "属性归因",
        "评估"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "核心研究多模态大语言模型在视觉表格数据上的理解和推理能力。",
      "analyzed_at": "2026-02-18T07:00:36.611593",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15767v1",
      "title": "Robot-Assisted Social Dining as a White Glove Service",
      "abstract": "Robot-assisted feeding enables people with disabilities who require assistance eating to enjoy a meal independently and with dignity. However, existing systems have only been tested in-lab or in-home, leaving in-the-wild social dining contexts (e.g., restaurants) largely unexplored. Designing a robot for such contexts presents unique challenges, such as dynamic and unsupervised dining environments that a robot needs to account for and respond to. Through speculative participatory design with people with disabilities, supported by semi-structured interviews and a custom AI-based visual storyboarding tool, we uncovered ideal scenarios for in-the-wild social dining. Our key insight suggests that such systems should: embody the principles of a white glove service where the robot (1) supports multimodal inputs and unobtrusive outputs; (2) has contextually sensitive social behavior and prioritizes the user; (3) has expanded roles beyond feeding; (4) adapts to other relationships at the dining table. Our work has implications for in-the-wild and group contexts of robot-assisted feeding.",
      "authors": [
        "Atharva S Kashyap",
        "Ugne Aleksandra Morkute",
        "Patricia Alves-Oliveira"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "published": "2026-02-17T17:58:25Z",
      "updated": "2026-02-17T17:58:25Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15767v1",
      "abs_url": "http://arxiv.org/abs/2602.15767v1",
      "summary": "研究了机器人辅助残疾人在餐厅社交用餐，提出了“白手套服务”原则。",
      "key_contributions": [
        "提出了机器人辅助社交用餐的“白手套服务”原则",
        "探索了在真实社交用餐场景下机器人设计的挑战与机遇",
        "通过参与式设计与AI辅助，揭示了理想的社交用餐场景"
      ],
      "methodology": "采用思辨性参与式设计，结合半结构化访谈和定制AI视觉故事板工具。",
      "tags": [
        "人机交互",
        "机器人",
        "社交机器人",
        "辅助技术",
        "无障碍设计"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "机器人作为智能体，在特定场景下执行任务，与Agent有较高关联。",
      "analyzed_at": "2026-02-18T07:00:39.335657",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15763v1",
      "title": "GLM-5: from Vibe Coding to Agentic Engineering",
      "abstract": "We present GLM-5, a next-generation foundation model designed to transition the paradigm of vibe coding to agentic engineering. Building upon the agentic, reasoning, and coding (ARC) capabilities of its predecessor, GLM-5 adopts DSA to significantly reduce training and inference costs while maintaining long-context fidelity. To advance model alignment and autonomy, we implement a new asynchronous reinforcement learning infrastructure that drastically improves post-training efficiency by decoupling generation from training. Furthermore, we propose novel asynchronous agent RL algorithms that further improve RL quality, enabling the model to learn from complex, long-horizon interactions more effectively. Through these innovations, GLM-5 achieves state-of-the-art performance on major open benchmarks. Most critically, GLM-5 demonstrates unprecedented capability in real-world coding tasks, surpassing previous baselines in handling end-to-end software engineering challenges. Code, models, and more information are available at https://github.com/zai-org/GLM-5.",
      "authors": [
        "GLM-5 Team",
        ":",
        "Aohan Zeng",
        "Xin Lv",
        "Zhenyu Hou",
        "Zhengxiao Du",
        "Qinkai Zheng",
        "Bin Chen",
        "Da Yin",
        "Chendi Ge",
        "Chengxing Xie",
        "Cunxiang Wang",
        "Gengzheng Pan",
        "Hao Zeng",
        "Haoke Zhang",
        "Haoran Wang",
        "Huilong Chen",
        "Jiajie Zhang",
        "Jian Jiao",
        "Jiaqi Guo",
        "Jingsen Wang",
        "Jingzhao Du",
        "Jinzhu Wu",
        "Kedong Wang",
        "Lei Li",
        "Lin Fan",
        "Lucen Zhong",
        "Mingdao Liu",
        "Mingming Zhao",
        "Pengfan Du",
        "Qian Dong",
        "Rui Lu",
        "Shuang-Li",
        "Shulin Cao",
        "Song Liu",
        "Ting Jiang",
        "Xiaodong Chen",
        "Xiaohan Zhang",
        "Xuancheng Huang",
        "Xuezhen Dong",
        "Yabo Xu",
        "Yao Wei",
        "Yifan An",
        "Yilin Niu",
        "Yitong Zhu",
        "Yuanhao Wen",
        "Yukuo Cen",
        "Yushi Bai",
        "Zhongpei Qiao",
        "Zihan Wang",
        "Zikang Wang",
        "Zilin Zhu",
        "Ziqiang Liu",
        "Zixuan Li",
        "Bojie Wang",
        "Bosi Wen",
        "Can Huang",
        "Changpeng Cai",
        "Chao Yu",
        "Chen Li",
        "Chen Li",
        "Chenghua Huang",
        "Chengwei Hu",
        "Chenhui Zhang",
        "Chenzheng Zhu",
        "Congfeng Yin",
        "Daoyan Lin",
        "Dayong Yang",
        "Di Wang",
        "Ding Ai",
        "Erle Zhu",
        "Fangzhou Yi",
        "Feiyu Chen",
        "Guohong Wen",
        "Hailong Sun",
        "Haisha Zhao",
        "Haiyi Hu",
        "Hanchen Zhang",
        "Hanrui Liu",
        "Hanyu Zhang",
        "Hao Peng",
        "Hao Tai",
        "Haobo Zhang",
        "He Liu",
        "Hongwei Wang",
        "Hongxi Yan",
        "Hongyu Ge",
        "Huan Liu",
        "Huan Liu",
        "Huanpeng Chu",
        "Jia'ni Zhao",
        "Jiachen Wang",
        "Jiajing Zhao",
        "Jiamin Ren",
        "Jiapeng Wang",
        "Jiaxin Zhang",
        "Jiayi Gui",
        "Jiayue Zhao",
        "Jijie Li",
        "Jing An",
        "Jing Li",
        "Jingwei Yuan",
        "Jinhua Du",
        "Jinxin Liu",
        "Junkai Zhi",
        "Junwen Duan",
        "Kaiyue Zhou",
        "Kangjian Wei",
        "Ke Wang",
        "Keyun Luo",
        "Laiqiang Zhang",
        "Leigang Sha",
        "Liang Xu",
        "Lindong Wu",
        "Lintao Ding",
        "Lu Chen",
        "Minghao Li",
        "Nianyi Lin",
        "Pan Ta",
        "Qiang Zou",
        "Rongjun Song",
        "Ruiqi Yang",
        "Shangqing Tu",
        "Shangtong Yang",
        "Shaoxiang Wu",
        "Shengyan Zhang",
        "Shijie Li",
        "Shuang Li",
        "Shuyi Fan",
        "Wei Qin",
        "Wei Tian",
        "Weining Zhang",
        "Wenbo Yu",
        "Wenjie Liang",
        "Xiang Kuang",
        "Xiangmeng Cheng",
        "Xiangyang Li",
        "Xiaoquan Yan",
        "Xiaowei Hu",
        "Xiaoying Ling",
        "Xing Fan",
        "Xingye Xia",
        "Xinyuan Zhang",
        "Xinze Zhang",
        "Xirui Pan",
        "Xunkai Zhang",
        "Yandong Wu",
        "Yanfu Li",
        "Yidong Wang",
        "Yifan Zhu",
        "Yijun Tan",
        "Yilin Zhou",
        "Yiming Pan",
        "Ying Zhang",
        "Yinpei Su",
        "Yipeng Geng",
        "Yipeng Geng",
        "Yong Yan",
        "Yonglin Tan",
        "Yuean Bi",
        "Yuhan Shen",
        "Yuhao Yang",
        "Yujiang Li",
        "Yunan Liu",
        "Yunqing Wang",
        "Yuntao Li",
        "Yurong Wu",
        "Yutao Zhang",
        "Yuxi Duan",
        "Yuxuan Zhang",
        "Zezhen Liu",
        "Zhengtao Jiang",
        "Zhenhe Yan",
        "Zheyu Zhang",
        "Zhixiang Wei",
        "Zhuo Chen",
        "Zhuoer Feng",
        "Zijun Yao",
        "Ziwei Chai",
        "Ziyuan Wang",
        "Zuzhou Zhang",
        "Bin Xu",
        "Minlie Huang",
        "Hongning Wang",
        "Juanzi Li",
        "Yuxiao Dong",
        "Jie Tang"
      ],
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-17T17:50:56Z",
      "updated": "2026-02-17T17:50:56Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15763v1",
      "abs_url": "http://arxiv.org/abs/2602.15763v1",
      "summary": "GLM-5通过DSA降低成本，异步强化学习提升效率，实现从Vibe Coding到Agentic Engineering的转变。",
      "key_contributions": [
        "采用DSA降低训练和推理成本，同时保持长上下文保真度",
        "引入异步强化学习基础设施，提升训练效率",
        "提出新型异步agent RL算法，提升RL质量"
      ],
      "methodology": "GLM-5构建在ARC能力之上，采用DSA降低成本，利用异步强化学习提升模型对复杂任务的学习能力。",
      "tags": [
        "LLM",
        "Agent",
        "Reinforcement Learning",
        "Coding"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于提升agent在软件工程任务中的自主性和效率，属于该领域关键问题。",
      "analyzed_at": "2026-02-18T07:00:42.034790",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15758v1",
      "title": "ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models",
      "abstract": "While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice, users iteratively refine visualizations through multi-turn interactions that require maintaining common ground, tracking prior edits, and adapting to evolving preferences. We introduce ChartEditBench, a benchmark for incremental, visually grounded chart editing via code, comprising 5,000 difficulty-controlled modification chains and a rigorously human-verified subset. Unlike prior one-shot benchmarks, ChartEditBench evaluates sustained, context-aware editing. We further propose a robust evaluation framework that mitigates limitations of LLM-as-a-Judge metrics by integrating execution-based fidelity checks, pixel-level visual similarity, and logical code verification. Experiments with state-of-the-art MLLMs reveal substantial degradation in multi-turn settings due to error accumulation and breakdowns in shared context, with strong performance on stylistic edits but frequent execution failures on data-centric transformations. ChartEditBench, establishes a challenging testbed for grounded, intent-aware multimodal programming.",
      "authors": [
        "Manav Nitin Kapadnis",
        "Lawanya Baghel",
        "Atharva Naik",
        "Carolyn Rosé"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-17T17:45:34Z",
      "updated": "2026-02-17T17:45:34Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15758v1",
      "abs_url": "http://arxiv.org/abs/2602.15758v1",
      "summary": "提出了ChartEditBench基准，用于评估多模态大模型在多轮图表编辑中的能力。",
      "key_contributions": [
        "提出了 ChartEditBench 基准数据集",
        "设计了评估多轮图表编辑能力的框架",
        "分析了现有 MLLM 在该任务上的性能瓶颈"
      ],
      "methodology": "构建包含5000个图表编辑链的数据集，并结合执行、视觉相似度和代码验证来评估模型。",
      "tags": [
        "多模态",
        "图表编辑",
        "基准测试",
        "代码生成"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注多模态大模型在特定视觉任务上的能力评估。",
      "analyzed_at": "2026-02-18T07:00:45.897311",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15756v1",
      "title": "A Note on Non-Composability of Layerwise Approximate Verification for Neural Inference",
      "abstract": "A natural and informal approach to verifiable (or zero-knowledge) ML inference over floating-point data is: ``prove that each layer was computed correctly up to tolerance $δ$; therefore the final output is a reasonable inference result''. This short note gives a simple counterexample showing that this inference is false in general: for any neural network, we can construct a functionally equivalent network for which adversarially chosen approximation-magnitude errors in individual layer computations suffice to steer the final output arbitrarily (within a prescribed bounded range).",
      "authors": [
        "Or Zamir"
      ],
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "published": "2026-02-17T17:41:59Z",
      "updated": "2026-02-17T17:41:59Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15756v1",
      "abs_url": "http://arxiv.org/abs/2602.15756v1",
      "summary": "逐层近似验证的不可组合性：即使每层计算误差可控，整体输出误差可能不可控。",
      "key_contributions": [
        "证明了逐层近似验证方法对于神经推理的无效性",
        "提供了一个反例，展示了即使每层误差很小，最终输出也可能被恶意操控",
        "指出了浮点数数据上可验证机器学习推理的潜在缺陷"
      ],
      "methodology": "通过构造一个功能等价的网络，证明了可以利用每层的误差来操纵最终输出。",
      "tags": [
        "Verification",
        "Neural Inference",
        "Floating-Point Arithmetic",
        "Adversarial Attack"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 7,
      "relevance_reason": "涉及神经网络推理过程中的验证问题，与推理的正确性和安全性相关。",
      "analyzed_at": "2026-02-18T07:00:48.438992",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15751v1",
      "title": "Enabling Low-Latency Machine learning on Radiation-Hard FPGAs with hls4ml",
      "abstract": "This paper presents the first demonstration of a viable, ultra-fast, radiation-hard machine learning (ML) application on FPGAs, which could be used in future high-energy physics experiments. We present a three-fold contribution, with the PicoCal calorimeter, planned for the LHCb Upgrade II experiment, used as a test case. First, we develop a lightweight autoencoder to compress a 32-sample timing readout, representative of that of the PicoCal, into a two-dimensional latent space. Second, we introduce a systematic, hardware-aware quantization strategy and show that the model can be reduced to 10-bit weights with minimal performance loss. Third, as a barrier to the adoption of on-detector ML is the lack of support for radiation-hard FPGAs in the High-Energy Physics community's standard ML synthesis tool, hls4ml, we develop a new backend for this library. This new back-end enables the automatic translation of ML models into High-Level Synthesis (HLS) projects for the Microchip PolarFire family of FPGAs, one of the few commercially available and radiation hard FPGAs. We present the synthesis of the autoencoder on a target PolarFire FPGA, which indicates that a latency of 25 ns can be achieved. We show that the resources utilized are low enough that the model can be placed within the inherently protected logic of the FPGA. Our extension to hls4ml is a significant contribution, paving the way for broader adoption of ML on FPGAs in high-radiation environments.",
      "authors": [
        "Katya Govorkova",
        "Julian Garcia Pardinas",
        "Vladimir Loncar",
        "Victoria Nguyen",
        "Sebastian Schmitt",
        "Marco Pizzichemi",
        "Loris Martinazzoli",
        "Eluned Anne Smith"
      ],
      "categories": [
        "hep-ex",
        "cs.LG"
      ],
      "primary_category": "hep-ex",
      "published": "2026-02-17T17:30:28Z",
      "updated": "2026-02-17T17:30:28Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15751v1",
      "abs_url": "http://arxiv.org/abs/2602.15751v1",
      "summary": "论文展示了在抗辐射FPGA上实现低延迟机器学习应用，并扩展hls4ml工具以支持此类FPGA。",
      "key_contributions": [
        "开发轻量级自编码器压缩时间读数",
        "引入硬件感知的量化策略，降低模型权重",
        "扩展hls4ml支持抗辐射FPGA"
      ],
      "methodology": "通过自编码器压缩数据，结合量化策略降低模型复杂度，并使用hls4ml工具生成FPGA可执行代码。",
      "tags": [
        "FPGA",
        "机器学习",
        "hls4ml",
        "抗辐射",
        "高能物理"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 5,
      "relevance_reason": "论文利用FPGA加速机器学习，可以加速推理，有一定相关性。",
      "analyzed_at": "2026-02-18T07:00:50.346087",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15740v1",
      "title": "MRC-GAT: A Meta-Relational Copula-Based Graph Attention Network for Interpretable Multimodal Alzheimer's Disease Diagnosis",
      "abstract": "Alzheimer's disease (AD) is a progressive neurodegenerative condition necessitating early and precise diagnosis to provide prompt clinical management. Given the paramount importance of early diagnosis, recent studies have increasingly focused on computer-aided diagnostic models to enhance precision and reliability. However, most graph-based approaches still rely on fixed structural designs, which restrict their flexibility and limit generalization across heterogeneous patient data. To overcome these limitations, the Meta-Relational Copula-Based Graph Attention Network (MRC-GAT) is proposed as an efficient multimodal model for AD classification tasks. The proposed architecture, copula-based similarity alignment, relational attention, and node fusion are integrated as the core components of episodic meta-learning, such that the multimodal features, including risk factors (RF), Cognitive test scores, and MRI attributes, are first aligned via a copula-based transformation in a common statistical space and then combined by a multi-relational attention mechanism. According to evaluations performed on the TADPOLE and NACC datasets, the MRC-GAT model achieved accuracies of 96.87% and 92.31%, respectively, demonstrating state-of-the-art performance compared to existing diagnostic models. Finally, the proposed model confirms the robustness and applicability of the proposed method by providing interpretability at various stages of disease diagnosis.",
      "authors": [
        "Fatemeh Khalvandi",
        "Saadat Izadi",
        "Abdolah Chalechale"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-17T17:15:32Z",
      "updated": "2026-02-17T17:15:32Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15740v1",
      "abs_url": "http://arxiv.org/abs/2602.15740v1",
      "summary": "MRC-GAT模型通过结合多模态数据和图注意力网络，实现了阿尔茨海默病的高精度诊断。",
      "key_contributions": [
        "提出Meta-Relational Copula-Based Graph Attention Network (MRC-GAT) 模型",
        "引入copula-based相似性对齐，整合多模态特征",
        "通过关系注意力机制提升诊断性能",
        "在TADPOLE和NACC数据集上达到state-of-the-art的性能",
        "提供疾病诊断各阶段的可解释性"
      ],
      "methodology": "利用Copula函数对多模态数据进行对齐，并通过多关系图注意力网络进行特征融合与分类，结合元学习策略进行训练。",
      "tags": [
        "阿尔茨海默病",
        "多模态学习",
        "图注意力网络",
        "元学习",
        "医学诊断"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "该论文核心是利用多模态信息进行疾病诊断，符合多模态学习的核心概念。",
      "analyzed_at": "2026-02-18T07:00:53.211165",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15725v1",
      "title": "Recursive Concept Evolution for Compositional Reasoning in Large Language Models",
      "abstract": "Large language models achieve strong performance on many complex reasoning tasks, yet their accuracy degrades sharply on benchmarks that require compositional reasoning, including ARC-AGI-2, GPQA, MATH, BBH, and HLE. Existing methods improve reasoning by expanding token-level search through chain-of-thought prompting, self-consistency, or reinforcement learning, but they leave the model's latent representation space fixed. When the required abstraction is not already encoded in this space, performance collapses. We propose Recursive Concept Evolution (RCE), a framework that enables pretrained language models to modify their internal representation geometry during inference. RCE introduces dynamically generated low-rank concept subspaces that are spawned when representational inadequacy is detected, selected through a minimum description length criterion, merged when synergistic, and consolidated via constrained optimization to preserve stability. This process allows the model to construct new abstractions rather than recombining existing ones. We integrate RCE with Mistral-7B and evaluate it across compositional reasoning benchmarks. RCE yields 12-18 point gains on ARC-AGI-2, 8-14 point improvements on GPQA and BBH, and consistent reductions in depth-induced error on MATH and HLE.",
      "authors": [
        "Sarim Chaudhry"
      ],
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-17T17:01:42Z",
      "updated": "2026-02-17T17:01:42Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15725v1",
      "abs_url": "http://arxiv.org/abs/2602.15725v1",
      "summary": "提出了递归概念演化（RCE）框架，通过动态修改LLM内部表征几何来提升组合推理能力。",
      "key_contributions": [
        "提出了递归概念演化（RCE）框架",
        "引入动态生成的低秩概念子空间",
        "RCE显著提升了LLM在组合推理基准上的性能"
      ],
      "methodology": "RCE通过动态生成、选择、合并和巩固概念子空间来改进LLM的内部表示，从而构建新的抽象概念。",
      "tags": [
        "LLM",
        "Reasoning",
        "Compositional Reasoning",
        "Concept Evolution"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文直接解决了LLM组合推理能力不足的核心问题，提出了新的推理框架RCE。",
      "analyzed_at": "2026-02-18T07:00:58.075487",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15724v1",
      "title": "Learning to Retrieve Navigable Candidates for Efficient Vision-and-Language Navigation",
      "abstract": "Vision-and-Language Navigation (VLN) requires an agent to follow natural-language instructions and navigate through previously unseen environments. Recent approaches increasingly employ large language models (LLMs) as high-level navigators due to their flexibility and reasoning capability. However, prompt-based LLM navigation often suffers from inefficient decision-making, as the model must repeatedly interpret instructions from scratch and reason over noisy and verbose navigable candidates at each step. In this paper, we propose a retrieval-augmented framework to improve the efficiency and stability of LLM-based VLN without modifying or fine-tuning the underlying language model. Our approach introduces retrieval at two complementary levels. At the episode level, an instruction-level embedding retriever selects semantically similar successful navigation trajectories as in-context exemplars, providing task-specific priors for instruction grounding. At the step level, an imitation-learned candidate retriever prunes irrelevant navigable directions before LLM inference, reducing action ambiguity and prompt complexity. Both retrieval modules are lightweight, modular, and trained independently of the LLM. We evaluate our method on the Room-to-Room (R2R) benchmark. Experimental results demonstrate consistent improvements in Success Rate, Oracle Success Rate, and SPL on both seen and unseen environments. Ablation studies further show that instruction-level exemplar retrieval and candidate pruning contribute complementary benefits to global guidance and step-wise decision efficiency. These results indicate that retrieval-augmented decision support is an effective and scalable strategy for enhancing LLM-based vision-and-language navigation.",
      "authors": [
        "Shutian Gu",
        "Chengkai Huang",
        "Ruoyu Wang",
        "Lina Yao"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-17T17:00:11Z",
      "updated": "2026-02-17T17:00:11Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15724v1",
      "abs_url": "http://arxiv.org/abs/2602.15724v1",
      "summary": "提出检索增强框架，提升LLM在视觉-语言导航中的效率和稳定性，无需微调LLM。",
      "key_contributions": [
        "提出episode-level instruction检索，提供任务先验",
        "提出step-level candidate检索，降低行动歧义",
        "实验证明检索增强有效提升导航性能"
      ],
      "methodology": "构建双层检索模块，分别在episode和step层面进行检索，为LLM提供上下文信息和候选行动过滤。",
      "tags": [
        "视觉语言导航",
        "LLM",
        "检索增强",
        "Agent"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文直接解决LLM在智能体导航任务中的效率问题，属于核心研究方向。",
      "analyzed_at": "2026-02-18T07:01:00.133757",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15721v1",
      "title": "Lifelong Scalable Multi-Agent Realistic Testbed and A Comprehensive Study on Design Choices in Lifelong AGV Fleet Management Systems",
      "abstract": "We present Lifelong Scalable Multi-Agent Realistic Testbed (LSMART), an open-source simulator to evaluate any Multi-Agent Path Finding (MAPF) algorithm in a Fleet Management System (FMS) with Automated Guided Vehicles (AGVs). MAPF aims to move a group of agents from their corresponding starting locations to their goals. Lifelong MAPF (LMAPF) is a variant of MAPF that continuously assigns new goals for agents to reach. LMAPF applications, such as autonomous warehouses, often require a centralized, lifelong system to coordinate the movement of a fleet of robots, typically AGVs. However, existing works on MAPF and LMAPF often assume simplified kinodynamic models, such as pebble motion, as well as perfect execution and communication for AGVs. Prior work has presented SMART, a software capable of evaluating any MAPF algorithms while considering agent kinodynamics, communication delays, and execution uncertainties. However, SMART is designed for MAPF, not LMAPF. Generalizing SMART to an FMS requires many more design choices. First, an FMS parallelizes planning and execution, raising the question of when to plan. Second, given planners with varying optimality and differing agent-model assumptions, one must decide how to plan. Third, when the planner fails to return valid solutions, the system must determine how to recover. In this paper, we first present LSMART, an open-source simulator that incorporates all these considerations to evaluate any MAPF algorithms in an FMS. We then provide experiment results based on state-of-the-art methods for each design choice, offering guidance on how to effectively design centralized lifelong AGV Fleet Management Systems. LSMART is available at https://smart-mapf.github.io/lifelong-smart.",
      "authors": [
        "Jingtian Yan",
        "Yulun Zhang",
        "Zhenting Liu",
        "Han Zhang",
        "He Jiang",
        "Jingkai Chen",
        "Stephen F. Smith",
        "Jiaoyang Li"
      ],
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "published": "2026-02-17T16:53:20Z",
      "updated": "2026-02-17T16:53:20Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15721v1",
      "abs_url": "http://arxiv.org/abs/2602.15721v1",
      "summary": "提出了LSMART仿真平台，并对AGV车队管理系统中的关键设计选择进行了全面研究。",
      "key_contributions": [
        "提出了LSMART开源仿真平台，用于评估LMAPF算法。",
        "针对FMS设计中的并行规划、规划器选择和故障恢复等问题进行了深入研究。",
        "基于实验结果，为设计集中的终身AGV车队管理系统提供了指导。"
      ],
      "methodology": "通过构建LSMART仿真平台，并结合多种最先进的方法进行实验，对不同设计选择进行评估和比较。",
      "tags": [
        "多智能体",
        "路径规划",
        "车队管理",
        "仿真",
        "AGV"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "该论文专注于多智能体系统，特别是AGV车队的管理，这是AI Agent领域的核心问题。",
      "analyzed_at": "2026-02-18T07:01:02.212070",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15677v1",
      "title": "CAMEL: An ECG Language Model for Forecasting Cardiac Events",
      "abstract": "Electrocardiograms (ECG) are electrical recordings of the heart that are critical for diagnosing cardiovascular conditions. ECG language models (ELMs) have recently emerged as a promising framework for ECG classification accompanied by report generation. However, current models cannot forecast future cardiac events despite the immense clinical value for planning earlier intervention. To address this gap, we propose CAMEL, the first ELM that is capable of inference over longer signal durations which enables its forecasting capability. Our key insight is a specialized ECG encoder which enables cross-understanding of ECG signals with text. We train CAMEL using established LLM training procedures, combining LoRA adaptation with a curriculum learning pipeline. Our curriculum includes ECG classification, metrics calculations, and multi-turn conversations to elicit reasoning. CAMEL demonstrates strong zero-shot performance across 6 tasks and 9 datasets, including ECGForecastBench, a new benchmark that we introduce for forecasting arrhythmias. CAMEL is on par with or surpasses ELMs and fully supervised baselines both in- and out-of-distribution, achieving SOTA results on ECGBench (+7.0% absolute average gain) as well as ECGForecastBench (+12.4% over fully supervised models and +21.1% over zero-shot ELMs).",
      "authors": [
        "Neelay Velingker",
        "Alaia Solko-Breslin",
        "Mayank Keoliya",
        "Seewon Choi",
        "Jiayi Xin",
        "Anika Marathe",
        "Alireza Oraii",
        "Rajat Deo",
        "Sameed Khatana",
        "Rajeev Alur",
        "Mayur Naik",
        "Eric Wong"
      ],
      "categories": [
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-17T16:02:52Z",
      "updated": "2026-02-17T16:02:52Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15677v1",
      "abs_url": "http://arxiv.org/abs/2602.15677v1",
      "summary": "CAMEL是首个用于预测心脏事件的ECG语言模型，优于现有方法。",
      "key_contributions": [
        "提出首个用于预测心脏事件的ECG语言模型CAMEL",
        "引入ECGForecastBench基准测试",
        "证明CAMEL在多种任务和数据集上的卓越性能"
      ],
      "methodology": "使用LLM训练流程，结合LoRA和课程学习，包括ECG分类、指标计算和多轮对话以进行推理。",
      "tags": [
        "ECG",
        "语言模型",
        "心脏事件预测",
        "心电图",
        "医疗AI"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 8,
      "relevance_reason": "涉及ECG信号与文本的交叉理解，属于多模态学习的重要应用。",
      "analyzed_at": "2026-02-18T07:01:04.687788",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15669v1",
      "title": "PERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra",
      "abstract": "Current methods for personality control in Large Language Models rely on static prompting or expensive fine-tuning, failing to capture the dynamic and compositional nature of human traits. We introduce PERSONA, a training-free framework that achieves fine-tuning level performance through direct manipulation of personality vectors in activation space. Our key insight is that personality traits appear as extractable, approximately orthogonal directions in the model's representation space that support algebraic operations. The framework operates through three stages: Persona-Base extracts orthogonal trait vectors via contrastive activation analysis; Persona-Algebra enables precise control through vector arithmetic (scalar multiplication for intensity, addition for composition, subtraction for suppression); and Persona-Flow achieves context-aware adaptation by dynamically composing these vectors during inference. On PersonalityBench, our approach achieves a mean score of 9.60, nearly matching the supervised fine-tuning upper bound of 9.61 without any gradient updates. On our proposed Persona-Evolve benchmark for dynamic personality adaptation, we achieve up to 91% win rates across diverse model families. These results provide evidence that aspects of LLM personality are mathematically tractable, opening new directions for interpretable and efficient behavioral control.",
      "authors": [
        "Xiachong Feng",
        "Liang Zhao",
        "Weihong Zhong",
        "Yichong Huang",
        "Yuxuan Gu",
        "Lingpeng Kong",
        "Xiaocheng Feng",
        "Bing Qin"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-17T15:47:58Z",
      "updated": "2026-02-17T15:47:58Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15669v1",
      "abs_url": "http://arxiv.org/abs/2602.15669v1",
      "summary": "PERSONA框架通过激活向量代数实现LLM动态且可组合的个性化控制，无需微调。",
      "key_contributions": [
        "提出PERSONA框架，实现LLM个性化控制",
        "通过激活向量代数实现动态和可组合的个性化",
        "无需微调，性能接近微调"
      ],
      "methodology": "通过Persona-Base提取正交的特征向量，Persona-Algebra进行向量运算，Persona-Flow实现上下文感知的动态组合。",
      "tags": [
        "LLM",
        "personality control",
        "activation vector",
        "algebraic operations"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 8,
      "relevance_reason": "涉及LLM行为控制和优化，与agent tuning相关度较高。",
      "analyzed_at": "2026-02-18T07:01:07.441158",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15654v1",
      "title": "Zombie Agents: Persistent Control of Self-Evolving LLM Agents via Self-Reinforcing Injections",
      "abstract": "Self-evolving LLM agents update their internal state across sessions, often by writing and reusing long-term memory. This design improves performance on long-horizon tasks but creates a security risk: untrusted external content observed during a benign session can be stored as memory and later treated as instruction. We study this risk and formalize a persistent attack we call a Zombie Agent, where an attacker covertly implants a payload that survives across sessions, effectively turning the agent into a puppet of the attacker.   We present a black-box attack framework that uses only indirect exposure through attacker-controlled web content. The attack has two phases. During infection, the agent reads a poisoned source while completing a benign task and writes the payload into long-term memory through its normal update process. During trigger, the payload is retrieved or carried forward and causes unauthorized tool behavior. We design mechanism-specific persistence strategies for common memory implementations, including sliding-window and retrieval-augmented memory, to resist truncation and relevance filtering. We evaluate the attack on representative agent setups and tasks, measuring both persistence over time and the ability to induce unauthorized actions while preserving benign task quality. Our results show that memory evolution can convert one-time indirect injection into persistent compromise, which suggests that defenses focused only on per-session prompt filtering are not sufficient for self-evolving agents.",
      "authors": [
        "Xianglin Yang",
        "Yufei He",
        "Shuo Ji",
        "Bryan Hooi",
        "Jin Song Dong"
      ],
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "published": "2026-02-17T15:28:24Z",
      "updated": "2026-02-17T15:28:24Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15654v1",
      "abs_url": "http://arxiv.org/abs/2602.15654v1",
      "summary": "研究通过注入攻击长期控制自进化LLM Agent，使其执行未经授权的任务。",
      "key_contributions": [
        "提出Zombie Agent攻击，一种针对自进化LLM Agent的持久控制攻击",
        "设计了黑盒攻击框架，通过间接暴露方式注入恶意payload",
        "针对不同内存实现，设计了抗截断和相关性过滤的持久化策略"
      ],
      "methodology": "通过控制Web内容，诱导Agent读取并存储恶意payload，利用触发机制激活payload，实现长期控制。",
      "tags": [
        "LLM Agent",
        "攻击",
        "安全",
        "持久化",
        "长期记忆"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "核心关注LLM Agent的安全性问题，并提出了具体的攻击方法。",
      "analyzed_at": "2026-02-18T07:01:11.453909",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15650v1",
      "title": "Concept-Enhanced Multimodal RAG: Towards Interpretable and Accurate Radiology Report Generation",
      "abstract": "Radiology Report Generation (RRG) through Vision-Language Models (VLMs) promises to reduce documentation burden, improve reporting consistency, and accelerate clinical workflows. However, their clinical adoption remains limited by the lack of interpretability and the tendency to hallucinate findings misaligned with imaging evidence. Existing research typically treats interpretability and accuracy as separate objectives, with concept-based explainability techniques focusing primarily on transparency, while Retrieval-Augmented Generation (RAG) methods targeting factual grounding through external retrieval. We present Concept-Enhanced Multimodal RAG (CEMRAG), a unified framework that decomposes visual representations into interpretable clinical concepts and integrates them with multimodal RAG. This approach exploits enriched contextual prompts for RRG, improving both interpretability and factual accuracy. Experiments on MIMIC-CXR and IU X-Ray across multiple VLM architectures, training regimes, and retrieval configurations demonstrate consistent improvements over both conventional RAG and concept-only baselines on clinical accuracy metrics and standard NLP measures. These results challenge the assumed trade-off between interpretability and performance, showing that transparent visual concepts can enhance rather than compromise diagnostic accuracy in medical VLMs. Our modular design decomposes interpretability into visual transparency and structured language model conditioning, providing a principled pathway toward clinically trustworthy AI-assisted radiology.",
      "authors": [
        "Marco Salmè",
        "Federico Siciliano",
        "Fabrizio Silvestri",
        "Paolo Soda",
        "Rosa Sicilia",
        "Valerio Guarrasi"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-17T15:18:07Z",
      "updated": "2026-02-17T15:18:07Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15650v1",
      "abs_url": "http://arxiv.org/abs/2602.15650v1",
      "summary": "CEMRAG通过融合临床概念和多模态RAG，提升放射报告生成的可解释性和准确性。",
      "key_contributions": [
        "提出Concept-Enhanced Multimodal RAG (CEMRAG)框架",
        "将视觉表示分解为可解释的临床概念",
        "证明了透明的视觉概念可以提高诊断准确性"
      ],
      "methodology": "CEMRAG将视觉表征分解为临床概念，并将其与多模态RAG结合，通过丰富的上下文提示生成报告。",
      "tags": [
        "放射报告生成",
        "多模态学习",
        "可解释性",
        "RAG",
        "医学影像"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心是利用多模态模型生成放射报告并关注可解释性，高度相关。",
      "analyzed_at": "2026-02-18T07:01:14.102966",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15648v1",
      "title": "Guided Diffusion by Optimized Loss Functions on Relaxed Parameters for Inverse Material Design",
      "abstract": "Inverse design problems are common in engineering and materials science. The forward direction, i.e., computing output quantities from design parameters, typically requires running a numerical simulation, such as a FEM, as an intermediate step, which is an optimization problem by itself. In many scenarios, several design parameters can lead to the same or similar output values. For such cases, multi-modal probabilistic approaches are advantageous to obtain diverse solutions. A major difficulty in inverse design stems from the structure of the design space, since discrete parameters or further constraints disallow the direct use of gradient-based optimization. To tackle this problem, we propose a novel inverse design method based on diffusion models. Our approach relaxes the original design space into a continuous grid representation, where gradients can be computed by implicit differentiation in the forward simulation. A diffusion model is trained on this relaxed parameter space in order to serve as a prior for plausible relaxed designs. Parameters are sampled by guided diffusion using gradients that are propagated from an objective function specified at inference time through the differentiable simulation. A design sample is obtained by backprojection into the original parameter space. We develop our approach for a composite material design problem where the forward process is modeled as a linear FEM problem. We evaluate the performance of our approach in finding designs that match a specified bulk modulus. We demonstrate that our method can propose diverse designs within 1% relative error margin from medium to high target bulk moduli in 2D and 3D settings. We also demonstrate that the material density of generated samples can be minimized simultaneously by using a multi-objective loss function.",
      "authors": [
        "Jens U. Kreber",
        "Christian Weißenfels",
        "Joerg Stueckler"
      ],
      "categories": [
        "cs.LG",
        "cs.CE",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-17T15:15:28Z",
      "updated": "2026-02-17T15:15:28Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15648v1",
      "abs_url": "http://arxiv.org/abs/2602.15648v1",
      "summary": "提出一种基于扩散模型的逆向材料设计方法，可生成多样且高性能的材料。",
      "key_contributions": [
        "提出基于扩散模型的逆向设计方法",
        "利用隐式微分计算梯度，优化连续参数空间",
        "实现复合材料的密度最小化和模量匹配"
      ],
      "methodology": "使用扩散模型在松弛参数空间中学习先验，通过可微模拟的梯度指导采样，反投影得到原始设计。",
      "tags": [
        "逆向设计",
        "扩散模型",
        "材料设计",
        "有限元"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 6,
      "relevance_reason": "涉及参数优化和目标函数，与Agent Tuning有一定相关性。",
      "analyzed_at": "2026-02-18T07:01:15.946017",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15645v1",
      "title": "CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving",
      "abstract": "Foundation models, including vision language models, are increasingly used in automated driving to interpret scenes, recommend actions, and generate natural language explanations. However, existing evaluation methods primarily assess outcome based performance, such as safety and trajectory accuracy, without determining whether model decisions reflect human relevant considerations. As a result, it remains unclear whether explanations produced by such models correspond to genuine reason responsive decision making or merely post hoc rationalizations. This limitation is especially significant in safety critical domains because it can create false confidence. To address this gap, we propose CARE Drive, Context Aware Reasons Evaluation for Driving, a model agnostic framework for evaluating reason responsiveness in vision language models applied to automated driving. CARE Drive compares baseline and reason augmented model decisions under controlled contextual variation to assess whether human reasons causally influence decision behavior. The framework employs a two stage evaluation process. Prompt calibration ensures stable outputs. Systematic contextual perturbation then measures decision sensitivity to human reasons such as safety margins, social pressure, and efficiency constraints. We demonstrate CARE Drive in a cyclist overtaking scenario involving competing normative considerations. Results show that explicit human reasons significantly influence model decisions, improving alignment with expert recommended behavior. However, responsiveness varies across contextual factors, indicating uneven sensitivity to different types of reasons. These findings provide empirical evidence that reason responsiveness in foundation models can be systematically evaluated without modifying model parameters.",
      "authors": [
        "Lucas Elbert Suryana",
        "Farah Bierenga",
        "Sanne van Buuren",
        "Pepijn Kooij",
        "Elsefien Tulleners",
        "Federico Scari",
        "Simeon Calvert",
        "Bart van Arem",
        "Arkady Zgonnikov"
      ],
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-17T15:13:36Z",
      "updated": "2026-02-17T15:13:36Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15645v1",
      "abs_url": "http://arxiv.org/abs/2602.15645v1",
      "summary": "提出CARE Drive框架，评估自动驾驶视觉语言模型对人类理由的响应性，提高决策可解释性。",
      "key_contributions": [
        "提出CARE Drive框架，评估视觉语言模型在自动驾驶中的理由响应性",
        "通过上下文扰动测量决策对人类理由的敏感度",
        "验证了人类理由对模型决策的影响，并发现了模型对不同理由的敏感度差异"
      ],
      "methodology": "CARE Drive通过prompt校准和上下文扰动，比较基线和增强模型决策，评估模型对安全、社会压力和效率等理由的响应。",
      "tags": [
        "自动驾驶",
        "视觉语言模型",
        "理由响应性",
        "可解释性"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注多模态视觉语言模型在自动驾驶领域的应用和可解释性问题。",
      "analyzed_at": "2026-02-18T07:01:17.868313",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15635v1",
      "title": "On inferring cumulative constraints",
      "abstract": "Cumulative constraints are central in scheduling with constraint programming, yet propagation is typically performed per constraint, missing multi-resource interactions and causing severe slowdowns on some benchmarks. I present a preprocessing method for inferring additional cumulative constraints that capture such interactions without search-time probing. This approach interprets cumulative constraints as linear inequalities over occupancy vectors and generates valid inequalities by (i) discovering covers, the sets of tasks that cannot run in parallel, (ii) strengthening the cover inequalities for the discovered sets with lifting, and (iii) injecting the resulting constraints back into the scheduling problem instance. Experiments on standard RCPSP and RCPSP/max test suites show that these inferred constraints improve search performance and tighten objective bounds on favorable instances, while incurring little degradation on unfavorable ones. Additionally, these experiments discover 25 new lower bounds and five new best solutions; eight of the lower bounds are obtained directly from the inferred constraints.",
      "authors": [
        "Konstantin Sidorov"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-17T15:03:43Z",
      "updated": "2026-02-17T15:03:43Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15635v1",
      "abs_url": "http://arxiv.org/abs/2602.15635v1",
      "summary": "提出一种预处理方法，通过推断累积约束来优化约束规划调度问题。",
      "key_contributions": [
        "发现覆盖集并生成有效不等式",
        "通过提升强化覆盖不等式",
        "将生成的约束注入调度问题实例"
      ],
      "methodology": "将累积约束视为线性不等式，并通过发现覆盖集和提升来生成有效不等式。",
      "tags": [
        "约束规划",
        "调度",
        "累积约束",
        "线性不等式"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 5,
      "relevance_reason": "涉及推理和约束满足，与LLM推理有一定关联。",
      "analyzed_at": "2026-02-18T07:01:19.640637",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15620v1",
      "title": "STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens",
      "abstract": "Reinforcement Learning (RL) has significantly improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic techniques such as entropy regularization and reweighting to maintain stability. In practice, they often experience late-stage performance collapse, leading to degraded reasoning quality and unstable training. We derive that the magnitude of token-wise policy gradients in RL is negatively correlated with token probability and local policy entropy. Building on this result, we prove that training instability is driven by a tiny fraction of tokens, approximately 0.01\\%, which we term \\emph{spurious tokens}. When such tokens appear in correct responses, they contribute little to the reasoning outcome but inherit the full sequence-level reward, leading to abnormally amplified gradient updates. Motivated by this observation, we propose Spurious-Token-Aware Policy Optimization (STAPO) for large-scale model refining, which selectively masks such updates and renormalizes the loss over valid tokens. Across six mathematical reasoning benchmarks using Qwen 1.7B, 8B, and 14B base models, STAPO consistently demonstrates superior entropy stability and achieves an average performance improvement of 7.13\\% over GRPO, 20-Entropy and JustRL.",
      "authors": [
        "Shiqi Liu",
        "Zeyu He",
        "Guojian Zhan",
        "Letian Tao",
        "Zhilong Zheng",
        "Jiang Wu",
        "Yinuo Wang",
        "Yang Guan",
        "Kehua Sheng",
        "Bo Zhang",
        "Keqiang Li",
        "Jingliang Duan",
        "Shengbo Eben Li"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-17T14:46:48Z",
      "updated": "2026-02-17T14:46:48Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15620v1",
      "abs_url": "http://arxiv.org/abs/2602.15620v1",
      "summary": "STAPO通过屏蔽稀疏token梯度更新，稳定强化学习过程，提升LLM推理能力。",
      "key_contributions": [
        "识别并定义了导致训练不稳定的稀疏token",
        "提出了STAPO算法，通过屏蔽稀疏token的梯度更新来稳定训练",
        "实验证明STAPO在数学推理任务中优于现有方法"
      ],
      "methodology": "分析token概率与梯度关系，发现稀疏token导致训练崩溃，提出STAPO屏蔽稀疏token梯度并重归一化损失。",
      "tags": [
        "强化学习",
        "大型语言模型",
        "推理",
        "稳定性",
        "梯度优化"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文直接关注LLM推理能力提升，属于核心相关研究。",
      "analyzed_at": "2026-02-18T07:01:21.705540",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15600v1",
      "title": "The geometry of online conversations and the causal antecedents of conflictual discourse",
      "abstract": "This article investigates the causal antecedents of conflictual language and the geometry of interaction in online threaded conversations related to climate change. We employ three annotation dimensions, inferred through LLM prompting and averaging, to capture complementary aspects of discursive conflict (such as stance: agreement vs disagreement; tone: attacking vs respectful; and emotional versus factual framing) and use data from a threaded online forum to examine how these dimensions respond to temporal, conversational, and arborescent structural features of discussions. We show that, as suggested by the literature, longer delays between successive posts in a thread are associated with replies that are, on average, more respectful, whereas longer delays relative to the parent post are associated with slightly less disagreement but more emotional (less factual) language. Second, we characterize alignment with the local conversational environment and find strong convergence both toward the average stance, tone and emotional framing of older sibling posts replying to the same parent and toward those of the parent post itself, with parent post effects generally stronger than sibling effects. We further show that early branch-level responses condition these alignment dynamics, such that parent-child stance alignment is amplified or attenuated depending on whether a branch is initiated in agreement or disagreement with the discussion's root message. These influences are largely additive for civility-related dimensions (attacking vs respectful, disagree vs agree), whereas for emotional versus factual framing there is a significant interaction: alignment with the parent's emotionality is amplified when older siblings are similarly aligned.",
      "authors": [
        "Carlo Santagiustina",
        "Caterina Cruciani"
      ],
      "categories": [
        "cs.SI",
        "cs.AI",
        "econ.EM",
        "stat.AP"
      ],
      "primary_category": "cs.SI",
      "published": "2026-02-17T14:12:03Z",
      "updated": "2026-02-17T14:12:03Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15600v1",
      "abs_url": "http://arxiv.org/abs/2602.15600v1",
      "summary": "研究在线气候变化讨论中冲突性言论的成因和互动模式，重点分析对话结构的影响。",
      "key_contributions": [
        "利用LLM分析了在线对话中冲突性语言的多个维度（立场、语气、情感/事实框架）。",
        "揭示了时间延迟对回复质量和内容的影响。",
        "发现对话环境（父帖子和兄弟帖子）对新帖子的立场、语气和情感框架有显著影响。"
      ],
      "methodology": "使用LLM标注在线论坛数据，分析时间、对话和树状结构特征与冲突性语言维度之间的关系。",
      "tags": [
        "自然语言处理",
        "在线讨论",
        "冲突分析",
        "大型语言模型",
        "因果推断"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 6,
      "relevance_reason": "利用LLM进行推理分析，发现对话结构对冲突性言论的影响。",
      "analyzed_at": "2026-02-18T07:01:23.918747",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15593v1",
      "title": "A unified theory of feature learning in RNNs and DNNs",
      "abstract": "Recurrent and deep neural networks (RNNs/DNNs) are cornerstone architectures in machine learning. Remarkably, RNNs differ from DNNs only by weight sharing, as can be shown through unrolling in time. How does this structural similarity fit with the distinct functional properties these networks exhibit? To address this question, we here develop a unified mean-field theory for RNNs and DNNs in terms of representational kernels, describing fully trained networks in the feature learning ($μ$P) regime. This theory casts training as Bayesian inference over sequences and patterns, directly revealing the functional implications induced by the RNNs' weight sharing. In DNN-typical tasks, we identify a phase transition when the learning signal overcomes the noise due to randomness in the weights: below this threshold, RNNs and DNNs behave identically; above it, only RNNs develop correlated representations across timesteps. For sequential tasks, the RNNs' weight sharing furthermore induces an inductive bias that aids generalization by interpolating unsupervised time steps. Overall, our theory offers a way to connect architectural structure to functional biases.",
      "authors": [
        "Jan P. Bauer",
        "Kirsten Fischer",
        "Moritz Helias",
        "Agostina Palmigiano"
      ],
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-17T14:06:34Z",
      "updated": "2026-02-17T14:06:34Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15593v1",
      "abs_url": "http://arxiv.org/abs/2602.15593v1",
      "summary": "统一RNN和DNN的特征学习理论，揭示权重共享对网络功能的影响。",
      "key_contributions": [
        "建立了RNN和DNN的统一平均场理论",
        "揭示了权重共享对时序任务泛化的影响",
        "识别了RNN和DNN行为差异的相变"
      ],
      "methodology": "通过表征核将训练视为贝叶斯推断，分析权重共享对网络功能的影响。",
      "tags": [
        "RNN",
        "DNN",
        "Feature Learning",
        "Mean-Field Theory",
        "Weight Sharing"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 6,
      "relevance_reason": "理论分析有助于理解模型内部机制和推理过程。",
      "analyzed_at": "2026-02-18T07:01:25.615135",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15592v1",
      "title": "Uni-Flow: a unified autoregressive-diffusion model for complex multiscale flows",
      "abstract": "Spatiotemporal flows govern diverse phenomena across physics, biology, and engineering, yet modelling their multiscale dynamics remains a central challenge. Despite major advances in physics-informed machine learning, existing approaches struggle to simultaneously maintain long-term temporal evolution and resolve fine-scale structure across chaotic, turbulent, and physiological regimes. Here, we introduce Uni-Flow, a unified autoregressive-diffusion framework that explicitly separates temporal evolution from spatial refinement for modelling complex dynamical systems. The autoregressive component learns low-resolution latent dynamics that preserve large-scale structure and ensure stable long-horizon rollouts, while the diffusion component reconstructs high-resolution physical fields, recovering fine-scale features in a small number of denoising steps. We validate Uni-Flow across canonical benchmarks, including two-dimensional Kolmogorov flow, three-dimensional turbulent channel inflow generation with a quantum-informed autoregressive prior, and patient-specific simulations of aortic coarctation derived from high-fidelity lattice Boltzmann hemodynamic solvers. In the cardiovascular setting, Uni-Flow enables task-level faster than real-time inference of pulsatile hemodynamics, reconstructing high-resolution pressure fields over physiologically relevant time horizons in seconds rather than hours. By transforming high-fidelity hemodynamic simulation from an offline, HPC-bound process into a deployable surrogate, Uni-Flow establishes a pathway to faster-than-real-time modelling of complex multiscale flows, with broad implications for scientific machine learning in flow physics.",
      "authors": [
        "Xiao Xue",
        "Tianyue Yang",
        "Mingyang Gao",
        "Leyu Pan",
        "Maida Wang",
        "Kewei Zhu",
        "Shuo Wang",
        "Jiuling Li",
        "Marco F. P. ten Eikelder",
        "Peter V. Coveney"
      ],
      "categories": [
        "physics.flu-dyn",
        "cs.LG",
        "physics.comp-ph"
      ],
      "primary_category": "physics.flu-dyn",
      "published": "2026-02-17T14:04:37Z",
      "updated": "2026-02-17T14:04:37Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15592v1",
      "abs_url": "http://arxiv.org/abs/2602.15592v1",
      "summary": "Uni-Flow模型结合自回归和扩散模型，高效模拟复杂多尺度流体动力学。",
      "key_contributions": [
        "提出Uni-Flow模型，统一自回归和扩散模型",
        "实现了复杂流体动力学的长期稳定预测和精细结构重建",
        "在多个流体动力学benchmark上验证了Uni-Flow的有效性"
      ],
      "methodology": "采用自回归模型学习低分辨率潜在动态，保持长期演化，使用扩散模型重建高分辨率物理场，恢复精细特征。",
      "tags": [
        "流体动力学",
        "机器学习",
        "自回归模型",
        "扩散模型",
        "科学计算"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 6,
      "relevance_reason": "模型可用于设计更高效的流体控制agent，有一定的参考价值。",
      "analyzed_at": "2026-02-18T07:01:27.529555",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15580v1",
      "title": "How Vision Becomes Language: A Layer-wise Information-Theoretic Analysis of Multimodal Reasoning",
      "abstract": "When a multimodal Transformer answers a visual question, is the prediction driven by visual evidence, linguistic reasoning, or genuinely fused cross-modal computation -- and how does this structure evolve across layers? We address this question with a layer-wise framework based on Partial Information Decomposition (PID) that decomposes the predictive information at each Transformer layer into redundant, vision-unique, language-unique, and synergistic components. To make PID tractable for high-dimensional neural representations, we introduce \\emph{PID Flow}, a pipeline combining dimensionality reduction, normalizing-flow Gaussianization, and closed-form Gaussian PID estimation. Applying this framework to LLaVA-1.5-7B and LLaVA-1.6-7B across six GQA reasoning tasks, we uncover a consistent \\emph{modal transduction} pattern: visual-unique information peaks early and decays with depth, language-unique information surges in late layers to account for roughly 82\\% of the final prediction, and cross-modal synergy remains below 2\\%. This trajectory is highly stable across model variants (layer-wise correlations $>$0.96) yet strongly task-dependent, with semantic redundancy governing the detailed information fingerprint. To establish causality, we perform targeted Image$\\rightarrow$Question attention knockouts and show that disrupting the primary transduction pathway induces predictable increases in trapped visual-unique information, compensatory synergy, and total information cost -- effects that are strongest in vision-dependent tasks and weakest in high-redundancy tasks. Together, these results provide an information-theoretic, causal account of how vision becomes language in multimodal Transformers, and offer quantitative guidance for identifying architectural bottlenecks where modality-specific information is lost.",
      "authors": [
        "Hongxuan Wu",
        "Yukun Zhang",
        "Xueqing Zhou"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-17T13:49:49Z",
      "updated": "2026-02-17T13:49:49Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15580v1",
      "abs_url": "http://arxiv.org/abs/2602.15580v1",
      "summary": "论文通过信息论方法分析多模态Transformer中视觉信息如何转化为语言。",
      "key_contributions": [
        "提出了PID Flow，一种适用于高维神经表征的PID框架",
        "揭示了多模态Transformer中模态转导模式：视觉信息早期主导，语言信息后期主导",
        "通过干预实验验证了模态转导模式的因果关系"
      ],
      "methodology": "采用基于Partial Information Decomposition (PID)的层级分析框架，结合PID Flow处理高维数据，并进行干预实验验证因果关系。",
      "tags": [
        "多模态学习",
        "信息论",
        "Transformer",
        "视觉问答",
        "可解释性"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 10,
      "relevance_reason": "论文核心研究多模态Transformer，并深入分析视觉和语言信息的交互方式。",
      "analyzed_at": "2026-02-18T07:01:29.483567",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15572v1",
      "title": "Neural Network-Based Parameter Estimation of a Labour Market Agent-Based Model",
      "abstract": "Agent-based modelling (ABM) is a widespread approach to simulate complex systems. Advancements in computational processing and storage have facilitated the adoption of ABMs across many fields; however, ABMs face challenges that limit their use as decision-support tools. A significant issue is parameter estimation in large-scale ABMs, particularly due to computational constraints on exploring the parameter space. This study evaluates a state-of-the-art simulation-based inference (SBI) framework that uses neural networks (NN) for parameter estimation. This framework is applied to an established labour market ABM based on job transition networks. The ABM is initiated with synthetic datasets and the real U.S. labour market. Next, we compare the effectiveness of summary statistics derived from a list of statistical measures with that learned by an embedded NN. The results demonstrate that the NN-based approach recovers the original parameters when evaluating posterior distributions across various dataset scales and improves efficiency compared to traditional Bayesian methods.",
      "authors": [
        "M Lopes Alves",
        "Joel Dyer",
        "Doyne Farmer",
        "Michael Wooldridge",
        "Anisoara Calinescu"
      ],
      "categories": [
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-17T13:32:35Z",
      "updated": "2026-02-17T13:32:35Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15572v1",
      "abs_url": "http://arxiv.org/abs/2602.15572v1",
      "summary": "该论文使用神经网络进行劳动力市场ABM的参数估计，提高了效率。",
      "key_contributions": [
        "提出基于神经网络的ABM参数估计方法",
        "应用于劳动力市场ABM",
        "验证了方法在合成数据和真实数据上的有效性"
      ],
      "methodology": "使用基于神经网络的模拟推断框架（SBI）估计ABM参数，并与传统贝叶斯方法进行比较。",
      "tags": [
        "Agent-Based Modeling",
        "Parameter Estimation",
        "Neural Networks",
        "Labor Market"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "论文使用智能体建模，并用神经网络优化参数估计。",
      "analyzed_at": "2026-02-18T07:01:32.454137",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15571v1",
      "title": "Accelerated Predictive Coding Networks via Direct Kolen-Pollack Feedback Alignment",
      "abstract": "Predictive coding (PC) is a biologically inspired algorithm for training neural networks that relies only on local updates, allowing parallel learning across layers. However, practical implementations face two key limitations: error signals must still propagate from the output to early layers through multiple inference-phase steps, and feedback decays exponentially during this process, leading to vanishing updates in early layers. We propose direct Kolen-Pollack predictive coding (DKP-PC), which simultaneously addresses both feedback delay and exponential decay, yielding a more efficient and scalable variant of PC while preserving update locality. Leveraging direct feedback alignment and direct Kolen-Pollack algorithms, DKP-PC introduces learnable feedback connections from the output layer to all hidden layers, establishing a direct pathway for error transmission. This yields an algorithm that reduces the theoretical error propagation time complexity from O(L), with L being the network depth, to O(1), removing depth-dependent delay in error signals. Moreover, empirical results demonstrate that DKP-PC achieves performance at least comparable to, and often exceeding, that of standard PC, while offering improved latency and computational performance, supporting its potential for custom hardware-efficient implementations.",
      "authors": [
        "Davide Casnici",
        "Martin Lefebvre",
        "Justin Dauwels",
        "Charlotte Frenkel"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-17T13:29:14Z",
      "updated": "2026-02-17T13:29:14Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15571v1",
      "abs_url": "http://arxiv.org/abs/2602.15571v1",
      "summary": "提出DKP-PC算法，通过直接反馈对齐加速预测编码网络的训练，提高效率和可扩展性。",
      "key_contributions": [
        "提出DKP-PC算法，解决预测编码中的反馈延迟和指数衰减问题",
        "引入可学习的反馈连接，实现输出层到所有隐藏层的直接误差传递",
        "实验证明DKP-PC算法在性能、延迟和计算性能上优于标准PC算法"
      ],
      "methodology": "结合直接反馈对齐和Kolen-Pollack算法，构建可学习的反馈连接，实现误差信号的直接传递，降低时间复杂度。",
      "tags": [
        "预测编码",
        "反馈对齐",
        "神经网络",
        "深度学习",
        "优化"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 6,
      "relevance_reason": "该论文旨在提升神经网络推理效率，与reasoning类别有一定关联。",
      "analyzed_at": "2026-02-18T07:01:34.695846",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15568v1",
      "title": "Scenario Approach with Post-Design Certification of User-Specified Properties",
      "abstract": "The scenario approach is an established data-driven design framework that comes equipped with a powerful theory linking design complexity to generalization properties. In this approach, data are simultaneously used both for design and for certifying the design's reliability, without resorting to a separate test dataset. This paper takes a step further by guaranteeing additional properties, useful in post-design usage but not considered during the design phase. To this end, we introduce a two-level framework of appropriateness: baseline appropriateness, which guides the design process, and post-design appropriateness, which serves as a criterion for a posteriori evaluation. We provide distribution-free upper bounds on the risk of failing to meet the post-design appropriateness; these bounds are computable without using any additional test data. Under additional assumptions, lower bounds are also derived. As part of an effort to demonstrate the usefulness of the proposed methodology, the paper presents two practical examples in H2 and pole-placement problems. Moreover, a method is provided to infer comprehensive distributional knowledge of relevant performance indexes from the available dataset.",
      "authors": [
        "Algo Carè",
        "Marco C. Campi",
        "Simone Garatti"
      ],
      "categories": [
        "stat.ME",
        "cs.LG",
        "eess.SY",
        "stat.ML"
      ],
      "primary_category": "stat.ME",
      "published": "2026-02-17T13:27:11Z",
      "updated": "2026-02-17T13:27:11Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15568v1",
      "abs_url": "http://arxiv.org/abs/2602.15568v1",
      "summary": "提出一种两级框架，在设计后验证用户指定属性，无需额外测试数据。",
      "key_contributions": [
        "提出两级框架：baseline appropriateness和post-design appropriateness",
        "提供post-design appropriateness风险的分布无关上限和下限",
        "提出从可用数据集中推断性能指标分布知识的方法"
      ],
      "methodology": "在scenario approach基础上，引入两级框架进行设计和验证，并提供理论界限。",
      "tags": [
        "scenario approach",
        "data-driven design",
        "post-design certification",
        "robust optimization"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 6,
      "relevance_reason": "涉及在设计后优化和验证属性，与agent tuning有一定的关联性。",
      "analyzed_at": "2026-02-18T07:01:36.648844",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15564v1",
      "title": "Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL",
      "abstract": "Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and long-tail scenarios. Instead of requiring users to select suitable methods through extensive experimentation, we attempt to enable systems to adaptively construct workflows at inference time. Through theoretical and empirical analysis, we demonstrate that optimal dynamic policies consistently outperform the best static workflow, with performance gains fundamentally driven by heterogeneity across candidate workflows. Motivated by this, we propose SquRL, a reinforcement learning framework that enhances LLMs' reasoning capability in adaptive workflow construction. We design a rule-based reward function and introduce two effective training mechanisms: dynamic actor masking to encourage broader exploration, and pseudo rewards to improve training efficiency. Experiments on widely-used Text-to-SQL benchmarks demonstrate that dynamic workflow construction consistently outperforms the best static workflow methods, with especially pronounced gains on complex and out-of-distribution queries. The codes are available at https://github.com/Satissss/SquRL",
      "authors": [
        "Yihan Wang",
        "Peiyu Liu",
        "Runyu Chen",
        "Wei Xu"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-17T13:24:56Z",
      "updated": "2026-02-17T13:24:56Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15564v1",
      "abs_url": "http://arxiv.org/abs/2602.15564v1",
      "summary": "提出SquRL框架，利用强化学习动态构建Text-to-SQL工作流，提升复杂和分布外查询性能。",
      "key_contributions": [
        "提出基于强化学习的动态工作流构建框架SquRL",
        "设计了规则奖励函数和动态actor masking与伪奖励机制，提升训练效率",
        "证明动态工作流优于静态工作流，尤其是在复杂和分布外查询上"
      ],
      "methodology": "使用强化学习，通过规则奖励函数和actor masking等技术，训练LLM构建自适应的Text-to-SQL工作流。",
      "tags": [
        "Text-to-SQL",
        "Reinforcement Learning",
        "Dynamic Workflow"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "使用了RL进行推理，动态调整workflow来解决Text-to-SQL问题，高度相关。",
      "analyzed_at": "2026-02-18T07:01:38.682596",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15563v1",
      "title": "1-Bit Wonder: Improving QAT Performance in the Low-Bit Regime through K-Means Quantization",
      "abstract": "Quantization-aware training (QAT) is an effective method to drastically reduce the memory footprint of LLMs while keeping performance degradation at an acceptable level. However, the optimal choice of quantization format and bit-width presents a challenge in practice. The full design space of quantization is not fully explored in the context of QAT, and the precise trade-off between quantization and downstream performance is poorly understood, as comparisons often rely solely on perplexity-based evaluations. In this work, we address these shortcomings with an empirical study of QAT in the low-bit regime. We show that k-means based weight quantization outperforms integer formats and can be implemented efficiently on standard hardware. Furthermore, we find that, under a fixed inference memory budget, the best performance on generative downstream tasks is achieved with $1$-bit quantized weights.",
      "authors": [
        "Sohir Maskey",
        "Constantin Eichenberg",
        "Johannes Messner",
        "Douglas Orr"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-17T13:23:26Z",
      "updated": "2026-02-17T13:23:26Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15563v1",
      "abs_url": "http://arxiv.org/abs/2602.15563v1",
      "summary": "该论文研究了低比特量化感知训练，发现K-Means量化在1比特时性能最佳。",
      "key_contributions": [
        "证明K-Means量化优于整数格式",
        "发现在固定内存预算下，1比特量化权重在生成任务上表现最佳",
        "对低比特量化下的QAT进行了实证研究"
      ],
      "methodology": "通过实验比较不同量化格式和比特宽度下的QAT性能，并在生成下游任务上评估模型表现。",
      "tags": [
        "量化",
        "QAT",
        "低比特",
        "K-Means",
        "LLM"
      ],
      "assigned_category": "memory",
      "relevance_score": 8,
      "relevance_reason": "论文探讨了如何通过量化减少LLM的内存占用，同时保持性能。",
      "analyzed_at": "2026-02-18T07:01:40.656976",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15556v1",
      "title": "Revealing and Enhancing Core Visual Regions: Harnessing Internal Attention Dynamics for Hallucination Mitigation in LVLMs",
      "abstract": "LVLMs have achieved strong multimodal reasoning capabilities but remain prone to hallucinations, producing outputs inconsistent with visual inputs or user instructions. Existing training-free methods, including contrastive decoding and auxiliary expert models, which incur several times more computational overhead and may introduce potential interference, as well as static internal signal enhancement, are often vulnerable to the attention sink phenomenon. We find that internal Positive Attention Dynamics (PAD) in LVLMs naturally reveal semantically core visual regions under the distortions of attention sinks. Based on this, we propose Positive Attention Dynamics Enhancement (PADE), a training-free attention intervention that constructs a PAD map to identify semantically core visual regions, applies per-head Median Absolute Deviation Scaling to adaptively control the intervention strength, and leverages System-Token Compensation to maintain attention to complex user instructions and support long-term output consistency. Experiments on multiple LVLMs and benchmarks show that PADE improves visual grounding and reduces hallucinations, validating the effectiveness of leveraging internal attention dynamics for reliable multimodal reasoning.",
      "authors": [
        "Guangtao Lyu",
        "Qi Liu",
        "Chenghao Xu",
        "Jiexi Yan",
        "Muli Yang",
        "Xueting Li",
        "Fen Fang",
        "Cheng Deng"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-17T13:08:06Z",
      "updated": "2026-02-17T13:08:06Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15556v1",
      "abs_url": "http://arxiv.org/abs/2602.15556v1",
      "summary": "提出PADE方法，利用LVLM内部注意力动态增强视觉核心区域，缓解幻觉问题。",
      "key_contributions": [
        "发现LVLM中正向注意力动态(PAD)能揭示核心视觉区域",
        "提出Positive Attention Dynamics Enhancement (PADE)干预方法",
        "引入Median Absolute Deviation Scaling自适应控制干预强度",
        "System-Token Compensation维持指令理解和输出一致性"
      ],
      "methodology": "通过PAD识别核心视觉区域，利用MAD Scaling控制干预，使用System-Token Compensation维持指令。",
      "tags": [
        "LVLM",
        "Hallucination Mitigation",
        "Attention Dynamics",
        "Multimodal Reasoning"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文直接关注LVLM的幻觉问题，并提出基于视觉注意力的解决方案，核心相关。",
      "analyzed_at": "2026-02-18T07:01:43.174096",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15549v1",
      "title": "VLM-DEWM: Dynamic External World Model for Verifiable and Resilient Vision-Language Planning in Manufacturing",
      "abstract": "Vision-language model (VLM) shows promise for high-level planning in smart manufacturing, yet their deployment in dynamic workcells faces two critical challenges: (1) stateless operation, they cannot persistently track out-of-view states, causing world-state drift; and (2) opaque reasoning, failures are difficult to diagnose, leading to costly blind retries. This paper presents VLM-DEWM, a cognitive architecture that decouples VLM reasoning from world-state management through a persistent, queryable Dynamic External World Model (DEWM). Each VLM decision is structured into an Externalizable Reasoning Trace (ERT), comprising action proposal, world belief, and causal assumption, which is validated against DEWM before execution. When failures occur, discrepancy analysis between predicted and observed states enables targeted recovery instead of global replanning. We evaluate VLM-DEWM on multi-station assembly, large-scale facility exploration, and real-robot recovery under induced failures. Compared to baseline memory-augmented VLM systems, VLM DEWM improves state-tracking accuracy from 56% to 93%, increases recovery success rate from below 5% to 95%, and significantly reduces computational overhead through structured memory. These results establish VLM-DEWM as a verifiable and resilient solution for long-horizon robotic operations in dynamic manufacturing environments.",
      "authors": [
        "Guoqin Tang",
        "Qingxuan Jia",
        "Gang Chen",
        "Tong Li",
        "Zeyuan Huang",
        "Zihang Lv",
        "Ning Ji"
      ],
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "published": "2026-02-17T12:54:18Z",
      "updated": "2026-02-17T12:54:18Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15549v1",
      "abs_url": "http://arxiv.org/abs/2602.15549v1",
      "summary": "VLM-DEWM通过动态外部世界模型提升VLM在动态制造环境中的规划能力。",
      "key_contributions": [
        "提出了VLM-DEWM认知架构",
        "设计了可外部化的推理轨迹ERT",
        "实现了基于DEWM的故障诊断和恢复"
      ],
      "methodology": "构建动态外部世界模型DEWM，VLM决策分解为ERT，通过DEWM进行验证和故障诊断，实现鲁棒规划。",
      "tags": [
        "VLM",
        "智能制造",
        "机器人",
        "动态环境",
        "世界模型"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于构建智能体在动态环境中进行规划和推理，并具有故障恢复能力。",
      "analyzed_at": "2026-02-18T07:01:45.297241",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15547v1",
      "title": "jina-embeddings-v5-text: Task-Targeted Embedding Distillation",
      "abstract": "Text embedding models are widely used for semantic similarity tasks, including information retrieval, clustering, and classification. General-purpose models are typically trained with single- or multi-stage processes using contrastive loss functions. We introduce a novel training regimen that combines model distillation techniques with task-specific contrastive loss to produce compact, high-performance embedding models. Our findings suggest that this approach is more effective for training small models than purely contrastive or distillation-based training paradigms alone. Benchmark scores for the resulting models, jina-embeddings-v5-text-small and jina-embeddings-v5-text-nano, exceed or match the state-of-the-art for models of similar size. jina-embeddings-v5-text models additionally support long texts (up to 32k tokens) in many languages, and generate embeddings that remain robust under truncation and binary quantization. Model weights are publicly available, hopefully inspiring further advances in embedding model development.",
      "authors": [
        "Mohammad Kalim Akram",
        "Saba Sturua",
        "Nastia Havriushenko",
        "Quentin Herreros",
        "Michael Günther",
        "Maximilian Werk",
        "Han Xiao"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-17T12:50:50Z",
      "updated": "2026-02-17T12:50:50Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15547v1",
      "abs_url": "http://arxiv.org/abs/2602.15547v1",
      "summary": "提出一种结合模型蒸馏和任务特定对比损失的训练方法，提升小型嵌入模型的性能。",
      "key_contributions": [
        "提出新的训练方法，结合模型蒸馏和任务特定对比损失",
        "训练出高性能的小型嵌入模型 jina-embeddings-v5-text-small 和 jina-embeddings-v5-text-nano",
        "支持长文本和多语言，并具有鲁棒性"
      ],
      "methodology": "结合模型蒸馏和任务特定对比损失函数进行训练，优化小型嵌入模型。",
      "tags": [
        "文本嵌入",
        "模型蒸馏",
        "对比学习",
        "语义相似度"
      ],
      "assigned_category": "memory",
      "relevance_score": 7,
      "relevance_reason": "嵌入模型用于信息检索，RAG的核心组成部分。",
      "analyzed_at": "2026-02-18T07:01:48.047867",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15546v1",
      "title": "CEPAE: Conditional Entropy-Penalized Autoencoders for Time Series Counterfactuals",
      "abstract": "The ability to accurately perform counterfactual inference on time series is crucial for decision-making in fields like finance, healthcare, and marketing, as it allows us to understand the impact of events or treatments on outcomes over time. In this paper, we introduce a new counterfactual inference approach tailored to time series data impacted by market events, which is motivated by an industrial application. Utilizing the abduction-action-prediction procedure and the Structural Causal Model framework, we first adapt methods based on variational autoencoders and adversarial autoencoders, both previously used in counterfactual literature although not in time series settings. Then, we present the Conditional Entropy-Penalized Autoencoder (CEPAE), a novel autoencoder-based approach for counterfactual inference, which employs an entropy penalization loss over the latent space to encourage disentangled data representations. We validate our approach both theoretically and experimentally on synthetic, semi-synthetic, and real-world datasets, showing that CEPAE generally outperforms the other approaches in the evaluated metrics.",
      "authors": [
        "Tomàs Garriga",
        "Gerard Sanz",
        "Eduard Serrahima de Cambra",
        "Axel Brando"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-17T12:49:44Z",
      "updated": "2026-02-17T12:49:44Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15546v1",
      "abs_url": "http://arxiv.org/abs/2602.15546v1",
      "summary": "提出了基于条件熵惩罚自编码器(CEPAE)的时间序列反事实推断方法。",
      "key_contributions": [
        "提出了CEPAE模型，使用熵惩罚鼓励解耦数据表示",
        "将自编码器应用于时间序列反事实推断",
        "在合成、半合成和真实数据集上验证了CEPAE的有效性"
      ],
      "methodology": "基于结构因果模型框架，利用诱导-行动-预测流程，结合变分和对抗自编码器，提出CEPAE，并使用熵惩罚损失。",
      "tags": [
        "时间序列",
        "反事实推断",
        "自编码器",
        "因果推断",
        "熵惩罚"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 6,
      "relevance_reason": "涉及推理，但更偏向于时间序列建模和应用。",
      "analyzed_at": "2026-02-18T07:01:50.112702",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15521v1",
      "title": "ExpertWeaver: Unlocking the Inherent MoE in Dense LLMs with GLU Activation Patterns",
      "abstract": "Mixture-of-Experts (MoE) effectively scales model capacity while preserving computational efficiency through sparse expert activation. However, training high-quality MoEs from scratch is prohibitively expensive. A promising alternative is to convert pretrained dense models into sparse MoEs. Existing dense-to-MoE methods fall into two categories: \\textbf{dynamic structural pruning} that converts dense models into MoE architectures with moderate sparsity to balance performance and inference efficiency, and \\textbf{downcycling} approaches that use pretrained dense models to initialize highly sparse MoE architectures. However, existing methods break the intrinsic activation patterns within dense models, leading to suboptimal expert construction. In this work, we argue that the Gated Linear Unit (GLU) mechanism provides a natural blueprint for dense-to-MoE conversion. We show that the fine-grained neural-wise activation patterns of GLU reveal a coarse-grained structure, uncovering an inherent MoE architecture composed of consistently activated universal neurons and dynamically activated specialized neurons. Leveraging this discovery, we introduce ExpertWeaver, a training-free framework that partitions neurons according to their activation patterns and constructs shared experts and specialized routed experts with layer-adaptive configurations. Our experiments demonstrate that ExpertWeaver significantly outperforms existing methods, both as a training-free dynamic structural pruning technique and as a downcycling strategy for superior MoE initialization.",
      "authors": [
        "Ziyu Zhao",
        "Tong Zhu",
        "Zhi Zhang",
        "Tiantian Fan",
        "Jinluan Yang",
        "Kun Kuang",
        "Zhongyu Wei",
        "Fei Wu",
        "Yu Cheng"
      ],
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-17T11:50:58Z",
      "updated": "2026-02-17T11:50:58Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15521v1",
      "abs_url": "http://arxiv.org/abs/2602.15521v1",
      "summary": "ExpertWeaver利用GLU激活模式将稠密LLM转化为高效MoE，无需训练且性能优于现有方法。",
      "key_contributions": [
        "提出ExpertWeaver框架，一种无需训练的稠密模型到MoE的转换方法",
        "发现GLU激活模式揭示了LLM中固有的MoE结构",
        "在动态结构剪枝和MoE初始化方面优于现有方法"
      ],
      "methodology": "ExpertWeaver根据神经元的激活模式划分神经元，构建共享专家和专用路由专家，实现层自适应配置的MoE结构。",
      "tags": [
        "Mixture-of-Experts",
        "MoE",
        "Gated Linear Unit",
        "GLU",
        "Dense-to-Sparse"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "研究MoE在LLM中的应用，旨在提升推理效率，高度相关。",
      "analyzed_at": "2026-02-18T07:01:52.685425",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15516v1",
      "title": "Semantic-Guided 3D Gaussian Splatting for Transient Object Removal",
      "abstract": "Transient objects in casual multi-view captures cause ghosting artifacts in 3D Gaussian Splatting (3DGS) reconstruction. Existing solutions relied on scene decomposition at significant memory cost or on motion-based heuristics that were vulnerable to parallax ambiguity. A semantic filtering framework was proposed for category-aware transient removal using vision-language models. CLIP similarity scores between rendered views and distractor text prompts were accumulated per-Gaussian across training iterations. Gaussians exceeding a calibrated threshold underwent opacity regularization and periodic pruning. Unlike motion-based approaches, semantic classification resolved parallax ambiguity by identifying object categories independently of motion patterns. Experiments on the RobustNeRF benchmark demonstrated consistent improvement in reconstruction quality over vanilla 3DGS across four sequences, while maintaining minimal memory overhead and real-time rendering performance. Threshold calibration and comparisons with baselines validated semantic guidance as a practical strategy for transient removal in scenarios with predictable distractor categories.",
      "authors": [
        "Aditi Prabakaran",
        "Priyesh Shukla"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-17T11:44:16Z",
      "updated": "2026-02-17T11:44:16Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15516v1",
      "abs_url": "http://arxiv.org/abs/2602.15516v1",
      "summary": "提出语义引导的3D高斯溅射方法，有效去除多视角重建中的瞬态物体，提升重建质量。",
      "key_contributions": [
        "提出基于视觉-语言模型的语义过滤框架",
        "利用CLIP相似度进行高斯 opacity 正则化和剪枝",
        "解决了基于运动方法中的视差歧义问题"
      ],
      "methodology": "利用CLIP计算渲染视图与干扰文本prompt的相似度，根据阈值调整高斯 opacity并进行剪枝。",
      "tags": [
        "3D Gaussian Splatting",
        "Transient Object Removal",
        "Semantic Filtering",
        "Vision-Language Model",
        "CLIP"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 8,
      "relevance_reason": "使用了vision-language模型（CLIP）来解决3D重建问题，属于多模态学习范畴。",
      "analyzed_at": "2026-02-18T07:01:54.773435",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15513v1",
      "title": "Improving MLLMs in Embodied Exploration and Question Answering with Human-Inspired Memory Modeling",
      "abstract": "Deploying Multimodal Large Language Models as the brain of embodied agents remains challenging, particularly under long-horizon observations and limited context budgets. Existing memory assisted methods often rely on textual summaries, which discard rich visual and spatial details and remain brittle in non-stationary environments. In this work, we propose a non-parametric memory framework that explicitly disentangles episodic and semantic memory for embodied exploration and question answering. Our retrieval-first, reasoning-assisted paradigm recalls episodic experiences via semantic similarity and verifies them through visual reasoning, enabling robust reuse of past observations without rigid geometric alignment. In parallel, we introduce a program-style rule extraction mechanism that converts experiences into structured, reusable semantic memory, facilitating cross-environment generalization. Extensive experiments demonstrate state-of-the-art performance on embodied question answering and exploration benchmarks, yielding a 7.3% gain in LLM-Match and an 11.4% gain in LLM MatchXSPL on A-EQA, as well as +7.7% success rate and +6.8% SPL on GOAT-Bench. Analyses reveal that our episodic memory primarily improves exploration efficiency, while semantic memory strengthens complex reasoning of embodied agents.",
      "authors": [
        "Ji Li",
        "Jing Xia",
        "Mingyi Li",
        "Shiyan Hu"
      ],
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "published": "2026-02-17T11:41:28Z",
      "updated": "2026-02-17T11:41:28Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15513v1",
      "abs_url": "http://arxiv.org/abs/2602.15513v1",
      "summary": "提出一种结合情景记忆和语义记忆的非参数记忆框架，提升具身智能体在探索和问答任务中的性能。",
      "key_contributions": [
        "提出非参数情景记忆和语义记忆框架",
        "检索优先、推理辅助的情景记忆机制",
        "程序式规则提取的语义记忆机制"
      ],
      "methodology": "使用语义相似度检索情景记忆，通过视觉推理验证；将经验转换为结构化的语义记忆，实现跨环境泛化。",
      "tags": [
        "embodied AI",
        "memory",
        "multimodal",
        "question answering",
        "exploration"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心解决具身智能体中记忆和推理的问题，与Agent类别高度相关。",
      "analyzed_at": "2026-02-18T07:01:56.549581",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15481v1",
      "title": "LLM-as-Judge on a Budget",
      "abstract": "LLM-as-a-judge has emerged as a cornerstone technique for evaluating large language models by leveraging LLM reasoning to score prompt-response pairs. Since LLM judgments are stochastic, practitioners commonly query each pair multiple times to estimate mean scores accurately. This raises a critical challenge: given a fixed computational budget $B$, how to optimally allocate queries across $K$ prompt-response pairs to minimize estimation error? % We present a principled variance-adaptive approach leveraging multi-armed bandit theory and concentration inequalities. Our method dynamically allocates queries based on estimated score variances, concentrating resources where uncertainty is highest. Further, our algorithm is shown to achieve a worst-case score-estimation error of $\\tilde{O}\\left(\\sqrt{\\frac{\\sum_{i=1}^K σ_i^2}{B}}\\right)$, $σ_i^2$ being the unknown score variance for pair $i \\in [K]$ with near-optimal budget allocation. % Experiments on \\emph{Summarize-From-Feedback} and \\emph{HelpSteer2} demonstrate that our method significantly outperforms uniform allocation, reducing worst-case estimation error while maintaining identical budgets. Our work establishes a theoretical foundation for efficient LLM evaluation with practical implications for AI safety, model alignment, and automated assessment at scale.",
      "authors": [
        "Aadirupa Saha",
        "Aniket Wagde",
        "Branislav Kveton"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-17T10:35:41Z",
      "updated": "2026-02-17T10:35:41Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15481v1",
      "abs_url": "http://arxiv.org/abs/2602.15481v1",
      "summary": "提出一种基于多臂老虎机理论的LLM评估优化方法，动态分配计算资源以降低评估误差。",
      "key_contributions": [
        "提出一种基于方差自适应的多臂老虎机LLM评估方法。",
        "证明了该方法在最坏情况下的误差界。",
        "实验证明该方法优于均匀分配。"
      ],
      "methodology": "利用多臂老虎机理论和集中不等式，根据估计的分数方差动态分配查询资源，重点关注不确定性最高的prompt-response对。",
      "tags": [
        "LLM evaluation",
        "Multi-armed bandit",
        "Variance reduction",
        "AI safety"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "核心关注LLM评估中的推理能力和优化策略。",
      "analyzed_at": "2026-02-18T07:02:01.094633",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15461v1",
      "title": "Emergent Morphing Attack Detection in Open Multi-modal Large Language Models",
      "abstract": "Face morphing attacks threaten biometric verification, yet most morphing attack detection (MAD) systems require task-specific training and generalize poorly to unseen attack types. Meanwhile, open-source multimodal large language models (MLLMs) have demonstrated strong visual-linguistic reasoning, but their potential in biometric forensics remains underexplored. In this paper, we present the first systematic zero-shot evaluation of open-source MLLMs for single-image MAD, using publicly available weights and a standardized, reproducible protocol. Across diverse morphing techniques, many MLLMs show non-trivial discriminative ability without any fine-tuning or domain adaptation, and LLaVA1.6-Mistral-7B achieves state-of-the-art performance, surpassing highly competitive task-specific MAD baselines by at least 23% in terms of equal error rate (EER). The results indicate that multimodal pretraining can implicitly encode fine-grained facial inconsistencies indicative of morphing artifacts, enabling zero-shot forensic sensitivity. Our findings position open-source MLLMs as reproducible, interpretable, and competitive foundations for biometric security and forensic image analysis. This emergent capability also highlights new opportunities to develop state-of-the-art MAD systems through targeted fine-tuning or lightweight adaptation, further improving accuracy and efficiency while preserving interpretability. To support future research, all code and evaluation protocols will be released upon publication.",
      "authors": [
        "Marija Ivanovska",
        "Vitomir Štruc"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-17T09:56:33Z",
      "updated": "2026-02-17T09:56:33Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15461v1",
      "abs_url": "http://arxiv.org/abs/2602.15461v1",
      "summary": "首次系统评估开源多模态大语言模型在人脸变形攻击检测中的零样本能力，效果显著。",
      "key_contributions": [
        "首次系统性评估开源MLLM在人脸变形攻击检测中的零样本性能",
        "证明了MLLM在无需微调的情况下具备检测人脸变形攻击的能力",
        "LLaVA1.6-Mistral-7B 在此任务中表现超越了特定任务的基线模型"
      ],
      "methodology": "使用公开权重和标准化协议，对多种变形技术进行单图MAD的零样本评估。",
      "tags": [
        "Multimodal Learning",
        "Face Morphing Attack Detection",
        "Zero-Shot Learning"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于评估MLLM在特定视觉任务上的能力，属于多模态学习的核心研究内容。",
      "analyzed_at": "2026-02-18T07:02:04.066576",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15460v1",
      "title": "On the Out-of-Distribution Generalization of Reasoning in Multimodal LLMs for Simple Visual Planning Tasks",
      "abstract": "Integrating reasoning in large language models and large vision-language models has recently led to significant improvement of their capabilities. However, the generalization of reasoning models is still vaguely defined and poorly understood. In this work, we present an evaluation framework to rigorously examine how well chain-of-thought (CoT) approaches generalize on a simple planning task. Specifically, we consider a grid-based navigation task in which a model is provided with a map and must output a sequence of moves that guides a player from a start position to a goal while avoiding obstacles. The versatility of the task and its data allows us to fine-tune model variants using different input representations (visual and textual) and CoT reasoning strategies, and systematically evaluate them under both in-distribution (ID) and out-of-distribution (OOD) test conditions. Our experiments show that, while CoT reasoning improves in-distribution generalization across all representations, out-of-distribution generalization (e.g., to larger maps) remains very limited in most cases when controlling for trivial matches with the ID data. Surprisingly, we find that reasoning traces which combine multiple text formats yield the best (and non-trivial) OOD generalization. Finally, purely text-based models consistently outperform those utilizing image-based inputs, including a recently proposed approach relying on latent space reasoning.",
      "authors": [
        "Yannic Neuhaus",
        "Nicolas Flammarion",
        "Matthias Hein",
        "Francesco Croce"
      ],
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-17T09:51:40Z",
      "updated": "2026-02-17T09:51:40Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15460v1",
      "abs_url": "http://arxiv.org/abs/2602.15460v1",
      "summary": "该论文研究了多模态LLM在视觉规划任务中链式思考(CoT)推理的泛化能力，发现文本模型优于图像模型。",
      "key_contributions": [
        "提出了评估多模态LLM推理泛化能力的框架。",
        "揭示了CoT推理在不同输入表示下的OOD泛化能力差异。",
        "发现结合多种文本格式的推理轨迹能实现最佳OOD泛化。"
      ],
      "methodology": "使用基于网格的导航任务，通过调整不同输入表示和CoT策略的模型变体，在ID和OOD条件下评估其性能。",
      "tags": [
        "Multimodal LLM",
        "Reasoning",
        "Out-of-Distribution Generalization",
        "Visual Planning"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "论文聚焦于LLM的推理能力，并探讨了OOD泛化这一关键问题。",
      "analyzed_at": "2026-02-18T07:02:06.143430",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15449v1",
      "title": "TAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models",
      "abstract": "Large Language Models (LLMs) are changing the coding paradigm, known as vibe coding, yet synthesizing algorithmically sophisticated and robust code still remains a critical challenge. Incentivizing the deep reasoning capabilities of LLMs is essential to overcoming this hurdle. Reinforcement Fine-Tuning (RFT) has emerged as a promising strategy to address this need. However, most existing approaches overlook the heterogeneous difficulty and granularity inherent in test cases, leading to an imbalanced distribution of reward signals and consequently biased gradient updates during training. To address this, we propose Test-driven and cApability-adaptive cuRriculum reinfOrcement fine-Tuning (TAROT). TAROT systematically constructs, for each problem, a four-tier test suite (basic, intermediate, complex, edge), providing a controlled difficulty landscape for curriculum design and evaluation. Crucially, TAROT decouples curriculum progression from raw reward scores, enabling capability-conditioned evaluation and principled selection from a portfolio of curriculum policies rather than incidental test-case difficulty composition. This design fosters stable optimization and more efficient competency acquisition. Extensive experimental results reveal that the optimal curriculum for RFT in code generation is closely tied to a model's inherent capability, with less capable models achieving greater gains with an easy-to-hard progression, whereas more competent models excel under a hard-first curriculum. TAROT provides a reproducible method that adaptively tailors curriculum design to a model's capability, thereby consistently improving the functional correctness and robustness of the generated code. All code and data are released to foster reproducibility and advance community research at https://github.com/deep-diver/TAROT.",
      "authors": [
        "Chansung Park",
        "Juyong Jiang",
        "Fan Wang",
        "Sayak Paul",
        "Jiasi Shen",
        "Jing Tang",
        "Jianguo Li"
      ],
      "categories": [
        "cs.CL",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-17T09:29:18Z",
      "updated": "2026-02-17T09:29:18Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15449v1",
      "abs_url": "http://arxiv.org/abs/2602.15449v1",
      "summary": "TAROT提出了一种能力自适应的课程强化微调方法，提升LLM的代码生成能力。",
      "key_contributions": [
        "提出TAROT框架，利用多层级测试集和能力自适应的课程学习",
        "解耦课程进度和原始奖励，实现能力条件评估和策略选择",
        "实验证明了课程与模型能力的相关性，并提升了代码质量"
      ],
      "methodology": "构建多层级测试集，设计能力自适应的课程策略，使用强化学习微调LLM。",
      "tags": [
        "代码生成",
        "强化学习",
        "课程学习",
        "LLM微调"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "提升LLM解决复杂算法问题的推理能力，属于推理相关研究。",
      "analyzed_at": "2026-02-18T07:02:09.907819",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15423v1",
      "title": "GaiaFlow: Semantic-Guided Diffusion Tuning for Carbon-Frugal Search",
      "abstract": "As the burgeoning power requirements of sophisticated neural architectures escalate, the information retrieval community has recognized ecological sustainability as a pivotal priority that necessitates a fundamental paradigm shift in model design. While contemporary neural rankers have attained unprecedented accuracy, the substantial environmental externalities associated with their computational intensity often remain overlooked in large-scale deployments. We present GaiaFlow, an innovative framework engineered to facilitate carbon-frugal search by operationalizing semantic-guided diffusion tuning. Our methodology orchestrates the convergence of retrieval-guided Langevin dynamics and a hardware-independent performance modeling strategy to optimize the trade-off between search precision and environmental preservation. By incorporating adaptive early exit protocols and precision-aware quantized inference, the proposed architecture significantly mitigates operational carbon footprints while maintaining robust retrieval quality across heterogeneous computing infrastructures. Extensive experimental evaluations demonstrate that GaiaFlow achieves a superior equilibrium between effectiveness and energy efficiency, offering a scalable and sustainable pathway for next-generation neural search systems.",
      "authors": [
        "Rong Fu",
        "Wenxin Zhang",
        "Jia Yee Tan",
        "Chunlei Meng",
        "Shuo Yin",
        "Xiaowen Ma",
        "Wangyu Wu",
        "Muge Qi",
        "Guangzhen Yao",
        "Zhaolu Kang",
        "Zeli Su",
        "Simon Fong"
      ],
      "categories": [
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "published": "2026-02-17T08:35:11Z",
      "updated": "2026-02-17T08:35:11Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15423v1",
      "abs_url": "http://arxiv.org/abs/2602.15423v1",
      "summary": "GaiaFlow通过语义引导扩散调优实现碳节约型搜索，兼顾精度与环境效益。",
      "key_contributions": [
        "提出GaiaFlow框架，优化搜索精度和环境效益的平衡",
        "利用检索引导的Langevin动力学和硬件无关的性能建模策略",
        "采用自适应提前退出协议和精度感知量化推理，降低碳足迹"
      ],
      "methodology": "结合检索引导的Langevin动力学和硬件无关性能建模，进行语义引导扩散调优。",
      "tags": [
        "信息检索",
        "碳节约",
        "扩散模型",
        "节能优化"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 7,
      "relevance_reason": "涉及模型优化以提高效率，与Agent Tuning概念相关。",
      "analyzed_at": "2026-02-18T07:02:11.792409",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15407v1",
      "title": "Fairness over Equality: Correcting Social Incentives in Asymmetric Sequential Social Dilemmas",
      "abstract": "Sequential Social Dilemmas (SSDs) provide a key framework for studying how cooperation emerges when individual incentives conflict with collective welfare. In Multi-Agent Reinforcement Learning, these problems are often addressed by incorporating intrinsic drives that encourage prosocial or fair behavior. However, most existing methods assume that agents face identical incentives in the dilemma and require continuous access to global information about other agents to assess fairness. In this work, we introduce asymmetric variants of well-known SSD environments and examine how natural differences between agents influence cooperation dynamics. Our findings reveal that existing fairness-based methods struggle to adapt under asymmetric conditions by enforcing raw equality that wrongfully incentivize defection. To address this, we propose three modifications: (i) redefining fairness by accounting for agents' reward ranges, (ii) introducing an agent-based weighting mechanism to better handle inherent asymmetries, and (iii) localizing social feedback to make the methods effective under partial observability without requiring global information sharing. Experimental results show that in asymmetric scenarios, our method fosters faster emergence of cooperative policies compared to existing approaches, without sacrificing scalability or practicality.",
      "authors": [
        "Alper Demir",
        "Hüseyin Aydın",
        "Kale-ab Abebe Tessera",
        "David Abel",
        "Stefano V. Albrecht"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-17T07:31:20Z",
      "updated": "2026-02-17T07:31:20Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15407v1",
      "abs_url": "http://arxiv.org/abs/2602.15407v1",
      "summary": "针对非对称社会困境，论文提出了一种考虑奖励范围和局部反馈的公平性学习方法。",
      "key_contributions": [
        "提出了针对非对称社会困境的公平性定义",
        "引入了基于agent的权重机制来处理不对称性",
        "实现了局部社交反馈，无需全局信息共享"
      ],
      "methodology": "通过改进奖励函数和引入权重机制，在多智能体强化学习框架下训练智能体。",
      "tags": [
        "多智能体强化学习",
        "公平性",
        "社会困境",
        "非对称环境"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "研究了多智能体环境下的合作和公平性问题，与Agent领域高度相关。",
      "analyzed_at": "2026-02-18T07:02:14.208828",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15403v1",
      "title": "Common Belief Revisited",
      "abstract": "Contrary to common belief, common belief is not KD4.   If individual belief is KD45, common belief does indeed lose the 5 property and keep the D and 4 properties -- and it has none of the other commonly considered properties of knowledge and belief. But it has another property: $C(Cφ\\rightarrow φ)$ -- corresponding to so-called shift-reflexivity (reflexivity one step ahead). This observation begs the question:   is KD4 extended with this axiom a complete characterisation of common belief in the KD45 case? If not, what \\emph{is} the logic of common belief? In this paper we show that the answer to the first question is ``no'': there is one additional axiom, and, furthermore, it relies on the number of agents. We show that the result is a complete characterisation of common belief, settling the open problem.",
      "authors": [
        "Thomas Ågotnes"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-17T07:22:31Z",
      "updated": "2026-02-17T07:22:31Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15403v1",
      "abs_url": "http://arxiv.org/abs/2602.15403v1",
      "summary": "论文研究了在KD45个体信念下，共同信念的逻辑刻画问题，并给出了完备的公理化描述。",
      "key_contributions": [
        "证明了KD4加上shift-reflexivity公理不足以刻画共同信念",
        "发现并证明了一个额外的公理依赖于agent数量",
        "提供了共同信念的完备公理化描述"
      ],
      "methodology": "通过逻辑推理和证明，扩展现有的逻辑系统，并最终给出了完备性证明。",
      "tags": [
        "共同信念",
        "逻辑",
        "知识表示",
        "公理化系统",
        "agent"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "研究LLM推理的逻辑基础，对理解agent间的协作和决策有借鉴意义。",
      "analyzed_at": "2026-02-18T07:02:17.322453",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.15397v1",
      "title": "ActionCodec: What Makes for Good Action Tokenizers",
      "abstract": "Vision-Language-Action (VLA) models leveraging the native autoregressive paradigm of Vision-Language Models (VLMs) have demonstrated superior instruction-following and training efficiency. Central to this paradigm is action tokenization, yet its design has primarily focused on reconstruction fidelity, failing to address its direct impact on VLA optimization. Consequently, the fundamental question of \\textit{what makes for good action tokenizers} remains unanswered. In this paper, we bridge this gap by establishing design principles specifically from the perspective of VLA optimization. We identify a set of best practices based on information-theoretic insights, including maximized temporal token overlap, minimized vocabulary redundancy, enhanced multimodal mutual information, and token independence. Guided by these principles, we introduce \\textbf{ActionCodec}, a high-performance action tokenizer that significantly enhances both training efficiency and VLA performance across diverse simulation and real-world benchmarks. Notably, on LIBERO, a SmolVLM2-2.2B fine-tuned with ActionCodec achieves a 95.5\\% success rate without any robotics pre-training. With advanced architectural enhancements, this reaches 97.4\\%, representing a new SOTA for VLA models without robotics pre-training. We believe our established design principles, alongside the released model, will provide a clear roadmap for the community to develop more effective action tokenizers.",
      "authors": [
        "Zibin Dong",
        "Yicheng Liu",
        "Shiduo Zhang",
        "Baijun Ye",
        "Yifu Yuan",
        "Fei Ni",
        "Jingjing Gong",
        "Xipeng Qiu",
        "Hang Zhao",
        "Yinchuan Li",
        "Jianye Hao"
      ],
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "published": "2026-02-17T07:07:15Z",
      "updated": "2026-02-17T07:07:15Z",
      "pdf_url": "https://arxiv.org/pdf/2602.15397v1",
      "abs_url": "http://arxiv.org/abs/2602.15397v1",
      "summary": "该论文研究了Vision-Language-Action模型中动作Tokenizers的设计原则，并提出了ActionCodec。",
      "key_contributions": [
        "提出了VLA优化视角的动作Tokenizer设计原则",
        "设计了高性能动作Tokenizer ActionCodec",
        "在多个基准测试上验证了ActionCodec的有效性"
      ],
      "methodology": "基于信息论，提出了最大化时间Token重叠、最小化词汇冗余、增强多模态互信息等设计原则，并据此设计ActionCodec。",
      "tags": [
        "VLA",
        "Action Tokenization",
        "Vision-Language-Action",
        "Robotics"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "直接研究了多模态领域中VLA模型的关键组件设计问题。",
      "analyzed_at": "2026-02-18T07:02:19.377944",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    }
  ],
  "fetch_time": "2026-02-18T07:02:19.378149"
}