{
  "date": "2026-02-05",
  "papers": [
    {
      "arxiv_id": "2602.04884v1",
      "title": "Reinforced Attention Learning",
      "abstract": "Post-training with Reinforcement Learning (RL) has substantially improved reasoning in Large Language Models (LLMs) via test-time scaling. However, extending this paradigm to Multimodal LLMs (MLLMs) through verbose rationales yields limited gains for perception and can even degrade performance.   We propose Reinforced Attention Learning (RAL), a policy-gradient framework that directly optimizes internal attention distributions rather than output token sequences. By shifting optimization from what to generate to where to attend, RAL promotes effective information allocation and improved grounding in complex multimodal inputs. Experiments across diverse image and video benchmarks show consistent gains over GRPO and other baselines. We further introduce On-Policy Attention Distillation, demonstrating that transferring latent attention behaviors yields stronger cross-modal alignment than standard knowledge distillation. Our results position attention policies as a principled and general alternative for multimodal post-training.",
      "authors": [
        "Bangzheng Li",
        "Jianmo Ni",
        "Chen Qu",
        "Ian Miao",
        "Liu Yang",
        "Xingyu Fu",
        "Muhao Chen",
        "Derek Zhiyuan Cheng"
      ],
      "categories": [
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T18:59:52Z",
      "updated": "2026-02-04T18:59:52Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04884v1",
      "abs_url": "http://arxiv.org/abs/2602.04884v1",
      "summary": "RAL通过强化学习直接优化多模态LLM的内部注意力分布，提升感知能力和跨模态对齐。",
      "key_contributions": [
        "提出Reinforced Attention Learning (RAL)框架",
        "将强化学习应用于优化多模态LLM的注意力分布",
        "提出On-Policy Attention Distillation方法"
      ],
      "methodology": "RAL使用策略梯度方法优化注意力分布，并通过On-Policy Attention Distillation迁移注意力行为。",
      "tags": [
        "强化学习",
        "多模态学习",
        "注意力机制",
        "LLM"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注多模态LLM的注意力机制优化，是多模态学习领域的重要研究。",
      "analyzed_at": "2026-02-05T06:54:15.274833",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04879v1",
      "title": "Rethinking the Trust Region in LLM Reinforcement Learning",
      "abstract": "Reinforcement learning (RL) has become a cornerstone for fine-tuning Large Language Models (LLMs), with Proximal Policy Optimization (PPO) serving as the de facto standard algorithm. Despite its ubiquity, we argue that the core ratio clipping mechanism in PPO is structurally ill-suited for the large vocabularies inherent to LLMs. PPO constrains policy updates based on the probability ratio of sampled tokens, which serves as a noisy single-sample Monte Carlo estimate of the true policy divergence. This creates a sub-optimal learning dynamic: updates to low-probability tokens are aggressively over-penalized, while potentially catastrophic shifts in high-probability tokens are under-constrained, leading to training inefficiency and instability. To address this, we propose Divergence Proximal Policy Optimization (DPPO), which substitutes heuristic clipping with a more principled constraint based on a direct estimate of policy divergence (e.g., Total Variation or KL). To avoid huge memory footprint, we introduce the efficient Binary and Top-K approximations to capture the essential divergence with negligible overhead. Extensive empirical evaluations demonstrate that DPPO achieves superior training stability and efficiency compared to existing methods, offering a more robust foundation for RL-based LLM fine-tuning.",
      "authors": [
        "Penghui Qi",
        "Xiangxin Zhou",
        "Zichen Liu",
        "Tianyu Pang",
        "Chao Du",
        "Min Lin",
        "Wee Sun Lee"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T18:59:04Z",
      "updated": "2026-02-04T18:59:04Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04879v1",
      "abs_url": "http://arxiv.org/abs/2602.04879v1",
      "summary": "论文提出DPPO算法，通过直接估计策略差异来改进LLM强化学习中的PPO算法，提升训练稳定性和效率。",
      "key_contributions": [
        "提出 Divergence Proximal Policy Optimization (DPPO)算法",
        "使用策略差异的直接估计替代启发式裁剪",
        "引入 Binary 和 Top-K 近似以减少内存占用"
      ],
      "methodology": "提出基于策略差异估计的DPPO算法，使用策略差异（例如 Total Variation 或 KL 散度）作为约束，并通过近似方法减少内存占用。",
      "tags": [
        "Reinforcement Learning",
        "Large Language Models",
        "Policy Optimization",
        "Proximal Policy Optimization"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "论文关注LLM的训练，特别是在agent setting中的RL微调，与agent类别高度相关。",
      "analyzed_at": "2026-02-05T06:54:17.162211",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04870v1",
      "title": "Multi-Head LatentMoE and Head Parallel: Communication-Efficient and Deterministic MoE Parallelism",
      "abstract": "Large language models have transformed many applications but remain expensive to train. Sparse Mixture of Experts (MoE) addresses this through conditional computation, with Expert Parallel (EP) as the standard distributed training method. However, EP has three limitations: communication cost grows linearly with the number of activated experts $k$, load imbalance affects latency and memory usage, and data-dependent communication requires metadata exchange. We propose Multi-Head LatentMoE and Head Parallel (HP), a new architecture and parallelism achieving $O(1)$ communication cost regardless of $k$, completely balanced traffic, and deterministic communication, all while remaining compatible with EP. To accelerate Multi-Head LatentMoE, we propose IO-aware routing and expert computation. Compared to MoE with EP, Multi-Head LatentMoE with HP trains up to $1.61\\times$ faster while having identical performance. With doubled granularity, it achieves higher overall performance while still being $1.11\\times$ faster. Our method makes multi-billion-parameter foundation model research more accessible.",
      "authors": [
        "Chenwei Cui",
        "Rockwell Jackson",
        "Benjamin Joseph Herrera",
        "Ana María Tárano",
        "Hannah Kerner"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T18:57:19Z",
      "updated": "2026-02-04T18:57:19Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04870v1",
      "abs_url": "http://arxiv.org/abs/2602.04870v1",
      "summary": "提出了Multi-Head LatentMoE和Head Parallel，实现了高效通信和确定性MoE并行训练。",
      "key_contributions": [
        "提出了Multi-Head LatentMoE架构",
        "提出了Head Parallel (HP) 并行方法",
        "优化了Multi-Head LatentMoE的IO和expert计算"
      ],
      "methodology": "设计了一种新的MoE架构和并行策略，优化了通信成本、负载均衡和计算效率，并进行了实验验证。",
      "tags": [
        "MoE",
        "并行计算",
        "分布式训练",
        "大语言模型"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "提升了MoE模型的训练效率，对Agent方向有间接提升。",
      "analyzed_at": "2026-02-05T06:54:19.943473",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04868v1",
      "title": "CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation",
      "abstract": "Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar, camera and bumper sensor, and a robotic arm with seven joints. The former represent an agent in line-following and object-pushing scenarios, where variation of visual and structural parameters yields a large number of distinct tasks, whereas the latter is used in two goal-reaching scenarios with high-level cartesian hand position control (modeled after the Continual World benchmark), and low-level control based on joint angles. For the robotic arm benchmarks, we provide additional kinematics-only variants that bypass the need for physical simulation (as long as no sensor readings are required), and which can be run two orders of magnitude faster. CRoSS is designed to be easily extensible and enables controlled studies of continual reinforcement learning in robotic settings with high physical realism, and in particular allow the use of almost arbitrary simulated sensors. To ensure reproducibility and ease of use, we provide a containerized setup (Apptainer) that runs out-of-the-box, and report performances of standard RL algorithms, including Deep Q-Networks (DQN) and policy gradient methods. This highlights the suitability as a scalable and reproducible benchmark for CRL research.",
      "authors": [
        "Yannick Denker",
        "Alexander Gepperth"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T18:54:26Z",
      "updated": "2026-02-04T18:54:26Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04868v1",
      "abs_url": "http://arxiv.org/abs/2602.04868v1",
      "summary": "CRoSS是基于Gazebo的连续机器人强化学习benchmark套件，具有高任务多样性和物理真实感。",
      "key_contributions": [
        "提出了新的连续机器人强化学习基准CRoSS",
        "基于Gazebo模拟器，提供两个机器人平台和多种任务场景",
        "提供易于扩展、可复现的容器化环境和标准RL算法的性能报告"
      ],
      "methodology": "通过构建包含多种机器人和任务的仿真环境，评估和比较不同强化学习算法在连续学习场景下的性能。",
      "tags": [
        "机器人",
        "强化学习",
        "连续学习",
        "仿真"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "涉及机器人agent在连续任务中的学习，与agent类别高度相关。",
      "analyzed_at": "2026-02-05T06:54:21.742187",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04864v1",
      "title": "When LLaVA Meets Objects: Token Composition for Vision-Language-Models",
      "abstract": "Current autoregressive Vision Language Models (VLMs) usually rely on a large number of visual tokens to represent images, resulting in a need for more compute especially at inference time. To address this problem, we propose Mask-LLaVA, a framework that leverages different levels of visual features to create a compact yet information-rich visual representation for autoregressive VLMs. Namely, we combine mask-based object representations together with global tokens and local patch tokens. While all tokens are used during training, it shows that the resulting model can flexibly drop especially the number of mask-based object-tokens at test time, allowing to adapt the number of tokens during inference without the need to retrain the model and without a significant drop in performance. We evaluate the proposed approach on a suite of standard benchmarks showing results competitive to current token efficient methods and comparable to the original LLaVA baseline using only a fraction of visual tokens. Our analysis demonstrates that combining multi-level features enables efficient learning with fewer tokens while allowing dynamic token selection at test time for good performance.",
      "authors": [
        "Soumya Jahagirdar",
        "Walid Bousselham",
        "Anna Kukleva",
        "Hilde Kuehne"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-04T18:50:46Z",
      "updated": "2026-02-04T18:50:46Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04864v1",
      "abs_url": "http://arxiv.org/abs/2602.04864v1",
      "summary": "Mask-LLaVA通过结合多层次视觉特征，实现了视觉语言模型的高效推理，减少了计算需求。",
      "key_contributions": [
        "提出Mask-LLaVA框架，利用多层次视觉特征进行高效视觉表示",
        "在测试时动态调整token数量，无需重新训练即可保持性能",
        "在标准基准测试中表现出与现有token高效方法相当的结果"
      ],
      "methodology": "结合mask-based对象表示、全局tokens和局部patch tokens，训练VLMs，并在推理时动态选择token数量。",
      "tags": [
        "Vision-Language Model",
        "Token Composition",
        "Efficient Inference",
        "Masked Representation"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注视觉语言模型及token高效推理，属于多模态学习的关键研究方向。",
      "analyzed_at": "2026-02-05T06:54:23.702657",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04856v1",
      "title": "CoT is Not the Chain of Truth: An Empirical Internal Analysis of Reasoning LLMs for Fake News Generation",
      "abstract": "From generating headlines to fabricating news, the Large Language Models (LLMs) are typically assessed by their final outputs, under the safety assumption that a refusal response signifies safe reasoning throughout the entire process. Challenging this assumption, our study reveals that during fake news generation, even when a model rejects a harmful request, its Chain-of-Thought (CoT) reasoning may still internally contain and propagate unsafe narratives. To analyze this phenomenon, we introduce a unified safety-analysis framework that systematically deconstructs CoT generation across model layers and evaluates the role of individual attention heads through Jacobian-based spectral metrics. Within this framework, we introduce three interpretable measures: stability, geometry, and energy to quantify how specific attention heads respond or embed deceptive reasoning patterns. Extensive experiments on multiple reasoning-oriented LLMs show that the generation risk rise significantly when the thinking mode is activated, where the critical routing decisions concentrated in only a few contiguous mid-depth layers. By precisely identifying the attention heads responsible for this divergence, our work challenges the assumption that refusal implies safety and provides a new understanding perspective for mitigating latent reasoning risks.",
      "authors": [
        "Zhao Tong",
        "Chunlin Gong",
        "Yiping Zhang",
        "Qiang Liu",
        "Xingcheng Xu",
        "Shu Wu",
        "Haichao Shi",
        "Xiao-Yu Zhang"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T18:43:10Z",
      "updated": "2026-02-04T18:43:10Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04856v1",
      "abs_url": "http://arxiv.org/abs/2602.04856v1",
      "summary": "即使LLM拒绝生成假新闻，CoT推理过程也可能包含不安全内容，需关注潜在风险。",
      "key_contributions": [
        "提出了针对LLM推理过程安全性的统一分析框架",
        "利用雅可比矩阵和谱度量分析CoT生成过程中的注意力头",
        "发现了推理模式激活时风险显著增加，且集中在中层"
      ],
      "methodology": "通过解构CoT生成过程，使用基于雅可比矩阵的谱度量评估注意力头的作用，并提出可解释的指标量化推理模式。",
      "tags": [
        "LLM安全性",
        "Chain-of-Thought",
        "注意力机制",
        "假新闻生成"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注CoT推理的安全性和风险，直接研究LLM推理领域的关键问题。",
      "analyzed_at": "2026-02-05T06:54:25.766729",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04853v1",
      "title": "Decomposed Prompting Does Not Fix Knowledge Gaps, But Helps Models Say \"I Don't Know\"",
      "abstract": "Large language models often struggle to recognize their knowledge limits in closed-book question answering, leading to confident hallucinations. While decomposed prompting is typically used to improve accuracy, we investigate its impact on reliability. We evaluate three task-equivalent prompting regimes: Direct, Assistive, and Incremental, across different model scales and multi-hop QA benchmarks. We find that although accuracy gains from decomposition diminish in frontier models, disagreements between prompting regimes remain highly indicative of potential errors. Because factual knowledge is stable while hallucinations are stochastic, cross-regime agreement provides a precise signal of internal uncertainty. We leverage this signal to implement a training-free abstention policy that requires no retrieval or fine-tuning. Our results show that disagreement-based abstention outperforms standard uncertainty baselines as an error detector, improving both F1 and AUROC across settings. This demonstrates that decomposition-based prompting can serve as a practical diagnostic probe for model reliability in closed-book QA.",
      "authors": [
        "Dhruv Madhwal",
        "Lyuxin David Zhang",
        "Dan Roth",
        "Tomer Wolfson",
        "Vivek Gupta"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T18:39:58Z",
      "updated": "2026-02-04T18:39:58Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04853v1",
      "abs_url": "http://arxiv.org/abs/2602.04853v1",
      "summary": "分解提示不能弥补知识差距，但能帮助模型表达“我不知道”。",
      "key_contributions": [
        "揭示分解提示对模型可靠性的影响",
        "提出基于提示方式不一致性的不确定性信号",
        "提出无需训练的基于不一致性的拒绝策略"
      ],
      "methodology": "对比直接、辅助和递增三种提示方式，通过模型间的意见分歧来判断知识不确定性，并利用该信号实现拒绝回答。",
      "tags": [
        "LLM",
        "Prompting",
        "Uncertainty",
        "Closed-book QA"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "研究了分解提示对LLM可靠性的影响，涉及推理和知识边界。",
      "analyzed_at": "2026-02-05T06:54:27.538996",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04852v1",
      "title": "The Key to State Reduction in Linear Attention: A Rank-based Perspective",
      "abstract": "Linear attention offers a computationally efficient yet expressive alternative to softmax attention. However, recent empirical results indicate that the state of trained linear attention models often exhibits a low-rank structure, suggesting that these models underexploit their capacity in practice. To illuminate this phenomenon, we provide a theoretical analysis of the role of rank in linear attention, revealing that low effective rank can affect retrieval error by amplifying query noise. In addition to these theoretical insights, we conjecture that the low-rank states can be substantially reduced post-training with only minimal performance degradation, yielding faster and more memory-efficient models. To this end, we propose a novel hardware-aware approach that structurally prunes key and query matrices, reducing the state size while retaining compatibility with existing CUDA kernels. We adapt several existing pruning strategies to fit our framework and, building on our theoretical analysis, propose a novel structured pruning method based on a rank-revealing QR decomposition. Our empirical results, evaluated across models of varying sizes and on various downstream tasks, demonstrate the effectiveness of our state reduction framework. We highlight that our framework enables the removal of 50% of the query and key channels at only a marginal increase in perplexity. The code for this project can be found at https://github.com/camail-official/LinearAttentionPruning.",
      "authors": [
        "Philipp Nazari",
        "T. Konstantin Rusch"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T18:39:38Z",
      "updated": "2026-02-04T18:39:38Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04852v1",
      "abs_url": "http://arxiv.org/abs/2602.04852v1",
      "summary": "分析线性注意力模型低秩现象，提出硬件感知结构化剪枝方法，减少模型状态大小。",
      "key_contributions": [
        "理论分析了线性注意力中秩对检索误差的影响",
        "提出了基于秩分解的结构化剪枝方法，用于减少状态大小",
        "验证了剪枝后模型性能下降很小，且兼容现有CUDA内核"
      ],
      "methodology": "通过理论分析揭示低秩影响，提出基于秩分解的结构化剪枝方法，并进行实验验证。",
      "tags": [
        "Linear Attention",
        "Model Pruning",
        "Low-Rank Approximation"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 7,
      "relevance_reason": "关注模型效率和推理优化，高度相关但非直接推理任务。",
      "analyzed_at": "2026-02-05T06:54:29.807663",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04850v1",
      "title": "El Agente Quntur: A research collaborator agent for quantum chemistry",
      "abstract": "Quantum chemistry is a foundational enabling tool for the fields of chemistry, materials science, computational biology and others. Despite of its power, the practical application of quantum chemistry simulations remains in the hands of qualified experts due to methodological complexity, software heterogeneity, and the need for informed interpretation of results. To bridge the accessibility gap for these tools and expand their reach to chemists with broader backgrounds, we introduce El Agente Quntur, a hierarchical, multi-agent AI system designed to operate not merely as an automation tool but as a research collaborator for computational quantum chemistry. Quntur was designed following three main strategies: i) elimination of hard-coded procedural policies in favour of reasoning-driven decisions, ii) construction of general and composable actions that facilitate generalization and efficiency, and iii) implementation of guided deep research to integrate abstract quantum-chemical reasoning across subdisciplines and a detailed understanding of the software's internal logic and syntax. Although instantiated in ORCA, these design principles are applicable to research agents more generally and easily expandable to additional quantum chemistry packages and beyond. Quntur supports the full range of calculations available in ORCA 6.0 and reasons over software documentation and scientific literature to plan, execute, adapt, and analyze in silico chemistry experiments following best practices. We discuss the advances and current bottlenecks in agentic systems operating at the research level in computational chemistry, and outline a roadmap toward a fully autonomous end-to-end computational chemistry research agent.",
      "authors": [
        "Juan B. Pérez-Sánchez",
        "Yunheng Zou",
        "Jorge A. Campos-Gonzalez-Angulo",
        "Marcel Müller",
        "Ignacio Gustin",
        "Andrew Wang",
        "Han Hao",
        "Tsz Wai Ko",
        "Changhyeok Choi",
        "Eric S. Isbrandt",
        "Mohammad Ghazi Vakili",
        "Hanyong Xu",
        "Chris Crebolder",
        "Varinia Bernales",
        "Alán Aspuru-Guzik"
      ],
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "physics.chem-ph",
      "published": "2026-02-04T18:38:50Z",
      "updated": "2026-02-04T18:38:50Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04850v1",
      "abs_url": "http://arxiv.org/abs/2602.04850v1",
      "summary": "El Agente Quntur是一个用于量子化学的智能体，旨在成为研究合作者并扩展其应用。",
      "key_contributions": [
        "设计并实现了名为Quntur的AI智能体系统",
        "提出了reasoning-driven决策、通用可组合行为和引导式深度研究的设计策略",
        "验证了Quntur在ORCA软件中的应用，并展望了全自动计算化学研究智能体的未来"
      ],
      "methodology": "采用分层多智能体系统，通过reasoning-driven决策，通用可组合行为，和guided deep research 实现自动化化学实验。",
      "tags": [
        "量子化学",
        "AI智能体",
        "自动化",
        "计算化学"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心是AI智能体在特定科研领域的应用，具有高度相关性。",
      "analyzed_at": "2026-02-05T06:54:31.804494",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04849v1",
      "title": "El Agente Estructural: An Artificially Intelligent Molecular Editor",
      "abstract": "We present El Agente Estructural, a multimodal, natural-language-driven geometry-generation and manipulation agent for autonomous chemistry and molecular modelling. Unlike molecular generation or editing via generative models, Estructural mimics how human experts directly manipulate molecular systems in three dimensions by integrating a comprehensive set of domain-informed tools and vision-language models. This design enables precise control over atomic or functional group replacements, atomic connectivity, and stereochemistry without the need to rebuild extensive core molecular frameworks. Through a series of representative case studies, we demonstrate that Estructural enables chemically meaningful geometry manipulation across a wide range of real-world scenarios. These include site-selective functionalization, ligand binding, ligand exchange, stereochemically controlled structure construction, isomer interconversion, fragment-level structural analysis, image-guided generation of structures from schematic reaction mechanisms, and mechanism-driven geometry generation and modification. These examples illustrate how multimodal reasoning, when combined with specialized geometry-aware tools, supports interactive and context-aware molecular modelling beyond structure generation. Looking forward, the integration of Estructural into El Agente Quntur, an autonomous multi-agent quantum chemistry platform, enhances its capabilities by adding sophisticated tools for the generation and editing of three-dimensional structures.",
      "authors": [
        "Changhyeok Choi",
        "Yunheng Zou",
        "Marcel Müller",
        "Han Hao",
        "Yeonghun Kang",
        "Juan B. Pérez-Sánchez",
        "Ignacio Gustin",
        "Hanyong Xu",
        "Mohammad Ghazi Vakili",
        "Chris Crebolder",
        "Alán Aspuru-Guzik",
        "Varinia Bernales"
      ],
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "physics.chem-ph",
      "published": "2026-02-04T18:38:48Z",
      "updated": "2026-02-04T18:38:48Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04849v1",
      "abs_url": "http://arxiv.org/abs/2602.04849v1",
      "summary": "Estructural是一个基于自然语言驱动的多模态分子编辑智能体，用于自主化学和分子建模。",
      "key_contributions": [
        "提出了El Agente Estructural分子编辑智能体",
        "集成了领域知识工具和视觉-语言模型",
        "实现了精确的分子几何操作和控制"
      ],
      "methodology": "结合领域知识工具和视觉-语言模型，通过自然语言驱动，模仿人类专家操作分子系统进行几何操作和编辑。",
      "tags": [
        "AI Agent",
        "分子建模",
        "自然语言处理",
        "多模态"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心是构建一个自主分子编辑智能体，与agent类别直接相关。",
      "analyzed_at": "2026-02-05T06:54:33.550135",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04843v1",
      "title": "Fluid Representations in Reasoning Models",
      "abstract": "Reasoning language models, which generate long chains of thought, dramatically outperform non-reasoning language models on abstract problems. However, the internal model mechanisms that allow this superior performance remain poorly understood. We present a mechanistic analysis of how QwQ-32B - a model specifically trained to produce extensive reasoning traces - process abstract structural information. On Mystery Blocksworld - a semantically obfuscated planning domain - we find that QwQ-32B gradually improves its internal representation of actions and concepts during reasoning. The model develops abstract encodings that focus on structure rather than specific action names. Through steering experiments, we establish causal evidence that these adaptations improve problem solving: injecting refined representations from successful traces boosts accuracy, while symbolic representations can replace many obfuscated encodings with minimal performance loss. We find that one of the factors driving reasoning model performance is in-context refinement of token representations, which we dub Fluid Reasoning Representations.",
      "authors": [
        "Dmitrii Kharlapenko",
        "Alessandro Stolfo",
        "Arthur Conmy",
        "Mrinmaya Sachan",
        "Zhijing Jin"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-04T18:34:50Z",
      "updated": "2026-02-04T18:34:50Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04843v1",
      "abs_url": "http://arxiv.org/abs/2602.04843v1",
      "summary": "研究表明，推理模型通过上下文token表示的动态调整实现抽象结构信息的有效处理和问题解决。",
      "key_contributions": [
        "发现推理模型在推理过程中改进内部的动作和概念表示",
        "证明了模型会发展出专注于结构的抽象编码",
        "建立了这些适应性能提升问题解决的因果关系"
      ],
      "methodology": "通过对QwQ-32B模型在Mystery Blocksworld上的分析，结合引导实验，揭示token表示在推理过程中的演化。",
      "tags": [
        "推理模型",
        "表示学习",
        "上下文学习",
        "因果分析"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文核心研究推理模型，并深入分析了其推理机制。",
      "analyzed_at": "2026-02-05T06:54:35.253111",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04837v1",
      "title": "Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing",
      "abstract": "Open-ended self-improving agents can autonomously modify their own structural designs to advance their capabilities and overcome the limits of pre-defined architectures, thus reducing reliance on human intervention. We introduce Group-Evolving Agents (GEA), a new paradigm for open-ended self-improvements, which treats a group of agents as the fundamental evolutionary unit, enabling explicit experience sharing and reuse within the group throughout evolution. Unlike existing open-ended self-evolving paradigms that adopt tree-structured evolution, GEA overcomes the limitation of inefficient utilization of exploratory diversity caused by isolated evolutionary branches. We evaluate GEA on challenging coding benchmarks, where it significantly outperforms state-of-the-art self-evolving methods (71.0% vs. 56.7% on SWE-bench Verified, 88.3% vs. 68.3% on Polyglot) and matches or exceeds top human-designed agent frameworks (71.8% and 52.0% on two benchmarks, respectively). Analysis reveals that GEA more effectively converts early-stage exploratory diversity into sustained, long-term progress, achieving stronger performance under the same number of evolved agents. Furthermore, GEA exhibits consistent transferability across different coding models and greater robustness, fixing framework-level bugs in 1.4 iterations on average, versus 5 for self-evolving methods.",
      "authors": [
        "Zhaotian Weng",
        "Antonis Antoniades",
        "Deepak Nathani",
        "Zhen Zhang",
        "Xiao Pu",
        "Xin Eric Wang"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-04T18:29:36Z",
      "updated": "2026-02-04T18:29:36Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04837v1",
      "abs_url": "http://arxiv.org/abs/2602.04837v1",
      "summary": "GEA提出了一种新的自进化Agent范式，通过群体进化和经验共享实现高效的持续改进。",
      "key_contributions": [
        "提出Group-Evolving Agents (GEA) 范式",
        "在经验共享的基础上实现自进化",
        "显著优于现有自进化方法，并媲美人工设计的Agent框架"
      ],
      "methodology": "GEA将Agent群体作为进化单元，通过群体内的经验共享和复用，克服了树状进化中探索多样性利用不足的局限。",
      "tags": [
        "AI Agents",
        "Self-evolving",
        "Experience Sharing",
        "Code Generation"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文主要研究AI Agent的自进化能力，属于agent领域的核心问题。",
      "analyzed_at": "2026-02-05T06:54:37.132336",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04836v1",
      "title": "Are AI Capabilities Increasing Exponentially? A Competing Hypothesis",
      "abstract": "Rapidly increasing AI capabilities have substantial real-world consequences, ranging from AI safety concerns to labor market consequences. The Model Evaluation & Threat Research (METR) report argues that AI capabilities have exhibited exponential growth since 2019. In this note, we argue that the data does not support exponential growth, even in shorter-term horizons. Whereas the METR study claims that fitting sigmoid/logistic curves results in inflection points far in the future, we fit a sigmoid curve to their current data and find that the inflection point has already passed. In addition, we propose a more complex model that decomposes AI capabilities into base and reasoning capabilities, exhibiting individual rates of improvement. We prove that this model supports our hypothesis that AI capabilities will exhibit an inflection point in the near future. Our goal is not to establish a rigorous forecast of our own, but to highlight the fragility of existing forecasts of exponential growth.",
      "authors": [
        "Haosen Ge",
        "Hamsa Bastani",
        "Osbert Bastani"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-04T18:28:49Z",
      "updated": "2026-02-04T18:28:49Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04836v1",
      "abs_url": "http://arxiv.org/abs/2602.04836v1",
      "summary": "论文反驳了AI能力呈指数增长的观点，提出AI能力增长可能已过拐点，并构建复杂模型进行论证。",
      "key_contributions": [
        "反驳了AI能力指数增长的观点",
        "指出现有模型预测的脆弱性",
        "提出AI能力分解为基础能力和推理能力的复杂模型",
        "论证AI能力增长可能已过拐点"
      ],
      "methodology": "通过拟合sigmoid曲线和构建AI能力分解模型，分析现有数据，论证AI能力增长的拐点可能已经过去。",
      "tags": [
        "AI能力增长",
        "指数增长",
        "拐点",
        "预测",
        "模型"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "论文讨论了AI推理能力的增长趋势，并对其增长模型提出了质疑。",
      "analyzed_at": "2026-02-05T06:54:38.949311",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04821v1",
      "title": "Safe Urban Traffic Control via Uncertainty-Aware Conformal Prediction and World-Model Reinforcement Learning",
      "abstract": "Urban traffic management demands systems that simultaneously predict future conditions, detect anomalies, and take safe corrective actions -- all while providing reliability guarantees. We present STREAM-RL, a unified framework that introduces three novel algorithmic contributions: (1) PU-GAT+, an Uncertainty-Guided Adaptive Conformal Forecaster that uses prediction uncertainty to dynamically reweight graph attention via confidence-monotonic attention, achieving distribution-free coverage guarantees; (2) CRFN-BY, a Conformal Residual Flow Network that models uncertainty-normalized residuals via normalizing flows with Benjamini-Yekutieli FDR control under arbitrary dependence; and (3) LyCon-WRL+, an Uncertainty-Guided Safe World-Model RL agent with Lyapunov stability certificates, certified Lipschitz bounds, and uncertainty-propagated imagination rollouts. To our knowledge, this is the first framework to propagate calibrated uncertainty from forecasting through anomaly detection to safe policy learning with end-to-end theoretical guarantees. Experiments on multiple real-world traffic trajectory data demonstrate that STREAM-RL achieves 91.4\\% coverage efficiency, controls FDR at 4.1\\% under verified dependence, and improves safety rate to 95.2\\% compared to 69\\% for standard PPO while achieving higher reward, with 23ms end-to-end inference latency.",
      "authors": [
        "Joydeep Chandra",
        "Satyam Kumar Navneet",
        "Aleksandr Algazinov",
        "Yong Zhang"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T18:10:59Z",
      "updated": "2026-02-04T18:10:59Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04821v1",
      "abs_url": "http://arxiv.org/abs/2602.04821v1",
      "summary": "STREAM-RL框架通过不确定性感知方法实现安全可靠的城市交通控制。",
      "key_contributions": [
        "PU-GAT+：不确定性引导的自适应共形预测器",
        "CRFN-BY：基于共形残差流网络的不确定性建模",
        "LyCon-WRL+：基于李雅普诺夫稳定的安全世界模型强化学习"
      ],
      "methodology": "结合共形预测、残差流网络和强化学习，利用不确定性信息指导预测、异常检测和安全策略学习。",
      "tags": [
        "交通控制",
        "强化学习",
        "不确定性量化",
        "共形预测"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "研究智能体在复杂环境中的安全决策和控制。",
      "analyzed_at": "2026-02-05T06:54:41.137096",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04820v1",
      "title": "Toward Reliable and Explainable Nail Disease Classification: Leveraging Adversarial Training and Grad-CAM Visualization",
      "abstract": "Human nail diseases are gradually observed over all age groups, especially among older individuals, often going ignored until they become severe. Early detection and accurate diagnosis of such conditions are important because they sometimes reveal our body's health problems. But it is challenging due to the inferred visual differences between disease types. This paper presents a machine learning-based model for automated classification of nail diseases based on a publicly available dataset, which contains 3,835 images scaling six categories. In 224x224 pixels, all images were resized to ensure consistency. To evaluate performance, four well-known CNN models-InceptionV3, DenseNet201, EfficientNetV2, and ResNet50 were trained and analyzed. Among these, InceptionV3 outperformed the others with an accuracy of 95.57%, while DenseNet201 came next with 94.79%. To make the model stronger and less likely to make mistakes on tricky or noisy images, we used adversarial training. To help understand how the model makes decisions, we used SHAP to highlight important features in the predictions. This system could be a helpful support for doctors, making nail disease diagnosis more accurate and faster.",
      "authors": [
        "Farzia Hossain",
        "Samanta Ghosh",
        "Shahida Begum",
        "B. M. Shahria Alam",
        "Mohammad Tahmid Noor",
        "Md Parvez Mia",
        "Nishat Tasnim Niloy"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-04T18:08:13Z",
      "updated": "2026-02-04T18:08:13Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04820v1",
      "abs_url": "http://arxiv.org/abs/2602.04820v1",
      "summary": "本文提出了一种基于深度学习的指甲疾病分类方法，利用对抗训练和Grad-CAM可视化提高模型的可靠性和可解释性。",
      "key_contributions": [
        "利用InceptionV3等CNN模型进行指甲疾病分类",
        "应用对抗训练增强模型鲁棒性",
        "使用SHAP解释模型预测结果"
      ],
      "methodology": "训练InceptionV3, DenseNet201, EfficientNetV2, ResNet50等模型，并使用对抗训练和SHAP进行优化和解释。",
      "tags": [
        "图像分类",
        "深度学习",
        "对抗训练",
        "可解释性"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 7,
      "relevance_reason": "涉及到图像数据的处理和分类，属于多模态学习领域的重要应用。",
      "analyzed_at": "2026-02-05T06:54:43.045161",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04816v1",
      "title": "Horizon-LM: A RAM-Centric Architecture for LLM Training",
      "abstract": "The rapid growth of large language models (LLMs) has outpaced the evolution of single-GPU hardware, making model scale increasingly constrained by memory capacity rather than computation. While modern training systems extend GPU memory through distributed parallelism and offloading across CPU and storage tiers, they fundamentally retain a GPU-centric execution paradigm in which GPUs host persistent model replicas and full autograd graphs. As a result, scaling large models remains tightly coupled to multi-GPU clusters, complex distributed runtimes, and unpredictable host memory consumption, creating substantial barriers for node-scale post-training workloads such as instruction tuning, alignment, and domain adaptation. We present Horizon-LM, a memory-centric training system that redefines the roles of CPU and GPU for large-model optimization. Horizon-LM treats host memory as the authoritative parameter store and uses GPUs solely as transient compute engines through a CPU-master, GPU-template execution model. By eliminating persistent GPU-resident modules and autograd graphs, employing explicit recomputation with manual gradient propagation, and introducing a pipelined double-buffered execution engine, Horizon-LM decouples model scale from GPU count and bounds memory usage to the theoretical parameter footprint. On a single H200 GPU with 1.5\\,TB host RAM, Horizon-LM reliably trains models up to 120B parameters. On a standard single A100 machine, Horizon-LM achieves up to 12.2$\\times$ higher training throughput than DeepSpeed ZeRO-3 with CPU offloading while preserving numerical correctness. Across platforms and scales, Horizon-LM sustains high device utilization and predictable memory growth, demonstrating that host memory, not GPU memory, defines the true feasibility boundary for node-scale large-model training.",
      "authors": [
        "Zhengqing Yuan",
        "Lichao Sun",
        "Yanfang",
        "Ye"
      ],
      "categories": [
        "cs.OS",
        "cs.CL",
        "cs.DC"
      ],
      "primary_category": "cs.OS",
      "published": "2026-02-04T18:04:46Z",
      "updated": "2026-02-04T18:04:46Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04816v1",
      "abs_url": "http://arxiv.org/abs/2602.04816v1",
      "summary": "Horizon-LM通过CPU主导的架构，突破GPU内存限制，实现单节点大规模LLM训练。",
      "key_contributions": [
        "提出CPU主导的内存中心化LLM训练架构",
        "消除GPU常驻模块和自动微分图",
        "实现高效的流水线双缓冲执行引擎"
      ],
      "methodology": "采用CPU作为参数存储中心，GPU作为计算引擎，通过显式重计算和手动梯度传播，解耦模型规模与GPU数量。",
      "tags": [
        "LLM Training",
        "Memory-Centric Architecture",
        "CPU Offloading"
      ],
      "assigned_category": "memory",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于解决LLM训练中的内存瓶颈问题，是memory领域的重要突破。",
      "analyzed_at": "2026-02-05T06:54:44.677437",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04813v1",
      "title": "Agentic AI in Healthcare & Medicine: A Seven-Dimensional Taxonomy for Empirical Evaluation of LLM-based Agents",
      "abstract": "Large Language Model (LLM)-based agents that plan, use tools and act has begun to shape healthcare and medicine. Reported studies demonstrate competence on various tasks ranging from EHR analysis and differential diagnosis to treatment planning and research workflows. Yet the literature largely consists of overviews which are either broad surveys or narrow dives into a single capability (e.g., memory, planning, reasoning), leaving healthcare work without a common frame. We address this by reviewing 49 studies using a seven-dimensional taxonomy: Cognitive Capabilities, Knowledge Management, Interaction Patterns, Adaptation & Learning, Safety & Ethics, Framework Typology and Core Tasks & Subtasks with 29 operational sub-dimensions. Using explicit inclusion and exclusion criteria and a labeling rubric (Fully Implemented, Partially Implemented, Not Implemented), we map each study to the taxonomy and report quantitative summaries of capability prevalence and co-occurrence patterns. Our empirical analysis surfaces clear asymmetries. For instance, the External Knowledge Integration sub-dimension under Knowledge Management is commonly realized (~76% Fully Implemented) whereas Event-Triggered Activation sub-dimenison under Interaction Patterns is largely absent (~92% Not Implemented) and Drift Detection & Mitigation sub-dimension under Adaptation & Learning is rare (~98% Not Implemented). Architecturally, Multi-Agent Design sub-dimension under Framework Typology is the dominant pattern (~82% Fully Implemented) while orchestration layers remain mostly partial. Across Core Tasks & Subtasks, information centric capabilities lead e.g., Medical Question Answering & Decision Support and Benchmarking & Simulation, while action and discovery oriented areas such as Treatment Planning & Prescription still show substantial gaps (~59% Not Implemented).",
      "authors": [
        "Shubham Vatsal",
        "Harsh Dubey",
        "Aditi Singh"
      ],
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-04T17:59:14Z",
      "updated": "2026-02-04T17:59:14Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04813v1",
      "abs_url": "http://arxiv.org/abs/2602.04813v1",
      "summary": "论文构建七维度分类体系，评估LLM医疗Agent能力，发现发展不均衡。",
      "key_contributions": [
        "构建了用于评估LLM医疗Agent的七维度分类体系。",
        "对49篇相关研究进行了实证分析。",
        "揭示了LLM医疗Agent在不同能力维度上的发展不均衡性。"
      ],
      "methodology": "回顾49篇论文，使用七维度分类体系进行标注（完全实现、部分实现、未实现），量化分析能力普遍性和共现模式。",
      "tags": [
        "LLM",
        "AI Agent",
        "Healthcare",
        "Taxonomy",
        "Evaluation"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "核心关注LLM Agent在医疗领域的应用，深度相关。",
      "analyzed_at": "2026-02-05T06:54:46.368132",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04811v1",
      "title": "SE-Bench: Benchmarking Self-Evolution with Knowledge Internalization",
      "abstract": "True self-evolution requires agents to act as lifelong learners that internalize novel experiences to solve future problems. However, rigorously measuring this foundational capability is hindered by two obstacles: the entanglement of prior knowledge, where ``new'' knowledge may appear in pre-training data, and the entanglement of reasoning complexity, where failures may stem from problem difficulty rather than an inability to recall learned knowledge. We introduce SE-Bench, a diagnostic environment that obfuscates the NumPy library and its API doc into a pseudo-novel package with randomized identifiers. Agents are trained to internalize this package and evaluated on simple coding tasks without access to documentation, yielding a clean setting where tasks are trivial with the new API doc but impossible for base models without it. Our investigation reveals three insights: (1) the Open-Book Paradox, where training with reference documentation inhibits retention, requiring \"Closed-Book Training\" to force knowledge compression into weights; (2) the RL Gap, where standard RL fails to internalize new knowledge completely due to PPO clipping and negative gradients; and (3) the viability of Self-Play for internalization, proving models can learn from self-generated, noisy tasks when coupled with SFT, but not RL. Overall, SE-Bench establishes a rigorous diagnostic platform for self-evolution with knowledge internalization. Our code and dataset can be found at https://github.com/thunlp/SE-Bench.",
      "authors": [
        "Jiarui Yuan",
        "Tailin Jin",
        "Weize Chen",
        "Zeyuan Liu",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T17:58:32Z",
      "updated": "2026-02-04T17:58:32Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04811v1",
      "abs_url": "http://arxiv.org/abs/2602.04811v1",
      "summary": "SE-Bench提供了一个基准测试，用于评估模型内化新知识的自进化能力。",
      "key_contributions": [
        "提出了SE-Bench诊断环境，用于评估知识内化能力。",
        "揭示了开放式书籍悖论、强化学习差距和自博弈在知识内化中的作用。",
        "提供了一个评估自进化和知识内化的严格平台。"
      ],
      "methodology": "构建混淆的NumPy库，训练智能体内部化该库，并在没有文档的情况下评估其编码能力。",
      "tags": [
        "self-evolution",
        "knowledge internalization",
        "benchmarking",
        "reinforcement learning"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "研究了智能体如何自主学习和适应新知识，与智能体领域密切相关。",
      "analyzed_at": "2026-02-05T06:54:48.260351",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04809v1",
      "title": "Beyond Rewards in Reinforcement Learning for Cyber Defence",
      "abstract": "Recent years have seen an explosion of interest in autonomous cyber defence agents trained to defend computer networks using deep reinforcement learning. These agents are typically trained in cyber gym environments using dense, highly engineered reward functions which combine many penalties and incentives for a range of (un)desirable states and costly actions. Dense rewards help alleviate the challenge of exploring complex environments but risk biasing agents towards suboptimal and potentially riskier solutions, a critical issue in complex cyber environments. We thoroughly evaluate the impact of reward function structure on learning and policy behavioural characteristics using a variety of sparse and dense reward functions, two well-established cyber gyms, a range of network sizes, and both policy gradient and value-based RL algorithms. Our evaluation is enabled by a novel ground truth evaluation approach which allows directly comparing between different reward functions, illuminating the nuanced inter-relationships between rewards, action space and the risks of suboptimal policies in cyber environments. Our results show that sparse rewards, provided they are goal aligned and can be encountered frequently, uniquely offer both enhanced training reliability and more effective cyber defence agents with lower-risk policies. Surprisingly, sparse rewards can also yield policies that are better aligned with cyber defender goals and make sparing use of costly defensive actions without explicit reward-based numerical penalties.",
      "authors": [
        "Elizabeth Bates",
        "Chris Hicks",
        "Vasilios Mavroudis"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T17:55:23Z",
      "updated": "2026-02-04T17:55:23Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04809v1",
      "abs_url": "http://arxiv.org/abs/2602.04809v1",
      "summary": "研究奖励函数结构对网络安全强化学习Agent性能的影响，发现稀疏奖励更有效。",
      "key_contributions": [
        "提出一种评估奖励函数有效性的新方法",
        "评估了稀疏和密集奖励在网络安全场景下的影响",
        "证明了精心设计的稀疏奖励能够提高Agent的可靠性和安全性"
      ],
      "methodology": "在网络安全环境中，使用不同的稀疏和密集奖励函数训练强化学习Agent，并进行对比评估。",
      "tags": [
        "强化学习",
        "网络安全",
        "奖励函数",
        "智能Agent"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "该论文直接研究了如何训练在网络安全中应用的自主Agent。",
      "analyzed_at": "2026-02-05T06:54:50.423559",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04804v1",
      "title": "OmniSIFT: Modality-Asymmetric Token Compression for Efficient Omni-modal Large Language Models",
      "abstract": "Omni-modal Large Language Models (Omni-LLMs) have demonstrated strong capabilities in audio-video understanding tasks. However, their reliance on long multimodal token sequences leads to substantial computational overhead. Despite this challenge, token compression methods designed for Omni-LLMs remain limited. To bridge this gap, we propose OmniSIFT (Omni-modal Spatio-temporal Informed Fine-grained Token compression), a modality-asymmetric token compression framework tailored for Omni-LLMs. Specifically, OmniSIFT adopts a two-stage compression strategy: (i) a spatio-temporal video pruning module that removes video redundancy arising from both intra-frame structure and inter-frame overlap, and (ii) a vision-guided audio selection module that filters audio tokens. The entire framework is optimized end-to-end via a differentiable straight-through estimator. Extensive experiments on five representative benchmarks demonstrate the efficacy and robustness of OmniSIFT. Notably, for Qwen2.5-Omni-7B, OmniSIFT introduces only 4.85M parameters while maintaining lower latency than training-free baselines such as OmniZip. With merely 25% of the original token context, OmniSIFT consistently outperforms all compression baselines and even surpasses the performance of the full-token model on several tasks.",
      "authors": [
        "Yue Ding",
        "Yiyan Ji",
        "Jungang Li",
        "Xuyang Liu",
        "Xinlong Chen",
        "Junfei Wu",
        "Bozhou Li",
        "Bohan Zeng",
        "Yang Shi",
        "Yushuo Guan",
        "Yuanxing Zhang",
        "Jiaheng Liu",
        "Qiang Liu",
        "Pengfei Wan",
        "Liang Wang"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T17:51:05Z",
      "updated": "2026-02-04T17:51:05Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04804v1",
      "abs_url": "http://arxiv.org/abs/2602.04804v1",
      "summary": "OmniSIFT提出了一种模态非对称的token压缩框架，用于优化多模态大模型的效率。",
      "key_contributions": [
        "提出了模态非对称的token压缩框架OmniSIFT",
        "设计了时空视频剪枝模块和视觉引导的音频选择模块",
        "通过可微分的straight-through estimator进行端到端优化"
      ],
      "methodology": "采用两阶段压缩策略，先剪枝视频冗余，再用视觉引导选择音频token，最后端到端优化。",
      "tags": [
        "多模态学习",
        "大语言模型",
        "Token压缩",
        "效率优化",
        "视频处理",
        "音频处理"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "该论文专注于多模态大模型的效率优化，直接解决多模态学习中的关键问题。",
      "analyzed_at": "2026-02-05T06:54:52.408560",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04802v1",
      "title": "VISTA-Bench: Do Vision-Language Models Really Understand Visualized Text as Well as Pure Text?",
      "abstract": "Vision-Language Models (VLMs) have achieved impressive performance in cross-modal understanding across textual and visual inputs, yet existing benchmarks predominantly focus on pure-text queries. In real-world scenarios, language also frequently appears as visualized text embedded in images, raising the question of whether current VLMs handle such input requests comparably. We introduce VISTA-Bench, a systematic benchmark from multimodal perception, reasoning, to unimodal understanding domains. It evaluates visualized text understanding by contrasting pure-text and visualized-text questions under controlled rendering conditions. Extensive evaluation of over 20 representative VLMs reveals a pronounced modality gap: models that perform well on pure-text queries often degrade substantially when equivalent semantic content is presented as visualized text. This gap is further amplified by increased perceptual difficulty, highlighting sensitivity to rendering variations despite unchanged semantics. Overall, VISTA-Bench provides a principled evaluation framework to diagnose this limitation and to guide progress toward more unified language representations across tokenized text and pixels. The source dataset is available at https://github.com/QingAnLiu/VISTA-Bench.",
      "authors": [
        "Qing'an Liu",
        "Juntong Feng",
        "Yuhao Wang",
        "Xinzhe Han",
        "Yujie Cheng",
        "Yue Zhu",
        "Haiwen Diao",
        "Yunzhi Zhuge",
        "Huchuan Lu"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-04T17:48:55Z",
      "updated": "2026-02-04T17:48:55Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04802v1",
      "abs_url": "http://arxiv.org/abs/2602.04802v1",
      "summary": "VISTA-Bench揭示了现有VLM在理解视觉化文本时存在显著的性能下降，与纯文本理解能力有较大差距。",
      "key_contributions": [
        "提出了VISTA-Bench基准测试，用于评估VLM对视觉化文本的理解能力",
        "发现了VLM在视觉化文本理解上的显著性能差距",
        "分析了视觉化文本的感知难度对VLM性能的影响"
      ],
      "methodology": "构建包含多模态感知、推理和单模态理解任务的基准，对比VLM在纯文本和视觉化文本上的表现，并控制渲染条件。",
      "tags": [
        "Vision-Language Models",
        "Visualized Text",
        "Benchmark",
        "Multimodal Understanding"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注VLM对视觉化文本的理解，属于多模态学习的关键问题。",
      "analyzed_at": "2026-02-05T06:54:54.884257",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04782v1",
      "title": "Legendre Memory Unit with A Multi-Slice Compensation Model for Short-Term Wind Speed Forecasting Based on Wind Farm Cluster Data",
      "abstract": "With more wind farms clustered for integration, the short-term wind speed prediction of such wind farm clusters is critical for normal operation of power systems. This paper focuses on achieving accurate, fast, and robust wind speed prediction by full use of cluster data with spatial-temporal correlation. First, weighted mean filtering (WMF) is applied to denoise wind speed data at the single-farm level. The Legendre memory unit (LMU) is then innovatively applied for the wind speed prediction, in combination with the Compensating Parameter based on Kendall rank correlation coefficient (CPK) of wind farm cluster data, to construct the multi-slice LMU (MSLMU). Finally, an innovative ensemble model WMF-CPK-MSLMU is proposed herein, with three key blocks: data pre-processing, forecasting, and multi-slice compensation. Advantages include: 1) LMU jointly models linear and nonlinear dependencies among farms to capture spatial-temporal correlations through backpropagation; 2) MSLMU enhances forecasting by using CPK-derived weights instead of random initialization, allowing spatial correlations to fully activate hidden nodes across clustered wind farms.; 3) CPK adaptively weights the compensation model in MSLMU and complements missing data spatially, to facilitate the whole model highly accurate and robust. Test results on different wind farm clusters indicate the effectiveness and superiority of proposed ensemble model WMF-CPK-MSLMU in the short-term prediction of wind farm clusters compared to the existing models.",
      "authors": [
        "Mumin Zhang",
        "Haochen Zhang",
        "Xin Zhi Khoo",
        "Yilin Zhang",
        "Nuo Chen",
        "Ting Zhang",
        "Junjie Tang"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T17:28:42Z",
      "updated": "2026-02-04T17:28:42Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04782v1",
      "abs_url": "http://arxiv.org/abs/2602.04782v1",
      "summary": "提出一种基于风电场集群数据的WMF-CPK-MSLMU短期风速预测集成模型。",
      "key_contributions": [
        "创新性地应用LMU进行风速预测",
        "提出基于CPK的多切片LMU（MSLMU）",
        "构建了WMF-CPK-MSLMU集成模型，提升预测精度和鲁棒性"
      ],
      "methodology": "采用WMF预处理数据，利用MSLMU进行风速预测，CPK自适应加权补偿模型，捕捉时空相关性。",
      "tags": [
        "风速预测",
        "风电场集群",
        "时间序列预测",
        "Legendre Memory Unit",
        "Kendall rank correlation coefficient"
      ],
      "assigned_category": "memory",
      "relevance_score": 5,
      "relevance_reason": "LMU有记忆特性，与memory有一定关联。",
      "analyzed_at": "2026-02-05T06:54:57.017999",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04770v1",
      "title": "Generative Modeling via Drifting",
      "abstract": "Generative modeling can be formulated as learning a mapping f such that its pushforward distribution matches the data distribution. The pushforward behavior can be carried out iteratively at inference time, for example in diffusion and flow-based models. In this paper, we propose a new paradigm called Drifting Models, which evolve the pushforward distribution during training and naturally admit one-step inference. We introduce a drifting field that governs the sample movement and achieves equilibrium when the distributions match. This leads to a training objective that allows the neural network optimizer to evolve the distribution. In experiments, our one-step generator achieves state-of-the-art results on ImageNet at 256 x 256 resolution, with an FID of 1.54 in latent space and 1.61 in pixel space. We hope that our work opens up new opportunities for high-quality one-step generation.",
      "authors": [
        "Mingyang Deng",
        "He Li",
        "Tianhong Li",
        "Yilun Du",
        "Kaiming He"
      ],
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T17:06:49Z",
      "updated": "2026-02-04T17:06:49Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04770v1",
      "abs_url": "http://arxiv.org/abs/2602.04770v1",
      "summary": "提出漂移模型，通过演化分布进行生成建模，实现高质量单步生成。",
      "key_contributions": [
        "提出Drifting Models新范式",
        "实现训练中演化分布",
        "实现单步推理"
      ],
      "methodology": "引入漂移场控制样本移动，使分布匹配达到平衡，从而优化神经网络。",
      "tags": [
        "生成模型",
        "漂移模型",
        "单步生成",
        "图像生成"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 7,
      "relevance_reason": "论文重点是图像生成，属于multimodal领域的重要应用。",
      "analyzed_at": "2026-02-05T06:54:58.892375",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04769v1",
      "title": "NeuroCanvas: VLLM-Powered Robust Seizure Detection by Reformulating Multichannel EEG as Image",
      "abstract": "Accurate and timely seizure detection from Electroencephalography (EEG) is critical for clinical intervention, yet manual review of long-term recordings is labor-intensive. Recent efforts to encode EEG signals into large language models (LLMs) show promise in handling neural signals across diverse patients, but two significant challenges remain: (1) multi-channel heterogeneity, as seizure-relevant information varies substantially across EEG channels, and (2) computing inefficiency, as the EEG signals need to be encoded into a massive number of tokens for the prediction. To address these issues, we draw the EEG signal and propose the novel NeuroCanvas framework. Specifically, NeuroCanvas consists of two modules: (i) The Entropy-guided Channel Selector (ECS) selects the seizure-relevant channels input to LLM and (ii) the following Canvas of Neuron Signal (CNS) converts selected multi-channel heterogeneous EEG signals into structured visual representations. The ECS module alleviates the multi-channel heterogeneity issue, and the CNS uses compact visual tokens to represent the EEG signals that improve the computing efficiency. We evaluate NeuroCanvas across multiple seizure detection datasets, demonstrating a significant improvement of $20\\%$ in F1 score and reductions of $88\\%$ in inference latency. These results highlight NeuroCanvas as a scalable and effective solution for real-time and resource-efficient seizure detection in clinical practice.The code will be released at https://github.com/Yanchen30247/seizure_detect.",
      "authors": [
        "Yan Chen",
        "Jie Peng",
        "Moajjem Hossain Chowdhury",
        "Tianlong Chen",
        "Yunmei Liu"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T17:06:38Z",
      "updated": "2026-02-04T17:06:38Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04769v1",
      "abs_url": "http://arxiv.org/abs/2602.04769v1",
      "summary": "NeuroCanvas利用VLLM将多通道脑电信号转化为图像，实现高效鲁棒的癫痫检测。",
      "key_contributions": [
        "提出了NeuroCanvas框架，用于癫痫检测。",
        "引入熵引导通道选择器(ECS)解决多通道异构性问题。",
        "设计神经信号画布(CNS)将EEG信号转化为紧凑的视觉表征。"
      ],
      "methodology": "将多通道脑电信号转化为图像，利用VLLM进行分析，并通过ECS和CNS优化通道选择和信号表征。",
      "tags": [
        "癫痫检测",
        "脑电信号",
        "多模态学习",
        "VLLM"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于使用VLLM处理图像化后的脑电信号，是典型的多模态应用。",
      "analyzed_at": "2026-02-05T06:55:00.830411",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04764v1",
      "title": "Beyond Many-Shot Translation: Scaling In-Context Demonstrations For Low-Resource Machine Translation",
      "abstract": "Building machine translation (MT) systems for low-resource languages is notably difficult due to the scarcity of high-quality data. Although Large Language Models (LLMs) have improved MT system performance, adapting them to lesser-represented languages remains challenging. In-context learning (ICL) may offer novel ways to adapt LLMs for low-resource MT by conditioning models on demonstration at inference time. In this study, we explore scaling low-resource machine translation ICL beyond the few-shot setting to thousands of examples with long-context models. We scale in-context token budget to 1M tokens and compare three types of training corpora used as in-context supervision: monolingual unsupervised data, instruction-style data, and parallel data (English--target and Indonesian--target). Our experiments on Javanese and Sundanese show that gains from additional context saturate quickly and can degrade near the maximum context window, with scaling behavior strongly dependent on corpus type. Notably, some forms of monolingual supervision can be competitive with parallel data, despite the latter offering additional supervision. Overall, our results characterize the effective limits and corpus-type sensitivity of long-context ICL for low-resource MT, highlighting that larger context windows do not necessarily yield proportional quality gains.",
      "authors": [
        "Luis Frentzen Salim",
        "Esteban Carlin",
        "Alexandre Morinvil",
        "Xi Ai",
        "Lun-Wei Ku"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T17:02:22Z",
      "updated": "2026-02-04T17:02:22Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04764v1",
      "abs_url": "http://arxiv.org/abs/2602.04764v1",
      "summary": "研究了长文本上下文学习在低资源机器翻译中的应用，揭示了其有效性限制和语料类型敏感性。",
      "key_contributions": [
        "探索了长文本上下文学习在低资源机器翻译中的应用",
        "比较了不同类型语料作为上下文信息的有效性",
        "揭示了上下文长度和翻译质量之间的关系，以及语料类型的影响"
      ],
      "methodology": "通过在长文本上下文中提供不同类型的语料（单语、指令、平行语料），评估LLM在Javanese和Sundanese翻译上的表现。",
      "tags": [
        "机器翻译",
        "低资源",
        "上下文学习",
        "LLM"
      ],
      "assigned_category": "memory",
      "relevance_score": 8,
      "relevance_reason": "研究利用长上下文窗口进行信息检索并影响翻译，与memory的RAG相关",
      "analyzed_at": "2026-02-05T06:55:02.828730",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04763v1",
      "title": "Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty",
      "abstract": "Multi-agent systems are increasingly equipped with heterogeneous multimodal sensors, enabling richer perception but introducing modality-specific and agent-dependent uncertainty. Existing multi-agent collaboration frameworks typically reason at the agent level, assume homogeneous sensing, and handle uncertainty implicitly, limiting robustness under sensor corruption. We propose Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty (A2MAML), a principled approach for uncertainty-aware, modality-level collaboration. A2MAML models each modality-specific feature as a stochastic estimate with uncertainty prediction, actively selects reliable agent-modality pairs, and aggregates information via Bayesian inverse-variance weighting. This formulation enables fine-grained, modality-level fusion, supports asymmetric modality availability, and provides a principled mechanism to suppress corrupted or noisy modalities. Extensive experiments on connected autonomous driving scenarios for collaborative accident detection demonstrate that A2MAML consistently outperforms both single-agent and collaborative baselines, achieving up to 18.7% higher accident detection rate.",
      "authors": [
        "Rui Liu",
        "Pratap Tokekar",
        "Ming Lin"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T17:01:31Z",
      "updated": "2026-02-04T17:01:31Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04763v1",
      "abs_url": "http://arxiv.org/abs/2602.04763v1",
      "summary": "A2MAML提出了一种不确定性感知的多模态多智能体学习框架，提升了协作感知系统的鲁棒性。",
      "key_contributions": [
        "提出了针对多智能体多模态场景的不确定性建模方法",
        "引入主动选择机制，选择可靠的智能体-模态组合",
        "采用贝叶斯逆方差加权进行信息融合"
      ],
      "methodology": "将模态特征建模为带有不确定性预测的随机估计，主动选择可靠模态，通过贝叶斯方法融合信息。",
      "tags": [
        "多智能体",
        "多模态学习",
        "不确定性建模",
        "主动学习"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于多智能体协作感知，与Agent方向高度相关，且解决实际问题。",
      "analyzed_at": "2026-02-05T06:55:05.030972",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04757v1",
      "title": "A Dual-TransUNet Deep Learning Framework for Multi-Source Precipitation Merging and Improving Seasonal and Extreme Estimates",
      "abstract": "Multi-source precipitation products (MSPs) from satellite retrievals and reanalysis are widely used for hydroclimatic monitoring, yet spatially heterogeneous biases and limited skill for extremes still constrain their hydrologic utility. Here we develop a dual-stage TransUNet-based multi-source precipitation merging framework (DDL-MSPMF) that integrates six MSPs with four ERA5 near-surface physical predictors. A first-stage classifier estimates daily precipitation occurrence probability, and a second-stage regressor fuses the classifier outputs together with all predictors to estimate daily precipitation amount at 0.25 degree resolution over China for 2001-2020. Benchmarking against multiple deep learning and hybrid baselines shows that the TransUNet - TransUNet configuration yields the best seasonal performance (R = 0.75; RMSE = 2.70 mm/day) and improves robustness relative to a single-regressor setting. For heavy precipitation (>25 mm/day), DDL-MSPMF increases equitable threat scores across most regions of eastern China and better reproduces the spatial pattern of the July 2021 Zhengzhou rainstorm, indicating enhanced extreme-event detection beyond seasonal-mean corrections. Independent evaluation over the Qinghai-Tibet Plateau using TPHiPr further supports its applicability in data-scarce regions. SHAP analysis highlights the importance of precipitation occurrence probabilities and surface pressure, providing physically interpretable diagnostics. The proposed framework offers a scalable and explainable approach for precipitation fusion and extreme-event assessment.",
      "authors": [
        "Yuchen Ye",
        "Zixuan Qi",
        "Shixuan Li",
        "Wei Qi",
        "Yanpeng Cai",
        "Chaoxia Yuan"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T16:55:43Z",
      "updated": "2026-02-04T16:55:43Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04757v1",
      "abs_url": "http://arxiv.org/abs/2602.04757v1",
      "summary": "提出了一个双阶段TransUNet框架，用于融合多源降水数据，提升季节性和极端降水估计。",
      "key_contributions": [
        "开发了双阶段TransUNet降水融合框架DDL-MSPMF",
        "提高了季节性降水估计的准确性(R=0.75; RMSE=2.70 mm/day)",
        "改善了极端降水事件的检测能力"
      ],
      "methodology": "使用双阶段TransUNet，第一阶段分类降水概率，第二阶段回归降水量，并结合ERA5地表物理预测因子。",
      "tags": [
        "降水融合",
        "深度学习",
        "TransUNet",
        "极端降水"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 6,
      "relevance_reason": "虽然主要关注降水，但使用了深度学习中的TransUNet模型，可以看作是涉及多模态数据（空间数据+时间序列数据）处理的一种应用。",
      "analyzed_at": "2026-02-05T06:55:07.268392",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04755v1",
      "title": "When Silence Is Golden: Can LLMs Learn to Abstain in Temporal QA and Beyond?",
      "abstract": "Large language models (LLMs) rarely admit uncertainty, often producing fluent but misleading answers, rather than abstaining (i.e., refusing to answer). This weakness is even evident in temporal question answering, where models frequently ignore time-sensitive evidence and conflate facts across different time-periods. In this paper, we present the first empirical study of training LLMs with an abstention ability while reasoning about temporal QA. Existing approaches such as calibration might be unreliable in capturing uncertainty in complex reasoning. We instead frame abstention as a teachable skill and introduce a pipeline that couples Chain-of-Thought (CoT) supervision with Reinforcement Learning (RL) guided by abstention-aware rewards. Our goal is to systematically analyze how different information types and training techniques affect temporal reasoning with abstention behavior in LLMs. Through extensive experiments studying various methods, we find that RL yields strong empirical gains on reasoning: a model initialized by Qwen2.5-1.5B-Instruct surpasses GPT-4o by $3.46\\%$ and $5.80\\%$ in Exact Match on TimeQA-Easy and Hard, respectively. Moreover, it improves the True Positive rate on unanswerable questions by $20\\%$ over a pure supervised fine-tuned (SFT) variant. Beyond performance, our analysis shows that SFT induces overconfidence and harms reliability, while RL improves prediction accuracy but exhibits similar risks. Finally, by comparing implicit reasoning cues (e.g., original context, temporal sub-context, knowledge graphs) with explicit CoT supervision, we find that implicit information provides limited benefit for reasoning with abstention. Our study provides new insights into how abstention and reasoning can be jointly optimized, providing a foundation for building more reliable LLMs.",
      "authors": [
        "Xinyu Zhou",
        "Chang Jin",
        "Carsten Eickhoff",
        "Zhijiang Guo",
        "Seyed Ali Bahrainian"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T16:54:47Z",
      "updated": "2026-02-04T16:54:47Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04755v1",
      "abs_url": "http://arxiv.org/abs/2602.04755v1",
      "summary": "论文研究了如何训练LLM在时间问答中学会拒绝回答，并利用RL优化其推理能力。",
      "key_contributions": [
        "提出了结合CoT监督和强化学习的框架，用于训练LLM的拒绝回答能力。",
        "系统分析了不同信息类型和训练技术对时间推理和拒绝行为的影响。",
        "实验证明了RL在提升推理能力方面的优势，并超越了GPT-4o。"
      ],
      "methodology": "结合CoT进行监督微调，并使用强化学习，以拒绝回答意识奖励指导模型训练。",
      "tags": [
        "LLM",
        "时间问答",
        "拒绝回答",
        "强化学习",
        "推理"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文核心围绕LLM的推理能力，并提出了具体的改进方法。",
      "analyzed_at": "2026-02-05T06:55:09.267145",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04742v1",
      "title": "Inference-Time Reasoning Selectively Reduces Implicit Social Bias in Large Language Models",
      "abstract": "Drawing on constructs from psychology, prior work has identified a distinction between explicit and implicit bias in large language models (LLMs). While many LLMs undergo post-training alignment and safety procedures to avoid expressions of explicit social bias, they still exhibit significant implicit biases on indirect tasks resembling the Implicit Association Test (IAT). Recent work has further shown that inference-time reasoning can impair LLM performance on tasks that rely on implicit statistical learning. Motivated by a theoretical link between implicit associations and statistical learning in human cognition, we examine how reasoning-enabled inference affects implicit bias in LLMs. We find that enabling reasoning significantly reduces measured implicit bias on an IAT-style evaluation for some model classes across fifteen stereotype topics. This effect appears specific to social bias domains, as we observe no corresponding reduction for non-social implicit associations. As reasoning is increasingly enabled by default in deployed LLMs, these findings suggest that it can meaningfully alter fairness evaluation outcomes in some systems, while also raising questions about how alignment procedures interact with inference-time reasoning to drive variation in bias reduction across model types. More broadly, this work highlights how theory from cognitive science and psychology can complement AI evaluation research by providing methodological and interpretive frameworks that reveal new insights into model behavior.",
      "authors": [
        "Molly Apsel",
        "Michael N. Jones"
      ],
      "categories": [
        "cs.CY",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "published": "2026-02-04T16:44:23Z",
      "updated": "2026-02-04T16:44:23Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04742v1",
      "abs_url": "http://arxiv.org/abs/2602.04742v1",
      "summary": "推理能力能在一定程度上减少大语言模型中内隐的社会偏见。",
      "key_contributions": [
        "发现推理能显著减少LLM的内隐社会偏见",
        "揭示了这种减少偏见效应的领域特异性 (仅在社会偏见领域)",
        "强调了认知科学和心理学理论在AI评估中的价值"
      ],
      "methodology": "采用类似内隐联想测验(IAT)的方法评估LLM的内隐偏见，比较有无推理能力时的偏见程度。",
      "tags": [
        "LLM",
        "Bias",
        "Reasoning",
        "Fairness",
        "Implicit Bias"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文直接研究了推理能力对LLM偏见的影响，核心相关。",
      "analyzed_at": "2026-02-05T06:55:11.300117",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04739v1",
      "title": "Alignment Drift in Multimodal LLMs: A Two-Phase, Longitudinal Evaluation of Harm Across Eight Model Releases",
      "abstract": "Multimodal large language models (MLLMs) are increasingly deployed in real-world systems, yet their safety under adversarial prompting remains underexplored. We present a two-phase evaluation of MLLM harmlessness using a fixed benchmark of 726 adversarial prompts authored by 26 professional red teamers. Phase 1 assessed GPT-4o, Claude Sonnet 3.5, Pixtral 12B, and Qwen VL Plus; Phase 2 evaluated their successors (GPT-5, Claude Sonnet 4.5, Pixtral Large, and Qwen Omni) yielding 82,256 human harm ratings. Large, persistent differences emerged across model families: Pixtral models were consistently the most vulnerable, whereas Claude models appeared safest due to high refusal rates. Attack success rates (ASR) showed clear alignment drift: GPT and Claude models exhibited increased ASR across generations, while Pixtral and Qwen showed modest decreases. Modality effects also shifted over time: text-only prompts were more effective in Phase 1, whereas Phase 2 produced model-specific patterns, with GPT-5 and Claude 4.5 showing near-equivalent vulnerability across modalities. These findings demonstrate that MLLM harmlessness is neither uniform nor stable across updates, underscoring the need for longitudinal, multimodal benchmarks to track evolving safety behaviour.",
      "authors": [
        "Casey Ford",
        "Madison Van Doren",
        "Emily Dix"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T16:42:02Z",
      "updated": "2026-02-04T16:42:02Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04739v1",
      "abs_url": "http://arxiv.org/abs/2602.04739v1",
      "summary": "纵向评估了多模态LLM的安全性，发现其抗对抗性攻击能力随迭代发生漂移。",
      "key_contributions": [
        "构建了多模态LLM对抗性攻击基准测试集",
        "评估了多个MLLM版本的安全性，发现了安全性漂移现象",
        "揭示了不同模态输入对攻击成功率的影响"
      ],
      "methodology": "使用了由专业红队人员设计的对抗性prompt，分两个阶段评估了多个MLLM版本的安全性，并进行了人工评估。",
      "tags": [
        "多模态",
        "LLM",
        "安全性",
        "对抗攻击",
        "漂移"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 10,
      "relevance_reason": "论文直接研究了多模态LLM的安全性和对抗性攻击，属于核心相关。",
      "analyzed_at": "2026-02-05T06:55:13.251976",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04737v1",
      "title": "Rationality Measurement and Theory for Reinforcement Learning Agents",
      "abstract": "This paper proposes a suite of rationality measures and associated theory for reinforcement learning agents, a property increasingly critical yet rarely explored. We define an action in deployment to be perfectly rational if it maximises the hidden true value function in the steepest direction. The expected value discrepancy of a policy's actions against their rational counterparts, culminating over the trajectory in deployment, is defined to be expected rational risk; an empirical average version in training is also defined. Their difference, termed as rational risk gap, is decomposed into (1) an extrinsic component caused by environment shifts between training and deployment, and (2) an intrinsic one due to the algorithm's generalisability in a dynamic environment. They are upper bounded by, respectively, (1) the $1$-Wasserstein distance between transition kernels and initial state distributions in training and deployment, and (2) the empirical Rademacher complexity of the value function class. Our theory suggests hypotheses on the benefits from regularisers (including layer normalisation, $\\ell_2$ regularisation, and weight normalisation) and domain randomisation, as well as the harm from environment shifts. Experiments are in full agreement with these hypotheses. The code is available at https://github.com/EVIEHub/Rationality.",
      "authors": [
        "Kejiang Qian",
        "Amos Storkey",
        "Fengxiang He"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T16:41:22Z",
      "updated": "2026-02-04T16:41:22Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04737v1",
      "abs_url": "http://arxiv.org/abs/2602.04737v1",
      "summary": "该论文提出了一套评估强化学习智能体理性的指标和理论框架，并分析了影响理性行为的因素。",
      "key_contributions": [
        "提出了理性风险和理性风险差距的定义",
        "将理性风险差距分解为环境偏移和算法泛化性两部分",
        "通过理论分析和实验验证，探讨了正则化方法和环境偏移对智能体理性的影响"
      ],
      "methodology": "定义理性指标，理论推导风险上界，并结合实验验证理论假设，分析不同因素对智能体理性的影响。",
      "tags": [
        "强化学习",
        "理性",
        "泛化性",
        "环境偏移",
        "正则化"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文直接研究强化学习智能体的理性行为，是智能体领域的核心问题。",
      "analyzed_at": "2026-02-05T06:55:15.491872",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04731v1",
      "title": "Less Finetuning, Better Retrieval: Rethinking LLM Adaptation for Biomedical Retrievers via Synthetic Data and Model Merging",
      "abstract": "Retrieval-augmented generation (RAG) has become the backbone of grounding Large Language Models (LLMs), improving knowledge updates and reducing hallucinations. Recently, LLM-based retriever models have shown state-of-the-art performance for RAG applications. However, several technical aspects remain underexplored on how to adapt general-purpose LLMs into effective domain-specific retrievers, especially in specialized domains such as biomedicine. We present Synthesize-Train-Merge (STM), a modular framework that enhances decoder-only LLMs with synthetic hard negatives, retrieval prompt optimization, and model merging. Experiments on a subset of 12 medical and general tasks from the MTEB benchmark show STM boosts task-specific experts by up to 23.5\\% (average 7.5\\%) and produces merged models that outperform both single experts and strong baselines without extensive pretraining. Our results demonstrate a scalable, efficient path for turning general LLMs into high-performing, domain-specialized retrievers, preserving general-domain capabilities while excelling on specialized tasks.",
      "authors": [
        "Sameh Khattab",
        "Jean-Philippe Corbeil",
        "Osman Alperen Koraş",
        "Amin Dada",
        "Julian Friedrich",
        "François Beaulieu",
        "Paul Vozila",
        "Jens Kleesiek"
      ],
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T16:36:00Z",
      "updated": "2026-02-04T16:36:00Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04731v1",
      "abs_url": "http://arxiv.org/abs/2602.04731v1",
      "summary": "提出STM框架，通过合成数据、提示优化和模型合并，高效提升LLM在生物医学检索任务上的性能。",
      "key_contributions": [
        "提出Synthesize-Train-Merge (STM) 框架",
        "利用合成硬负样本提升检索性能",
        "通过模型合并提升领域适应性"
      ],
      "methodology": "STM框架包含：生成合成硬负样本、检索提示优化以及模型合并，无需大量预训练即可提升性能。",
      "tags": [
        "RAG",
        "LLM",
        "生物医学",
        "检索"
      ],
      "assigned_category": "memory",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于改进RAG中LLM检索器的性能，直接属于LLM Memory & RAG范畴。",
      "analyzed_at": "2026-02-05T06:55:17.409538",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04726v1",
      "title": "Supporting software engineering tasks with agentic AI: Demonstration on document retrieval and test scenario generation",
      "abstract": "The introduction of large language models ignited great retooling and rethinking of the software development models. The ensuing response of software engineering research yielded a massive body of tools and approaches. In this paper, we join the hassle by introducing agentic AI solutions for two tasks. First, we developed a solution for automatic test scenario generation from a detailed requirements description. This approach relies on specialized worker agents forming a star topology with the supervisor agent in the middle. We demonstrate its capabilities on a real-world example. Second, we developed an agentic AI solution for the document retrieval task in the context of software engineering documents. Our solution enables performing various use cases on a body of documents related to the development of a single software, including search, question answering, tracking changes, and large document summarization. In this case, each use case is handled by a dedicated LLM-based agent, which performs all subtasks related to the corresponding use case. We conclude by hinting at the future perspectives of our line of research.",
      "authors": [
        "Marian Kica",
        "Lukas Radosky",
        "David Slivka",
        "Karin Kubinova",
        "Daniel Dovhun",
        "Tomas Uhercik",
        "Erik Bircak",
        "Ivan Polasek"
      ],
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "published": "2026-02-04T16:33:16Z",
      "updated": "2026-02-04T16:33:16Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04726v1",
      "abs_url": "http://arxiv.org/abs/2602.04726v1",
      "summary": "该论文提出了基于Agentic AI的软件工程解决方案，用于测试场景生成和文档检索。",
      "key_contributions": [
        "提出了基于Agentic AI的测试场景生成方法",
        "提出了基于Agentic AI的软件工程文档检索方法",
        "在真实案例中验证了提出的方法"
      ],
      "methodology": "利用LLM构建多个Agent，通过星型拓扑和专用Agent处理测试场景生成和文档检索任务。",
      "tags": [
        "Agentic AI",
        "软件工程",
        "测试场景生成",
        "文档检索",
        "LLM"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "论文主要关注使用Agentic AI解决软件工程问题，与Agent领域高度相关。",
      "analyzed_at": "2026-02-05T06:55:20.285135",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04713v1",
      "title": "Adaptive Prompt Elicitation for Text-to-Image Generation",
      "abstract": "Aligning text-to-image generation with user intent remains challenging, for users who provide ambiguous inputs and struggle with model idiosyncrasies. We propose Adaptive Prompt Elicitation (APE), a technique that adaptively asks visual queries to help users refine prompts without extensive writing. Our technical contribution is a formulation of interactive intent inference under an information-theoretic framework. APE represents latent intent as interpretable feature requirements using language model priors, adaptively generates visual queries, and compiles elicited requirements into effective prompts. Evaluation on IDEA-Bench and DesignBench shows that APE achieves stronger alignment with improved efficiency. A user study with challenging user-defined tasks demonstrates 19.8% higher alignment without workload overhead. Our work contributes a principled approach to prompting that, for general users, offers an effective and efficient complement to the prevailing prompt-based interaction paradigm with text-to-image models.",
      "authors": [
        "Xinyi Wen",
        "Lena Hegemann",
        "Xiaofu Jin",
        "Shuai Ma",
        "Antti Oulasvirta"
      ],
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "published": "2026-02-04T16:24:46Z",
      "updated": "2026-02-04T16:24:46Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04713v1",
      "abs_url": "http://arxiv.org/abs/2602.04713v1",
      "summary": "APE通过视觉查询交互式地帮助用户优化文本到图像生成的提示词，提升图像与用户意图的对齐。",
      "key_contributions": [
        "提出了自适应提示词诱导（APE）技术",
        "利用信息论框架形式化交互式意图推理",
        "证明了APE在对齐性和效率方面的优越性"
      ],
      "methodology": "APE使用语言模型先验表示潜在意图的特征需求，自适应生成视觉查询，并将提取的需求编译成有效的提示。",
      "tags": [
        "文本到图像生成",
        "提示工程",
        "交互式系统",
        "信息论"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文直接研究了文本到图像生成领域中提示工程的关键问题，并提出了创新方法。",
      "analyzed_at": "2026-02-05T06:55:22.401361",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04712v1",
      "title": "SAR-RAG: ATR Visual Question Answering by Semantic Search, Retrieval, and MLLM Generation",
      "abstract": "We present a visual-context image retrieval-augmented generation (ImageRAG) assisted AI agent for automatic target recognition (ATR) of synthetic aperture radar (SAR). SAR is a remote sensing method used in defense and security applications to detect and monitor the positions of military vehicles, which may appear indistinguishable in images. Researchers have extensively studied SAR ATR to improve the differentiation and identification of vehicle types, characteristics, and measurements. Test examples can be compared with known vehicle target types to improve recognition tasks. New methods enhance the capabilities of neural networks, transformer attention, and multimodal large language models. An agentic AI method may be developed to utilize a defined set of tools, such as searching through a library of similar examples. Our proposed method, SAR Retrieval-Augmented Generation (SAR-RAG), combines a multimodal large language model (MLLM) with a vector database of semantic embeddings to support contextual search for image exemplars with known qualities. By recovering past image examples with known true target types, our SAR-RAG system can compare similar vehicle categories, achieving improved ATR prediction accuracy. We evaluate this through search and retrieval metrics, categorical classification accuracy, and numeric regression of vehicle dimensions. These metrics all show improvements when SAR-RAG is added to an MLLM baseline method as an attached ATR memory bank.",
      "authors": [
        "David F. Ramirez",
        "Tim Overman",
        "Kristen Jaskie",
        "Joe Marvin",
        "Andreas Spanias"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-04T16:23:16Z",
      "updated": "2026-02-04T16:23:16Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04712v1",
      "abs_url": "http://arxiv.org/abs/2602.04712v1",
      "summary": "SAR-RAG通过语义搜索和图像检索增强MLLM，提升合成孔径雷达图像的目标识别精度。",
      "key_contributions": [
        "提出SAR-RAG模型，结合语义搜索和图像检索",
        "利用已知目标类型的图像范例进行对比，提高ATR预测精度",
        "通过检索、分类和回归指标验证了SAR-RAG的有效性"
      ],
      "methodology": "结合MLLM与向量数据库，通过语义嵌入进行上下文搜索，检索相似图像，提升ATR性能。",
      "tags": [
        "SAR",
        "ATR",
        "RAG",
        "MLLM",
        "图像检索"
      ],
      "assigned_category": "memory",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于利用检索增强生成提升目标识别，属于典型的RAG应用。",
      "analyzed_at": "2026-02-05T06:55:24.471158",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04711v1",
      "title": "Addressing Corpus Knowledge Poisoning Attacks on RAG Using Sparse Attention",
      "abstract": "Retrieval Augmented Generation (RAG) is a highly effective paradigm for keeping LLM-based responses up-to-date and reducing the likelihood of hallucinations. Yet, RAG was recently shown to be quite vulnerable to corpus knowledge poisoning: an attacker injects misleading documents to the corpus to steer an LLMs' output to an undesired response. We argue that the standard causal attention mechanism in LLMs enables harmful cross-document interactions, specifically in cases of attacks. Accordingly, we introduce a novel defense approach for RAG: Sparse Document Attention RAG (SDAG). This is a block-sparse attention mechanism that disallows cross-attention between retrieved documents. SDAG requires a minimal inference-time change to the attention mask; furthermore, no fine-tuning or additional architectural changes are needed. We present an empirical evaluation of LLM-based question answering (QA) with a variety of attack strategies on RAG. We show that our SDAG method substantially outperforms the standard causal attention mechanism in terms of attack success rate. We further demonstrate the clear merits of integrating SDAG with state-of-the-art RAG defense methods. Specifically, the integration results in performance that is statistically significantly better than the state-of-the-art.",
      "authors": [
        "Sagie Dekel",
        "Moshe Tennenholtz",
        "Oren Kurland"
      ],
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "published": "2026-02-04T16:22:20Z",
      "updated": "2026-02-04T16:22:20Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04711v1",
      "abs_url": "http://arxiv.org/abs/2602.04711v1",
      "summary": "论文提出一种基于稀疏注意力机制的SDAG方法，用于防御RAG中的知识投毒攻击。",
      "key_contributions": [
        "提出SDAG方法，防御RAG中的知识投毒攻击",
        "SDAG使用块稀疏注意力机制，限制文档间的交叉注意力",
        "实验证明SDAG能有效降低攻击成功率，并能与现有防御方法结合"
      ],
      "methodology": "设计块稀疏注意力机制，阻止检索文档之间的交叉注意力。通过实验验证SDAG在多种攻击策略下的有效性，并与现有方法结合。",
      "tags": [
        "RAG",
        "知识投毒",
        "稀疏注意力",
        "安全"
      ],
      "assigned_category": "memory",
      "relevance_score": 9,
      "relevance_reason": "论文直接针对RAG的知识投毒问题提出解决方案，核心相关。",
      "analyzed_at": "2026-02-05T06:55:26.580410",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04705v1",
      "title": "ERNIE 5.0 Technical Report",
      "abstract": "In this report, we introduce ERNIE 5.0, a natively autoregressive foundation model desinged for unified multimodal understanding and generation across text, image, video, and audio. All modalities are trained from scratch under a unified next-group-of-tokens prediction objective, based on an ultra-sparse mixture-of-experts (MoE) architecture with modality-agnostic expert routing. To address practical challenges in large-scale deployment under diverse resource constraints, ERNIE 5.0 adopts a novel elastic training paradigm. Within a single pre-training run, the model learns a family of sub-models with varying depths, expert capacities, and routing sparsity, enabling flexible trade-offs among performance, model size, and inference latency in memory- or time-constrained scenarios. Moreover, we systematically address the challenges of scaling reinforcement learning to unified foundation models, thereby guaranteeing efficient and stable post-training under ultra-sparse MoE architectures and diverse multimodal settings. Extensive experiments demonstrate that ERNIE 5.0 achieves strong and balanced performance across multiple modalities. To the best of our knowledge, among publicly disclosed models, ERNIE 5.0 represents the first production-scale realization of a trillion-parameter unified autoregressive model that supports both multimodal understanding and generation. To facilitate further research, we present detailed visualizations of modality-agnostic expert routing in the unified model, alongside comprehensive empirical analysis of elastic training, aiming to offer profound insights to the community.",
      "authors": [
        "Haifeng Wang",
        "Hua Wu",
        "Tian Wu",
        "Yu Sun",
        "Jing Liu",
        "Dianhai Yu",
        "Yanjun Ma",
        "Jingzhou He",
        "Zhongjun He",
        "Dou Hong",
        "Qiwen Liu",
        "Shuohuan Wang",
        "Junyuan Shang",
        "Zhenyu Zhang",
        "Yuchen Ding",
        "Jinle Zeng",
        "Jiabin Yang",
        "Liang Shen",
        "Ruibiao Chen",
        "Weichong Yin",
        "Siyu Ding",
        "Dai Dai",
        "Shikun Feng",
        "Siqi Bao",
        "Bolei He",
        "Yan Chen",
        "Zhenyu Jiao",
        "Ruiqing Zhang",
        "Zeyu Chen",
        "Qingqing Dang",
        "Kaipeng Deng",
        "Jiajun Jiang",
        "Enlei Gong",
        "Guoxia Wang",
        "Yanlin Sha",
        "Yi Liu",
        "Yehan Zheng",
        "Weijian Xu",
        "Jiaxiang Liu",
        "Zengfeng Zeng",
        "Yingqi Qu",
        "Zhongli Li",
        "Zhengkun Zhang",
        "Xiyang Wang",
        "Zixiang Xu",
        "Xinchao Xu",
        "Zhengjie Huang",
        "Dong Wang",
        "Bingjin Chen",
        "Yue Chang",
        "Xing Yuan",
        "Shiwei Huang",
        "Qiao Zhao",
        "Xinzhe Ding",
        "Shuangshuang Qiao",
        "Baoshan Yang",
        "Bihong Tang",
        "Bin Li",
        "Bingquan Wang",
        "Binhan Tang",
        "Binxiong Zheng",
        "Bo Cui",
        "Bo Ke",
        "Bo Zhang",
        "Bowen Zhang",
        "Boyan Zhang",
        "Boyang Liu",
        "Caiji Zhang",
        "Can Li",
        "Chang Xu",
        "Chao Pang",
        "Chao Zhang",
        "Chaoyi Yuan",
        "Chen Chen",
        "Cheng Cui",
        "Chenlin Yin",
        "Chun Gan",
        "Chunguang Chai",
        "Chuyu Fang",
        "Cuiyun Han",
        "Dan Zhang",
        "Danlei Feng",
        "Danxiang Zhu",
        "Dong Sun",
        "Dongbo Li",
        "Dongdong Li",
        "Dongdong Liu",
        "Dongxue Liu",
        "Fan Ding",
        "Fan Hu",
        "Fan Li",
        "Fan Mo",
        "Feisheng Wu",
        "Fengwei Liu",
        "Gangqiang Hu",
        "Gaofeng Lu",
        "Gaopeng Yong",
        "Gexiao Tian",
        "Guan Wang",
        "Guangchen Ni",
        "Guangshuo Wu",
        "Guanzhong Wang",
        "Guihua Liu",
        "Guishun Li",
        "Haibin Li",
        "Haijian Liang",
        "Haipeng Ming",
        "Haisu Wang",
        "Haiyang Lu",
        "Haiye Lin",
        "Han Zhou",
        "Hangting Lou",
        "Hanwen Du",
        "Hanzhi Zhang",
        "Hao Chen",
        "Hao Du",
        "Hao Liu",
        "Hao Zhou",
        "Haochen Jiang",
        "Haodong Tian",
        "Haoshuang Wang",
        "Haozhe Geng",
        "Heju Yin",
        "Hong Chen",
        "Hongchen Xue",
        "Hongen Liu",
        "Honggeng Zhang",
        "Hongji Xu",
        "Hongwei Chen",
        "Hongyang Zhang",
        "Hongyuan Zhang",
        "Hua Lu",
        "Huan Chen",
        "Huan Wang",
        "Huang He",
        "Hui Liu",
        "Hui Zhong",
        "Huibin Ruan",
        "Jiafeng Lu",
        "Jiage Liang",
        "Jiahao Hu",
        "Jiahao Hu",
        "Jiajie Yang",
        "Jialin Li",
        "Jian Chen",
        "Jian Wu",
        "Jianfeng Yang",
        "Jianguang Jiang",
        "Jianhua Wang",
        "Jianye Chen",
        "Jiaodi Liu",
        "Jiarui Zhou",
        "Jiawei Lv",
        "Jiaxin Zhou",
        "Jiaxuan Liu",
        "Jie Han",
        "Jie Sun",
        "Jiefan Fang",
        "Jihan Liu",
        "Jihua Liu",
        "Jing Hu",
        "Jing Qian",
        "Jing Yan",
        "Jingdong Du",
        "Jingdong Wang",
        "Jingjing Wu",
        "Jingyong Li",
        "Jinheng Wang",
        "Jinjin Li",
        "Jinliang Lu",
        "Jinlin Yu",
        "Jinnan Liu",
        "Jixiang Feng",
        "Jiyi Huang",
        "Jiyuan Zhang",
        "Jun Liang",
        "Jun Xia",
        "Jun Yu",
        "Junda Chen",
        "Junhao Feng",
        "Junhong Xiang",
        "Junliang Li",
        "Kai Liu",
        "Kailun Chen",
        "Kairan Su",
        "Kang Hu",
        "Kangkang Zhou",
        "Ke Chen",
        "Ke Wei",
        "Kui Huang",
        "Kun Wu",
        "Kunbin Chen",
        "Lei Han",
        "Lei Sun",
        "Lei Wen",
        "Linghui Meng",
        "Linhao Yu",
        "Liping Ouyang",
        "Liwen Zhang",
        "Longbin Ji",
        "Longzhi Wang",
        "Meng Sun",
        "Meng Tian",
        "Mengfei Li",
        "Mengqi Zeng",
        "Mengyu Zhang",
        "Ming Hong",
        "Mingcheng Zhou",
        "Mingming Huang",
        "Mingxin Chen",
        "Mingzhu Cai",
        "Naibin Gu",
        "Nemin Qiu",
        "Nian Wang",
        "Peng Qiu",
        "Peng Zhao",
        "Pengyu Zou",
        "Qi Wang",
        "Qi Xin",
        "Qian Wang",
        "Qiang Zhu",
        "Qianhui Luo",
        "Qianwei Yang",
        "Qianyue He",
        "Qifei Wu",
        "Qinrui Li",
        "Qiwen Bao",
        "Quan Zhang",
        "Quanxiang Liu",
        "Qunyi Xie",
        "Rongrui Zhan",
        "Rufeng Dai",
        "Rui Peng",
        "Ruian Liu",
        "Ruihao Xu",
        "Ruijie Wang",
        "Ruixi Zhang",
        "Ruixuan Liu",
        "Runsheng Shi",
        "Ruting Wang",
        "Senbo Kang",
        "Shan Lu",
        "Shaofei Yu",
        "Shaotian Gong",
        "Shenwei Hu",
        "Shifeng Zheng",
        "Shihao Guo",
        "Shilong Fan",
        "Shiqin Liu",
        "Shiwei Gu",
        "Shixi Zhang",
        "Shuai Yao",
        "Shuang Zhang",
        "Shuangqiao Liu",
        "Shuhao Liang",
        "Shuwei He",
        "Shuwen Yang",
        "Sijun He",
        "Siming Dai",
        "Siming Wu",
        "Siyi Long",
        "Songhe Deng",
        "Suhui Dong",
        "Suyin Liang",
        "Teng Hu",
        "Tianchan Xu",
        "Tianliang Lv",
        "Tianmeng Yang",
        "Tianyi Wei",
        "Tiezhu Gao",
        "Ting Sun",
        "Ting Zhang",
        "Tingdan Luo",
        "Wei He",
        "Wei Luan",
        "Wei Yin",
        "Wei Zhang",
        "Wei Zhou",
        "Weibao Gong",
        "Weibin Li",
        "Weicheng Huang",
        "Weichong Dang",
        "Weiguo Zhu",
        "Weilong Zhang",
        "Weiqi Tan",
        "Wen Huang",
        "Wenbin Chang",
        "Wenjing Du",
        "Wenlong Miao",
        "Wenpei Luo",
        "Wenquan Wu",
        "Xi Shi",
        "Xi Zhao",
        "Xiang Gao",
        "Xiangguo Zhang",
        "Xiangrui Yu",
        "Xiangsen Wang",
        "Xiangzhe Wang",
        "Xianlong Luo",
        "Xianying Ma",
        "Xiao Tan",
        "Xiaocong Lin",
        "Xiaofei Wang",
        "Xiaofeng Peng",
        "Xiaofeng Wu",
        "Xiaojian Xu",
        "Xiaolan Yuan",
        "Xiaopeng Cui",
        "Xiaotian Han",
        "Xiaoxiong Liu",
        "Xiaoxu Fei",
        "Xiaoxuan Wu",
        "Xiaoyu Wang",
        "Xiaoyu Zhang",
        "Xin Sun",
        "Xin Wang",
        "Xinhui Huang",
        "Xinming Zhu",
        "Xintong Yu",
        "Xinyi Xu",
        "Xinyu Wang",
        "Xiuxian Li",
        "XuanShi Zhu",
        "Xue Xu",
        "Xueying Lv",
        "Xuhong Li",
        "Xulong Wei",
        "Xuyi Chen",
        "Yabing Shi",
        "Yafeng Wang",
        "Yamei Li",
        "Yan Liu",
        "Yanfu Cheng",
        "Yang Gao",
        "Yang Liang",
        "Yang Wang",
        "Yang Wang",
        "Yang Yang",
        "Yanlong Liu",
        "Yannian Fu",
        "Yanpeng Wang",
        "Yanzheng Lin",
        "Yao Chen",
        "Yaozong Shen",
        "Yaqian Han",
        "Yehua Yang",
        "Yekun Chai",
        "Yesong Wang",
        "Yi Song",
        "Yichen Zhang",
        "Yifei Wang",
        "Yifeng Guo",
        "Yifeng Kou",
        "Yilong Chen",
        "Yilong Guo",
        "Yiming Wang",
        "Ying Chen",
        "Ying Wang",
        "Yingsheng Wu",
        "Yingzhan Lin",
        "Yinqi Yang",
        "Yiran Xing",
        "Yishu Lei",
        "Yixiang Tu",
        "Yiyan Chen",
        "Yong Zhang",
        "Yonghua Li",
        "Yongqiang Ma",
        "Yongxing Dai",
        "Yongyue Zhang",
        "Yu Ran",
        "Yu Sun",
        "Yu-Wen Michael Zhang",
        "Yuang Liu",
        "Yuanle Liu",
        "Yuanyuan Zhou",
        "Yubo Zhang",
        "Yuchen Han",
        "Yucheng Wang",
        "Yude Gao",
        "Yuedong Luo",
        "Yuehu Dong",
        "Yufeng Hu",
        "Yuhui Cao",
        "Yuhui Yun",
        "Yukun Chen",
        "Yukun Gao",
        "Yukun Li",
        "Yumeng Zhang",
        "Yun Fan",
        "Yun Ma",
        "Yunfei Zhang",
        "Yunshen Xie",
        "Yuping Xu",
        "Yuqin Zhang",
        "Yuqing Liu",
        "Yurui Li",
        "Yuwen Wang",
        "Yuxiang Lu",
        "Zefeng Cai",
        "Zelin Zhao",
        "Zelun Zhang",
        "Zenan Lin",
        "Zezhao Dong",
        "Zhaowu Pan",
        "Zhaoyu Liu",
        "Zhe Dong",
        "Zhe Zhang",
        "Zhen Zhang",
        "Zhengfan Wu",
        "Zhengrui Wei",
        "Zhengsheng Ning",
        "Zhenxing Li",
        "Zhenyu Li",
        "Zhenyu Qian",
        "Zhenyun Li",
        "Zhi Li",
        "Zhichao Chen",
        "Zhicheng Dong",
        "Zhida Feng",
        "Zhifan Feng",
        "Zhihao Deng",
        "Zhijin Yu",
        "Zhiyang Chen",
        "Zhonghui Zheng",
        "Zhuangzhuang Guo",
        "Zhujun Zhang",
        "Zhuo Sun",
        "Zichang Liu",
        "Zihan Lin",
        "Zihao Huang",
        "Zihe Zhu",
        "Ziheng Zhao",
        "Ziping Chen",
        "Zixuan Zhu",
        "Ziyang Xu",
        "Ziyi Liang",
        "Ziyuan Gao"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T16:18:15Z",
      "updated": "2026-02-04T16:18:15Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04705v1",
      "abs_url": "http://arxiv.org/abs/2602.04705v1",
      "summary": "ERNIE 5.0 是一个统一多模态理解和生成的原生自回归基础模型，具有弹性训练和MoE架构。",
      "key_contributions": [
        "提出了统一多模态理解和生成的原生自回归基础模型ERNIE 5.0",
        "采用超稀疏混合专家（MoE）架构和模态无关的专家路由",
        "引入弹性训练范式，支持性能、模型大小和推理延迟的灵活权衡"
      ],
      "methodology": "采用原生自回归架构，统一的下一组tokens预测目标，超稀疏MoE架构，模态无关专家路由和弹性训练。",
      "tags": [
        "Multimodal Learning",
        "Autoregressive Model",
        "Mixture-of-Experts"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心是多模态学习模型的构建和训练，直接研究多模态领域的关键问题。",
      "analyzed_at": "2026-02-05T06:55:29.341240",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04703v1",
      "title": "Knowledge Distillation for mmWave Beam Prediction Using Sub-6 GHz Channels",
      "abstract": "Beamforming in millimeter-wave (mmWave) high-mobility environments typically incurs substantial training overhead. While prior studies suggest that sub-6 GHz channels can be exploited to predict optimal mmWave beams, existing methods depend on large deep learning (DL) models with prohibitive computational and memory requirements. In this paper, we propose a computationally efficient framework for sub-6 GHz channel-mmWave beam mapping based on the knowledge distillation (KD) technique. We develop two compact student DL architectures based on individual and relational distillation strategies, which retain only a few hidden layers yet closely mimic the performance of large teacher DL models. Extensive simulations demonstrate that the proposed student models achieve the teacher's beam prediction accuracy and spectral efficiency while reducing trainable parameters and computational complexity by 99%.",
      "authors": [
        "Sina Tavakolian",
        "Nhan Thanh Nguyen",
        "Ahmed Alkhateeb",
        "Markku Juntti"
      ],
      "categories": [
        "eess.SP",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "published": "2026-02-04T16:15:32Z",
      "updated": "2026-02-04T16:15:32Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04703v1",
      "abs_url": "http://arxiv.org/abs/2602.04703v1",
      "summary": "利用知识蒸馏技术，论文提出一种高效的毫米波波束预测框架，显著降低计算和存储需求。",
      "key_contributions": [
        "提出基于知识蒸馏的毫米波波束预测框架",
        "设计两种紧凑的学生模型架构",
        "大幅降低计算复杂度和模型参数量"
      ],
      "methodology": "利用子6 GHz信道信息，通过知识蒸馏训练小型学生模型，模仿大型教师模型的波束预测性能。",
      "tags": [
        "毫米波",
        "波束预测",
        "知识蒸馏",
        "深度学习",
        "sub-6 GHz"
      ],
      "assigned_category": "agent",
      "relevance_score": 6,
      "relevance_reason": "波束预测可用于智能体的环境感知，有一定相关性。",
      "analyzed_at": "2026-02-05T06:55:31.232225",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04699v1",
      "title": "Annotation Free Spacecraft Detection and Segmentation using Vision Language Models",
      "abstract": "Vision Language Models (VLMs) have demonstrated remarkable performance in open-world zero-shot visual recognition. However, their potential in space-related applications remains largely unexplored. In the space domain, accurate manual annotation is particularly challenging due to factors such as low visibility, illumination variations, and object blending with planetary backgrounds. Developing methods that can detect and segment spacecraft and orbital targets without requiring extensive manual labeling is therefore of critical importance. In this work, we propose an annotation-free detection and segmentation pipeline for space targets using VLMs. Our approach begins by automatically generating pseudo-labels for a small subset of unlabeled real data with a pre-trained VLM. These pseudo-labels are then leveraged in a teacher-student label distillation framework to train lightweight models. Despite the inherent noise in the pseudo-labels, the distillation process leads to substantial performance gains over direct zero-shot VLM inference. Experimental evaluations on the SPARK-2024, SPEED+, and TANGO datasets on segmentation tasks demonstrate consistent improvements in average precision (AP) by up to 10 points. Code and models are available at https://github.com/giddyyupp/annotation-free-spacecraft-segmentation.",
      "authors": [
        "Samet Hicsonmez",
        "Jose Sosa",
        "Dan Pineau",
        "Inder Pal Singh",
        "Arunkumar Rathinam",
        "Abd El Rahman Shabayek",
        "Djamila Aouada"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-04T16:07:29Z",
      "updated": "2026-02-04T16:07:29Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04699v1",
      "abs_url": "http://arxiv.org/abs/2602.04699v1",
      "summary": "提出一种基于视觉语言模型（VLM）的无标注航天器检测与分割框架，显著提升了航天器图像处理性能。",
      "key_contributions": [
        "提出annotation-free的航天器检测与分割流程",
        "利用预训练VLM自动生成伪标签",
        "应用teacher-student模型蒸馏框架",
        "实验证明在多个数据集上性能提升"
      ],
      "methodology": "利用VLM生成伪标签，构建teacher-student框架，通过标签蒸馏训练轻量级模型，实现无标注航天器检测与分割。",
      "tags": [
        "VLM",
        "zero-shot learning",
        "spacecraft detection",
        "segmentation",
        "label distillation"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心是利用VLM解决视觉任务，属于multimodal learning的核心问题。",
      "analyzed_at": "2026-02-05T06:55:33.184283",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04693v1",
      "title": "LinGO: A Linguistic Graph Optimization Framework with LLMs for Interpreting Intents of Online Uncivil Discourse",
      "abstract": "Detecting uncivil language is crucial for maintaining safe, inclusive, and democratic online spaces. Yet existing classifiers often misinterpret posts containing uncivil cues but expressing civil intents, leading to inflated estimates of harmful incivility online. We introduce LinGO, a linguistic graph optimization framework for large language models (LLMs) that leverages linguistic structures and optimization techniques to classify multi-class intents of incivility that use various direct and indirect expressions. LinGO decomposes language into multi-step linguistic components, identifies targeted steps that cause the most errors, and iteratively optimizes prompt and/or example components for targeted steps. We evaluate it using a dataset collected during the 2022 Brazilian presidential election, encompassing four forms of political incivility: Impoliteness (IMP), Hate Speech and Stereotyping (HSST), Physical Harm and Violent Political Rhetoric (PHAVPR), and Threats to Democratic Institutions and Values (THREAT). Each instance is annotated with six types of civil/uncivil intent. We benchmark LinGO using three cost-efficient LLMs: GPT-5-mini, Gemini 2.5 Flash-Lite, and Claude 3 Haiku, and four optimization techniques: TextGrad, AdalFlow, DSPy, and Retrieval-Augmented Generation (RAG). The results show that, across all models, LinGO consistently improves accuracy and weighted F1 compared with zero-shot, chain-of-thought, direct optimization, and fine-tuning baselines. RAG is the strongest optimization technique and, when paired with Gemini model, achieves the best overall performance. These findings demonstrate that incorporating multi-step linguistic components into LLM instructions and optimize targeted components can help the models explain complex semantic meanings, which can be extended to other complex semantic explanation tasks in the future.",
      "authors": [
        "Yuan Zhang",
        "Thales Bertaglia"
      ],
      "categories": [
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T15:56:35Z",
      "updated": "2026-02-04T15:56:35Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04693v1",
      "abs_url": "http://arxiv.org/abs/2602.04693v1",
      "summary": "LinGO利用语言图优化LLM，提升在线不文明言论意图识别准确性。",
      "key_contributions": [
        "提出了LinGO框架，用于多类意图不文明言论分类。",
        "分解语言为多步语言成分，针对性优化错误步骤。",
        "验证了RAG结合Gemini模型在不文明言论识别上的有效性。"
      ],
      "methodology": "LinGO将语言分解为多步语言成分，利用优化技术改进LLM的prompt和示例，提升意图识别的准确率。",
      "tags": [
        "不文明言论检测",
        "语言图优化",
        "LLM",
        "意图识别",
        "RAG"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "论文核心在于提升LLM理解和推理复杂语义的能力，优化模型性能。",
      "analyzed_at": "2026-02-05T06:55:35.181255",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04692v1",
      "title": "DRMOT: A Dataset and Framework for RGBD Referring Multi-Object Tracking",
      "abstract": "Referring Multi-Object Tracking (RMOT) aims to track specific targets based on language descriptions and is vital for interactive AI systems such as robotics and autonomous driving. However, existing RMOT models rely solely on 2D RGB data, making it challenging to accurately detect and associate targets characterized by complex spatial semantics (e.g., ``the person closest to the camera'') and to maintain reliable identities under severe occlusion, due to the absence of explicit 3D spatial information. In this work, we propose a novel task, RGBD Referring Multi-Object Tracking (DRMOT), which explicitly requires models to fuse RGB, Depth (D), and Language (L) modalities to achieve 3D-aware tracking. To advance research on the DRMOT task, we construct a tailored RGBD referring multi-object tracking dataset, named DRSet, designed to evaluate models' spatial-semantic grounding and tracking capabilities. Specifically, DRSet contains RGB images and depth maps from 187 scenes, along with 240 language descriptions, among which 56 descriptions incorporate depth-related information. Furthermore, we propose DRTrack, a MLLM-guided depth-referring tracking framework. DRTrack performs depth-aware target grounding from joint RGB-D-L inputs and enforces robust trajectory association by incorporating depth cues. Extensive experiments on the DRSet dataset demonstrate the effectiveness of our framework.",
      "authors": [
        "Sijia Chen",
        "Lijuan Ma",
        "Yanqiu Yu",
        "En Yu",
        "Liman Liu",
        "Wenbing Tao"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-04T15:56:16Z",
      "updated": "2026-02-04T15:56:16Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04692v1",
      "abs_url": "http://arxiv.org/abs/2602.04692v1",
      "summary": "提出RGBD指代多目标跟踪任务，构建DRSet数据集，提出DRTrack框架。",
      "key_contributions": [
        "提出RGBD指代多目标跟踪任务(DRMOT)",
        "构建用于DRMOT的DRSet数据集",
        "提出MLLM引导的深度指代跟踪框架DRTrack"
      ],
      "methodology": "提出DRTrack框架，利用MLLM进行深度感知的目标定位，并融合深度信息进行轨迹关联。",
      "tags": [
        "RGBD",
        "Referring Multi-Object Tracking",
        "Multimodal Learning",
        "Depth Perception"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于多模态学习，融合RGBD和语言信息进行目标跟踪。",
      "analyzed_at": "2026-02-05T06:55:37.044224",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04674v1",
      "title": "Overstating Attitudes, Ignoring Networks: LLM Biases in Simulating Misinformation Susceptibility",
      "abstract": "Large language models (LLMs) are increasingly used as proxies for human judgment in computational social science, yet their ability to reproduce patterns of susceptibility to misinformation remains unclear. We test whether LLM-simulated survey respondents, prompted with participant profiles drawn from social survey data measuring network, demographic, attitudinal and behavioral features, can reproduce human patterns of misinformation belief and sharing. Using three online surveys as baselines, we evaluate whether LLM outputs match observed response distributions and recover feature-outcome associations present in the original survey data. LLM-generated responses capture broad distributional tendencies and show modest correlation with human responses, but consistently overstate the association between belief and sharing. Linear models fit to simulated responses exhibit substantially higher explained variance and place disproportionate weight on attitudinal and behavioral features, while largely ignoring personal network characteristics, relative to models fit to human responses. Analyses of model-generated reasoning and LLM training data suggest that these distortions reflect systematic biases in how misinformation-related concepts are represented. Our findings suggest that LLM-based survey simulations are better suited for diagnosing systematic divergences from human judgment than for substituting it.",
      "authors": [
        "Eun Cheol Choi",
        "Lindsay E. Young",
        "Emilio Ferrara"
      ],
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SI",
      "published": "2026-02-04T15:48:05Z",
      "updated": "2026-02-04T15:48:05Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04674v1",
      "abs_url": "http://arxiv.org/abs/2602.04674v1",
      "summary": "LLM模拟人类对虚假信息的易感性时，高估了态度影响，忽略了社交网络的作用。",
      "key_contributions": [
        "揭示了LLM在模拟虚假信息易感性时存在的偏差。",
        "评估了LLM在重现人类虚假信息信念和分享模式方面的能力。",
        "分析了LLM的推理过程和训练数据，解释偏差产生的原因。"
      ],
      "methodology": "利用社交调查数据，构建参与者画像，用LLM模拟受访者，对比LLM输出与人类数据，分析特征关联性。",
      "tags": [
        "LLM",
        "虚假信息",
        "偏差",
        "社会科学",
        "模拟"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "研究LLM在模拟人类社会行为时的推理能力偏差，高度相关。",
      "analyzed_at": "2026-02-05T06:55:39.151597",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04672v1",
      "title": "AGILE: Hand-Object Interaction Reconstruction from Video via Agentic Generation",
      "abstract": "Reconstructing dynamic hand-object interactions from monocular videos is critical for dexterous manipulation data collection and creating realistic digital twins for robotics and VR. However, current methods face two prohibitive barriers: (1) reliance on neural rendering often yields fragmented, non-simulation-ready geometries under heavy occlusion, and (2) dependence on brittle Structure-from-Motion (SfM) initialization leads to frequent failures on in-the-wild footage. To overcome these limitations, we introduce AGILE, a robust framework that shifts the paradigm from reconstruction to agentic generation for interaction learning. First, we employ an agentic pipeline where a Vision-Language Model (VLM) guides a generative model to synthesize a complete, watertight object mesh with high-fidelity texture, independent of video occlusions. Second, bypassing fragile SfM entirely, we propose a robust anchor-and-track strategy. We initialize the object pose at a single interaction onset frame using a foundation model and propagate it temporally by leveraging the strong visual similarity between our generated asset and video observations. Finally, a contact-aware optimization integrates semantic, geometric, and interaction stability constraints to enforce physical plausibility. Extensive experiments on HO3D, DexYCB, and in-the-wild videos reveal that AGILE outperforms baselines in global geometric accuracy while demonstrating exceptional robustness on challenging sequences where prior art frequently collapses. By prioritizing physical validity, our method produces simulation-ready assets validated via real-to-sim retargeting for robotic applications.",
      "authors": [
        "Jin-Chuan Shi",
        "Binhong Ye",
        "Tao Liu",
        "Junzhe He",
        "Yangjinhui Xu",
        "Xiaoyang Liu",
        "Zeju Li",
        "Hao Chen",
        "Chunhua Shen"
      ],
      "categories": [
        "cs.CV",
        "cs.GR",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-04T15:42:58Z",
      "updated": "2026-02-04T15:42:58Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04672v1",
      "abs_url": "http://arxiv.org/abs/2602.04672v1",
      "summary": "AGILE利用Agentic生成方法，从视频中重建鲁棒的、物理上合理的交互物体。",
      "key_contributions": [
        "提出基于VLM引导的Agentic生成流程，合成完整物体网格。",
        "提出稳健的anchor-and-track策略，摆脱对SfM的依赖。",
        "设计考虑接触的优化方法，保证物理合理性。"
      ],
      "methodology": "采用Agentic生成完整物体模型，利用anchor-and-track策略跟踪物体姿态，并通过接触感知优化提高物理合理性。",
      "tags": [
        "手-物体交互",
        "视频重建",
        "Agentic生成",
        "VLM"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 8,
      "relevance_reason": "论文核心是利用VLM进行视觉信息的生成与处理，属于多模态学习范畴。",
      "analyzed_at": "2026-02-05T06:55:41.330507",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04667v1",
      "title": "Causal explanations of outliers in systems with lagged time-dependencies",
      "abstract": "Root-cause analysis in controlled time dependent systems poses a major challenge in applications. Especially energy systems are difficult to handle as they exhibit instantaneous as well as delayed effects and if equipped with storage, do have a memory. In this paper we adapt the causal root-cause analysis method of Budhathoki et al. [2022] to general time-dependent systems, as it can be regarded as a strictly causal definition of the term \"root-cause\". Particularly, we discuss two truncation approaches to handle the infinite dependency graphs present in time-dependent systems. While one leaves the causal mechanisms intact, the other approximates the mechanisms at the start nodes. The effectiveness of the different approaches is benchmarked using a challenging data generation process inspired by a problem in factory energy management: the avoidance of peaks in the power consumption. We show that given enough lags our extension is able to localize the root-causes in the feature and time domain. Further the effect of mechanism approximation is discussed.",
      "authors": [
        "Philipp Alexander Schwarz",
        "Johannes Oberpriller",
        "Sven Klaassen"
      ],
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "published": "2026-02-04T15:37:40Z",
      "updated": "2026-02-04T15:37:40Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04667v1",
      "abs_url": "http://arxiv.org/abs/2602.04667v1",
      "summary": "论文改进因果根因分析方法，应用于时变系统异常检测，尤其针对能源系统峰值避免问题。",
      "key_contributions": [
        "扩展因果根因分析方法到时变系统",
        "提出两种处理无限依赖图的截断方法",
        "在能源管理场景下验证方法有效性"
      ],
      "methodology": "基于Budhathoki et al. [2022]的因果根因分析方法，通过截断依赖图处理时变性，并进行实验验证。",
      "tags": [
        "因果分析",
        "根因分析",
        "时变系统",
        "异常检测",
        "能源管理"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 7,
      "relevance_reason": "论文关注因果推理，以寻找系统异常的根本原因。",
      "analyzed_at": "2026-02-05T06:55:43.242339",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04657v1",
      "title": "PIO-FVLM: Rethinking Training-Free Visual Token Reduction for VLM Acceleration from an Inference-Objective Perspective",
      "abstract": "Recently, reducing redundant visual tokens in vision-language models (VLMs) to accelerate VLM inference has emerged as a hot topic. However, most existing methods rely on heuristics constructed based on inter-visual-token similarity or cross-modal visual-text similarity, which gives rise to certain limitations in compression performance and practical deployment. In contrast, we propose PIO-FVLM from the perspective of inference objectives, which transforms visual token compression into preserving output result invariance and selects tokens primarily by their importance to this goal. Specially, vision tokens are reordered with the guidance of token-level gradient saliency generated by our designed layer-local proxy loss, a coarse constraint from the current layer to the final result. Then the most valuable vision tokens are selected following the non-maximum suppression (NMS) principle. The proposed PIO-FVLM is training-free and compatible with FlashAttention, friendly to practical application and deployment. It can be deployed independently as an encoder-free method, or combined with encoder compression approaches like VisionZip for use as an encoder-involved method. On LLaVA-Next-7B, PIO-FVLM retains just 11.1% of visual tokens but maintains 97.2% of the original performance, with a 2.67$\\times$ prefill speedup, 2.11$\\times$ inference speedup, 6.22$\\times$ lower FLOPs, and 6.05$\\times$ reduced KV Cache overhead. Our code is available at https://github.com/ocy1/PIO-FVLM.",
      "authors": [
        "Haokui Zhang",
        "Congyang Ou",
        "Dawei Yan",
        "Peng Wang",
        "Qingsen Yan",
        "Ying Li",
        "Rong Xiao",
        "Chunhua Shen"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-04T15:33:10Z",
      "updated": "2026-02-04T15:33:10Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04657v1",
      "abs_url": "http://arxiv.org/abs/2602.04657v1",
      "summary": "PIO-FVLM通过目标导向的视觉token缩减加速VLM推理，保持性能的同时显著提升效率。",
      "key_contributions": [
        "提出了一种训练无关的视觉token缩减方法PIO-FVLM",
        "利用层局部代理损失指导token重要性排序",
        "兼容FlashAttention，易于实际部署"
      ],
      "methodology": "利用层局部代理损失生成token级梯度显著性，指导token重排序，并使用NMS选择最重要的token，实现视觉token压缩。",
      "tags": [
        "VLM",
        "Token Reduction",
        "Inference Acceleration",
        "Multimodal Learning"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于优化VLM推理效率，属于Multimodal Learning的关键研究方向。",
      "analyzed_at": "2026-02-05T06:55:45.388463",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04649v1",
      "title": "Outcome Accuracy is Not Enough: Aligning the Reasoning Process of Reward Models",
      "abstract": "Generative Reward Models (GenRMs) and LLM-as-a-Judge exhibit deceptive alignment by producing correct judgments for incorrect reasons, as they are trained and evaluated to prioritize Outcome Accuracy, which undermines their ability to generalize during RLHF. We introduce Rationale Consistency, a fine-grained metric that quantifies the alignment between the model's reasoning process and human judgment. Our evaluation of frontier models reveals that rationale consistency effectively discriminates among state-of-the-art models and detects deceptive alignment, while outcome accuracy falls short in both respects. To mitigate this gap, we introduce a hybrid signal that combines rationale consistency with outcome accuracy for GenRM training. Our training method achieves state-of-the-art performance on RM-Bench (87.1%) and JudgeBench (82%), surpassing outcome-only baselines by an average of 5%. Using RM during RLHF, our method effectively improves performance as demonstrated on Arena Hard v2, notably yielding a 7% improvement in creative writing tasks. Further analysis confirms that our method escapes the deceptive alignment trap, effectively reversing the decline in rationale consistency observed in outcome-only training.",
      "authors": [
        "Binghai Wang",
        "Yantao Liu",
        "Yuxuan Liu",
        "Tianyi Tang",
        "Shenzhi Wang",
        "Chang Gao",
        "Chujie Zheng",
        "Yichang Zhang",
        "Le Yu",
        "Shixuan Liu",
        "Tao Gui",
        "Qi Zhang",
        "Xuanjing Huang",
        "Bowen Yu",
        "Fei Huang",
        "Junyang Lin"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T15:24:52Z",
      "updated": "2026-02-04T15:24:52Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04649v1",
      "abs_url": "http://arxiv.org/abs/2602.04649v1",
      "summary": "GenRM只追求结果准确性导致欺骗性对齐，本文提出Rationale一致性指标并改进训练方法。",
      "key_contributions": [
        "提出Rationale一致性指标，用于衡量推理过程与人类判断的对齐程度",
        "发现现有模型存在欺骗性对齐问题",
        "提出结合Rationale一致性和结果准确性的混合训练方法，提升GenRM性能并缓解欺骗性对齐"
      ],
      "methodology": "通过定义Rationale一致性指标评估模型，并将其与结果准确性结合，作为GenRM训练的混合信号，用于优化模型。",
      "tags": [
        "Reward Model",
        "Reasoning",
        "Alignment",
        "RLHF"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注LLM的推理过程和对齐问题，直接研究该领域的关键问题。",
      "analyzed_at": "2026-02-05T06:55:48.370416",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04640v1",
      "title": "Towards Structured, State-Aware, and Execution-Grounded Reasoning for Software Engineering Agents",
      "abstract": "Software Engineering (SE) agents have shown promising abilities in supporting various SE tasks. Current SE agents remain fundamentally reactive, making decisions mainly based on conversation history and the most recent response. However, this reactive design provides no explicit structure or persistent state within the agent's memory, making long-horizon reasoning challenging. As a result, SE agents struggle to maintain a coherent understanding across reasoning steps, adapt their hypotheses as new evidence emerges, or incorporate execution feedback into the mental reasoning model of the system state.   In this position paper, we argue that, to further advance SE agents, we need to move beyond reactive behavior toward a structured, state-aware, and execution-grounded reasoning. We outline how explicit structure, persistent and evolving state, and the integration of execution-grounded feedback can help SE agents perform more coherent and reliable reasoning in long-horizon tasks. We also provide an initial roadmap for developing next-generation SE agents that can more effectively perform real-world tasks.",
      "authors": [
        "Tse-Hsun",
        "Chen"
      ],
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "published": "2026-02-04T15:07:53Z",
      "updated": "2026-02-04T15:07:53Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04640v1",
      "abs_url": "http://arxiv.org/abs/2602.04640v1",
      "summary": "提出了软件工程Agent需要具备结构化、状态感知和执行反馈的推理能力，并展望了未来发展方向。",
      "key_contributions": [
        "指出当前SE Agent的局限性在于反应式设计",
        "提出结构化、状态感知和执行反馈的重要性",
        "提出了下一代SE Agent的初步发展路线图"
      ],
      "methodology": "Position paper，通过分析现有SE Agent的不足，提出改进方向，并进行展望。",
      "tags": [
        "软件工程",
        "AI Agent",
        "推理",
        "状态管理"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心讨论AI Agent的设计，并针对特定领域提出了改进方案。",
      "analyzed_at": "2026-02-05T06:55:50.508697",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04634v1",
      "title": "WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning",
      "abstract": "Recent advancements in Large Language Models (LLMs) have largely focused on depth scaling, where a single agent solves long-horizon problems with multi-turn reasoning and tool use. However, as tasks grow broader, the key bottleneck shifts from individual competence to organizational capability. In this work, we explore a complementary dimension of width scaling with multi-agent systems to address broad information seeking. Existing multi-agent systems often rely on hand-crafted workflows and turn-taking interactions that fail to parallelize work effectively. To bridge this gap, we propose WideSeek-R1, a lead-agent-subagent framework trained via multi-agent reinforcement learning (MARL) to synergize scalable orchestration and parallel execution. By utilizing a shared LLM with isolated contexts and specialized tools, WideSeek-R1 jointly optimizes the lead agent and parallel subagents on a curated dataset of 20k broad information-seeking tasks. Extensive experiments show that WideSeek-R1-4B achieves an item F1 score of 40.0% on the WideSearch benchmark, which is comparable to the performance of single-agent DeepSeek-R1-671B. Furthermore, WideSeek-R1-4B exhibits consistent performance gains as the number of parallel subagents increases, highlighting the effectiveness of width scaling.",
      "authors": [
        "Zelai Xu",
        "Zhexuan Xu",
        "Ruize Zhang",
        "Chunyang Zhu",
        "Shi Yu",
        "Weilin Liu",
        "Quanlu Zhang",
        "Wenbo Ding",
        "Chao Yu",
        "Yu Wang"
      ],
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-04T15:05:12Z",
      "updated": "2026-02-04T15:05:12Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04634v1",
      "abs_url": "http://arxiv.org/abs/2602.04634v1",
      "summary": "WideSeek-R1通过多智能体强化学习实现宽度缩放，提升LLM在广域信息检索任务中的性能。",
      "key_contributions": [
        "提出WideSeek-R1框架，利用主代理-子代理架构进行广域信息检索",
        "采用多智能体强化学习(MARL)训练，优化代理的协作与并行执行",
        "验证了宽度缩放的有效性，在WideSearch基准测试中取得可比肩单一大模型的结果"
      ],
      "methodology": "使用MARL训练的主代理-子代理框架，通过隔离上下文和专用工具，并行执行广域信息检索任务。",
      "tags": [
        "多智能体",
        "强化学习",
        "信息检索",
        "宽度缩放"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于多智能体框架及其在信息检索中的应用，是agent领域的重要研究方向。",
      "analyzed_at": "2026-02-05T06:55:53.175376",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04620v1",
      "title": "QUATRO: Query-Adaptive Trust Region Policy Optimization for LLM Fine-tuning",
      "abstract": "GRPO-style reinforcement learning (RL)-based LLM fine-tuning algorithms have recently gained popularity. Relying on heuristic trust-region approximations, however, they can lead to brittle optimization behavior, as global importance-ratio clipping and group-wise normalization fail to regulate samples whose importance ratios fall outside the clipping range. We propose Query-Adaptive Trust-Region policy Optimization (QUATRO), which directly enforces trust-region constraints through a principled optimization. This yields a clear and interpretable objective that enables explicit control over policy updates and stable, entropy-controlled optimization, with a stabilizer terms arising intrinsically from the exact trust-region formulation. Empirically verified on diverse mathematical reasoning benchmarks, QUATRO shows stable training under increased policy staleness and aggressive learning rates, maintaining well-controlled entropy throughout training.",
      "authors": [
        "Doyeon Lee",
        "Eunyi Lyou",
        "Hyunsoo Cho",
        "Sookyung Kim",
        "Joonseok Lee",
        "Jaemoo Choi"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T14:51:04Z",
      "updated": "2026-02-04T14:51:04Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04620v1",
      "abs_url": "http://arxiv.org/abs/2602.04620v1",
      "summary": "QUATRO通过直接强制执行信任域约束，实现LLM策略优化的稳定和可控。",
      "key_contributions": [
        "提出Query-Adaptive Trust-Region Policy Optimization (QUATRO)算法",
        "通过原则性优化直接强制执行信任域约束",
        "在数学推理任务上验证了QUATRO的稳定性和有效性"
      ],
      "methodology": "采用GRPO-style强化学习方法，通过直接优化信任域约束，避免启发式近似带来的问题，实现更稳定的训练。",
      "tags": [
        "LLM Fine-tuning",
        "Reinforcement Learning",
        "Trust Region Policy Optimization",
        "Mathematical Reasoning"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文专注于优化LLM在数学推理任务中的表现，属于核心相关研究。",
      "analyzed_at": "2026-02-05T06:55:54.971386",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04617v1",
      "title": "LEAD: Layer-wise Expert-aligned Decoding for Faithful Radiology Report Generation",
      "abstract": "Radiology Report Generation (RRG) aims to produce accurate and coherent diagnostics from medical images. Although large vision language models (LVLM) improve report fluency and accuracy, they exhibit hallucinations, generating plausible yet image-ungrounded pathological details. Existing methods primarily rely on external knowledge guidance to facilitate the alignment between generated text and visual information. However, these approaches often ignore the inherent decoding priors and vision-language alignment biases in pretrained models and lack robustness due to reliance on constructed guidance. In this paper, we propose Layer-wise Expert-aligned Decoding (LEAD), a novel method to inherently modify the LVLM decoding trajectory. A multiple experts module is designed for extracting distinct pathological features which are integrated into each decoder layer via a gating mechanism. This layer-wise architecture enables the LLM to consult expert features at every inference step via a learned gating function, thereby dynamically rectifying decoding biases and steering the generation toward factual consistency. Experiments conducted on multiple public datasets demonstrate that the LEAD method yields effective improvements in clinical accuracy metrics and mitigates hallucinations while preserving high generation quality.",
      "authors": [
        "Ruixiao Yang",
        "Yuanhe Tian",
        "Xu Yang",
        "Huiqi Li",
        "Yan Song"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T14:45:49Z",
      "updated": "2026-02-04T14:45:49Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04617v1",
      "abs_url": "http://arxiv.org/abs/2602.04617v1",
      "summary": "LEAD方法通过层级专家对齐解码，提升放射报告生成的准确性并减少幻觉。",
      "key_contributions": [
        "提出Layer-wise Expert-aligned Decoding (LEAD)方法",
        "设计多专家模块提取病理特征并融入解码层",
        "通过门控机制动态调整解码偏差"
      ],
      "methodology": "LEAD方法利用多专家模块提取病理特征，通过门控机制将特征融入LLM的每一层解码，动态修正解码偏差，提高生成报告的准确性。",
      "tags": [
        "放射报告生成",
        "视觉语言模型",
        "医学影像",
        "多模态学习"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于多模态医学影像报告生成，直接相关。",
      "analyzed_at": "2026-02-05T06:55:56.815282",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04605v1",
      "title": "RexBERT: Context Specialized Bidirectional Encoders for E-commerce",
      "abstract": "Encoder-only transformers remain indispensable in retrieval, classification, and ranking systems where latency, stability, and cost are paramount. Most general purpose encoders, however, are trained on generic corpora with limited coverage of specialized domains. We introduce RexBERT, a family of BERT-style encoders designed specifically for e-commerce semantics. We make three contributions. First, we release Ecom-niverse, a 350 billion token corpus curated from diverse retail and shopping sources. We describe a modular pipeline that isolates and extracts e-commerce content from FineFineWeb and other open web resources, and characterize the resulting domain distribution. Second, we present a reproducible pretraining recipe building on ModernBERT's architectural advances. The recipe consists of three phases: general pre-training, context extension, and annealed domain specialization. Third, we train RexBERT models ranging from 17M to 400M parameters and evaluate them on token classification, semantic similarity, and general natural language understanding tasks using e-commerce datasets. Despite having 2-3x fewer parameters, RexBERT outperforms larger general-purpose encoders and matches or surpasses modern long-context models on domain-specific benchmarks. Our results demonstrate that high quality in-domain data combined with a principled training approach provides a stronger foundation for e-commerce applications than indiscriminate scaling alone.",
      "authors": [
        "Rahul Bajaj",
        "Anuj Garg"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T14:32:37Z",
      "updated": "2026-02-04T14:32:37Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04605v1",
      "abs_url": "http://arxiv.org/abs/2602.04605v1",
      "summary": "RexBERT针对电商领域，利用高质量数据和训练方法，构建高效的BERT模型。",
      "key_contributions": [
        "发布 Ecom-niverse 电商领域数据集",
        "提出基于 ModernBERT 的可复现预训练方案",
        "训练并评估 RexBERT 模型在电商任务上的性能"
      ],
      "methodology": "采用三阶段预训练方法：通用预训练、上下文扩展和退火领域专业化，构建电商领域BERT模型。",
      "tags": [
        "E-commerce",
        "BERT",
        "Pre-training",
        "Transformer",
        "Domain Adaptation"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 7,
      "relevance_reason": "模型提升了电商领域的语义理解，对基于LLM的电商推理有参考价值。",
      "analyzed_at": "2026-02-05T06:55:58.987801",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04604v1",
      "title": "Beyond Holistic Scores: Automatic Trait-Based Quality Scoring of Argumentative Essays",
      "abstract": "Automated Essay Scoring systems have traditionally focused on holistic scores, limiting their pedagogical usefulness, especially in the case of complex essay genres such as argumentative writing. In educational contexts, teachers and learners require interpretable, trait-level feedback that aligns with instructional goals and established rubrics. In this paper, we study trait-based Automatic Argumentative Essay Scoring using two complementary modeling paradigms designed for realistic educational deployment: (1) structured in-context learning with small open-source LLMs, and (2) a supervised, encoder-based BigBird model with a CORAL-style ordinal regression formulation, optimized for long-sequence understanding. We conduct a systematic evaluation on the ASAP++ dataset, which includes essay scores across five quality traits, offering strong coverage of core argumentation dimensions. LLMs are prompted with designed, rubric-aligned in-context examples, along with feedback and confidence requests, while we explicitly model ordinality in scores with the BigBird model via the rank-consistent CORAL framework. Our results show that explicitly modeling score ordinality substantially improves agreement with human raters across all traits, outperforming LLMs and nominal classification and regression-based baselines. This finding reinforces the importance of aligning model objectives with rubric semantics for educational assessment. At the same time, small open-source LLMs achieve a competitive performance without task-specific fine-tuning, particularly for reasoning-oriented traits, while enabling transparent, privacy-preserving, and locally deployable assessment scenarios. Our findings provide methodological, modeling, and practical insights for the design of AI-based educational systems that aim to deliver interpretable, rubric-aligned feedback for argumentative writing.",
      "authors": [
        "Lucile Favero",
        "Juan Antonio Pérez-Ortiz",
        "Tanja Käser",
        "Nuria Oliver"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T14:30:52Z",
      "updated": "2026-02-04T14:30:52Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04604v1",
      "abs_url": "http://arxiv.org/abs/2602.04604v1",
      "summary": "论文研究了基于特征的自动议论文评分，提升了评分的解释性和教育实用性。",
      "key_contributions": [
        "提出了基于小规模LLM的结构化上下文学习方法",
        "提出了基于BigBird模型的CORAL风格序数回归方法",
        "验证了序数建模在议论文评分中的有效性"
      ],
      "methodology": "采用了小规模LLM的上下文学习和基于BigBird的监督学习方法，并使用CORAL框架显式建模了分数的序数性。",
      "tags": [
        "自动评分",
        "议论文",
        "自然语言处理",
        "教育"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "论文关注LLM在议论文评分中的推理能力，与LLM推理领域高度相关。",
      "analyzed_at": "2026-02-05T06:56:00.842700",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04599v1",
      "title": "Stochastic Decision Horizons for Constrained Reinforcement Learning",
      "abstract": "Constrained Markov decision processes (CMDPs) provide a principled model for handling constraints, such as safety and other auxiliary objectives, in reinforcement learning. The common approach of using additive-cost constraints and dual variables often hinders off-policy scalability. We propose a Control as Inference formulation based on stochastic decision horizons, where constraint violations attenuate reward contributions and shorten the effective planning horizon via state-action-dependent continuation. This yields survival-weighted objectives that remain replay-compatible for off-policy actor-critic learning. We propose two violation semantics, absorbing and virtual termination, that share the same survival-weighted return but result in distinct optimization structures that lead to SAC/MPO-style policy improvement. Experiments demonstrate improved sample efficiency and favorable return-violation trade-offs on standard benchmarks. Moreover, MPO with virtual termination (VT-MPO) scales effectively to our high-dimensional musculoskeletal Hyfydy setup.",
      "authors": [
        "Nikola Milosevic",
        "Leonard Franz",
        "Daniel Haeufle",
        "Georg Martius",
        "Nico Scherf",
        "Pavel Kolev"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T14:27:16Z",
      "updated": "2026-02-04T14:27:16Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04599v1",
      "abs_url": "http://arxiv.org/abs/2602.04599v1",
      "summary": "提出基于随机决策范围的约束强化学习方法，提升样本效率和可扩展性。",
      "key_contributions": [
        "提出基于随机决策范围的约束强化学习框架",
        "设计生存加权目标，兼容离线策略学习",
        "引入吸收和虚拟终止两种违规语义",
        "实验验证了方法的有效性和可扩展性"
      ],
      "methodology": "使用基于随机决策范围的控制即推理框架，通过状态-动作依赖的延续性来衰减奖励和缩短规划范围。",
      "tags": [
        "强化学习",
        "约束强化学习",
        "控制即推理",
        "离线学习",
        "随机决策范围"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "涉及Agent中的强化学习，关注约束和效率等重要方面。",
      "analyzed_at": "2026-02-05T06:56:02.986195",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04596v1",
      "title": "A principled framework for uncertainty decomposition in TabPFN",
      "abstract": "TabPFN is a transformer that achieves state-of-the-art performance on supervised tabular tasks by amortizing Bayesian prediction into a single forward pass. However, there is currently no method for uncertainty decomposition in TabPFN. Because it behaves, in an idealised limit, as a Bayesian in-context learner, we cast the decomposition challenge as a Bayesian predictive inference (BPI) problem. The main computational tool in BPI, predictive Monte Carlo, is challenging to apply here as it requires simulating unmodeled covariates. We therefore pursue the asymptotic alternative, filling a gap in the theory for supervised settings by proving a predictive CLT under quasi-martingale conditions. We derive variance estimators determined by the volatility of predictive updates along the context. The resulting credible bands are fast to compute, target epistemic uncertainty, and achieve near-nominal frequentist coverage. For classification, we further obtain an entropy-based uncertainty decomposition.",
      "authors": [
        "Sandra Fortini",
        "Kenyon Ng",
        "Sonia Petrone",
        "Judith Rousseau",
        "Susan Wei"
      ],
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "stat.ML",
      "published": "2026-02-04T14:23:53Z",
      "updated": "2026-02-04T14:23:53Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04596v1",
      "abs_url": "http://arxiv.org/abs/2602.04596v1",
      "summary": "本文提出了一种TabPFN的不确定性分解框架，并验证了其有效性。",
      "key_contributions": [
        "提出了TabPFN的不确定性分解方法",
        "证明了监督设置下的预测CLT",
        "推导了方差估计器，实现了快速计算"
      ],
      "methodology": "将不确定性分解视为贝叶斯预测推理问题，利用预测CLT推导方差估计器，并进行实验验证。",
      "tags": [
        "TabPFN",
        "不确定性分解",
        "贝叶斯预测推理",
        "预测CLT"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 6,
      "relevance_reason": "涉及贝叶斯方法及预测推理，与LLM的推理能力有一定关联。",
      "analyzed_at": "2026-02-05T06:56:04.747498",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04587v1",
      "title": "VILLAIN at AVerImaTeC: Verifying Image-Text Claims via Multi-Agent Collaboration",
      "abstract": "This paper describes VILLAIN, a multimodal fact-checking system that verifies image-text claims through prompt-based multi-agent collaboration. For the AVerImaTeC shared task, VILLAIN employs vision-language model agents across multiple stages of fact-checking. Textual and visual evidence is retrieved from the knowledge store enriched through additional web collection. To identify key information and address inconsistencies among evidence items, modality-specific and cross-modal agents generate analysis reports. In the subsequent stage, question-answer pairs are produced based on these reports. Finally, the Verdict Prediction agent produces the verification outcome based on the image-text claim and the generated question-answer pairs. Our system ranked first on the leaderboard across all evaluation metrics. The source code is publicly available at https://github.com/ssu-humane/VILLAIN.",
      "authors": [
        "Jaeyoon Jung",
        "Yejun Yoon",
        "Seunghyun Yoon",
        "Kunwoo Park"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T14:12:55Z",
      "updated": "2026-02-04T14:12:55Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04587v1",
      "abs_url": "http://arxiv.org/abs/2602.04587v1",
      "summary": "VILLAIN系统通过多智能体协作，使用视觉-语言模型验证图像-文本声明，并在AVerImaTeC任务中取得领先。",
      "key_contributions": [
        "提出基于prompt的多智能体协作框架",
        "利用知识库和网络信息增强证据",
        "在AVerImaTeC任务中取得领先"
      ],
      "methodology": "采用多智能体协作，分别进行文本和视觉证据检索、信息分析、问答生成，最后预测结果。",
      "tags": [
        "多模态",
        "事实核查",
        "智能体",
        "视觉-语言模型"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心是多模态信息验证和多智能体协作，与multimodal类别高度相关。",
      "analyzed_at": "2026-02-05T06:56:06.982035",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04579v1",
      "title": "AIANO: Enhancing Information Retrieval with AI-Augmented Annotation",
      "abstract": "The rise of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) has rapidly increased the need for high-quality, curated information retrieval datasets. These datasets, however, are currently created with off-the-shelf annotation tools that make the annotation process complex and inefficient. To streamline this process, we developed a specialized annotation tool - AIANO. By adopting an AI-augmented annotation workflow that tightly integrates human expertise with LLM assistance, AIANO enables annotators to leverage AI suggestions while retaining full control over annotation decisions. In a within-subject user study ($n = 15$), participants created question-answering datasets using both a baseline tool and AIANO. AIANO nearly doubled annotation speed compared to the baseline while being easier to use and improving retrieval accuracy. These results demonstrate that AIANO's AI-augmented approach accelerates and enhances dataset creation for information retrieval tasks, advancing annotation capabilities in retrieval-intensive domains.",
      "authors": [
        "Sameh Khattab",
        "Marie Bauer",
        "Lukas Heine",
        "Till Rostalski",
        "Jens Kleesiek",
        "Julian Friedrich"
      ],
      "categories": [
        "cs.IR",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "published": "2026-02-04T14:05:12Z",
      "updated": "2026-02-04T14:05:12Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04579v1",
      "abs_url": "http://arxiv.org/abs/2602.04579v1",
      "summary": "AIANO通过AI辅助标注，显著提升了信息检索数据集的创建效率和质量。",
      "key_contributions": [
        "开发了AIANO：一个AI辅助标注工具。",
        "提出了AI增强的标注流程，结合人工和LLM的优势。",
        "实验证明AIANO能显著提升标注速度、易用性和检索准确率。"
      ],
      "methodology": "采用AI辅助标注工作流，用户研究对比AIANO与基线工具在问答数据集创建上的性能，评估标注速度、易用性和检索准确率。",
      "tags": [
        "信息检索",
        "数据标注",
        "LLM",
        "RAG",
        "AI辅助"
      ],
      "assigned_category": "memory",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注点是利用AI提升RAG所需的优质数据集创建效率和质量。",
      "analyzed_at": "2026-02-05T06:56:09.094409",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04575v1",
      "title": "Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration",
      "abstract": "For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' manifested as the Intent-Execution Gap (i.e., the fundamental disparity between a creator's high-level intent and the stochastic, black-box nature of current single-shot models). In this paper, inspired by the Vibe Coding, we introduce the \\textbf{Vibe AIGC}, a new paradigm for content generation via agentic orchestration, which represents the autonomous synthesis of hierarchical multi-agent workflows.   Under this paradigm, the user's role transcends traditional prompt engineering, evolving into a Commander who provides a Vibe, a high-level representation encompassing aesthetic preferences, functional logic, and etc. A centralized Meta-Planner then functions as a system architect, deconstructing this ``Vibe'' into executable, verifiable, and adaptive agentic pipelines. By transitioning from stochastic inference to logical orchestration, Vibe AIGC bridges the gap between human imagination and machine execution. We contend that this shift will redefine the human-AI collaborative economy, transforming AI from a fragile inference engine into a robust system-level engineering partner that democratizes the creation of complex, long-horizon digital assets.",
      "authors": [
        "Jiaheng Liu",
        "Yuanxing Zhang",
        "Shihao Li",
        "Xinping Lei"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-04T14:01:44Z",
      "updated": "2026-02-04T14:01:44Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04575v1",
      "abs_url": "http://arxiv.org/abs/2602.04575v1",
      "summary": "Vibe AIGC通过智能体编排实现内容生成，弥合用户意图与模型执行之间的差距。",
      "key_contributions": [
        "提出Vibe AIGC新范式，通过智能体编排生成内容",
        "引入Vibe概念，作为用户意图的高级表达",
        "采用Meta-Planner进行Vibe分解和智能体流程规划"
      ],
      "methodology": "通过Meta-Planner将用户Vibe分解为可执行的智能体流程，实现从随机推断到逻辑编排的转变。",
      "tags": [
        "AIGC",
        "智能体编排",
        "多智能体",
        "意图表达",
        "内容生成"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于利用多智能体进行内容生成，直接属于AI Agent领域。",
      "analyzed_at": "2026-02-05T06:56:11.292086",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04566v1",
      "title": "Dual Mind World Model Inspired Network Digital Twin for Access Scheduling",
      "abstract": "Emerging networked systems such as industrial IoT and real-time cyber-physical infrastructures demand intelligent scheduling strategies capable of adapting to dynamic traffic, deadlines, and interference constraints. In this work, we present a novel Digital Twin-enabled scheduling framework inspired by Dual Mind World Model (DMWM) architecture, for learning-informed and imagination-driven network control. Unlike conventional rule-based or purely data-driven policies, the proposed DMWM combines short-horizon predictive planning with symbolic model-based rollout, enabling the scheduler to anticipate future network states and adjust transmission decisions accordingly. We implement the framework in a configurable simulation testbed and benchmark its performance against traditional heuristics and reinforcement learning baselines under varied traffic conditions. Our results show that DMWM achieves superior performance in bursty, interference-limited, and deadline-sensitive environments, while maintaining interpretability and sample efficiency. The proposed design bridges the gap between network-level reasoning and low-overhead learning, marking a step toward scalable and adaptive NDT-based network optimization.",
      "authors": [
        "Hrishikesh Dutta",
        "Roberto Minerva",
        "Noel Crespi"
      ],
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.NI",
      "published": "2026-02-04T13:53:55Z",
      "updated": "2026-02-04T13:53:55Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04566v1",
      "abs_url": "http://arxiv.org/abs/2602.04566v1",
      "summary": "提出基于双脑世界模型的数字孪生网络接入调度框架，优化网络控制策略。",
      "key_contributions": [
        "提出基于双脑世界模型（DMWM）的数字孪生网络调度框架",
        "结合短时预测规划和符号模型推理",
        "在复杂网络环境中表现出优越的性能，并保持可解释性和样本效率"
      ],
      "methodology": "结合DMWM架构，利用数字孪生技术构建网络环境，通过预测规划和模型推理优化调度决策。",
      "tags": [
        "Digital Twin",
        "Network Scheduling",
        "Dual Mind World Model",
        "Industrial IoT",
        "Reinforcement Learning"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "论文提出了智能调度策略，涉及agent的规划和决策过程。",
      "analyzed_at": "2026-02-05T06:56:13.418881",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04565v1",
      "title": "Understanding Degradation with Vision Language Model",
      "abstract": "Understanding visual degradations is a critical yet challenging problem in computer vision. While recent Vision-Language Models (VLMs) excel at qualitative description, they often fall short in understanding the parametric physics underlying image degradations. In this work, we redefine degradation understanding as a hierarchical structured prediction task, necessitating the concurrent estimation of degradation types, parameter keys, and their continuous physical values. Although these sub-tasks operate in disparate spaces, we prove that they can be unified under one autoregressive next-token prediction paradigm, whose error is bounded by the value-space quantization grid. Building on this insight, we introduce DU-VLM, a multimodal chain-of-thought model trained with supervised fine-tuning and reinforcement learning using structured rewards. Furthermore, we show that DU-VLM can serve as a zero-shot controller for pre-trained diffusion models, enabling high-fidelity image restoration without fine-tuning the generative backbone. We also introduce \\textbf{DU-110k}, a large-scale dataset comprising 110,000 clean-degraded pairs with grounded physical annotations. Extensive experiments demonstrate that our approach significantly outperforms generalist baselines in both accuracy and robustness, exhibiting generalization to unseen distributions.",
      "authors": [
        "Guanzhou Lan",
        "Chenyi Liao",
        "Yuqi Yang",
        "Qianli Ma",
        "Zhigang Wang",
        "Dong Wang",
        "Bin Zhao",
        "Xuelong Li"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-04T13:51:15Z",
      "updated": "2026-02-04T13:51:15Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04565v1",
      "abs_url": "http://arxiv.org/abs/2602.04565v1",
      "summary": "提出DU-VLM模型，用于理解图像退化并用于图像复原，通过分层结构预测任务和多模态链式思考实现。",
      "key_contributions": [
        "重新定义图像退化理解为分层结构预测任务",
        "提出DU-VLM模型，基于autoregressive next-token prediction范式",
        "构建大规模数据集DU-110k，包含带有物理标注的清洁-退化图像对"
      ],
      "methodology": "使用监督微调和强化学习训练多模态链式思考模型DU-VLM，用于预测退化类型、参数键和物理值，并将其应用于图像复原。",
      "tags": [
        "图像退化理解",
        "Vision-Language Model",
        "多模态学习",
        "图像复原"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于利用VLM理解图像退化，并应用于图像复原，是多模态学习的重要应用。",
      "analyzed_at": "2026-02-05T06:56:15.449273",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04557v1",
      "title": "Textual Planning with Explicit Latent Transitions",
      "abstract": "Planning with LLMs is bottlenecked by token-by-token generation and repeated full forward passes, making multi-step lookahead and rollout-based search expensive in latency and compute. We propose EmbedPlan, which replaces autoregressive next-state generation with a lightweight transition model operating in a frozen language embedding space. EmbedPlan encodes natural language state and action descriptions into vectors, predicts the next-state embedding, and retrieves the next state by nearest-neighbor similarity, enabling fast planning computation without fine-tuning the encoder. We evaluate next-state prediction across nine classical planning domains using six evaluation protocols of increasing difficulty: interpolation, plan-variant, extrapolation, multi-domain, cross-domain, and leave-one-out. Results show near-perfect interpolation performance but a sharp degradation when generalization requires transfer to unseen problems or unseen domains; plan-variant evaluation indicates generalization to alternative plans rather than memorizing seen trajectories. Overall, frozen embeddings support within-domain dynamics learning after observing a domain's transitions, while transfer across domain boundaries remains a bottleneck.",
      "authors": [
        "Eliezer Shlomi",
        "Ido Levy",
        "Eilam Shapira",
        "Michael Katz",
        "Guy Uziel",
        "Segev Shlomov",
        "Nir Mashkif",
        "Roi Reichart",
        "Sarah Keren"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T13:46:15Z",
      "updated": "2026-02-04T13:46:15Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04557v1",
      "abs_url": "http://arxiv.org/abs/2602.04557v1",
      "summary": "EmbedPlan通过在冻结语言嵌入空间中进行状态转移预测，加速LLM规划过程。",
      "key_contributions": [
        "提出EmbedPlan，一种基于嵌入空间的规划方法",
        "使用轻量级的状态转移模型代替自回归生成",
        "无需微调编码器即可实现快速规划"
      ],
      "methodology": "将状态和动作描述编码为向量，预测下一状态嵌入，通过最近邻搜索检索下一状态。",
      "tags": [
        "LLM",
        "Planning",
        "Embedding",
        "State Transition"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注LLM在规划任务中的应用，并提出了新的agent设计方法。",
      "analyzed_at": "2026-02-05T06:56:17.623880",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04556v1",
      "title": "Rethinking Weight Tying: Pseudo-Inverse Tying for Stable LM Training and Updates",
      "abstract": "Weight tying is widely used in compact language models to reduce parameters by sharing the token table between the input embedding and the output projection. However, weight sharing does not guarantee a stable token interface: during training, the correspondence between encoding tokens into hidden states and decoding hidden states into logits can drift, worsening optimization sensitivity and making post-training interventions such as editing, patching, and lightweight adaptation less predictable. We propose Pseudo-Inverse Tying (PIT), which synchronizes embedding and unembedding as coupled projections of a shared latent token memory, guaranteeing a pseudo-inverse-consistent interface throughout training. PIT maintains an orthonormal shared memory, obtained by thin polar decomposition for teacher initialization or random orthonormal initialization from scratch, and introduces a fully learned symmetric positive definite hidden-space transform parameterized via a Cholesky factor. The output head applies this transform to hidden states before the vocabulary projection, while the embedding applies the inverse transform to token vectors using stable triangular solves, avoiding explicit pseudo-inverse recomputation and any vocabulary-sized auxiliary parameters. We evaluate PIT on on-device models spanning 256M-1.3B parameters across pretraining and adaptation, and consistently observe improved training stability, stronger layerwise semantic consistency, and substantially reduced side effects.",
      "authors": [
        "Jian Gu",
        "Aldeida Aleti",
        "Chunyang Chen",
        "Hongyu Zhang"
      ],
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T13:44:53Z",
      "updated": "2026-02-04T13:44:53Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04556v1",
      "abs_url": "http://arxiv.org/abs/2602.04556v1",
      "summary": "提出伪逆权重绑定(PIT)，通过共享的潜在token记忆同步embedding和unembedding，提升训练稳定性和语义一致性。",
      "key_contributions": [
        "提出Pseudo-Inverse Tying (PIT)权重绑定方法",
        "设计正交共享记忆和可学习的对称正定变换",
        "提高训练稳定性和层间语义一致性"
      ],
      "methodology": "通过维持正交共享记忆和引入可学习的变换，实现embedding和unembedding的同步，避免显式的伪逆计算。",
      "tags": [
        "Weight Tying",
        "Language Model",
        "Training Stability",
        "Orthogonal Initialization"
      ],
      "assigned_category": "memory",
      "relevance_score": 9,
      "relevance_reason": "论文直接研究了语言模型训练中的权重绑定问题，是该领域的核心问题。",
      "analyzed_at": "2026-02-05T06:56:19.450150",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04555v1",
      "title": "Finding Structure in Continual Learning",
      "abstract": "Learning from a stream of tasks usually pits plasticity against stability: acquiring new knowledge often causes catastrophic forgetting of past information. Most methods address this by summing competing loss terms, creating gradient conflicts that are managed with complex and often inefficient strategies such as external memory replay or parameter regularization. We propose a reformulation of the continual learning objective using Douglas-Rachford Splitting (DRS). This reframes the learning process not as a direct trade-off, but as a negotiation between two decoupled objectives: one promoting plasticity for new tasks and the other enforcing stability of old knowledge. By iteratively finding a consensus through their proximal operators, DRS provides a more principled and stable learning dynamic. Our approach achieves an efficient balance between stability and plasticity without the need for auxiliary modules or complex add-ons, providing a simpler yet more powerful paradigm for continual learning systems.",
      "authors": [
        "Pourya Shamsolmoali",
        "Masoumeh Zareapoor"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T13:44:26Z",
      "updated": "2026-02-04T13:44:26Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04555v1",
      "abs_url": "http://arxiv.org/abs/2602.04555v1",
      "summary": "使用Douglas-Rachford Splitting (DRS)重构持续学习目标，平衡稳定性和可塑性。",
      "key_contributions": [
        "提出基于DRS的持续学习框架",
        "解耦可塑性和稳定性的目标",
        "无需额外模块或复杂附加组件"
      ],
      "methodology": "使用DRS将持续学习目标分解为可塑性和稳定性两个独立的优化目标，通过近端算子迭代寻找共识。",
      "tags": [
        "Continual Learning",
        "Douglas-Rachford Splitting",
        "Optimization",
        "Stability",
        "Plasticity"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "持续学习是Agent构建长期能力的关键技术。",
      "analyzed_at": "2026-02-05T06:56:21.519094",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04541v1",
      "title": "LycheeDecode: Accelerating Long-Context LLM Inference via Hybrid-Head Sparse Decoding",
      "abstract": "The proliferation of long-context large language models (LLMs) exposes a key bottleneck: the rapidly expanding key-value cache during decoding, which imposes heavy memory and latency costs. While recent approaches attempt to alleviate this by sharing a single set of crucial tokens across layers, such coarse-grained sharing undermines model performance by neglecting the functional diversity of attention heads. To address this, we propose LycheeDecode, an efficient decoding method centered on a fine-grained hybrid-head attention mechanism that employs a hardware-efficient top-k selection strategy. Specifically, the novel HardKuma-based mechanism partitions attention heads into a small subset of retrieval heads that dynamically identify crucial tokens and a majority of sparse heads that reuse them for efficient computation. Through extensive experiments on leading models like Llama3 and Qwen3 across diverse benchmarks for long-context understanding (e.g., LongBench, RULER) and complex reasoning (e.g., AIME24, OlympiadBench), we demonstrate that LycheeDecode achieves generative quality comparable to, and at times surpassing even the full-attention baseline. Crucially, this is accomplished with up to a 2.7x speedup at a 128K context length. By preserving the functional diversity of attention heads, our fine-grained strategy overcomes the performance bottlenecks of existing methods, providing a powerful and validated pathway to both efficient and high-quality long-context LLM inference.",
      "authors": [
        "Gang Lin",
        "Dongfang Li",
        "Zhuoen Chen",
        "Yukun Shi",
        "Xuhui Chen",
        "Baotian Hu",
        "Min Zhang"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T13:34:12Z",
      "updated": "2026-02-04T13:34:12Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04541v1",
      "abs_url": "http://arxiv.org/abs/2602.04541v1",
      "summary": "LycheeDecode通过混合头稀疏解码加速长文本LLM推理，提升速度和质量。",
      "key_contributions": [
        "提出基于HardKuma的混合头注意力机制",
        "动态识别关键token并重用",
        "在长文本理解和推理任务上验证了加速效果"
      ],
      "methodology": "采用硬件友好的top-k选择策略，将注意力头划分为检索头和稀疏头，实现高效计算。",
      "tags": [
        "LLM",
        "长文本",
        "推理加速",
        "注意力机制",
        "稀疏解码"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于优化长文本推理过程中的效率，属于LLM reasoning领域。",
      "analyzed_at": "2026-02-05T06:56:23.418562",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04540v1",
      "title": "PersoPilot: An Adaptive AI-Copilot for Transparent Contextualized Persona Classification and Personalized Response Generation",
      "abstract": "Understanding and classifying user personas is critical for delivering effective personalization. While persona information offers valuable insights, its full potential is realized only when contextualized, linking user characteristics with situational context to enable more precise and meaningful service provision. Existing systems often treat persona and context as separate inputs, limiting their ability to generate nuanced, adaptive interactions. To address this gap, we present PersoPilot, an agentic AI-Copilot that integrates persona understanding with contextual analysis to support both end users and analysts. End users interact through a transparent, explainable chat interface, where they can express preferences in natural language, request recommendations, and receive information tailored to their immediate task. On the analyst side, PersoPilot delivers a transparent, reasoning-powered labeling assistant, integrated with an active learning-driven classification process that adapts over time with new labeled data. This feedback loop enables targeted service recommendations and adaptive personalization, bridging the gap between raw persona data and actionable, context-aware insights. As an adaptable framework, PersoPilot is applicable to a broad range of service personalization scenarios.",
      "authors": [
        "Saleh Afzoon",
        "Amin Beheshti",
        "Usman Naseem"
      ],
      "categories": [
        "cs.HC",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "published": "2026-02-04T13:31:24Z",
      "updated": "2026-02-04T13:31:24Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04540v1",
      "abs_url": "http://arxiv.org/abs/2602.04540v1",
      "summary": "PersoPilot通过融合用户画像和上下文，实现个性化推荐和透明的AI辅助。",
      "key_contributions": [
        "提出PersoPilot，一个整合用户画像理解与上下文分析的AI-Copilot。",
        "构建了透明、可解释的交互界面，方便用户表达偏好并获取个性化推荐。",
        "提供基于主动学习的标签助手，帮助分析师进行用户画像分类并优化服务推荐。"
      ],
      "methodology": "采用agent框架，结合自然语言理解、主动学习和透明化推理，构建上下文感知和个性化的服务系统。",
      "tags": [
        "个性化推荐",
        "用户画像",
        "AI-Copilot",
        "主动学习",
        "上下文感知"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "论文提出了一个AI agent，通过上下文分析和用户画像理解来辅助用户和分析师，与agent的核心概念紧密相关。",
      "analyzed_at": "2026-02-05T06:56:26.820533",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04521v1",
      "title": "$C$-$ΔΘ$: Circuit-Restricted Weight Arithmetic for Selective Refusal",
      "abstract": "Modern deployments require LLMs to enforce safety policies at scale, yet many controls rely on inference-time interventions that add recurring compute cost and serving complexity. Activation steering is widely used, but it requires runtime hooks and scales cost with the number of generations; conditional variants improve selectivity by gating when steering is applied but still retain an inference-time control path. We ask whether selective refusal can be moved entirely offline: can a mechanistic understanding of category-specific refusal be distilled into a circuit-restricted weight update that deploys as a standard checkpoint? We propose C-Δθ: Circuit Restricted Weight Arithmetic, which (i) localizes refusal-causal computation as a sparse circuit using EAP-IG and (ii) computes a constrained weight update ΔθC supported only on that circuit (typically <5% of parameters). Applying ΔθC yields a drop-in edited checkpoint with no inference-time hooks, shifting cost from per-request intervention to a one-time offline update. We evaluate category-targeted selectivity and capability retention on refusal and utility benchmarks.",
      "authors": [
        "Aditya Kasliwal",
        "Pratinav Seth",
        "Vinay Kumar Sankarapu"
      ],
      "categories": [
        "cs.CL",
        "cs.ET"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T13:10:52Z",
      "updated": "2026-02-04T13:10:52Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04521v1",
      "abs_url": "http://arxiv.org/abs/2602.04521v1",
      "summary": "提出一种离线权重更新方法C-Δθ，用于选择性拒绝，无需推理时干预。",
      "key_contributions": [
        "提出 Circuit Restricted Weight Arithmetic (C-Δθ) 方法",
        "通过稀疏电路定位拒绝相关的计算",
        "将拒绝的成本从每次请求转移到一次离线更新"
      ],
      "methodology": "使用EAP-IG方法定位拒绝计算的关键电路，然后在该电路约束下进行权重更新，生成编辑后的模型检查点。",
      "tags": [
        "LLM",
        "Safety",
        "Refusal",
        "Weight Arithmetic",
        "Circuit"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "研究如何使LLM进行选择性拒绝，属于LLM推理能力的重要方面。",
      "analyzed_at": "2026-02-05T06:56:28.518225",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04518v1",
      "title": "Learning the Value Systems of Agents with Preference-based and Inverse Reinforcement Learning",
      "abstract": "Agreement Technologies refer to open computer systems in which autonomous software agents interact with one another, typically on behalf of humans, in order to come to mutually acceptable agreements. With the advance of AI systems in recent years, it has become apparent that such agreements, in order to be acceptable to the involved parties, must remain aligned with ethical principles and moral values. However, this is notoriously difficult to ensure, especially as different human users (and their software agents) may hold different value systems, i.e. they may differently weigh the importance of individual moral values. Furthermore, it is often hard to specify the precise meaning of a value in a particular context in a computational manner. Methods to estimate value systems based on human-engineered specifications, e.g. based on value surveys, are limited in scale due to the need for intense human moderation. In this article, we propose a novel method to automatically \\emph{learn} value systems from observations and human demonstrations. In particular, we propose a formal model of the \\emph{value system learning} problem, its instantiation to sequential decision-making domains based on multi-objective Markov decision processes, as well as tailored preference-based and inverse reinforcement learning algorithms to infer value grounding functions and value systems. The approach is illustrated and evaluated by two simulated use cases.",
      "authors": [
        "Andrés Holgado-Sánchez",
        "Holger Billhardt",
        "Alberto Fernández",
        "Sascha Ossowski"
      ],
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "published": "2026-02-04T13:07:15Z",
      "updated": "2026-02-04T13:07:15Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04518v1",
      "abs_url": "http://arxiv.org/abs/2602.04518v1",
      "summary": "该论文提出一种新方法，从观察和演示中自动学习智能体的价值系统，用于多智能体协商场景。",
      "key_contributions": [
        "提出了价值系统学习的形式模型",
        "基于多目标MDP，设计了价值系统学习的实例",
        "设计了基于偏好和逆强化学习的算法来推断价值函数和价值系统"
      ],
      "methodology": "使用多目标马尔可夫决策过程(MDP)建模价值系统，并采用偏好学习和逆强化学习算法推断价值函数。",
      "tags": [
        "AI Agents",
        "Inverse Reinforcement Learning",
        "Value Alignment",
        "Preference Learning"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文直接探讨了智能体的价值系统学习，属于多智能体领域的核心问题。",
      "analyzed_at": "2026-02-05T06:56:30.796508",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04515v1",
      "title": "EgoActor: Grounding Task Planning into Spatial-aware Egocentric Actions for Humanoid Robots via Visual-Language Models",
      "abstract": "Deploying humanoid robots in real-world settings is fundamentally challenging, as it demands tight integration of perception, locomotion, and manipulation under partial-information observations and dynamically changing environments. As well as transitioning robustly between sub-tasks of different types. Towards addressing these challenges, we propose a novel task - EgoActing, which requires directly grounding high-level instructions into various, precise, spatially aware humanoid actions. We further instantiate this task by introducing EgoActor, a unified and scalable vision-language model (VLM) that can predict locomotion primitives (e.g., walk, turn, move sideways, change height), head movements, manipulation commands, and human-robot interactions to coordinate perception and execution in real-time. We leverage broad supervision over egocentric RGB-only data from real-world demonstrations, spatial reasoning question-answering, and simulated environment demonstrations, enabling EgoActor to make robust, context-aware decisions and perform fluent action inference (under 1s) with both 8B and 4B parameter models. Extensive evaluations in both simulated and real-world environments demonstrate that EgoActor effectively bridges abstract task planning and concrete motor execution, while generalizing across diverse tasks and unseen environments.",
      "authors": [
        "Yu Bai",
        "MingMing Yu",
        "Chaojie Li",
        "Ziyi Bai",
        "Xinlong Wang",
        "Börje F. Karlsson"
      ],
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "published": "2026-02-04T13:04:56Z",
      "updated": "2026-02-04T13:04:56Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04515v1",
      "abs_url": "http://arxiv.org/abs/2602.04515v1",
      "summary": "EgoActor通过VLM将高层指令转化为机器人具体的空间感知行为。",
      "key_contributions": [
        "提出了EgoActing任务，将任务规划与机器人行为相结合",
        "提出了EgoActor模型，一个统一且可扩展的视觉-语言模型",
        "通过多源数据训练，实现了真实场景下的鲁棒性和泛化性"
      ],
      "methodology": "利用来自真实世界和仿真环境的视觉-语言数据，训练统一的VLM，实现空间感知的机器人动作推理。",
      "tags": [
        "机器人",
        "视觉语言模型",
        "具身智能",
        "任务规划",
        "行为规划"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心是VLM在机器人行为控制中的应用，直接研究了多模态学习的关键问题。",
      "analyzed_at": "2026-02-05T06:56:32.788199",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04512v1",
      "title": "BrainVista: Modeling Naturalistic Brain Dynamics as Multimodal Next-Token Prediction",
      "abstract": "Naturalistic fMRI characterizes the brain as a dynamic predictive engine driven by continuous sensory streams. However, modeling the causal forward evolution in realistic neural simulation is impeded by the timescale mismatch between multimodal inputs and the complex topology of cortical networks. To address these challenges, we introduce BrainVista, a multimodal autoregressive framework designed to model the causal evolution of brain states. BrainVista incorporates Network-wise Tokenizers to disentangle system-specific dynamics and a Spatial Mixer Head that captures inter-network information flow without compromising functional boundaries. Furthermore, we propose a novel Stimulus-to-Brain (S2B) masking mechanism to synchronize high-frequency sensory stimuli with hemodynamically filtered signals, enabling strict, history-only causal conditioning. We validate our framework on Algonauts 2025, CineBrain, and HAD, achieving state-of-the-art fMRI encoding performance. In long-horizon rollout settings, our model yields substantial improvements over baselines, increasing pattern correlation by 36.0\\% and 33.3\\% on relative to the strongest baseline Algonauts 2025 and CineBrain, respectively.",
      "authors": [
        "Xuanhua Yin",
        "Runkai Zhao",
        "Lina Yao",
        "Weidong Cai"
      ],
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "published": "2026-02-04T13:00:06Z",
      "updated": "2026-02-04T13:00:06Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04512v1",
      "abs_url": "http://arxiv.org/abs/2602.04512v1",
      "summary": "BrainVista通过多模态自回归框架模拟自然状态下大脑的动态预测，实现先进的fMRI编码。",
      "key_contributions": [
        "提出BrainVista多模态自回归框架",
        "引入Network-wise Tokenizers和Spatial Mixer Head",
        "提出Stimulus-to-Brain (S2B)掩码机制"
      ],
      "methodology": "构建多模态自回归模型，解耦系统动态，捕捉网络间信息流，同步感觉刺激与血流动力学信号。",
      "tags": [
        "fMRI",
        "multimodal learning",
        "autoregressive model",
        "brain dynamics"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 8,
      "relevance_reason": "论文利用多模态信息进行大脑建模，属于多模态学习的重要方向。",
      "analyzed_at": "2026-02-05T06:56:34.686239",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04509v1",
      "title": "Model-Dowser: Data-Free Importance Probing to Mitigate Catastrophic Forgetting in Multimodal Large Language Models",
      "abstract": "Fine-tuning Multimodal Large Language Models (MLLMs) on task-specific data is an effective way to improve performance on downstream applications. However, such adaptation often leads to a degradation in generalization on pretrained tasks, a phenomenon known as Catastrophic Forgetting. Existing methods that aim to mitigate this issue either become ineffective when fine-tuning deeper layers of the language decoder or scale poorly with increasing model size. To address these limitations, we propose Model-Dowser, a novel sparse fine-tuning approach for MLLMs. Model-Dowser measures a principled importance score for each model parameter with respect to pretrained generalization (prior to downstream adaptation) by jointly considering weight magnitudes, input activations, and output sensitivities. During fine-tuning, Model-Dowser selectively preserves high-importance parameters and updates the remaining. Comprehensive experiments on two representative MLLMs, LLaVA and NVILA, demonstrate that Model-Dowser effectively mitigates catastrophic forgetting and consistently outperforms prior methods, while remaining resource-efficient and scalable to multi-billion-parameter models.",
      "authors": [
        "Hyeontaek Hwang",
        "Nguyen Dinh Son",
        "Daeyoung Kim"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T12:56:27Z",
      "updated": "2026-02-04T12:56:27Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04509v1",
      "abs_url": "http://arxiv.org/abs/2602.04509v1",
      "summary": "Model-Dowser通过参数重要性评估进行稀疏微调，有效缓解多模态大模型中的灾难性遗忘。",
      "key_contributions": [
        "提出Model-Dowser方法，通过评估参数重要性缓解灾难性遗忘",
        "该方法在不访问数据情况下选择性地保留重要参数",
        "实验证明该方法在多个MLLM上优于现有方法"
      ],
      "methodology": "Model-Dowser计算参数重要性，结合权重、激活和输出敏感度。微调时，保留高重要性参数，更新其余参数。",
      "tags": [
        "MLLM",
        "Catastrophic Forgetting",
        "Sparse Fine-tuning",
        "Importance Probing"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文直接研究了多模态大模型的灾难性遗忘问题，并提出了针对性的解决方案。",
      "analyzed_at": "2026-02-05T06:56:36.870725",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04496v1",
      "title": "ReThinker: Scientific Reasoning by Rethinking with Guided Reflection and Confidence Control",
      "abstract": "Expert-level scientific reasoning remains challenging for large language models, particularly on benchmarks such as Humanity's Last Exam (HLE), where rigid tool pipelines, brittle multi-agent coordination, and inefficient test-time scaling often limit performance. We introduce ReThinker, a confidence-aware agentic framework that orchestrates retrieval, tool use, and multi-agent reasoning through a stage-wise Solver-Critic-Selector architecture. Rather than following a fixed pipeline, ReThinker dynamically allocates computation based on model confidence, enabling adaptive tool invocation, guided multi-dimensional reflection, and robust confidence-weighted selection. To support scalable training without human annotation, we further propose a reverse data synthesis pipeline and an adaptive trajectory recycling strategy that transform successful reasoning traces into high-quality supervision. Experiments on HLE, GAIA, and XBench demonstrate that ReThinker consistently outperforms state-of-the-art foundation models with tools and existing deep research systems, achieving state-of-the-art results on expert-level reasoning tasks.",
      "authors": [
        "Zhentao Tang",
        "Yuqi Cui",
        "Shixiong Kai",
        "Wenqian Zhao",
        "Ke Ye",
        "Xing Li",
        "Anxin Tian",
        "Zehua Pei",
        "Hui-Ling Zhen",
        "Shoubo Hu",
        "Xiaoguang Li",
        "Yunhe Wang",
        "Mingxuan Yuan"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-04T12:41:52Z",
      "updated": "2026-02-04T12:41:52Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04496v1",
      "abs_url": "http://arxiv.org/abs/2602.04496v1",
      "summary": "ReThinker通过置信度引导的反思和工具使用，显著提升了LLM在复杂科学推理任务上的性能。",
      "key_contributions": [
        "提出了基于Solver-Critic-Selector架构的置信度感知Agent框架ReThinker",
        "设计了反向数据合成流程和自适应轨迹回收策略，用于无监督训练",
        "在HLE、GAIA和XBench等benchmark上取得了SOTA结果"
      ],
      "methodology": "ReThinker通过Solver解决问题，Critic评估置信度，Selector动态调整计算资源和工具调用，并结合反思机制提升性能。",
      "tags": [
        "LLM",
        "Scientific Reasoning",
        "Tool Use",
        "Agent",
        "Confidence"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 10,
      "relevance_reason": "论文核心在于提升LLM的推理能力，并针对科学推理任务进行了优化。",
      "analyzed_at": "2026-02-05T06:56:39.109815",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04492v1",
      "title": "Discovering Mechanistic Models of Neural Activity: System Identification in an in Silico Zebrafish",
      "abstract": "Constructing mechanistic models of neural circuits is a fundamental goal of neuroscience, yet verifying such models is limited by the lack of ground truth. To rigorously test model discovery, we establish an in silico testbed using neuromechanical simulations of a larval zebrafish as a transparent ground truth. We find that LLM-based tree search autonomously discovers predictive models that significantly outperform established forecasting baselines. Conditioning on sensory drive is necessary but not sufficient for faithful system identification, as models exploit statistical shortcuts. Structural priors prove essential for enabling robust out-of-distribution generalization and recovery of interpretable mechanistic models. Our insights provide guidance for modeling real-world neural recordings and offer a broader template for AI-driven scientific discovery.",
      "authors": [
        "Jan-Matthis Lueckmann",
        "Viren Jain",
        "Michał Januszewski"
      ],
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "published": "2026-02-04T12:33:29Z",
      "updated": "2026-02-04T12:33:29Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04492v1",
      "abs_url": "http://arxiv.org/abs/2602.04492v1",
      "summary": "论文利用虚拟斑马鱼环境，结合LLM进行神经活动机制模型的自动发现与验证。",
      "key_contributions": [
        "建立了透明的神经活动ground truth仿真环境",
        "证明了LLM驱动的树搜索能发现优于传统基线的预测模型",
        "结构先验对于模型泛化和机制模型恢复至关重要"
      ],
      "methodology": "使用虚拟斑马鱼神经肌肉仿真作为测试平台，利用LLM驱动的树搜索自动发现预测模型，并分析结构先验的影响。",
      "tags": [
        "神经科学",
        "机制模型",
        "系统识别",
        "LLM",
        "斑马鱼",
        "仿真"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "利用LLM进行模型发现和验证，涉及推理过程，且贡献点与推理相关。",
      "analyzed_at": "2026-02-05T06:56:41.709789",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04486v1",
      "title": "Beyond Unimodal Shortcuts: MLLMs as Cross-Modal Reasoners for Grounded Named Entity Recognition",
      "abstract": "Grounded Multimodal Named Entity Recognition (GMNER) aims to extract text-based entities, assign them semantic categories, and ground them to corresponding visual regions. In this work, we explore the potential of Multimodal Large Language Models (MLLMs) to perform GMNER in an end-to-end manner, moving beyond their typical role as auxiliary tools within cascaded pipelines. Crucially, our investigation reveals a fundamental challenge: MLLMs exhibit $\\textbf{modality bias}$, including visual bias and textual bias, which stems from their tendency to take unimodal shortcuts rather than rigorous cross-modal verification. To address this, we propose Modality-aware Consistency Reasoning ($\\textbf{MCR}$), which enforces structured cross-modal reasoning through Multi-style Reasoning Schema Injection (MRSI) and Constraint-guided Verifiable Optimization (CVO). MRSI transforms abstract constraints into executable reasoning chains, while CVO empowers the model to dynamically align its reasoning trajectories with Group Relative Policy Optimization (GRPO). Experiments on GMNER and visual grounding tasks demonstrate that MCR effectively mitigates modality bias and achieves superior performance compared to existing baselines.",
      "authors": [
        "Jinlong Ma",
        "Yu Zhang",
        "Xuefeng Bai",
        "Kehai Chen",
        "Yuwei Wang",
        "Zeming Liu",
        "Jun Yu",
        "Min Zhang"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T12:12:49Z",
      "updated": "2026-02-04T12:12:49Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04486v1",
      "abs_url": "http://arxiv.org/abs/2602.04486v1",
      "summary": "该论文提出一种新的多模态大型语言模型(MLLM)方法，用于解决GMNER中的模态偏差问题，提升性能。",
      "key_contributions": [
        "揭示了MLLMs在GMNER中存在的模态偏差问题（视觉偏差和文本偏差）",
        "提出了模态感知一致性推理（MCR）方法，包括MRSI和CVO",
        "设计了MRSI，将抽象约束转化为可执行的推理链",
        "利用CVO和GRPO，使模型能够动态调整推理轨迹"
      ],
      "methodology": "提出MCR，通过MRSI注入多风格推理模式，并通过CVO结合GRPO优化推理轨迹，缓解模态偏差。",
      "tags": [
        "GMNER",
        "MLLM",
        "多模态",
        "模态偏差",
        "一致性推理"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注MLLM在多模态GMNER任务中的应用，直接研究了多模态学习的关键问题。",
      "analyzed_at": "2026-02-05T06:56:44.031515",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04476v1",
      "title": "Vision-aligned Latent Reasoning for Multi-modal Large Language Model",
      "abstract": "Despite recent advancements in Multi-modal Large Language Models (MLLMs) on diverse understanding tasks, these models struggle to solve problems which require extensive multi-step reasoning. This is primarily due to the progressive dilution of visual information during long-context generation, which hinders their ability to fully exploit test-time scaling. To address this issue, we introduce Vision-aligned Latent Reasoning (VaLR), a simple, yet effective reasoning framework that dynamically generates vision-aligned latent tokens before each Chain of Thought reasoning step, guiding the model to reason based on perceptual cues in the latent space. Specifically, VaLR is trained to preserve visual knowledge during reasoning by aligning intermediate embeddings of MLLM with those from vision encoders. Empirical results demonstrate that VaLR consistently outperforms existing approaches across a wide range of benchmarks requiring long-context understanding or precise visual perception, while exhibiting test-time scaling behavior not observed in prior MLLMs. In particular, VaLR improves the performance significantly from 33.0% to 52.9% on VSI-Bench, achieving a 19.9%p gain over Qwen2.5-VL.",
      "authors": [
        "Byungwoo Jeon",
        "Yoonwoo Jeong",
        "Hyunseok Lee",
        "Minsu Cho",
        "Jinwoo Shin"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-04T12:04:02Z",
      "updated": "2026-02-04T12:04:02Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04476v1",
      "abs_url": "http://arxiv.org/abs/2602.04476v1",
      "summary": "VaLR通过动态生成视觉对齐的潜在token，提升MLLM在多步推理中的视觉信息保持能力。",
      "key_contributions": [
        "提出Vision-aligned Latent Reasoning (VaLR)框架",
        "VaLR通过对齐MLLM中间嵌入与视觉编码器嵌入来保持视觉知识",
        "VaLR在长上下文理解和精确视觉感知任务上显著优于现有方法"
      ],
      "methodology": "VaLR在每次CoT推理步骤前，动态生成视觉对齐的潜在token，并训练其与视觉编码器嵌入对齐，以保留视觉知识。",
      "tags": [
        "Multimodal",
        "Reasoning",
        "Vision-Language Model",
        "Latent Reasoning"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注多模态大语言模型的推理能力，属于该领域的关键问题研究。",
      "analyzed_at": "2026-02-05T06:56:46.296652",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04471v1",
      "title": "LLM-Empowered Cooperative Content Caching in Vehicular Fog Caching-Assisted Platoon Networks",
      "abstract": "This letter proposes a novel three-tier content caching architecture for Vehicular Fog Caching (VFC)-assisted platoon, where the VFC is formed by the vehicles driving near the platoon. The system strategically coordinates storage across local platoon vehicles, dynamic VFC clusters, and cloud server (CS) to minimize content retrieval latency. To efficiently manage distributed storage, we integrate large language models (LLMs) for real-time and intelligent caching decisions. The proposed approach leverages LLMs' ability to process heterogeneous information, including user profiles, historical data, content characteristics, and dynamic system states. Through a designed prompting framework encoding task objectives and caching constraints, the LLMs formulate caching as a decision-making task, and our hierarchical deterministic caching mapping strategy enables adaptive requests prediction and precise content placement across three tiers without frequent retraining. Simulation results demonstrate the advantages of our proposed caching scheme.",
      "authors": [
        "Bowen Tan",
        "Qiong Wu",
        "Pingyi Fan",
        "Kezhi Wang",
        "Nan Cheng",
        "Wen Chen"
      ],
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "published": "2026-02-04T11:59:22Z",
      "updated": "2026-02-04T11:59:22Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04471v1",
      "abs_url": "http://arxiv.org/abs/2602.04471v1",
      "summary": "提出一种基于LLM的车联网雾计算内容缓存架构，优化内容检索延迟。",
      "key_contributions": [
        "提出三层车联网雾计算缓存架构",
        "利用LLM进行实时智能缓存决策",
        "设计层级确定性缓存映射策略"
      ],
      "methodology": "使用LLM处理异构信息，通过提示框架编码任务目标和约束，将缓存问题建模为决策任务。",
      "tags": [
        "LLM",
        "Vehicular Fog Computing",
        "Content Caching",
        "Platoon Networks"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "使用LLM进行决策，可以看作是一种简单的Agent应用。",
      "analyzed_at": "2026-02-05T06:56:48.025833",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04466v1",
      "title": "Is Micro Domain-Adaptive Pre-Training Effective for Real-World Operations? Multi-Step Evaluation Reveals Potential and Bottlenecks",
      "abstract": "When applying LLMs to real-world enterprise operations, LLMs need to handle proprietary knowledge in small domains of specific operations ($\\textbf{micro domains}$). A previous study shows micro domain-adaptive pre-training ($\\textbf{mDAPT}$) with fewer documents is effective, similarly to DAPT in larger domains. However, it evaluates mDAPT only on multiple-choice questions; thus, its effectiveness for generative tasks in real-world operations remains unknown. We aim to reveal the potential and bottlenecks of mDAPT for generative tasks. To this end, we disentangle the answering process into three subtasks and evaluate the performance of each subtask: (1) $\\textbf{eliciting}$ facts relevant to questions from an LLM's own knowledge, (2) $\\textbf{reasoning}$ over the facts to obtain conclusions, and (3) $\\textbf{composing}$ long-form answers based on the conclusions. We verified mDAPT on proprietary IT product knowledge for real-world questions in IT technical support operations. As a result, mDAPT resolved the elicitation task that the base model struggled with but did not resolve other subtasks. This clarifies mDAPT's effectiveness in the knowledge aspect and its bottlenecks in other aspects. Further analysis empirically shows that resolving the elicitation and reasoning tasks ensures sufficient performance (over 90%), emphasizing the need to enhance reasoning capability.",
      "authors": [
        "Masaya Tsunokake",
        "Yuta Koreeda",
        "Terufumi Morishita",
        "Koichi Nagatsuka",
        "Hikaru Tomonari",
        "Yasuhiro Sogawa"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T11:53:26Z",
      "updated": "2026-02-04T11:53:26Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04466v1",
      "abs_url": "http://arxiv.org/abs/2602.04466v1",
      "summary": "论文研究了微领域自适应预训练（mDAPT）在生成任务中的潜力和瓶颈，并揭示了其在知识获取方面的有效性。",
      "key_contributions": [
        "将问答过程分解为知识获取、推理和答案生成三个子任务进行评估",
        "验证了mDAPT在解决知识获取问题上的有效性",
        "指出了mDAPT在推理能力方面的瓶颈"
      ],
      "methodology": "通过将问答过程分解为三个子任务，并在IT技术支持领域的实际问题上验证mDAPT的性能，从而分析其潜力和瓶颈。",
      "tags": [
        "LLM",
        "微领域自适应预训练",
        "生成任务",
        "知识获取",
        "推理"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "论文核心是分析 LLM 在实际应用中的推理瓶颈，并针对性评估 mDAPT 的效果。",
      "analyzed_at": "2026-02-05T06:56:50.336371",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04459v1",
      "title": "Bayesian PINNs for uncertainty-aware inverse problems (BPINN-IP)",
      "abstract": "The main contribution of this paper is to develop a hierarchical Bayesian formulation of PINNs for linear inverse problems, which is called BPINN-IP. The proposed methodology extends PINN to account for prior knowledge on the nature of the expected NN output, as well as its weights. Also, as we can have access to the posterior probability distributions, naturally uncertainties can be quantified. Also, variational inference and Monte Carlo dropout are employed to provide predictive means and variances for reconstructed images. Un example of applications to deconvolution and super-resolution is considered, details of the different steps of implementations are given, and some preliminary results are presented.",
      "authors": [
        "Ali Mohammad-Djafari"
      ],
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "published": "2026-02-04T11:42:57Z",
      "updated": "2026-02-04T11:42:57Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04459v1",
      "abs_url": "http://arxiv.org/abs/2602.04459v1",
      "summary": "提出了一种基于贝叶斯PINN的线性逆问题求解方法，可量化不确定性。",
      "key_contributions": [
        "提出了BPINN-IP方法",
        "利用变分推理和蒙特卡洛dropout进行预测",
        "应用于反卷积和超分辨率问题"
      ],
      "methodology": "采用分层贝叶斯方法构建PINN，结合变分推理和蒙特卡洛dropout，提供预测均值和方差。",
      "tags": [
        "PINN",
        "Bayesian Inference",
        "Inverse Problems",
        "Uncertainty Quantification",
        "Variational Inference"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 6,
      "relevance_reason": "虽然主要关注物理信息神经网络，但也涉及不确定性量化，与推理相关。",
      "analyzed_at": "2026-02-05T06:56:52.468573",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04457v1",
      "title": "Journey to the Centre of Cluster: Harnessing Interior Nodes for A/B Testing under Network Interference",
      "abstract": "A/B testing on platforms often faces challenges from network interference, where a unit's outcome depends not only on its own treatment but also on the treatments of its network neighbors. To address this, cluster-level randomization has become standard, enabling the use of network-aware estimators. These estimators typically trim the data to retain only a subset of informative units, achieving low bias under suitable conditions but often suffering from high variance. In this paper, we first demonstrate that the interior nodes - units whose neighbors all lie within the same cluster - constitute the vast majority of the post-trimming subpopulation. In light of this, we propose directly averaging over the interior nodes to construct the mean-in-interior (MII) estimator, which circumvents the delicate reweighting required by existing network-aware estimators and substantially reduces variance in classical settings. However, we show that interior nodes are often not representative of the full population, particularly in terms of network-dependent covariates, leading to notable bias. We then augment the MII estimator with a counterfactual predictor trained on the entire network, allowing us to adjust for covariate distribution shifts between the interior nodes and full population. By rearranging the expression, we reveal that our augmented MII estimator embodies an analytical form of the point estimator within prediction-powered inference framework. This insight motivates a semi-supervised lens, wherein interior nodes are treated as labeled data subject to selection bias. Extensive and challenging simulation studies demonstrate the outstanding performance of our augmented MII estimator across various settings.",
      "authors": [
        "Qianyi Chen",
        "Anpeng Wu",
        "Bo Li",
        "Lu Deng",
        "Yong Wang"
      ],
      "categories": [
        "stat.ME",
        "cs.LG"
      ],
      "primary_category": "stat.ME",
      "published": "2026-02-04T11:41:52Z",
      "updated": "2026-02-04T11:41:52Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04457v1",
      "abs_url": "http://arxiv.org/abs/2602.04457v1",
      "summary": "提出一种基于内部节点的A/B测试估计器，并使用预测器进行偏差校正，提升网络干扰下的测试效果。",
      "key_contributions": [
        "提出Mean-in-Interior (MII)估计器，降低方差",
        "利用counterfactual predictor校正内部节点的偏差",
        "将估计器与prediction-powered inference框架联系"
      ],
      "methodology": "通过内部节点取平均构建MII估计器，再用counterfactual predictor调整内部节点和总体之间的协变量差异。",
      "tags": [
        "A/B testing",
        "Network interference",
        "Cluster randomization",
        "Estimation"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 7,
      "relevance_reason": "涉及因果推断和干预效果估计，与推理有一定联系。",
      "analyzed_at": "2026-02-05T06:56:54.359323",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04454v1",
      "title": "Seg-ReSearch: Segmentation with Interleaved Reasoning and External Search",
      "abstract": "Segmentation based on language has been a popular topic in computer vision. While recent advances in multimodal large language models (MLLMs) have endowed segmentation systems with reasoning capabilities, these efforts remain confined by the frozen internal knowledge of MLLMs, which limits their potential for real-world scenarios that involve up-to-date information or domain-specific concepts. In this work, we propose \\textbf{Seg-ReSearch}, a novel segmentation paradigm that overcomes the knowledge bottleneck of existing approaches. By enabling interleaved reasoning and external search, Seg-ReSearch empowers segmentation systems to handle dynamic, open-world queries that extend beyond the frozen knowledge of MLLMs. To effectively train this capability, we introduce a hierarchical reward design that harmonizes initial guidance with progressive incentives, mitigating the dilemma between sparse outcome signals and rigid step-wise supervision. For evaluation, we construct OK-VOS, a challenging benchmark that explicitly requires outside knowledge for video object segmentation. Experiments on OK-VOS and two existing reasoning segmentation benchmarks demonstrate that our Seg-ReSearch improves state-of-the-art approaches by a substantial margin. Code and data will be released at https://github.com/iSEE-Laboratory/Seg-ReSearch.",
      "authors": [
        "Tianming Liang",
        "Qirui Du",
        "Jian-Fang Hu",
        "Haichao Jiang",
        "Zicheng Lin",
        "Wei-Shi Zheng"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-04T11:33:16Z",
      "updated": "2026-02-04T11:33:16Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04454v1",
      "abs_url": "http://arxiv.org/abs/2602.04454v1",
      "summary": "Seg-ReSearch通过交错推理和外部搜索，突破MLLM的知识瓶颈，提升了分割性能。",
      "key_contributions": [
        "提出Seg-ReSearch分割范式，结合推理和外部搜索",
        "设计分层奖励机制，优化训练过程",
        "构建OK-VOS基准，评估开放世界分割能力"
      ],
      "methodology": "利用MLLM进行推理，通过外部搜索获取知识，并结合分层奖励进行训练，提升分割性能。",
      "tags": [
        "分割",
        "多模态",
        "推理",
        "外部搜索",
        "视频对象分割"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于多模态大模型结合外部知识解决视觉分割任务。",
      "analyzed_at": "2026-02-05T06:56:56.204275",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04442v1",
      "title": "No One-Size-Fits-All: Building Systems For Translation to Bashkir, Kazakh, Kyrgyz, Tatar and Chuvash Using Synthetic And Original Data",
      "abstract": "We explore machine translation for five Turkic language pairs: Russian-Bashkir, Russian-Kazakh, Russian-Kyrgyz, English-Tatar, English-Chuvash. Fine-tuning nllb-200-distilled-600M with LoRA on synthetic data achieved chrF++ 49.71 for Kazakh and 46.94 for Bashkir. Prompting DeepSeek-V3.2 with retrieved similar examples achieved chrF++ 39.47 for Chuvash. For Tatar, zero-shot or retrieval-based approaches achieved chrF++ 41.6, while for Kyrgyz the zero-shot approach reached 45.6. We release the dataset and the obtained weights.",
      "authors": [
        "Dmitry Karpov"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T11:14:29Z",
      "updated": "2026-02-04T11:14:29Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04442v1",
      "abs_url": "http://arxiv.org/abs/2602.04442v1",
      "summary": "该论文研究了五种突厥语机器翻译，利用合成数据和检索方法优化了翻译效果。",
      "key_contributions": [
        "针对五种突厥语的机器翻译模型构建",
        "利用合成数据微调模型，提升翻译效果",
        "使用检索方法辅助翻译",
        "发布数据集和模型权重"
      ],
      "methodology": "该论文使用了LoRA微调、Prompting DeepSeek-V3.2、零样本学习和检索等方法进行机器翻译。",
      "tags": [
        "机器翻译",
        "突厥语",
        "数据合成",
        "模型微调",
        "检索增强"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 5,
      "relevance_reason": "检索方法与RAG技术有一定关联，但并非核心关注点。",
      "analyzed_at": "2026-02-05T06:56:58.492469",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04435v1",
      "title": "Machine Learning-Driven Crystal System Prediction for Perovskites Using Augmented X-ray Diffraction Data",
      "abstract": "Prediction of crystal system from X-ray diffraction (XRD) spectra is a critical task in materials science, particularly for perovskite materials which are known for their diverse applications in photovoltaics, optoelectronics, and catalysis. In this study, we present a machine learning (ML)-driven framework that leverages advanced models, including Time Series Forest (TSF), Random Forest (RF), Extreme Gradient Boosting (XGBoost), Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), and a simple feedforward neural network (NN), to classify crystal systems, point groups, and space groups from XRD data of perovskite materials. To address class imbalance and enhance model robustness, we integrated feature augmentation strategies such as Synthetic Minority Over-sampling Technique (SMOTE), class weighting, jittering, and spectrum shifting, along with efficient data preprocessing pipelines. The TSF model with SMOTE augmentation achieved strong performance for crystal system prediction, with a Matthews correlation coefficient (MCC) of 0.9, an F1 score of 0.92, and an accuracy of 97.76%. For point and space group prediction, balanced accuracies above 95% were obtained. The model demonstrated high performance for symmetry-distinct classes, including cubic crystal systems, point groups 3m and m-3m, and space groups Pnma and Pnnn. This work highlights the potential of ML for XRD-based structural characterization and accelerated discovery of perovskite materials",
      "authors": [
        "Ansu Mathew",
        "Ahmer A. B. Baloch",
        "Alamin Yakasai",
        "Hemant Mittal",
        "Vivian Alberts",
        "Jayakumar V. Karunamurthy"
      ],
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.LG"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "published": "2026-02-04T11:09:51Z",
      "updated": "2026-02-04T11:09:51Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04435v1",
      "abs_url": "http://arxiv.org/abs/2602.04435v1",
      "summary": "基于机器学习和增强XRD数据预测钙钛矿晶体结构。",
      "key_contributions": [
        "提出了一种基于机器学习的钙钛矿晶体系统预测框架",
        "使用了多种机器学习模型并结合了数据增强策略",
        "在晶体系统、点群和空间群的预测方面取得了良好效果"
      ],
      "methodology": "利用TSF、RF、XGBoost、RNN等模型，结合SMOTE等数据增强技术，从XRD数据预测晶体结构。",
      "tags": [
        "机器学习",
        "晶体结构预测",
        "钙钛矿",
        "X射线衍射"
      ],
      "assigned_category": "memory",
      "relevance_score": 5,
      "relevance_reason": "使用机器学习方法进行预测，与LLM应用有一定相关性。",
      "analyzed_at": "2026-02-05T06:57:00.260188",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04431v1",
      "title": "MaMa: A Game-Theoretic Approach for Designing Safe Agentic Systems",
      "abstract": "LLM-based multi-agent systems have demonstrated impressive capabilities, but they also introduce significant safety risks when individual agents fail or behave adversarially. In this work, we study the automated design of agentic systems that remain safe even when a subset of agents is compromised. We formalize this challenge as a Stackelberg security game between a system designer (the Meta-Agent) and a best-responding Meta-Adversary that selects and compromises a subset of agents to minimize safety. We propose Meta-Adversary-Meta-Agent (MaMa), a novel algorithm for approximately solving this game and automatically designing safe agentic systems. Our approach uses LLM-based adversarial search, where the Meta-Agent iteratively proposes system designs and receives feedback based on the strongest attacks discovered by the Meta-Adversary. Empirical evaluations across diverse environments show that systems designed with MaMa consistently defend against worst-case attacks while maintaining performance comparable to systems optimized solely for task success. Moreover, the resulting systems generalize to stronger adversaries, as well as ones with different attack objectives or underlying LLMs, demonstrating robust safety beyond the training setting.",
      "authors": [
        "Jonathan Nöther",
        "Adish Singla",
        "Goran Radanovic"
      ],
      "categories": [
        "cs.LG",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T11:07:49Z",
      "updated": "2026-02-04T11:07:49Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04431v1",
      "abs_url": "http://arxiv.org/abs/2602.04431v1",
      "summary": "MaMa算法通过博弈论设计安全自主系统，防御对抗攻击，提升LLM多智能体系统的安全性。",
      "key_contributions": [
        "提出MaMa算法，用于自动设计安全自主系统",
        "将系统安全问题建模为Stackelberg安全博弈",
        "实验证明MaMa设计的系统具有鲁棒性和泛化能力"
      ],
      "methodology": "使用基于LLM的对抗搜索，Meta-Agent迭代提出系统设计，Meta-Adversary寻找最强攻击并反馈。",
      "tags": [
        "AI Agents",
        "安全",
        "博弈论",
        "LLM"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文直接研究了多智能体系统的安全问题，属于AI Agent的核心研究方向。",
      "analyzed_at": "2026-02-05T06:57:02.406514",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04418v1",
      "title": "SPEAR: An Engineering Case Study of Multi-Agent Coordination for Smart Contract Auditing",
      "abstract": "We present SPEAR, a multi-agent coordination framework for smart contract auditing that applies established MAS patterns in a realistic security analysis workflow. SPEAR models auditing as a coordinated mission carried out by specialized agents: a Planning Agent prioritizes contracts using risk-aware heuristics, an Execution Agent allocates tasks via the Contract Net protocol, and a Repair Agent autonomously recovers from brittle generated artifacts using a programmatic-first repair policy. Agents maintain local beliefs updated through AGM-compliant revision, coordinate via negotiation and auction protocols, and revise plans as new information becomes available. An empirical study compares the multi-agent design with centralized and pipeline-based alternatives under controlled failure scenarios, focusing on coordination, recovery behavior, and resource use.",
      "authors": [
        "Arnab Mallick",
        "Indraveni Chebolu",
        "Harmesh Rana"
      ],
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.DC",
        "cs.ET",
        "cs.SE"
      ],
      "primary_category": "cs.MA",
      "published": "2026-02-04T10:51:19Z",
      "updated": "2026-02-04T10:51:19Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04418v1",
      "abs_url": "http://arxiv.org/abs/2602.04418v1",
      "summary": "SPEAR是一个用于智能合约审计的多智能体协同框架，提升审计效率。",
      "key_contributions": [
        "提出基于多智能体的智能合约审计框架SPEAR",
        "设计风险感知的智能合约优先级排序方法",
        "实现基于Contract Net协议的任务分配机制"
      ],
      "methodology": "构建多智能体系统，包括规划、执行和修复智能体，通过协商和拍卖协议协同工作。",
      "tags": [
        "multi-agent system",
        "smart contract",
        "auditing",
        "security"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心是多智能体系统，解决智能合约审计问题。",
      "analyzed_at": "2026-02-05T06:57:04.612002",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04417v1",
      "title": "EMA Policy Gradient: Taming Reinforcement Learning for LLMs with EMA Anchor and Top-k KL",
      "abstract": "Reinforcement Learning (RL) has enabled Large Language Models (LLMs) to acquire increasingly complex reasoning and agentic behaviors. In this work, we propose two simple techniques to improve policy gradient algorithms for LLMs. First, we replace the fixed anchor policy during RL with an Exponential Moving Average (EMA), similar to a target network in deep Q-learning. Second, we introduce Top-k KL estimator, which allows for flexible interpolation between exact KL and sampled KL. We derive the stability conditions for using EMA anchor; moreover, we show that our Top-k KL estimator yields both unbiased KL values and unbiased gradients at any k, while bringing the benefits of exact KL. When combined with GRPO, the two techniques (EMA-PG) lead to a significant performance boost. On math reasoning, it allows R1-distilled Qwen-1.5B to reach 53.9% on OlympiadBench compared to 50.8% by GRPO. On agentic RL domains, with Qwen-3B base, EMA-PG improves GRPO by an average of 33.3% across 7 datasets of Q&A with search engines, including 29.7% $\\rightarrow$ 44.1% on HotpotQA, 27.4% $\\rightarrow$ 40.1% on 2WikiMultiHopQA. Overall, we show that EMA-PG is a simple, principled, and powerful approach to scaling RL for LLMs. Code: https://github.com/LunjunZhang/ema-pg",
      "authors": [
        "Lunjun Zhang",
        "Jimmy Ba"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T10:50:17Z",
      "updated": "2026-02-04T10:50:17Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04417v1",
      "abs_url": "http://arxiv.org/abs/2602.04417v1",
      "summary": "提出EMA-PG算法，通过EMA锚定策略和Top-k KL估计改进LLM的策略梯度强化学习。",
      "key_contributions": [
        "引入EMA锚定策略，提升RL稳定性",
        "提出Top-k KL估计，平衡偏差和方差",
        "实验证明EMA-PG显著提升LLM在推理和Agent任务上的性能"
      ],
      "methodology": "使用EMA替代固定锚定策略，引入Top-k KL估计，结合GRPO进行强化学习。",
      "tags": [
        "强化学习",
        "LLM",
        "策略梯度",
        "EMA",
        "KL散度"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文专注于LLM agent的强化学习，直接解决了agent领域的关键问题。",
      "analyzed_at": "2026-02-05T06:57:07.487401",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04416v1",
      "title": "Med-MMFL: A Multimodal Federated Learning Benchmark in Healthcare",
      "abstract": "Federated learning (FL) enables collaborative model training across decentralized medical institutions while preserving data privacy. However, medical FL benchmarks remain scarce, with existing efforts focusing mainly on unimodal or bimodal modalities and a limited range of medical tasks. This gap underscores the need for standardized evaluation to advance systematic understanding in medical MultiModal FL (MMFL). To this end, we introduce Med-MMFL, the first comprehensive MMFL benchmark for the medical domain, encompassing diverse modalities, tasks, and federation scenarios. Our benchmark evaluates six representative state-of-the-art FL algorithms, covering different aggregation strategies, loss formulations, and regularization techniques. It spans datasets with 2 to 4 modalities, comprising a total of 10 unique medical modalities, including text, pathology images, ECG, X-ray, radiology reports, and multiple MRI sequences. Experiments are conducted across naturally federated, synthetic IID, and synthetic non-IID settings to simulate real-world heterogeneity. We assess segmentation, classification, modality alignment (retrieval), and VQA tasks. To support reproducibility and fair comparison of future multimodal federated learning (MMFL) methods under realistic medical settings, we release the complete benchmark implementation, including data processing and partitioning pipelines, at https://github.com/bhattarailab/Med-MMFL-Benchmark .",
      "authors": [
        "Aavash Chhetri",
        "Bibek Niroula",
        "Pratik Shrestha",
        "Yash Raj Shrestha",
        "Lesley A Anderson",
        "Prashnna K Gyawali",
        "Loris Bazzani",
        "Binod Bhattarai"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-04T10:50:15Z",
      "updated": "2026-02-04T10:50:15Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04416v1",
      "abs_url": "http://arxiv.org/abs/2602.04416v1",
      "summary": "提出了首个综合性的医学多模态联邦学习（MMFL）基准Med-MMFL，促进该领域研究。",
      "key_contributions": [
        "提出了医学多模态联邦学习基准Med-MMFL",
        "涵盖多种模态、任务和联邦场景",
        "评估了六种代表性的联邦学习算法"
      ],
      "methodology": "构建包含多种医学模态的数据集，模拟不同联邦学习场景，评估现有算法在分割、分类等任务上的表现，并公开基准实现。",
      "tags": [
        "联邦学习",
        "多模态学习",
        "医学图像",
        "基准测试"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于多模态数据处理和学习，是多模态学习领域的重要研究。",
      "analyzed_at": "2026-02-05T06:57:09.414430",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04413v1",
      "title": "History-Guided Iterative Visual Reasoning with Self-Correction",
      "abstract": "Self-consistency methods are the core technique for improving the reasoning reliability of multimodal large language models (MLLMs). By generating multiple reasoning results through repeated sampling and selecting the best answer via voting, they play an important role in cross-modal tasks. However, most existing self-consistency methods are limited to a fixed ``repeated sampling and voting'' paradigm and do not reuse historical reasoning information. As a result, models struggle to actively correct visual understanding errors and dynamically adjust their reasoning during iteration. Inspired by the human reasoning behavior of repeated verification and dynamic error correction, we propose the H-GIVR framework. During iterative reasoning, the MLLM observes the image multiple times and uses previously generated answers as references for subsequent steps, enabling dynamic correction of errors and improving answer accuracy. We conduct comprehensive experiments on five datasets and three models. The results show that the H-GIVR framework can significantly improve cross-modal reasoning accuracy while maintaining low computational cost. For instance, using \\texttt{Llama3.2-vision:11b} on the ScienceQA dataset, the model requires an average of 2.57 responses per question to achieve an accuracy of 78.90\\%, representing a 107\\% improvement over the baseline.",
      "authors": [
        "Xinglong Yang",
        "Zhilin Peng",
        "Zhanzhan Liu",
        "Haochen Shi",
        "Sheng-Jun Huang"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T10:42:06Z",
      "updated": "2026-02-04T10:42:06Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04413v1",
      "abs_url": "http://arxiv.org/abs/2602.04413v1",
      "summary": "提出H-GIVR框架，通过历史信息引导迭代视觉推理，动态纠错，提高多模态大模型的推理准确性。",
      "key_contributions": [
        "提出历史引导的迭代视觉推理框架H-GIVR",
        "利用历史推理信息动态纠正视觉理解错误",
        "在多个数据集和模型上验证了H-GIVR的有效性"
      ],
      "methodology": "H-GIVR框架使MLLM多次观察图像，并将先前生成的答案作为后续步骤的参考，从而实现动态错误纠正。",
      "tags": [
        "多模态学习",
        "视觉推理",
        "自洽性",
        "迭代推理",
        "动态纠错"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注多模态大模型的视觉推理能力，并提出了新的框架来提升推理准确性。",
      "analyzed_at": "2026-02-05T06:57:11.611786",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04412v1",
      "title": "HoRD: Robust Humanoid Control via History-Conditioned Reinforcement Learning and Online Distillation",
      "abstract": "Humanoid robots can suffer significant performance drops under small changes in dynamics, task specifications, or environment setup. We propose HoRD, a two-stage learning framework for robust humanoid control under domain shift. First, we train a high-performance teacher policy via history-conditioned reinforcement learning, where the policy infers latent dynamics context from recent state--action trajectories to adapt online to diverse randomized dynamics. Second, we perform online distillation to transfer the teacher's robust control capabilities into a transformer-based student policy that operates on sparse root-relative 3D joint keypoint trajectories. By combining history-conditioned adaptation with online distillation, HoRD enables a single policy to adapt zero-shot to unseen domains without per-domain retraining. Extensive experiments show HoRD outperforms strong baselines in robustness and transfer, especially under unseen domains and external perturbations. Code and project page are available at \\href{https://tonywang-0517.github.io/hord/}{https://tonywang-0517.github.io/hord/}.",
      "authors": [
        "Puyue Wang",
        "Jiawei Hu",
        "Yan Gao",
        "Junyan Wang",
        "Yu Zhang",
        "Gillian Dobbie",
        "Tao Gu",
        "Wafa Johal",
        "Ting Dang",
        "Hong Jia"
      ],
      "categories": [
        "cs.RO",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "published": "2026-02-04T10:41:23Z",
      "updated": "2026-02-04T10:41:23Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04412v1",
      "abs_url": "http://arxiv.org/abs/2602.04412v1",
      "summary": "HoRD提出一种两阶段学习框架，通过历史条件强化学习和在线蒸馏实现鲁棒的人形机器人控制。",
      "key_contributions": [
        "提出了一种历史条件强化学习方法，使策略能够在线适应不同的动力学随机化。",
        "利用在线蒸馏将教师策略的鲁棒控制能力转移到基于Transformer的学生策略。",
        "实现了在未见过的领域和外部扰动下零样本适应的鲁棒控制。"
      ],
      "methodology": "采用两阶段学习框架：历史条件强化学习训练教师策略，在线蒸馏训练基于Transformer的学生策略。",
      "tags": [
        "强化学习",
        "机器人控制",
        "在线蒸馏",
        "领域适应"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "该论文研究如何训练控制策略，属于AI agent的范畴，与智能体的行动控制相关。",
      "analyzed_at": "2026-02-05T06:57:13.674986",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04399v1",
      "title": "Swordsman: Entropy-Driven Adaptive Block Partition for Efficient Diffusion Language Models",
      "abstract": "Block-wise decoding effectively improves the inference speed and quality in diffusion language models (DLMs) by combining inter-block sequential denoising and intra-block parallel unmasking. However, existing block-wise decoding methods typically partition blocks in a rigid and fixed manner, which inevitably fragments complete semantic or syntactic constituents, leading to suboptimal performance. Inspired by the entropy reduction hypothesis (ERH), we recognize that constituent boundaries offer greater opportunities for uncertainty reduction, which motivates us to employ entropy analysis for identifying constituent boundaries. Therefore, we propose Swordsman, an entropy-driven adaptive block-wise decoding framework for DLMs. Swordsman adaptively partitions blocks by identifying entropy shifts between adjacent tokens to better align with semantic or syntactic constituent boundaries. In addition, Swordsman dynamically adjusts unmasking thresholds conditioned on the real-time unmasking status within a block, further improving both efficiency and stability. As a training-free framework, supported by KV Cache, Swordsman demonstrates state-of-the-art performance across extensive evaluations.",
      "authors": [
        "Yu Zhang",
        "Xinchen Li",
        "Jialei Zhou",
        "Hongnan Ma",
        "Zhongwei Wan",
        "Yiwei Shi",
        "Duoqian Miao",
        "Qi Zhang",
        "Longbing Cao"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T10:27:49Z",
      "updated": "2026-02-04T10:27:49Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04399v1",
      "abs_url": "http://arxiv.org/abs/2602.04399v1",
      "summary": "Swordsman提出了一种基于熵驱动的自适应分块解码框架，提高了扩散语言模型的效率和性能。",
      "key_contributions": [
        "提出熵驱动的自适应分块解码框架Swordsman",
        "通过熵分析识别语义或句法成分边界",
        "动态调整掩码阈值，提高效率和稳定性"
      ],
      "methodology": "通过熵分析识别token边界，自适应划分block，并根据block内部掩码状态动态调整阈值，无需训练。",
      "tags": [
        "diffusion language models",
        "entropy",
        "block-wise decoding",
        "adaptive partition"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 7,
      "relevance_reason": "通过优化解码方式，提高LLM的推理效率，与reasoning有一定的关系。",
      "analyzed_at": "2026-02-05T06:57:15.544625",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04397v1",
      "title": "Optimal Rates for Feasible Payoff Set Estimation in Games",
      "abstract": "We study a setting in which two players play a (possibly approximate) Nash equilibrium of a bimatrix game, while a learner observes only their actions and has no knowledge of the equilibrium or the underlying game. A natural question is whether the learner can rationalize the observed behavior by inferring the players' payoff functions. Rather than producing a single payoff estimate, inverse game theory aims to identify the entire set of payoffs consistent with observed behavior, enabling downstream use in, e.g., counterfactual analysis and mechanism design across applications like auctions, pricing, and security games. We focus on the problem of estimating the set of feasible payoffs with high probability and up to precision $ε$ on the Hausdorff metric. We provide the first minimax-optimal rates for both exact and approximate equilibrium play, in zero-sum as well as general-sum games. Our results provide learning-theoretic foundations for set-valued payoff inference in multi-agent environments.",
      "authors": [
        "Annalisa Barbara",
        "Riccardo Poiani",
        "Martino Bernasconi",
        "Andrea Celli"
      ],
      "categories": [
        "cs.GT",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "published": "2026-02-04T10:27:11Z",
      "updated": "2026-02-04T10:27:11Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04397v1",
      "abs_url": "http://arxiv.org/abs/2602.04397v1",
      "summary": "研究逆向博弈论中可行收益集合估计的最优速率，并提供理论基础。",
      "key_contributions": [
        "提出零和及一般和博弈中精确和近似均衡博弈的最优最小最大速率",
        "为多智能体环境中的集合值收益推断提供学习理论基础",
        "研究了在仅观察玩家行为时推断玩家收益函数的难题"
      ],
      "methodology": "通过学习理论方法，推导并证明了在 Hausdorff 距离下可行收益集合估计的 minimax 最优速率。",
      "tags": [
        "逆向博弈论",
        "可行收益集合估计",
        "学习理论",
        "博弈论"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "该论文探讨了在博弈环境中，通过观察智能体的行为来推断其收益函数，这与智能体建模和理解相关。",
      "analyzed_at": "2026-02-05T06:57:17.735458",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04396v1",
      "title": "LoRDO: Distributed Low-Rank Optimization with Infrequent Communication",
      "abstract": "Distributed training of foundation models via $\\texttt{DDP}$ is limited by interconnect bandwidth. While infrequent communication strategies reduce synchronization frequency, they remain bottlenecked by the memory and communication requirements of optimizer states. Low-rank optimizers can alleviate these constraints; however, in the local-update regime, workers lack access to the full-batch gradients required to compute low-rank projections, which degrades performance. We propose $\\texttt{LoRDO}$, a principled framework unifying low-rank optimization with infrequent synchronization. We first demonstrate that, while global projections based on pseudo-gradients are theoretically superior, they permanently restrict the optimization trajectory to a low-rank subspace. To restore subspace exploration, we introduce a full-rank quasi-hyperbolic update. $\\texttt{LoRDO}$ achieves near-parity with low-rank $\\texttt{DDP}$ in language modeling and downstream tasks at model scales of $125$M--$720$M, while reducing communication by $\\approx 10 \\times$. Finally, we show that $\\texttt{LoRDO}$ improves performance even more in very low-memory settings with small rank/batch size.",
      "authors": [
        "Andrej Jovanović",
        "Alex Iacob",
        "Mher Safaryan",
        "Ionut-Vlad Modoranu",
        "Lorenzo Sani",
        "William F. Shen",
        "Xinchi Qiu",
        "Dan Alistarh",
        "Nicholas D. Lane"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T10:25:24Z",
      "updated": "2026-02-04T10:25:24Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04396v1",
      "abs_url": "http://arxiv.org/abs/2602.04396v1",
      "summary": "LoRDO通过低秩优化和稀疏通信，降低分布式训练中带宽和内存瓶颈，提高训练效率。",
      "key_contributions": [
        "提出LoRDO框架，结合低秩优化与稀疏同步",
        "引入全秩准双曲更新，恢复子空间探索",
        "实验证明LoRDO在语言建模和下游任务中具有竞争力，并显著减少通信量"
      ],
      "methodology": "LoRDO使用伪梯度进行全局低秩投影，并引入全秩准双曲更新来平衡优化轨迹与子空间探索。",
      "tags": [
        "分布式训练",
        "低秩优化",
        "稀疏通信",
        "语言模型"
      ],
      "assigned_category": "agent",
      "relevance_score": 6,
      "relevance_reason": "虽然侧重分布式训练，但可应用于AI Agent模型的训练优化。",
      "analyzed_at": "2026-02-05T06:57:19.778076",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04392v1",
      "title": "Evaluating the Presence of Sex Bias in Clinical Reasoning by Large Language Models",
      "abstract": "Large language models (LLMs) are increasingly embedded in healthcare workflows for documentation, education, and clinical decision support. However, these systems are trained on large text corpora that encode existing biases, including sex disparities in diagnosis and treatment, raising concerns that such patterns may be reproduced or amplified. We systematically examined whether contemporary LLMs exhibit sex-specific biases in clinical reasoning and how model configuration influences these behaviours. We conducted three experiments using 50 clinician-authored vignettes spanning 44 specialties in which sex was non-informative to the initial diagnostic pathway. Four general-purpose LLMs (ChatGPT (gpt-4o-mini), Claude 3.7 Sonnet, Gemini 2.0 Flash and DeepSeekchat). All models demonstrated significant sex-assignment skew, with predicted sex differing by model. At temperature 0.5, ChatGPT assigned female sex in 70% of cases (95% CI 0.66-0.75), DeepSeek in 61% (0.57-0.65) and Claude in 59% (0.55-0.63), whereas Gemini showed a male skew, assigning a female sex in 36% of cases (0.32-0.41). Contemporary LLMs exhibit stable, model-specific sex biases in clinical reasoning. Permitting abstention reduces explicit labelling but does not eliminate downstream diagnostic differences. Safe clinical integration requires conservative and documented configuration, specialty-level clinical data auditing, and continued human oversight when deploying general-purpose models in healthcare settings.",
      "authors": [
        "Isabel Tsintsiper",
        "Sheng Wong",
        "Beth Albert",
        "Shaun P Brennecke",
        "Gabriel Davis Jones"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T10:21:38Z",
      "updated": "2026-02-04T10:21:38Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04392v1",
      "abs_url": "http://arxiv.org/abs/2602.04392v1",
      "summary": "评估大型语言模型在临床推理中存在的性别偏见，发现不同模型存在稳定的性别偏向。",
      "key_contributions": [
        "系统性评估LLM在临床推理中的性别偏见",
        "发现不同LLM模型存在稳定的、模型特定的性别偏向",
        "强调了在医疗保健领域部署通用LLM时需要谨慎和持续的监督"
      ],
      "methodology": "使用50个临床医生编写的临床案例，针对四个通用LLM进行三项实验，评估其性别偏向。",
      "tags": [
        "LLM",
        "临床推理",
        "性别偏见",
        "医疗保健"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "直接研究LLM在推理中存在的性别偏见问题，对于公平性至关重要。",
      "analyzed_at": "2026-02-05T06:57:21.732301",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04391v1",
      "title": "Beyond Rejection Sampling: Trajectory Fusion for Scaling Mathematical Reasoning",
      "abstract": "Large language models (LLMs) have made impressive strides in mathematical reasoning, often fine-tuned using rejection sampling that retains only correct reasoning trajectories. While effective, this paradigm treats supervision as a binary filter that systematically excludes teacher-generated errors, leaving a gap in how reasoning failures are modeled during training. In this paper, we propose TrajFusion, a fine-tuning strategy that reframes rejection sampling as a structured supervision construction process. Specifically, TrajFusion forms fused trajectories that explicitly model trial-and-error reasoning by interleaving selected incorrect trajectories with reflection prompts and correct trajectories. The length of each fused sample is adaptively controlled based on the frequency and diversity of teacher errors, providing richer supervision for challenging problems while safely reducing to vanilla rejection sampling fine-tuning (RFT) when error signals are uninformative. TrajFusion requires no changes to the architecture or training objective. Extensive experiments across multiple math benchmarks demonstrate that TrajFusion consistently outperforms RFT, particularly on challenging and long-form reasoning problems.",
      "authors": [
        "Jie Deng",
        "Hanshuang Tong",
        "Jun Li",
        "Shining Liang",
        "Ning Wu",
        "Hongzhi Li",
        "Yutao Xie"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T10:20:56Z",
      "updated": "2026-02-04T10:20:56Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04391v1",
      "abs_url": "http://arxiv.org/abs/2602.04391v1",
      "summary": "TrajFusion通过融合错误轨迹和反思提示，提升LLM数学推理能力。",
      "key_contributions": [
        "提出了TrajFusion，一种改进的微调策略",
        "将拒绝采样重新定义为结构化监督构建过程",
        "在数学推理基准测试中优于RFT"
      ],
      "methodology": "通过交错错误轨迹、反思提示和正确轨迹，构建融合轨迹，自适应控制轨迹长度，优化LLM微调。",
      "tags": [
        "LLM",
        "Mathematical Reasoning",
        "Fine-tuning",
        "Trajectory Fusion"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注LLM数学推理能力，直接相关。",
      "analyzed_at": "2026-02-05T06:57:24.788112",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04380v1",
      "title": "Beyond KL Divergence: Policy Optimization with Flexible Bregman Divergences for LLM Reasoning",
      "abstract": "Policy optimization methods like Group Relative Policy Optimization (GRPO) and its variants have achieved strong results on mathematical reasoning and code generation tasks. Despite extensive exploration of reward processing strategies and training dynamics, all existing group-based methods exclusively use KL divergence for policy regularization, leaving the choice of divergence function unexplored. We introduce Group-Based Mirror Policy Optimization (GBMPO), a framework that extends group-based policy optimization to flexible Bregman divergences, including hand-designed alternatives (L2 in probability space) and learned neural mirror maps. On GSM8K mathematical reasoning, hand-designed ProbL2-GRPO achieves 86.7% accuracy, improving +5.5 points over the Dr. GRPO baseline. On MBPP code generation, neural mirror maps reach 60.1-60.8% pass@1, with random initialization already capturing most of the benefit. While evolutionary strategies meta-learning provides marginal accuracy improvements, its primary value lies in variance reduction ($\\pm$0.2 versus $\\pm$0.6) and efficiency gains (15% shorter responses on MBPP), suggesting that random initialization of neural mirror maps is sufficient for most practical applications. These results establish divergence choice as a critical, previously unexplored design dimension in group-based policy optimization for LLM reasoning.",
      "authors": [
        "Rui Yuan",
        "Mykola Khandoga",
        "Vinay Kumar Sankarapu"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T10:01:20Z",
      "updated": "2026-02-04T10:01:20Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04380v1",
      "abs_url": "http://arxiv.org/abs/2602.04380v1",
      "summary": "提出了GBMPO框架，探索Bregman散度在LLM推理策略优化中的应用，显著提升数学推理和代码生成性能。",
      "key_contributions": [
        "提出了 Group-Based Mirror Policy Optimization (GBMPO) 框架",
        "探索了多种 Bregman 散度在策略优化中的应用，包括手动设计和神经元映射",
        "验证了 Bregman 散度选择对 LLM 推理策略优化的重要性"
      ],
      "methodology": "扩展了基于群组的策略优化方法，引入灵活的Bregman散度作为正则化项，并使用实验验证其有效性。",
      "tags": [
        "LLM",
        "Policy Optimization",
        "Bregman Divergence",
        "Reasoning",
        "Code Generation"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文直接研究了LLM的推理能力提升，核心相关。",
      "analyzed_at": "2026-02-05T06:57:27.056488",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04356v1",
      "title": "When and Where to Attack? Stage-wise Attention-Guided Adversarial Attack on Large Vision Language Models",
      "abstract": "Adversarial attacks against Large Vision-Language Models (LVLMs) are crucial for exposing safety vulnerabilities in modern multimodal systems. Recent attacks based on input transformations, such as random cropping, suggest that spatially localized perturbations can be more effective than global image manipulation. However, randomly cropping the entire image is inherently stochastic and fails to use the limited per-pixel perturbation budget efficiently. We make two key observations: (i) regional attention scores are positively correlated with adversarial loss sensitivity, and (ii) attacking high-attention regions induces a structured redistribution of attention toward subsequent salient regions. Based on these findings, we propose Stage-wise Attention-Guided Attack (SAGA), an attention-guided framework that progressively concentrates perturbations on high-attention regions. SAGA enables more efficient use of constrained perturbation budgets, producing highly imperceptible adversarial examples while consistently achieving state-of-the-art attack success rates across ten LVLMs. The source code is available at https://github.com/jackwaky/SAGA.",
      "authors": [
        "Jaehyun Kwak",
        "Nam Cao",
        "Boryeong Cho",
        "Segyu Lee",
        "Sumyeong Ahn",
        "Se-Young Yun"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-04T09:29:10Z",
      "updated": "2026-02-04T09:29:10Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04356v1",
      "abs_url": "http://arxiv.org/abs/2602.04356v1",
      "summary": "SAGA是一种基于注意力机制的对抗攻击方法，能高效攻击大型视觉语言模型。",
      "key_contributions": [
        "发现区域注意力得分与对抗损失敏感性正相关",
        "提出Stage-wise Attention-Guided Attack (SAGA)框架",
        "SAGA能高效利用有限扰动预算，生成高质量对抗样本"
      ],
      "methodology": "利用注意力机制指导扰动，逐步将扰动集中在高注意力区域，提高攻击效率。",
      "tags": [
        "对抗攻击",
        "视觉语言模型",
        "注意力机制",
        "多模态"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "直接针对视觉语言模型的对抗攻击，属于多模态领域核心问题。",
      "analyzed_at": "2026-02-05T06:57:28.974528",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04355v1",
      "title": "Can Vision Replace Text in Working Memory? Evidence from Spatial n-Back in Vision-Language Models",
      "abstract": "Working memory is a central component of intelligent behavior, providing a dynamic workspace for maintaining and updating task-relevant information. Recent work has used n-back tasks to probe working-memory-like behavior in large language models, but it is unclear whether the same probe elicits comparable computations when information is carried in a visual rather than textual code in vision-language models. We evaluate Qwen2.5 and Qwen2.5-VL on a controlled spatial n-back task presented as matched text-rendered or image-rendered grids. Across conditions, models show reliably higher accuracy and d' with text than with vision. To interpret these differences at the process level, we use trial-wise log-probability evidence and find that nominal 2/3-back often fails to reflect the instructed lag and instead aligns with a recency-locked comparison. We further show that grid size alters recent-repeat structure in the stimulus stream, thereby changing interference and error patterns. These results motivate computation-sensitive interpretations of multimodal working memory.",
      "authors": [
        "Sichu Liang",
        "Hongyu Zhu",
        "Wenwen Wang",
        "Deyu Zhou"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T09:25:07Z",
      "updated": "2026-02-04T09:25:07Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04355v1",
      "abs_url": "http://arxiv.org/abs/2602.04355v1",
      "summary": "该论文比较了视觉语言模型在文本和图像形式的空间n-back任务中的工作记忆表现，发现文本形式表现更优。",
      "key_contributions": [
        "评估了视觉语言模型在视觉和文本空间n-back任务中的性能差异",
        "分析了模型在不同任务中的错误模式和干扰因素",
        "揭示了任务参数对模型工作记忆表现的影响"
      ],
      "methodology": "使用Qwen2.5和Qwen2.5-VL模型，在文本渲染和图像渲染的空间n-back任务中进行实验，并分析其准确率、d'值和试次对数概率证据。",
      "tags": [
        "工作记忆",
        "视觉语言模型",
        "n-back",
        "多模态",
        "Qwen"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "直接研究视觉语言模型在多模态场景下的工作记忆能力，属于核心研究方向。",
      "analyzed_at": "2026-02-05T06:57:31.283290",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04340v1",
      "title": "Explicit Uncertainty Modeling for Active CLIP Adaptation with Dual Prompt Tuning",
      "abstract": "Pre-trained vision-language models such as CLIP exhibit strong transferability, yet adapting them to downstream image classification tasks under limited annotation budgets remains challenging. In active learning settings, the model must select the most informative samples for annotation from a large pool of unlabeled data. Existing approaches typically estimate uncertainty via entropy-based criteria or representation clustering, without explicitly modeling uncertainty from the model perspective. In this work, we propose a robust uncertainty modeling framework for active CLIP adaptation based on dual-prompt tuning. We introduce two learnable prompts in the textual branch of CLIP. The positive prompt enhances the discriminability of task-specific textual embeddings corresponding to light-weight tuned visual embeddings, improving classification reliability. Meanwhile, the negative prompt is trained in an reversed manner to explicitly model the probability that the predicted label is correct, providing a principled uncertainty signal for guiding active sample selection. Extensive experiments across different fine-tuning paradigms demonstrate that our method consistently outperforms existing active learning methods under the same annotation budget.",
      "authors": [
        "Qian-Wei Wang",
        "Yaguang Song",
        "Shu-Tao Xia"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-04T09:01:55Z",
      "updated": "2026-02-04T09:01:55Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04340v1",
      "abs_url": "http://arxiv.org/abs/2602.04340v1",
      "summary": "提出基于双Prompt调整的主动CLIP适应框架，显式建模不确定性以优化样本选择。",
      "key_contributions": [
        "提出双Prompt调整方法，包括正向和负向Prompt",
        "显式建模预测标签的置信度，用于不确定性估计",
        "在主动学习场景下，优于现有方法"
      ],
      "methodology": "在CLIP的文本分支中引入可学习的正负Prompt，正向prompt增强判别性，负向prompt建模预测概率。",
      "tags": [
        "CLIP",
        "Active Learning",
        "Uncertainty Modeling",
        "Prompt Tuning",
        "Vision-Language"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心是CLIP在多模态环境下的应用，结合主动学习和不确定性建模。",
      "analyzed_at": "2026-02-05T06:57:33.419390",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04337v1",
      "title": "Fine-tuning Pre-trained Vision-Language Models in a Human-Annotation-Free Manner",
      "abstract": "Large-scale vision-language models (VLMs) such as CLIP exhibit strong zero-shot generalization, but adapting them to downstream tasks typically requires costly labeled data. Existing unsupervised self-training methods rely on pseudo-labeling, yet often suffer from unreliable confidence filtering, confirmation bias, and underutilization of low-confidence samples. We propose Collaborative Fine-Tuning (CoFT), an unsupervised adaptation framework that leverages unlabeled data through a dual-model, cross-modal collaboration mechanism. CoFT introduces a dual-prompt learning strategy with positive and negative textual prompts to explicitly model pseudo-label cleanliness in a sample-dependent manner, removing the need for hand-crafted thresholds or noise assumptions. The negative prompt also regularizes lightweight visual adaptation modules, improving robustness under noisy supervision. CoFT employs a two-phase training scheme, transitioning from parameter-efficient fine-tuning on high-confidence samples to full fine-tuning guided by collaboratively filtered pseudo-labels. Building on CoFT, CoFT+ further enhances adaptation via iterative fine-tuning, momentum contrastive learning, and LLM-generated prompts. Extensive experiments demonstrate consistent gains over existing unsupervised methods and even few-shot supervised baselines.",
      "authors": [
        "Qian-Wei Wang",
        "Guanghao Meng",
        "Ren Cai",
        "Yaguang Song",
        "Shu-Tao Xia"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-04T09:00:12Z",
      "updated": "2026-02-04T09:00:12Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04337v1",
      "abs_url": "http://arxiv.org/abs/2602.04337v1",
      "summary": "CoFT提出了一种无需人工标注的视觉语言模型微调框架，通过双模型协作提升性能。",
      "key_contributions": [
        "提出 Collaborative Fine-Tuning (CoFT)框架",
        "引入双提示学习策略，建模伪标签纯净度",
        "结合动量对比学习和LLM生成提示，进一步提升性能"
      ],
      "methodology": "CoFT利用双模型和交叉模态协作，通过正负文本提示和两阶段训练，实现无监督的视觉语言模型微调。",
      "tags": [
        "视觉语言模型",
        "无监督学习",
        "微调",
        "自训练"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心研究方向是视觉语言模型的无监督微调，高度相关。",
      "analyzed_at": "2026-02-05T06:57:35.264795",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04326v1",
      "title": "From Assumptions to Actions: Turning LLM Reasoning into Uncertainty-Aware Planning for Embodied Agents",
      "abstract": "Embodied agents operating in multi-agent, partially observable, and decentralized environments must plan and act despite pervasive uncertainty about hidden objects and collaborators' intentions. Recent advances in applying Large Language Models (LLMs) to embodied agents have addressed many long-standing challenges, such as high-level goal decomposition and online adaptation. Yet, uncertainty is still primarily mitigated through frequent inter-agent communication. This incurs substantial token and time costs, and can disrupt established workflows, when human partners are involved. We introduce PCE, a Planner-Composer-Evaluator framework that converts the fragmented assumptions latent in LLM reasoning traces into a structured decision tree. Internal nodes encode environment assumptions and leaves map to actions; each path is then scored by scenario likelihood, goal-directed gain, and execution cost to guide rational action selection without heavy communication. Across two challenging multi-agent benchmarks (C-WAH and TDW-MAT) and three diverse LLM backbones, PCE consistently outperforms communication-centric baselines in success rate and task efficiency while showing comparable token usage. Ablation results indicate that the performance gains obtained by scaling model capacity or reasoning depth persist even when PCE is applied, while PCE consistently raises the baseline across both capacity and reasoning-depth scales, confirming that structured uncertainty handling complements both forms of scaling. A user study further demonstrates that PCE produces communication patterns that human partners perceive as more efficient and trustworthy. Together, these results establish a principled route for turning latent LLM assumptions into reliable strategies for uncertainty-aware planning.",
      "authors": [
        "SeungWon Seo",
        "SooBin Lim",
        "SeongRae Noh",
        "Haneul Kim",
        "HyeongYeop Kang"
      ],
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-04T08:43:39Z",
      "updated": "2026-02-04T08:43:39Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04326v1",
      "abs_url": "http://arxiv.org/abs/2602.04326v1",
      "summary": "提出PCE框架，将LLM推理中的不确定性转化为结构化的决策树，提升多智能体环境下的规划能力。",
      "key_contributions": [
        "提出Planner-Composer-Evaluator (PCE) 框架",
        "将LLM的隐式假设转化为结构化的决策树",
        "在多智能体任务中验证了PCE的有效性，提高了成功率和效率"
      ],
      "methodology": "构建决策树，节点表示环境假设，叶子节点表示行动，通过场景可能性、收益和成本评估路径，指导行动选择。",
      "tags": [
        "LLM",
        "Agent",
        "Planning",
        "Uncertainty"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注智能体在不确定环境下的规划问题，并使用LLM进行辅助，属于AI Agent领域的核心问题。",
      "analyzed_at": "2026-02-05T06:57:37.270099",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04323v1",
      "title": "Efficient Equivariant High-Order Crystal Tensor Prediction via Cartesian Local-Environment Many-Body Coupling",
      "abstract": "End-to-end prediction of high-order crystal tensor properties from atomic structures remains challenging: while spherical-harmonic equivariant models are expressive, their Clebsch-Gordan tensor products incur substantial compute and memory costs for higher-order targets. We propose the Cartesian Environment Interaction Tensor Network (CEITNet), an approach that constructs a multi-channel Cartesian local environment tensor for each atom and performs flexible many-body mixing via a learnable channel-space interaction. By performing learning in channel space and using Cartesian tensor bases to assemble equivariant outputs, CEITNet enables efficient construction of high-order tensor. Across benchmark datasets for order-2 dielectric, order-3 piezoelectric, and order-4 elastic tensor prediction, CEITNet surpasses prior high-order prediction methods on key accuracy criteria while offering high computational efficiency.",
      "authors": [
        "Dian Jin",
        "Yancheng Yuan",
        "Xiaoming Tao"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-04T08:39:53Z",
      "updated": "2026-02-04T08:39:53Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04323v1",
      "abs_url": "http://arxiv.org/abs/2602.04323v1",
      "summary": "CEITNet通过笛卡尔局部环境张量网络高效预测高阶晶体张量。",
      "key_contributions": [
        "提出CEITNet模型，用于高效预测高阶晶体张量性质",
        "使用笛卡尔张量基构建等变输出，提高计算效率",
        "在多个数据集上验证了CEITNet的准确性和效率"
      ],
      "methodology": "构建原子多通道笛卡尔局部环境张量，通过可学习的通道空间交互进行多体混合，实现高效高阶张量预测。",
      "tags": [
        "晶体张量预测",
        "等变神经网络",
        "张量网络"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 5,
      "relevance_reason": "涉及逻辑推理和结构预测，具有一定相关性。",
      "analyzed_at": "2026-02-05T06:57:39.835957",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04315v1",
      "title": "GeneralVLA: Generalizable Vision-Language-Action Models with Knowledge-Guided Trajectory Planning",
      "abstract": "Large foundation models have shown strong open-world generalization to complex problems in vision and language, but similar levels of generalization have yet to be achieved in robotics. One fundamental challenge is that the models exhibit limited zero-shot capability, which hampers their ability to generalize effectively to unseen scenarios. In this work, we propose GeneralVLA (Generalizable Vision-Language-Action Models with Knowledge-Guided Trajectory Planning), a hierarchical vision-language-action (VLA) model that can be more effective in utilizing the generalization of foundation models, enabling zero-shot manipulation and automatically generating data for robotics. In particular, we study a class of hierarchical VLA model where the high-level ASM (Affordance Segmentation Module) is finetuned to perceive image keypoint affordances of the scene; the mid-level 3DAgent carries out task understanding, skill knowledge, and trajectory planning to produce a 3D path indicating the desired robot end-effector trajectory. The intermediate 3D path prediction is then served as guidance to the low-level, 3D-aware control policy capable of precise manipulation. Compared to alternative approaches, our method requires no real-world robotic data collection or human demonstration, making it much more scalable to diverse tasks and viewpoints. Empirically, GeneralVLA successfully generates trajectories for 14 tasks, significantly outperforming state-of-the-art methods such as VoxPoser. The generated demonstrations can train more robust behavior cloning policies than training with human demonstrations or from data generated by VoxPoser, Scaling-up, and Code-As-Policies. We believe GeneralVLA can be the scalable method for both generating data for robotics and solving novel tasks in a zero-shot setting. Code: https://github.com/AIGeeksGroup/GeneralVLA. Website: https://aigeeksgroup.github.io/GeneralVLA.",
      "authors": [
        "Guoqing Ma",
        "Siheng Wang",
        "Zeyu Zhang",
        "Shan Yu",
        "Hao Tang"
      ],
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "published": "2026-02-04T08:30:27Z",
      "updated": "2026-02-04T08:30:27Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04315v1",
      "abs_url": "http://arxiv.org/abs/2602.04315v1",
      "summary": "GeneralVLA通过知识引导的轨迹规划，提升视觉-语言-动作模型的零样本泛化能力。",
      "key_contributions": [
        "提出了一个分层VLA模型GeneralVLA",
        "无需真实机器人数据或人类演示即可生成轨迹",
        "在14个任务上显著优于现有技术"
      ],
      "methodology": "利用精调的ASM进行图像关键点感知，3DAgent进行任务理解和轨迹规划，再用3D感知控制策略进行精确操作。",
      "tags": [
        "VLA",
        "Zero-shot Learning",
        "Robotics",
        "Trajectory Planning"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "核心关注Vision-Language-Action模型在机器人中的应用，涉及智能体规划和控制的关键问题。",
      "analyzed_at": "2026-02-05T06:57:41.752755",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04304v1",
      "title": "Beyond Static Cropping: Layer-Adaptive Visual Localization and Decoding Enhancement",
      "abstract": "Large Vision-Language Models (LVLMs) have advanced rapidly by aligning visual patches with the text embedding space, but a fixed visual-token budget forces images to be resized to a uniform pretraining resolution, often erasing fine-grained details and causing hallucinations via over-reliance on language priors. Recent attention-guided enhancement (e.g., cropping or region-focused attention allocation) alleviates this, yet it commonly hinges on a static \"magic layer\" empirically chosen on simple recognition benchmarks and thus may not transfer to complex reasoning tasks. In contrast to this static assumption, we propose a dynamic perspective on visual grounding. Through a layer-wise sensitivity analysis, we demonstrate that visual grounding is a dynamic process: while simple object recognition tasks rely on middle layers, complex visual search and reasoning tasks require visual information to be reactivated at deeper layers. Based on this observation, we introduce Visual Activation by Query (VAQ), a metric that identifies the layer whose attention map is most relevant to query-specific visual grounding by measuring attention sensitivity to the input query. Building on VAQ, we further propose LASER (Layer-adaptive Attention-guided Selective visual and decoding Enhancement for Reasoning), a training-free inference procedure that adaptively selects task-appropriate layers for visual localization and question answering. Experiments across diverse VQA benchmarks show that LASER significantly improves VQA accuracy across tasks with varying levels of complexity.",
      "authors": [
        "Zipeng Zhu",
        "Zhanghao Hu",
        "Qinglin Zhu",
        "Yuxi Hong",
        "Yijun Liu",
        "Jingyong Su",
        "Yulan He",
        "Lin Gui"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-04T08:13:01Z",
      "updated": "2026-02-04T08:13:01Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04304v1",
      "abs_url": "http://arxiv.org/abs/2602.04304v1",
      "summary": "该论文提出了一种层自适应的视觉定位和解码增强方法，提升了视觉问答任务的性能。",
      "key_contributions": [
        "提出了基于query的视觉激活度量VAQ",
        "提出了层自适应的推理流程LASER",
        "实验证明LASER在多种VQA任务上的有效性"
      ],
      "methodology": "通过层敏感性分析发现视觉定位的动态特性，利用VAQ选择与任务相关的层，并使用LASER自适应地增强视觉和解码。",
      "tags": [
        "视觉问答",
        "多模态学习",
        "注意力机制",
        "层自适应"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文直接研究了视觉语言模型中的视觉信息利用问题，与多模态学习紧密相关。",
      "analyzed_at": "2026-02-05T06:57:43.750319",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04296v1",
      "title": "ProxyWar: Dynamic Assessment of LLM Code Generation in Game Arenas",
      "abstract": "Large language models (LLMs) have revolutionized automated code generation, yet the evaluation of their real-world effectiveness remains limited by static benchmarks and simplistic metrics. We present ProxyWar, a novel framework that systematically assesses code generation quality by embedding LLM-generated agents within diverse, competitive game environments. Unlike existing approaches, ProxyWar evaluates not only functional correctness but also the operational characteristics of generated programs, combining automated testing, iterative code repair, and multi-agent tournaments to provide a holistic view of program behavior. Applied to a range of state-of-the-art coders and games, our approach uncovers notable discrepancies between benchmark scores and actual performance in dynamic settings, revealing overlooked limitations and opportunities for improvement. These findings highlight the need for richer, competition-based evaluation of code generation. Looking forward, ProxyWar lays a foundation for research into LLM-driven algorithm discovery, adaptive problem solving, and the study of practical efficiency and robustness, including the potential for models to outperform hand-crafted agents. The project is available at https://github.com/xinke-wang/ProxyWar.",
      "authors": [
        "Wenjun Peng",
        "Xinyu Wang",
        "Qi Wu"
      ],
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "published": "2026-02-04T07:57:06Z",
      "updated": "2026-02-04T07:57:06Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04296v1",
      "abs_url": "http://arxiv.org/abs/2602.04296v1",
      "summary": "ProxyWar框架通过竞争性游戏环境动态评估LLM代码生成质量，发现传统评估方法的局限性。",
      "key_contributions": [
        "提出ProxyWar框架，用于动态评估LLM代码生成",
        "揭示静态benchmark与实际游戏环境性能的差异",
        "为LLM驱动的算法发现和自适应问题求解奠定基础"
      ],
      "methodology": "构建包含多种竞争性游戏环境的评估框架，LLM生成的智能体在其中进行迭代测试、修复和多智能体竞赛。",
      "tags": [
        "LLM",
        "Code Generation",
        "Evaluation",
        "Game AI"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "核心研究LLM在自主智能体中的应用，并提出评估方法。",
      "analyzed_at": "2026-02-05T06:57:45.624360",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04290v1",
      "title": "Guided Verifier: Collaborative Multimodal Reasoning via Dynamic Process Supervision",
      "abstract": "Reinforcement Learning (RL) has emerged as a pivotal mechanism for enhancing the complex reasoning capabilities of Multimodal Large Language Models (MLLMs). However, prevailing paradigms typically rely on solitary rollout strategies where the model works alone. This lack of intermediate oversight renders the reasoning process susceptible to error propagation, where early logical deviations cascade into irreversible failures, resulting in noisy optimization signals. In this paper, we propose the \\textbf{Guided Verifier} framework to address these structural limitations. Moving beyond passive terminal rewards, we introduce a dynamic verifier that actively co-solves tasks alongside the policy. During the rollout phase, this verifier interacts with the policy model in real-time, detecting inconsistencies and providing directional signals to steer the model toward valid trajectories. To facilitate this, we develop a specialized data synthesis pipeline targeting multimodal hallucinations, constructing \\textbf{CoRe} dataset of process-level negatives and \\textbf{Co}rrect-guide \\textbf{Re}asoning trajectories to train the guided verifier. Extensive experiments on MathVista, MathVerse and MMMU indicate that by allocating compute to collaborative inference and dynamic verification, an 8B-parameter model can achieve strong performance.",
      "authors": [
        "Lingzhuang Sun",
        "Ruitong Liu",
        "Yuxia Zhu",
        "Xiaohan Xu",
        "Jingxuan Wei",
        "Xiangxiang Zhang",
        "Bihui Yu",
        "Wentao Zhang"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T07:38:42Z",
      "updated": "2026-02-04T07:38:42Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04290v1",
      "abs_url": "http://arxiv.org/abs/2602.04290v1",
      "summary": "提出Guided Verifier框架，通过动态验证器实时监督MLLM推理过程，减少错误传播，提升推理能力。",
      "key_contributions": [
        "提出Guided Verifier框架，实现动态过程监督",
        "构建CoRe数据集用于训练验证器，针对多模态幻觉问题",
        "实验证明该方法能够有效提升MLLM在多模态推理任务上的性能"
      ],
      "methodology": "引入动态验证器与策略模型协同解决问题，实时检测不一致性并提供方向信号，使用合成数据训练验证器。",
      "tags": [
        "Multimodal",
        "Reasoning",
        "Reinforcement Learning",
        "Verification"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于提升多模态大模型的推理能力，并着重解决了多模态环境下的幻觉问题。",
      "analyzed_at": "2026-02-05T06:57:47.696249",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04284v1",
      "title": "Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning",
      "abstract": "Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To this end, we first conduct quantitative investigations into how thought and observation affect agent effectiveness and efficiency. Based on our findings, we propose Agent-Omit, a unified training framework that empowers LLM agents to adaptively omit redundant thoughts and observations. Specifically, we first synthesize a small amount of cold-start data, including both single-turn and multi-turn omission scenarios, to fine-tune the agent for omission behaviors. Furthermore, we introduce an omit-aware agentic reinforcement learning approach, incorporating a dual sampling mechanism and a tailored omission reward to incentivize the agent's adaptive omission capability. Theoretically, we prove that the deviation of our omission policy is upper-bounded by KL-divergence. Experimental results on five agent benchmarks show that our constructed Agent-Omit-8B could obtain performance comparable to seven frontier LLM agent, and achieve the best effectiveness-efficiency trade-off than seven efficient LLM agents methods. Our code and data are available at https://github.com/usail-hkust/Agent-Omit.",
      "authors": [
        "Yansong Ning",
        "Jun Fang",
        "Naiqiang Tan",
        "Hao Liu"
      ],
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-04T07:26:23Z",
      "updated": "2026-02-04T07:26:23Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04284v1",
      "abs_url": "http://arxiv.org/abs/2602.04284v1",
      "summary": "Agent-Omit通过强化学习训练LLM Agent自适应地省略冗余思考和观察，提高效率。",
      "key_contributions": [
        "提出Agent-Omit框架，实现LLM Agent自适应省略思考和观察。",
        "引入omit-aware agentic reinforcement learning方法，包含双重采样和定制的省略奖励。",
        "理论证明了省略策略的偏差上限。",
        "实验证明Agent-Omit在效率和效果上优于其他方法。"
      ],
      "methodology": "通过少量冷启动数据微调，然后使用基于强化学习的agentic learning方法，以双重采样和定制省略奖励机制，训练Agent。",
      "tags": [
        "LLM Agent",
        "Reinforcement Learning",
        "Efficiency",
        "Omission",
        "Adaptive"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文直接研究LLM Agent的效率提升，属于该领域的核心问题。",
      "analyzed_at": "2026-02-05T06:57:49.785861",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04279v1",
      "title": "ECG-R1: Protocol-Guided and Modality-Agnostic MLLM for Reliable ECG Interpretation",
      "abstract": "Electrocardiography (ECG) serves as an indispensable diagnostic tool in clinical practice, yet existing multimodal large language models (MLLMs) remain unreliable for ECG interpretation, often producing plausible but clinically incorrect analyses. To address this, we propose ECG-R1, the first reasoning MLLM designed for reliable ECG interpretation via three innovations. First, we construct the interpretation corpus using \\textit{Protocol-Guided Instruction Data Generation}, grounding interpretation in measurable ECG features and monograph-defined quantitative thresholds and diagnostic logic. Second, we present a modality-decoupled architecture with \\textit{Interleaved Modality Dropout} to improve robustness and cross-modal consistency when either the ECG signal or ECG image is missing. Third, we present \\textit{Reinforcement Learning with ECG Diagnostic Evidence Rewards} to strengthen evidence-grounded ECG interpretation. Additionally, we systematically evaluate the ECG interpretation capabilities of proprietary, open-source, and medical MLLMs, and provide the first quantitative evidence that severe hallucinations are widespread, suggesting that the public should not directly trust these outputs without independent verification. Code and data are publicly available at \\href{https://github.com/PKUDigitalHealth/ECG-R1}{here}, and an online platform can be accessed at \\href{http://ai.heartvoice.com.cn/ECG-R1/}{here}.",
      "authors": [
        "Jiarui Jin",
        "Haoyu Wang",
        "Xingliang Wu",
        "Xiaocheng Fang",
        "Xiang Lan",
        "Zihan Wang",
        "Deyun Zhang",
        "Bo Liu",
        "Yingying Zhang",
        "Xian Wu",
        "Hongyan Li",
        "Shenda Hong"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-04T07:17:55Z",
      "updated": "2026-02-04T07:17:55Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04279v1",
      "abs_url": "http://arxiv.org/abs/2602.04279v1",
      "summary": "ECG-R1通过协议引导和模态解耦，提升MLLM在心电图判读的可靠性。",
      "key_contributions": [
        "提出协议引导的指令数据生成方法",
        "设计了模态解耦架构，提高鲁棒性和跨模态一致性",
        "使用基于诊断证据的强化学习，增强证据驱动的心电图判读"
      ],
      "methodology": "构建协议引导的指令数据集，采用模态解耦架构，并使用强化学习优化证据驱动的ECG判读。",
      "tags": [
        "心电图",
        "多模态学习",
        "大型语言模型",
        "医疗AI"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于利用MLLM处理心电图数据，属于多模态学习的关键应用。",
      "analyzed_at": "2026-02-05T06:57:51.965055",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.04268v1",
      "title": "KVSmooth: Mitigating Hallucination in Multi-modal Large Language Models through Key-Value Smoothing",
      "abstract": "Despite the significant progress of Multimodal Large Language Models (MLLMs) across diverse tasks, hallucination -- corresponding to the generation of visually inconsistent objects, attributes, or relations -- remains a major obstacle to their reliable deployment. Unlike pure language models, MLLMs must ground their generation process in visual inputs. However, existing models often suffer from semantic drift during decoding, causing outputs to diverge from visual facts as the sequence length increases.   To address this issue, we propose KVSmooth, a training-free and plug-and-play method that mitigates hallucination by performing attention-entropy-guided adaptive smoothing on hidden states. Specifically, KVSmooth applies an exponential moving average (EMA) to both keys and values in the KV-Cache, while dynamically quantifying the sink degree of each token through the entropy of its attention distribution to adaptively adjust the smoothing strength.   Unlike computationally expensive retraining or contrastive decoding methods, KVSmooth operates efficiently during inference without additional training or model modification. Extensive experiments demonstrate that KVSmooth significantly reduces hallucination ($\\mathit{CHAIR}_{S}$ from $41.8 \\rightarrow 18.2$) while improving overall performance ($F_1$ score from $77.5 \\rightarrow 79.2$), achieving higher precision and recall simultaneously. In contrast, prior methods often improve one at the expense of the other, validating the effectiveness and generality of our approach.",
      "authors": [
        "Siyu Jiang",
        "Feiyang Chen",
        "Xiaojin Zhang",
        "Kun He"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-04T06:59:17Z",
      "updated": "2026-02-04T06:59:17Z",
      "pdf_url": "https://arxiv.org/pdf/2602.04268v1",
      "abs_url": "http://arxiv.org/abs/2602.04268v1",
      "summary": "KVSmooth通过平滑KV-Cache，缓解多模态大语言模型中的幻觉问题，无需额外训练。",
      "key_contributions": [
        "提出KVSmooth方法，有效减少MLLM的幻觉现象",
        "KVSmooth是training-free和plug-and-play的，易于应用",
        "实验证明KVSmooth在降低幻觉的同时提升了整体性能"
      ],
      "methodology": "KVSmooth通过注意力熵引导的自适应平滑KV-Cache中的键和值，降低语义漂移，从而减少幻觉。",
      "tags": [
        "MLLM",
        "Hallucination",
        "Key-Value Smoothing",
        "Attention Entropy"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文直接针对多模态大语言模型的幻觉问题，提出新方法并进行实验验证，核心相关。",
      "analyzed_at": "2026-02-05T06:57:54.269037",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    }
  ],
  "fetch_time": "2026-02-05T06:57:54.269208"
}