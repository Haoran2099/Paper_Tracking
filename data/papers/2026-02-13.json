{
  "date": "2026-02-13",
  "papers": [
    {
      "arxiv_id": "2602.12281v1",
      "title": "Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment",
      "abstract": "The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given instructions. In this paper, we investigate test-time verification as a means to shrink the \"intention-action gap.'' We first characterize the test-time scaling law for embodied instruction following and demonstrate that jointly scaling the number of rephrased instructions and generated actions greatly increases test-time sample diversity, often recovering correct actions more efficiently than scaling each dimension independently. To capitalize on these scaling laws, we present CoVer, a contrastive verifier for vision-language-action alignment, and show that our architecture scales gracefully with additional computational resources and data. We then introduce \"boot-time compute\" and a hierarchical verification inference pipeline for VLAs. At deployment, our framework precomputes a diverse set of rephrased instructions from a Vision-Language-Model (VLM), repeatedly generates action candidates for each instruction, and then uses a verifier to select the optimal high-level prompt and low-level action chunks. Compared to scaling policy pre-training on the same data, our verification approach yields 22% gains in-distribution and 13% out-of-distribution on the SIMPLER benchmark, with a further 45% improvement in real-world experiments. On the PolaRiS benchmark, CoVer achieves 14% gains in task progress and 9% in success rate.",
      "authors": [
        "Jacky Kwok",
        "Xilun Zhang",
        "Mengdi Xu",
        "Yuejiang Liu",
        "Azalia Mirhoseini",
        "Chelsea Finn",
        "Marco Pavone"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "published": "2026-02-12T18:59:59Z",
      "updated": "2026-02-12T18:59:59Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12281v1",
      "abs_url": "http://arxiv.org/abs/2602.12281v1",
      "summary": "验证方法比策略学习更有效地提升视觉-语言-动作对齐，并提出了CoVer框架。",
      "key_contributions": [
        "提出test-time验证方法提升VLA模型性能",
        "提出对比验证器CoVer，提升计算效率和数据利用率",
        "提出boot-time compute和分层验证推理管线"
      ],
      "methodology": "利用VLM生成多样指令，重复生成动作候选，通过对比验证器选择最优提示和动作块。",
      "tags": [
        "视觉-语言-动作对齐",
        "验证",
        "机器人",
        "指令跟随"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于视觉语言动作模型的对齐问题，属于多模态领域关键研究。",
      "analyzed_at": "2026-02-13T06:58:08.998622",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12279v1",
      "title": "UniT: Unified Multimodal Chain-of-Thought Test-time Scaling",
      "abstract": "Unified models can handle both multimodal understanding and generation within a single architecture, yet they typically operate in a single pass without iteratively refining their outputs. Many multimodal tasks, especially those involving complex spatial compositions, multiple interacting objects, or evolving instructions, require decomposing instructions, verifying intermediate results, and making iterative corrections. While test-time scaling (TTS) has demonstrated that allocating additional inference compute for iterative reasoning substantially improves language model performance, extending this paradigm to unified multimodal models remains an open challenge. We introduce UniT, a framework for multimodal chain-of-thought test-time scaling that enables a single unified model to reason, verify, and refine across multiple rounds. UniT combines agentic data synthesis, unified model training, and flexible test-time inference to elicit cognitive behaviors including verification, subgoal decomposition, and content memory. Our key findings are: (1) unified models trained on short reasoning trajectories generalize to longer inference chains at test time; (2) sequential chain-of-thought reasoning provides a more scalable and compute-efficient TTS strategy than parallel sampling; (3) training on generation and editing trajectories improves out-of-distribution visual reasoning. These results establish multimodal test-time scaling as an effective paradigm for advancing both generation and understanding in unified models.",
      "authors": [
        "Leon Liangyu Chen",
        "Haoyu Ma",
        "Zhipeng Fan",
        "Ziqi Huang",
        "Animesh Sinha",
        "Xiaoliang Dai",
        "Jialiang Wang",
        "Zecheng He",
        "Jianwei Yang",
        "Chunyuan Li",
        "Junzhe Sun",
        "Chu Wang",
        "Serena Yeung-Levy",
        "Felix Juefei-Xu"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-12T18:59:49Z",
      "updated": "2026-02-12T18:59:49Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12279v1",
      "abs_url": "http://arxiv.org/abs/2602.12279v1",
      "summary": "UniT提出多模态链式思考测试时扩展框架，提升统一模型在复杂任务中的推理能力。",
      "key_contributions": [
        "提出UniT框架，实现多模态链式思考测试时扩展",
        "验证了统一模型在短推理轨迹上训练后，可泛化到更长的推理链",
        "证明了序列CoT比并行采样更高效"
      ],
      "methodology": "结合agentic数据合成、统一模型训练和灵活的测试时推理，使模型具备验证、分解子目标和内容记忆等认知行为。",
      "tags": [
        "Multimodal",
        "Chain-of-Thought",
        "Test-Time Scaling",
        "Unified Model"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心围绕多模态模型的推理能力和测试时扩展，与多模态领域高度相关。",
      "analyzed_at": "2026-02-13T06:58:10.653568",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12278v1",
      "title": "AttentionRetriever: Attention Layers are Secretly Long Document Retrievers",
      "abstract": "Retrieval augmented generation (RAG) has been widely adopted to help Large Language Models (LLMs) to process tasks involving long documents. However, existing retrieval models are not designed for long document retrieval and fail to address several key challenges of long document retrieval, including context-awareness, causal dependence, and scope of retrieval. In this paper, we proposed AttentionRetriever, a novel long document retrieval model that leverages attention mechanism and entity-based retrieval to build context-aware embeddings for long document and determine the scope of retrieval. With extensive experiments, we found AttentionRetriever is able to outperform existing retrieval models on long document retrieval datasets by a large margin while remaining as efficient as dense retrieval models.",
      "authors": [
        "David Jiahao Fu",
        "Lam Thanh Do",
        "Jiayu Li",
        "Kevin Chen-Chuan Chang"
      ],
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "published": "2026-02-12T18:59:35Z",
      "updated": "2026-02-12T18:59:35Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12278v1",
      "abs_url": "http://arxiv.org/abs/2602.12278v1",
      "summary": "AttentionRetriever利用注意力机制和实体检索，构建上下文感知嵌入，提升长文档检索性能和效率。",
      "key_contributions": [
        "提出AttentionRetriever模型，提升长文档检索性能",
        "利用注意力机制构建上下文感知嵌入",
        "通过实体检索确定检索范围"
      ],
      "methodology": "提出AttentionRetriever，结合注意力机制和实体检索，为长文档构建上下文感知嵌入，优化检索范围。",
      "tags": [
        "RAG",
        "长文档检索",
        "注意力机制",
        "实体检索"
      ],
      "assigned_category": "memory",
      "relevance_score": 9,
      "relevance_reason": "论文直接研究了RAG中长文档检索的关键问题，核心相关。",
      "analyzed_at": "2026-02-13T06:58:12.109474",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12276v1",
      "title": "Agentic Test-Time Scaling for WebAgents",
      "abstract": "Test-time scaling has become a standard way to improve performance and boost reliability of neural network models. However, its behavior on agentic, multi-step tasks remains less well-understood: small per-step errors can compound over long horizons; and we find that naive policies that uniformly increase sampling show diminishing returns. In this work, we present CATTS, a simple technique for dynamically allocating compute for multi-step agents. We first conduct an empirical study of inference-time scaling for web agents. We find that uniformly increasing per-step compute quickly saturates in long-horizon environments. We then investigate stronger aggregation strategies, including an LLM-based Arbiter that can outperform naive voting, but that can overrule high-consensus decisions. We show that uncertainty statistics derived from the agent's own vote distribution (entropy and top-1/top-2 margin) correlate with downstream success and provide a practical signal for dynamic compute allocation. Based on these findings, we introduce Confidence-Aware Test-Time Scaling (CATTS), which uses vote-derived uncertainty to allocate compute only when decisions are genuinely contentious. CATTS improves performance on WebArena-Lite and GoBrowse by up to 9.1% over React while using up to 2.3x fewer tokens than uniform scaling, providing both efficiency gains and an interpretable decision rule.",
      "authors": [
        "Nicholas Lee",
        "Lutfi Eren Erdogan",
        "Chris Joseph John",
        "Surya Krishnapillai",
        "Michael W. Mahoney",
        "Kurt Keutzer",
        "Amir Gholami"
      ],
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T18:58:30Z",
      "updated": "2026-02-12T18:58:30Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12276v1",
      "abs_url": "http://arxiv.org/abs/2602.12276v1",
      "summary": "针对WebAgent，提出一种基于置信度的动态计算分配方法CATTS，提升效率和性能。",
      "key_contributions": [
        "发现均匀增加计算量在长程任务中收益递减",
        "提出基于Agent投票分布的不确定性统计指标",
        "提出Confidence-Aware Test-Time Scaling (CATTS) 策略"
      ],
      "methodology": "通过对WebAgent的推理时缩放进行经验研究，利用Agent投票分布的不确定性指标，动态分配计算资源。",
      "tags": [
        "WebAgent",
        "Test-time Scaling",
        "Uncertainty Estimation",
        "Dynamic Compute Allocation"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文专注于Agent的性能优化和效率提升，与Agent领域核心相关。",
      "analyzed_at": "2026-02-13T06:58:13.810744",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12275v1",
      "title": "On-Policy Context Distillation for Language Models",
      "abstract": "Context distillation enables language models to internalize in-context knowledge into their parameters. In our work, we propose On-Policy Context Distillation (OPCD), a framework that bridges on-policy distillation with context distillation by training a student model on its own generated trajectories while minimizing reverse Kullback-Leibler divergence against a context-conditioned teacher. We demonstrate the effectiveness of OPCD on two important applications: experiential knowledge distillation, where models extract and consolidate transferable knowledge from their historical solution traces, and system prompt distillation, where models internalize beneficial behaviors encoded in optimized prompts. Across mathematical reasoning, text-based games, and domain-specific tasks, OPCD consistently outperforms baseline methods, achieving higher task accuracy while better preserving out-of-distribution capabilities. We further show that OPCD enables effective cross-size distillation, where smaller student models can internalize experiential knowledge from larger teachers.",
      "authors": [
        "Tianzhu Ye",
        "Li Dong",
        "Xun Wu",
        "Shaohan Huang",
        "Furu Wei"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-12T18:58:28Z",
      "updated": "2026-02-12T18:58:28Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12275v1",
      "abs_url": "http://arxiv.org/abs/2602.12275v1",
      "summary": "提出On-Policy上下文蒸馏(OPCD)，通过在生成轨迹上训练学生模型来提取和整合上下文知识。",
      "key_contributions": [
        "提出On-Policy上下文蒸馏框架OPCD",
        "OPCD在经验知识蒸馏和系统提示蒸馏上的有效性",
        "证明OPCD在跨尺寸蒸馏中的有效性"
      ],
      "methodology": "OPCD训练学生模型在自身生成轨迹上最小化与上下文条件教师的反向KL散度，从而实现上下文知识的内化。",
      "tags": [
        "上下文蒸馏",
        "知识蒸馏",
        "语言模型",
        "On-Policy"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 8,
      "relevance_reason": "论文关注如何优化agent行为，与agent tuning主题高度相关。",
      "analyzed_at": "2026-02-13T06:58:15.448904",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12268v1",
      "title": "CM2: Reinforcement Learning with Checklist Rewards for Multi-Turn and Multi-Step Agentic Tool Use",
      "abstract": "AI agents are increasingly used to solve real-world tasks by reasoning over multi-turn user interactions and invoking external tools. However, applying reinforcement learning to such settings remains difficult: realistic objectives often lack verifiable rewards and instead emphasize open-ended behaviors; moreover, RL for multi-turn, multi-step agentic tool use is still underexplored; and building and maintaining executable tool environments is costly, limiting scale and coverage. We propose CM2, an RL framework that replaces verifiable outcome rewards with checklist rewards. CM2 decomposes each turn's intended behavior into fine-grained binary criteria with explicit evidence grounding and structured metadata, turning open-ended judging into more stable classification-style decisions. To balance stability and informativeness, our method adopts a strategy of sparse reward assignment but dense evaluation criteria. Training is performed in a scalable LLM-simulated tool environment, avoiding heavy engineering for large tool sets. Experiments show that CM2 consistently improves over supervised fine-tuning. Starting from an 8B Base model and training on an 8k-example RL dataset, CM2 improves over the SFT counterpart by 8 points on tau^-Bench, by 10 points on BFCL-V4, and by 12 points on ToolSandbox. The results match or even outperform similarly sized open-source baselines, including the judging model. CM2 thus provides a scalable recipe for optimizing multi-turn, multi-step tool-using agents without relying on verifiable rewards. Code provided by the open-source community: https://github.com/namezhenzhang/CM2-RLCR-Tool-Agent.",
      "authors": [
        "Zhen Zhang",
        "Kaiqiang Song",
        "Xun Wang",
        "Yebowen Hu",
        "Weixiang Yan",
        "Chenyang Zhao",
        "Henry Peng Zou",
        "Haoyun Deng",
        "Sathish Reddy Indurthi",
        "Shujian Liu",
        "Simin Ma",
        "Xiaoyang Wang",
        "Xin Eric Wang",
        "Song Wang"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T18:55:09Z",
      "updated": "2026-02-12T18:55:09Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12268v1",
      "abs_url": "http://arxiv.org/abs/2602.12268v1",
      "summary": "CM2提出使用checklist奖励的强化学习框架，优化多轮多步骤的智能体工具使用。",
      "key_contributions": [
        "提出checklist奖励代替可验证结果奖励",
        "构建可扩展的LLM模拟工具环境",
        "验证了CM2在多项任务上的有效性"
      ],
      "methodology": "使用LLM模拟环境，将开放式判断转化为分类任务，通过稀疏奖励和密集评估标准进行强化学习训练。",
      "tags": [
        "强化学习",
        "AI Agent",
        "Tool Use",
        "Checklist Rewards"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 9,
      "relevance_reason": "直接针对智能体工具使用进行优化，属于agent tuning的核心问题。",
      "analyzed_at": "2026-02-13T06:58:17.279126",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12262v1",
      "title": "T3D: Few-Step Diffusion Language Models via Trajectory Self-Distillation with Direct Discriminative Optimization",
      "abstract": "Diffusion large language models (DLLMs) have the potential to enable fast text generation by decoding multiple tokens in parallel. However, in practice, their inference efficiency is constrained by the need for many refinement steps, while aggressively reducing the number of steps leads to a substantial degradation in generation quality. To alleviate this, we propose a trajectory self-distillation framework that improves few-step decoding by distilling the model's own generative trajectories. We incorporate Direct Discriminative Optimization (DDO), a reverse-KL objective that promotes mode-seeking distillation and encourages the student to concentrate on high-probability teacher modes. Across benchmarks, our approach consistently outperforms strong few-step baselines and standard training under tight step budgets. Although full-step decoding remains superior, we substantially narrow the gap, establishing a strong foundation towards practical few-step DLLMs. The source code is available at https://github.com/Tyrion58/T3D.",
      "authors": [
        "Tunyu Zhang",
        "Xinxi Zhang",
        "Ligong Han",
        "Haizhou Shi",
        "Xiaoxiao He",
        "Zhuowei Li",
        "Hao Wang",
        "Kai Xu",
        "Akash Srivastava",
        "Hao Wang",
        "Vladimir Pavlovic",
        "Dimitris N. Metaxas"
      ],
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-12T18:52:35Z",
      "updated": "2026-02-12T18:52:35Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12262v1",
      "abs_url": "http://arxiv.org/abs/2602.12262v1",
      "summary": "提出T3D框架，通过轨迹自蒸馏和DDO优化，提升扩散语言模型少步解码的生成质量和效率。",
      "key_contributions": [
        "提出基于轨迹自蒸馏的少步解码优化框架T3D",
        "引入DDO（Direct Discriminative Optimization）来促进模态寻找蒸馏",
        "在多个基准测试上优于现有少步解码基线"
      ],
      "methodology": "利用模型自身的生成轨迹进行自蒸馏，并通过DDO目标函数优化，使学生模型专注于高概率教师模型输出。",
      "tags": [
        "扩散语言模型",
        "自蒸馏",
        "少步解码",
        "DDO"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 7,
      "relevance_reason": "该研究旨在提升LLM的生成效率，涉及优化过程。",
      "analyzed_at": "2026-02-13T06:58:19.776985",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12259v1",
      "title": "Think like a Scientist: Physics-guided LLM Agent for Equation Discovery",
      "abstract": "Explaining observed phenomena through symbolic, interpretable formulas is a fundamental goal of science. Recently, large language models (LLMs) have emerged as promising tools for symbolic equation discovery, owing to their broad domain knowledge and strong reasoning capabilities. However, most existing LLM-based systems try to guess equations directly from data, without modeling the multi-step reasoning process that scientists often follow: first inferring physical properties such as symmetries, then using these as priors to restrict the space of candidate equations. We introduce KeplerAgent, an agentic framework that explicitly follows this scientific reasoning process. The agent coordinates physics-based tools to extract intermediate structure and uses these results to configure symbolic regression engines such as PySINDy and PySR, including their function libraries and structural constraints. Across a suite of physical equation benchmarks, KeplerAgent achieves substantially higher symbolic accuracy and greater robustness to noisy data than both LLM and traditional baselines.",
      "authors": [
        "Jianke Yang",
        "Ohm Venkatachalam",
        "Mohammad Kianezhad",
        "Sharvaree Vadgama",
        "Rose Yu"
      ],
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T18:49:27Z",
      "updated": "2026-02-12T18:49:27Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12259v1",
      "abs_url": "http://arxiv.org/abs/2602.12259v1",
      "summary": "KeplerAgent利用物理知识引导LLM进行符号公式发现，提升了公式发现的准确性和鲁棒性。",
      "key_contributions": [
        "提出KeplerAgent框架，模拟科学家发现公式的推理过程",
        "结合物理知识和LLM进行公式发现",
        "在物理公式发现基准测试中表现优于其他方法"
      ],
      "methodology": "KeplerAgent利用物理工具提取中间结构，并将其用于配置符号回归引擎，例如PySINDy和PySR。",
      "tags": [
        "LLM",
        "Agent",
        "Symbolic Regression",
        "Physics-guided",
        "Equation Discovery"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "该论文提出了一种基于LLM的Agent框架，用于解决科学公式发现问题，与Agent主题高度相关。",
      "analyzed_at": "2026-02-13T06:58:21.612287",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12250v1",
      "title": "Community Concealment from Unsupervised Graph Learning-Based Clustering",
      "abstract": "Graph neural networks (GNNs) are designed to use attributed graphs to learn representations. Such representations are beneficial in the unsupervised learning of clusters and community detection. Nonetheless, such inference may reveal sensitive groups, clustered systems, or collective behaviors, raising concerns regarding group-level privacy. Community attribution in social and critical infrastructure networks, for example, can expose coordinated asset groups, operational hierarchies, and system dependencies that could be used for profiling or intelligence gathering. We study a defensive setting in which a data publisher (defender) seeks to conceal a community of interest while making limited, utility-aware changes in the network. Our analysis indicates that community concealment is strongly influenced by two quantifiable factors: connectivity at the community boundary and feature similarity between the protected community and adjacent communities. Informed by these findings, we present a perturbation strategy that rewires a set of selected edges and modifies node features to reduce the distinctiveness leveraged by GNN message passing. The proposed method outperforms DICE in our experiments on synthetic benchmarks and real network graphs under identical perturbation budgets. Overall, it achieves median relative concealment improvements of approximately 20-45% across the evaluated settings. These findings demonstrate a mitigation strategy against GNN-based community learning and highlight group-level privacy risks intrinsic to graph learning.",
      "authors": [
        "Dalyapraz Manatova",
        "Pablo Moriano",
        "L. Jean Camp"
      ],
      "categories": [
        "cs.LG",
        "cs.CR",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T18:36:19Z",
      "updated": "2026-02-12T18:36:19Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12250v1",
      "abs_url": "http://arxiv.org/abs/2602.12250v1",
      "summary": "研究GNN在图聚类中暴露群体隐私的风险，提出了一种基于扰动的社区隐藏策略。",
      "key_contributions": [
        "分析了影响社区隐藏的关键因素：边界连接性和特征相似性",
        "提出了一种通过重连边和修改节点特征来隐藏社区的扰动策略",
        "实验证明该方法优于DICE，提升了社区隐藏效果"
      ],
      "methodology": "通过分析影响社区隐藏的因素，设计扰动策略，重连边和修改节点特征，减少GNN消息传递的区分性。",
      "tags": [
        "图神经网络",
        "隐私保护",
        "社区检测",
        "对抗学习"
      ],
      "assigned_category": "agent",
      "relevance_score": 5,
      "relevance_reason": "涉及到保护群体隐私，防止被agent利用，有一定的参考价值。",
      "analyzed_at": "2026-02-13T06:58:23.470122",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12241v1",
      "title": "Moonshine v2: Ergodic Streaming Encoder ASR for Latency-Critical Speech Applications",
      "abstract": "Latency-critical speech applications (e.g., live transcription, voice commands, and real-time translation) demand low time-to-first-token (TTFT) and high transcription accuracy, particularly on resource-constrained edge devices. Full-attention Transformer encoders remain a strong accuracy baseline for automatic speech recognition (ASR) because every frame can directly attend to every other frame, which resolves otherwise locally ambiguous acoustics using distant lexical context. However, this global dependency incurs quadratic complexity in sequence length, inducing an inherent \"encode-the-whole-utterance\" latency profile. For streaming use cases, this causes TTFT to grow linearly with utterance length as the encoder must process the entire prefix before any decoder token can be emitted. To better meet the needs of on-device, streaming ASR use cases we introduce Moonshine v2, an ergodic streaming-encoder ASR model that employs sliding-window self-attention to achieve bounded, low-latency inference while preserving strong local context. Our models achieve state of the art word error rates across standard benchmarks, attaining accuracy on-par with models 6x their size while running significantly faster. These results demonstrate that carefully designed local attention is competitive with the accuracy of full attention at a fraction of the size and latency cost, opening new possibilities for interactive speech interfaces on edge devices.",
      "authors": [
        "Manjunath Kudlur",
        "Evan King",
        "James Wang",
        "Pete Warden"
      ],
      "categories": [
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-12T18:20:45Z",
      "updated": "2026-02-12T18:20:45Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12241v1",
      "abs_url": "http://arxiv.org/abs/2602.12241v1",
      "summary": "Moonshine v2提出了一种低延迟、高精度的流式语音识别模型，适用于资源受限的边缘设备。",
      "key_contributions": [
        "提出一种基于滑动窗口自注意力的流式encoder ASR模型",
        "在标准数据集上达到state-of-the-art的词错误率",
        "模型大小和延迟成本显著降低，性能媲美大型模型"
      ],
      "methodology": "采用滑动窗口自注意力机制，在保证局部上下文信息的同时，实现低延迟的流式语音识别。",
      "tags": [
        "语音识别",
        "流式ASR",
        "低延迟",
        "自注意力",
        "边缘计算"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "边缘设备上的语音识别是Agent与环境交互的关键环节，该论文提升了语音交互的效率。",
      "analyzed_at": "2026-02-13T06:58:25.683047",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12235v1",
      "title": "Detecting Overflow in Compressed Token Representations for Retrieval-Augmented Generation",
      "abstract": "Efficient long-context processing remains a crucial challenge for contemporary large language models (LLMs), especially in resource-constrained environments. Soft compression architectures promise to extend effective context length by replacing long token sequences with smaller sets of learned compressed tokens. Yet, the limits of compressibility -- and when compression begins to erase task-relevant content -- remain underexplored. In this paper, we define \\emph{token overflow} as a regime in which compressed representations no longer contain sufficient information to answer a given query, and propose a methodology to characterize and detect it. In the xRAG soft-compression setting, we find that query-agnostic saturation statistics reliably separate compressed from uncompressed token representations, providing a practical tool for identifying compressed tokens but showing limited overflow detection capability. Lightweight probing classifiers over both query and context xRAG representations detect overflow with 0.72 AUC-ROC on average on HotpotQA, SQuADv2, and TriviaQA datasets, demonstrating that incorporating query information improves detection performance. These results advance from query-independent diagnostics to query-aware detectors, enabling low-cost pre-LLM gating to mitigate compression-induced errors.",
      "authors": [
        "Julia Belikova",
        "Danila Rozhevskii",
        "Dennis Svirin",
        "Konstantin Polev",
        "Alexander Panchenko"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-12T18:15:08Z",
      "updated": "2026-02-12T18:15:08Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12235v1",
      "abs_url": "http://arxiv.org/abs/2602.12235v1",
      "summary": "论文研究了压缩表征在RAG中信息溢出的问题，并提出了检测方法，以提高长文本处理能力。",
      "key_contributions": [
        "定义了token overflow的概念",
        "提出了检测token overflow的方法论",
        "证明了query-aware检测器能有效缓解压缩带来的误差"
      ],
      "methodology": "论文提出了基于饱和度统计和轻量级探测分类器的两种检测方法，并验证了query信息的有效性。",
      "tags": [
        "RAG",
        "长文本处理",
        "信息压缩",
        "Overflow Detection"
      ],
      "assigned_category": "memory",
      "relevance_score": 9,
      "relevance_reason": "论文直接研究了RAG中的信息溢出问题，属于该领域的核心研究内容。",
      "analyzed_at": "2026-02-13T06:58:27.240605",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12233v1",
      "title": "Categorical Flow Maps",
      "abstract": "We introduce Categorical Flow Maps, a flow-matching method for accelerated few-step generation of categorical data via self-distillation. Building on recent variational formulations of flow matching and the broader trend towards accelerated inference in diffusion and flow-based models, we define a flow map towards the simplex that transports probability mass toward a predicted endpoint, yielding a parametrisation that naturally constrains model predictions. Since our trajectories are continuous rather than discrete, Categorical Flow Maps can be trained with existing distillation techniques, as well as a new objective based on endpoint consistency. This continuous formulation also automatically unlocks test-time inference: we can directly reuse existing guidance and reweighting techniques in the categorical setting to steer sampling toward downstream objectives. Empirically, we achieve state-of-the-art few-step results on images, molecular graphs, and text, with strong performance even in single-step generation.",
      "authors": [
        "Daan Roos",
        "Oscar Davis",
        "Floor Eijkelboom",
        "Michael Bronstein",
        "Max Welling",
        "İsmail İlkan Ceylan",
        "Luca Ambrogioni",
        "Jan-Willem van de Meent"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T18:10:46Z",
      "updated": "2026-02-12T18:10:46Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12233v1",
      "abs_url": "http://arxiv.org/abs/2602.12233v1",
      "summary": "提出Categorical Flow Maps，加速类别数据的少步生成，实现优异性能。",
      "key_contributions": [
        "提出Categorical Flow Maps方法",
        "基于flow matching的类别数据生成",
        "利用自蒸馏加速生成",
        "持续轨迹，可使用现有蒸馏技术"
      ],
      "methodology": "构建从单纯形到预测终点的flow map，利用连续轨迹训练，结合蒸馏技术和终点一致性目标。",
      "tags": [
        "Flow Matching",
        "Self-Distillation",
        "Categorical Data Generation",
        "Generative Models"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 6,
      "relevance_reason": "涉及到图像、分子图和文本生成，具有一定多模态相关性。",
      "analyzed_at": "2026-02-13T06:58:28.923084",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12224v1",
      "title": "Bandit Learning in Matching Markets with Interviews",
      "abstract": "Two-sided matching markets rely on preferences from both sides, yet it is often impractical to evaluate preferences. Participants, therefore, conduct a limited number of interviews, which provide early, noisy impressions and shape final decisions. We study bandit learning in matching markets with interviews, modeling interviews as \\textit{low-cost hints} that reveal partial preference information to both sides. Our framework departs from existing work by allowing firm-side uncertainty: firms, like agents, may be unsure of their own preferences and can make early hiring mistakes by hiring less preferred agents. To handle this, we extend the firm's action space to allow \\emph{strategic deferral} (choosing not to hire in a round), enabling recovery from suboptimal hires and supporting decentralized learning without coordination. We design novel algorithms for (i) a centralized setting with an omniscient interview allocator and (ii) decentralized settings with two types of firm-side feedback. Across all settings, our algorithms achieve time-independent regret, a substantial improvement over the $O(\\log T)$ regret bounds known for learning stable matchings without interviews. Also, under mild structured markets, decentralized performance matches the centralized counterpart up to polynomial factors in the number of agents and firms.",
      "authors": [
        "Amirmahdi Mirfakhar",
        "Xuchuang Wang",
        "Mengfan Xu",
        "Hedyeh Beyhaghi",
        "Mohammad Hajiesmaili"
      ],
      "categories": [
        "cs.GT",
        "cs.AI",
        "econ.TH"
      ],
      "primary_category": "cs.GT",
      "published": "2026-02-12T18:03:37Z",
      "updated": "2026-02-12T18:03:37Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12224v1",
      "abs_url": "http://arxiv.org/abs/2602.12224v1",
      "summary": "研究了带面试的双边匹配市场中的bandit学习，提出了战略延迟和新算法。",
      "key_contributions": [
        "提出了带面试的双边匹配市场bandit学习框架",
        "允许公司方的不确定性，引入战略延迟动作",
        "设计了中心化和去中心化两种场景下的算法，实现时间无关的regret"
      ],
      "methodology": "通过bandit学习模拟面试过程，扩展公司方的动作空间，设计算法最小化regret。",
      "tags": [
        "Bandit Learning",
        "Matching Market",
        "Game Theory",
        "Decentralized Learning",
        "Regret Minimization"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "论文研究涉及决策和策略，与agent的决策规划问题相关。",
      "analyzed_at": "2026-02-13T06:58:30.779456",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12221v1",
      "title": "Best of Both Worlds: Multimodal Reasoning and Generation via Unified Discrete Flow Matching",
      "abstract": "We propose UniDFlow, a unified discrete flow-matching framework for multimodal understanding, generation, and editing. It decouples understanding and generation via task-specific low-rank adapters, avoiding objective interference and representation entanglement, while a novel reference-based multimodal preference alignment optimizes relative outcomes under identical conditioning, improving faithfulness and controllability without large-scale retraining. UniDFlpw achieves SOTA performance across eight benchmarks and exhibits strong zero-shot generalization to tasks including inpainting, in-context image generation, reference-based editing, and compositional generation, despite no explicit task-specific training.",
      "authors": [
        "Onkar Susladkar",
        "Tushar Prakash",
        "Gayatri Deshmukh",
        "Kiet A. Nguyen",
        "Jiaxun Zhang",
        "Adheesh Juvekar",
        "Tianshu Bao",
        "Lin Chai",
        "Sparsh Mittal",
        "Inderjit S Dhillon",
        "Ismini Lourentzou"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-12T17:59:08Z",
      "updated": "2026-02-12T17:59:08Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12221v1",
      "abs_url": "http://arxiv.org/abs/2602.12221v1",
      "summary": "UniDFlow通过解耦理解和生成，优化多模态偏好对齐，实现多模态任务的SOTA性能。",
      "key_contributions": [
        "提出UniDFlow统一离散流匹配框架",
        "使用低秩适配器解耦理解和生成",
        "提出基于参考的多模态偏好对齐方法"
      ],
      "methodology": "使用任务特定低秩适配器解耦理解和生成，并通过参考进行偏好对齐优化结果。",
      "tags": [
        "多模态学习",
        "离散流匹配",
        "图像生成",
        "图像编辑"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注多模态理解、生成和编辑，是该领域的关键研究。",
      "analyzed_at": "2026-02-13T06:58:32.421077",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12207v1",
      "title": "VIRENA: Virtual Arena for Research, Education, and Democratic Innovation",
      "abstract": "Digital platforms shape how people communicate, deliberate, and form opinions. Studying these dynamics has become increasingly difficult due to restricted data access, ethical constraints on real-world experiments, and limitations of existing research tools. VIRENA (Virtual Arena) is a platform that enables controlled experimentation in realistic social media environments. Multiple participants interact simultaneously in realistic replicas of feed-based platforms (Instagram, Facebook, Reddit) and messaging apps (WhatsApp, Messenger). Large language model-powered AI agents participate alongside humans with configurable personas and realistic behavior. Researchers can manipulate content moderation approaches, pre-schedule stimulus content, and run experiments across conditions through a visual interface requiring no programming skills. VIRENA makes possible research designs that were previously impractical: studying human--AI interaction in realistic social contexts, experimentally comparing moderation interventions, and observing group deliberation as it unfolds. Built on open-source technologies that ensure data remain under institutional control and comply with data protection requirements, VIRENA is currently in use at the University of Zurich and available for pilot collaborations. Designed for researchers, educators, and public organizations alike, VIRENA's no-code interface makes controlled social media simulation accessible across disciplines and sectors. This paper documents its design, architecture, and capabilities.",
      "authors": [
        "Emma Hoes",
        "K. Jonathan Klueser",
        "Fabrizio Gilardi"
      ],
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.HC",
      "published": "2026-02-12T17:46:52Z",
      "updated": "2026-02-12T17:46:52Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12207v1",
      "abs_url": "http://arxiv.org/abs/2602.12207v1",
      "summary": "VIRENA是一个用于模拟社交媒体环境，支持受控实验的开放平台。",
      "key_contributions": [
        "构建了可控的社交媒体模拟平台VIRENA",
        "实现了人类与AI agent在仿真环境中的交互",
        "提供了无需编程的可视化实验界面"
      ],
      "methodology": "VIRENA通过构建逼真的社交媒体环境，并结合可配置的AI agent，实现了对社会互动和信息传播的实验研究。",
      "tags": [
        "社交媒体",
        "仿真",
        "AI Agent",
        "实验平台"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "论文重点在于构建与人类交互的AI agent仿真环境。",
      "analyzed_at": "2026-02-13T06:58:34.112422",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12205v1",
      "title": "DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing",
      "abstract": "Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10B), entailing prohibitive training costs and deployment footprints. In this work, we present DeepGen 1.0, a lightweight 5B unified model that achieves comprehensive capabilities competitive with or surpassing much larger counterparts. To overcome the limitations of compact models in semantic understanding and fine-grained control, we introduce Stacked Channel Bridging (SCB), a deep alignment framework that extracts hierarchical features from multiple VLM layers and fuses them with learnable 'think tokens' to provide the generative backbone with structured, reasoning-rich guidance. We further design a data-centric training strategy spanning three progressive stages: (1) Alignment Pre-training on large-scale image-text pairs and editing triplets to synchronize VLM and DiT representations, (2) Joint Supervised Fine-tuning on a high-quality mixture of generation, editing, and reasoning tasks to foster omni-capabilities, and (3) Reinforcement Learning with MR-GRPO, which leverages a mixture of reward functions and supervision signals, resulting in substantial gains in generation quality and alignment with human preferences, while maintaining stable training progress and avoiding visual artifacts. Despite being trained on only ~50M samples, DeepGen 1.0 achieves leading performance across diverse benchmarks, surpassing the 80B HunyuanImage by 28% on WISE and the 27B Qwen-Image-Edit by 37% on UniREditBench. By open-sourcing our training code, weights, and datasets, we provide an efficient, high-performance alternative to democratize unified multimodal research.",
      "authors": [
        "Dianyi Wang",
        "Ruihang Li",
        "Feng Han",
        "Chaofan Ma",
        "Wei Song",
        "Siyuan Wang",
        "Yibin Wang",
        "Yi Xin",
        "Hongjian Liu",
        "Zhixiong Zhang",
        "Shengyuan Ding",
        "Tianhang Wang",
        "Zhenglin Cheng",
        "Tao Lin",
        "Cheng Jin",
        "Kaicheng Yu",
        "Jingjing Chen",
        "Wenjie Wang",
        "Zhongyu Wei",
        "Jiaqi Wang"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-12T17:44:24Z",
      "updated": "2026-02-12T17:44:24Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12205v1",
      "abs_url": "http://arxiv.org/abs/2602.12205v1",
      "summary": "DeepGen 1.0提出轻量级多模态模型，在图像生成和编辑方面表现出色。",
      "key_contributions": [
        "提出Stacked Channel Bridging (SCB)结构",
        "设计数据驱动的三阶段训练策略",
        "开源代码、权重和数据集"
      ],
      "methodology": "采用SCB提取VLM分层特征，融合think tokens，结合三阶段训练策略，提升模型生成质量和对齐。",
      "tags": [
        "多模态学习",
        "图像生成",
        "图像编辑",
        "轻量级模型",
        "视觉语言模型"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于多模态图像生成和编辑模型，属于multimodal领域关键研究。",
      "analyzed_at": "2026-02-13T06:58:35.936227",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12204v1",
      "title": "Learning to Forget Attention: Memory Consolidation for Adaptive Compute Reduction",
      "abstract": "Hybrid architectures combining state-space models with attention have achieved strong efficiency-quality tradeoffs, yet existing approaches either apply attention uniformly or learn static sparse patterns. This misses a key opportunity: \\emph{attention demand should decrease over time as recurring patterns become familiar}. We present a surprising finding from analyzing GPT-2 models: \\textbf{88\\%} of attention operations retrieve information already predictable from the model's hidden state, and this redundancy does \\emph{not} decrease during training. Motivated by this observation, we introduce \\textbf{\\ours{}} (\\textbf{C}onsolidation-based \\textbf{R}outing for \\textbf{A}daptive \\textbf{M}emory), a biologically inspired memory consolidation mechanism that gradually distills episodic retrievals into parametric semantic memory. Unlike prior sparse attention methods, \\ours{} exhibits \\emph{decreasing attention utilization} over training, achieving a \\textbf{37.8$\\times$} reduction through a sharp phase transition at approximately 3K steps. We prove that this capability is \\emph{impossible} without consolidation: any static routing scheme requires $Ω(f \\cdot n)$ attention for tasks with recurring patterns of frequency $f$. On our proposed SRCD benchmark, \\ours{} achieves \\textbf{100\\% retrieval accuracy} at 1.6\\% attention compute (vs.\\ 68\\% for baselines), and consolidated patterns transfer to unseen tasks with \\textbf{48--52\\%} attention reduction without retraining. Remarkably, the learned consolidation dynamics quantitatively match human episodic-to-semantic memory transition curves from cognitive psychology ($γ= 0.43$ vs.\\ $γ_{\\text{human}} \\approx 0.4$--$0.5$). Code and benchmarks are available at [anonymized].",
      "authors": [
        "Ibne Farabi Shihab",
        "Sanjeda Akter",
        "Anuj Sharma"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T17:40:15Z",
      "updated": "2026-02-12T17:40:15Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12204v1",
      "abs_url": "http://arxiv.org/abs/2602.12204v1",
      "summary": "提出了一种基于记忆整合的自适应计算缩减方法,通过动态减少冗余注意力计算提高效率。",
      "key_contributions": [
        "发现GPT-2模型中大量注意力操作是冗余的，并提出CRMA解决此问题。",
        "引入基于整合的路由机制CRMA，实现注意力利用率随训练过程下降。",
        "证明了没有整合机制，静态路由方案的注意力复杂度是Ω(f * n)。"
      ],
      "methodology": "提出了一个受生物启发的记忆整合机制，将情景检索逐步提炼为参数化语义记忆，减少冗余注意力计算。",
      "tags": [
        "attention",
        "memory consolidation",
        "adaptive computation",
        "state-space models"
      ],
      "assigned_category": "memory",
      "relevance_score": 9,
      "relevance_reason": "论文的核心在于解决注意力机制的冗余计算问题，并引入记忆整合方法提高效率，与LLM Memory & RAG高度相关。",
      "analyzed_at": "2026-02-13T06:58:38.012794",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12203v1",
      "title": "ExStrucTiny: A Benchmark for Schema-Variable Structured Information Extraction from Document Images",
      "abstract": "Enterprise documents, such as forms and reports, embed critical information for downstream applications like data archiving, automated workflows, and analytics. Although generalist Vision Language Models (VLMs) perform well on established document understanding benchmarks, their ability to conduct holistic, fine-grained structured extraction across diverse document types and flexible schemas is not well studied. Existing Key Entity Extraction (KEE), Relation Extraction (RE), and Visual Question Answering (VQA) datasets are limited by narrow entity ontologies, simple queries, or homogeneous document types, often overlooking the need for adaptable and structured extraction. To address these gaps, we introduce ExStrucTiny, a new benchmark dataset for structured Information Extraction (IE) from document images, unifying aspects of KEE, RE, and VQA. Built through a novel pipeline combining manual and synthetic human-validated samples, ExStrucTiny covers more varied document types and extraction scenarios. We analyze open and closed VLMs on this benchmark, highlighting challenges such as schema adaptation, query under-specification, and answer localization. We hope our work provides a bedrock for improving generalist models for structured IE in documents.",
      "authors": [
        "Mathieu Sibue",
        "Andres Muñoz Garza",
        "Samuel Mensah",
        "Pranav Shetty",
        "Zhiqiang Ma",
        "Xiaomo Liu",
        "Manuela Veloso"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-12T17:38:57Z",
      "updated": "2026-02-12T17:38:57Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12203v1",
      "abs_url": "http://arxiv.org/abs/2602.12203v1",
      "summary": "提出ExStrucTiny基准数据集，用于评估通用视觉语言模型在文档图像结构化信息抽取方面的能力。",
      "key_contributions": [
        "构建了ExStrucTiny基准数据集，包含多样文档类型和抽取场景",
        "提出了一个结合人工和合成数据的新型数据生成流程",
        "分析了现有视觉语言模型在结构化信息抽取方面的挑战"
      ],
      "methodology": "通过手动和合成相结合的方式构建数据集，并对现有VLMs进行评估，突出模型在schema适应、查询理解和定位方面的挑战。",
      "tags": [
        "结构化信息抽取",
        "文档图像理解",
        "视觉语言模型",
        "基准数据集"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注文档图像上的多模态信息抽取，是VLM在该领域的应用和评估。",
      "analyzed_at": "2026-02-13T06:58:39.868282",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12196v1",
      "title": "Visual Reasoning Benchmark: Evaluating Multimodal LLMs on Classroom-Authentic Visual Problems from Primary Education",
      "abstract": "AI models have achieved state-of-the-art results in textual reasoning; however, their ability to reason over spatial and relational structures remains a critical bottleneck -- particularly in early-grade maths, which relies heavily on visuals. This paper introduces the visual reasoning benchmark (VRB), a novel dataset designed to evaluate Multimodal Large Language Models (MLLMs) on their ability to solve authentic visual problems from classrooms. This benchmark is built on a set of 701 questions sourced from primary school examinations in Zambia and India, which cover a range of tasks such as reasoning by analogy, pattern completion, and spatial matching. We outline the methodology and development of the benchmark which intentionally uses unedited, minimal-text images to test if models can meet realistic needs of primary education. Our findings reveal a ``jagged frontier'' of capability where models demonstrate better proficiency in static skills such as counting and scaling, but reach a distinct ``spatial ceiling'' when faced with dynamic operations like folding, reflection, and rotation. These weaknesses pose a risk for classroom use on visual reasoning problems, with the potential for incorrect marking, false scaffolding, and reinforcing student misconceptions. Consequently, education-focused benchmarks like the VRB are essential for determining the functional boundaries of multimodal tools used in classrooms.",
      "authors": [
        "Mohamed Huti",
        "Alasdair Mackintosh",
        "Amy Waldock",
        "Dominic Andrews",
        "Maxime Lelièvre",
        "Moritz Boos",
        "Tobias Murray",
        "Paul Atherton",
        "Robin A. A. Ince",
        "Oliver G. B. Garrod"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-12T17:29:03Z",
      "updated": "2026-02-12T17:29:03Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12196v1",
      "abs_url": "http://arxiv.org/abs/2602.12196v1",
      "summary": "论文提出了视觉推理基准VRB，用于评估MLLM解决小学视觉问题的能力，揭示了模型在空间推理方面的局限性。",
      "key_contributions": [
        "提出了视觉推理基准VRB数据集",
        "评估了MLLM在解决小学视觉问题上的能力",
        "指出了MLLM在空间推理方面的弱点"
      ],
      "methodology": "该基准包含来自赞比亚和印度的小学考试题目，通过未经编辑的图像和最少文本来测试模型。",
      "tags": [
        "Multimodal LLMs",
        "Visual Reasoning",
        "Primary Education",
        "Benchmark",
        "Spatial Reasoning"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文直接评估MLLM的视觉推理能力，与多模态学习的核心问题相关。",
      "analyzed_at": "2026-02-13T06:58:41.653678",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12192v1",
      "title": "Query-focused and Memory-aware Reranker for Long Context Processing",
      "abstract": "Built upon the existing analysis of retrieval heads in large language models, we propose an alternative reranking framework that trains models to estimate passage-query relevance using the attention scores of selected heads. This approach provides a listwise solution that leverages holistic information within the entire candidate shortlist during ranking. At the same time, it naturally produces continuous relevance scores, enabling training on arbitrary retrieval datasets without requiring Likert-scale supervision. Our framework is lightweight and effective, requiring only small-scale models (e.g., 4B parameters) to achieve strong performance. Extensive experiments demonstrate that our method outperforms existing state-of-the-art pointwise and listwise rerankers across multiple domains, including Wikipedia and long narrative datasets. It further establishes a new state-of-the-art on the LoCoMo benchmark that assesses the capabilities of dialogue understanding and memory usage. We further demonstrate that our framework supports flexible extensions. For example, augmenting candidate passages with contextual information further improves ranking accuracy, while training attention heads from middle layers enhances efficiency without sacrificing performance.",
      "authors": [
        "Yuqing Li",
        "Jiangnan Li",
        "Mo Yu",
        "Guoxuan Ding",
        "Zheng Lin",
        "Weiping Wang",
        "Jie Zhou"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-12T17:23:38Z",
      "updated": "2026-02-12T17:23:38Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12192v1",
      "abs_url": "http://arxiv.org/abs/2602.12192v1",
      "summary": "提出一种新的query-focused的memory-aware reranking框架，在多个数据集上超越SOTA。",
      "key_contributions": [
        "提出query-focused reranking框架",
        "利用attention score估计passage-query相关性",
        "在多个数据集上超越SOTA"
      ],
      "methodology": "利用预训练语言模型的注意力机制，训练模型利用候选列表的整体信息，估计passage-query的相关性。",
      "tags": [
        "Reranking",
        "Long Context",
        "Attention Mechanism",
        "Information Retrieval"
      ],
      "assigned_category": "memory",
      "relevance_score": 9,
      "relevance_reason": "针对长文本RAG，利用记忆和检索头部进行优化，核心相关。",
      "analyzed_at": "2026-02-13T06:58:43.399865",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12187v1",
      "title": "SAGEO Arena: A Realistic Environment for Evaluating Search-Augmented Generative Engine Optimization",
      "abstract": "Search-Augmented Generative Engines (SAGE) have emerged as a new paradigm for information access, bridging web-scale retrieval with generative capabilities to deliver synthesized answers. This shift has fundamentally reshaped how web content gains exposure online, giving rise to Search-Augmented Generative Engine Optimization (SAGEO), the practice of optimizing web documents to improve their visibility in AI-generated responses. Despite growing interest, no evaluation environment currently supports comprehensive investigation of SAGEO. Specifically, existing benchmarks lack end-to-end visibility evaluation of optimization strategies, operating on pre-determined candidate documents that abstract away retrieval and reranking preceding generation. Moreover, existing benchmarks discard structural information (e.g., schema markup) present in real web documents, overlooking the rich signals that search systems actively leverage in practice. Motivated by these gaps, we introduce SAGEO Arena, a realistic and reproducible environment for stage-level SAGEO analysis. Our objective is to jointly target search-oriented optimization (SEO) and generation-centric optimization (GEO). To achieve this, we integrate a full generative search pipeline over a large-scale corpus of web documents with rich structural information. Our findings reveal that existing approaches remain largely impractical under realistic conditions and often degrade performance in retrieval and reranking. We also find that structural information helps mitigate these limitations, and that effective SAGEO requires tailoring optimization to each pipeline stage. Overall, our benchmark paves the way for realistic SAGEO evaluation and optimization beyond simplified settings.",
      "authors": [
        "Sunghwan Kim",
        "Wooseok Jeong",
        "Serin Kim",
        "Sangam Lee",
        "Dongha Lee"
      ],
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "published": "2026-02-12T17:18:00Z",
      "updated": "2026-02-12T17:18:00Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12187v1",
      "abs_url": "http://arxiv.org/abs/2602.12187v1",
      "summary": "提出了SAGEO Arena，一个用于评估搜索增强生成引擎优化（SAGEO）的真实环境。",
      "key_contributions": [
        "构建了真实的SAGEO评估环境",
        "集成了完整的生成搜索流程",
        "揭示了现有方法在真实环境下的局限性"
      ],
      "methodology": "构建了一个包含大规模web文档和丰富结构信息的生成搜索pipeline，用于评估优化策略。",
      "tags": [
        "SAGEO",
        "搜索引擎优化",
        "生成式AI",
        "评估环境"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 8,
      "relevance_reason": "论文直接针对优化生成式引擎在搜索环境中的表现，与Agent Tuning密切相关。",
      "analyzed_at": "2026-02-13T06:58:44.960971",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12181v1",
      "title": "Convex Markov Games and Beyond: New Proof of Existence, Characterization and Learning Algorithms for Nash Equilibria",
      "abstract": "Convex Markov Games (cMGs) were recently introduced as a broad class of multi-agent learning problems that generalize Markov games to settings where strategic agents optimize general utilities beyond additive rewards. While cMGs expand the modeling frontier, their theoretical foundations, particularly the structure of Nash equilibria (NE) and guarantees for learning algorithms, are not yet well understood. In this work, we address these gaps for an extension of cMGs, which we term General Utility Markov Games (GUMGs), capturing new applications requiring coupling between agents' occupancy measures. We prove that in GUMGs, Nash equilibria coincide with the fixed points of projected pseudo-gradient dynamics (i.e., first-order stationary points), enabled by a novel agent-wise gradient domination property. This insight also yields a simple proof of NE existence using Brouwer's fixed-point theorem. We further show the existence of Markov perfect equilibria. Building on this characterization, we establish a policy gradient theorem for GUMGs and design a model-free policy gradient algorithm. For potential GUMGs, we establish iteration complexity guarantees for computing approximate-NE under exact gradients and provide sample complexity bounds in both the generative model and on-policy settings. Our results extend beyond prior work restricted to zero-sum cMGs, providing the first theoretical analysis of common-interest cMGs.",
      "authors": [
        "Anas Barakat",
        "Ioannis Panageas",
        "Antonios Varvitsiotis"
      ],
      "categories": [
        "cs.GT",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "published": "2026-02-12T17:11:20Z",
      "updated": "2026-02-12T17:11:20Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12181v1",
      "abs_url": "http://arxiv.org/abs/2602.12181v1",
      "summary": "论文扩展了凸马尔可夫博弈，提出了广义效用马尔可夫博弈，并提供了纳什均衡的存在性证明和学习算法。",
      "key_contributions": [
        "证明了广义效用马尔可夫博弈中纳什均衡与不动点的关系",
        "提出了基于策略梯度的学习算法",
        "为势博弈提供了迭代复杂度和样本复杂度保证"
      ],
      "methodology": "利用不动点定理证明均衡存在性，通过梯度优势性质推导策略梯度定理，设计模型无关的策略梯度算法。",
      "tags": [
        "马尔可夫博弈",
        "纳什均衡",
        "多智能体学习"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "属于多智能体系统，与智能体协作和博弈相关。",
      "analyzed_at": "2026-02-13T06:58:47.174091",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12180v1",
      "title": "How Sampling Shapes LLM Alignment: From One-Shot Optima to Iterative Dynamics",
      "abstract": "Standard methods for aligning large language models with human preferences learn from pairwise comparisons among sampled candidate responses and regularize toward a reference policy. Despite their effectiveness, the effects of sampling and reference choices are poorly understood theoretically. We investigate these effects through Identity Preference Optimization, a widely used preference alignment framework, and show that proper instance-dependent sampling can yield stronger ranking guarantees, while skewed on-policy sampling can induce excessive concentration under structured preferences. We then analyze iterative alignment dynamics in which the learned policy feeds back into future sampling and reference policies, reflecting a common practice of model-generated preference data. We prove that these dynamics can exhibit persistent oscillations or entropy collapse for certain parameter choices, and characterize regimes that guarantee stability. Our theoretical insights extend to Direct Preference Optimization, indicating the phenomena we captured are common to a broader class of preference-alignment methods. Experiments on real-world preference data validate our findings.",
      "authors": [
        "Yurong Chen",
        "Yu He",
        "Michael I. Jordan",
        "Fan Yao"
      ],
      "categories": [
        "cs.LG",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T17:11:08Z",
      "updated": "2026-02-12T17:11:08Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12180v1",
      "abs_url": "http://arxiv.org/abs/2602.12180v1",
      "summary": "该论文理论分析了采样方法对LLM对齐的影响，揭示了采样偏差可能导致的对齐问题。",
      "key_contributions": [
        "证明了实例相关的采样可以增强排序保证",
        "揭示了片面的策略采样可能导致过度集中",
        "分析了迭代对齐动态中出现的振荡和熵坍塌现象"
      ],
      "methodology": "通过理论分析Identity Preference Optimization和Direct Preference Optimization框架，结合实验验证。",
      "tags": [
        "LLM对齐",
        "采样方法",
        "偏好优化",
        "理论分析"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 9,
      "relevance_reason": "直接研究LLM对齐中的采样问题，属于agent tuning的核心问题。",
      "analyzed_at": "2026-02-13T06:58:49.004446",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12173v1",
      "title": "SAM3-LiteText: An Anatomical Study of the SAM3 Text Encoder for Efficient Vision-Language Segmentation",
      "abstract": "Vision-language segmentation models such as SAM3 enable flexible, prompt-driven visual grounding, but inherit large, general-purpose text encoders originally designed for open-ended language understanding. In practice, segmentation prompts are short, structured, and semantically constrained, leading to substantial over-provisioning in text encoder capacity and persistent computational and memory overhead. In this paper, we perform a large-scale anatomical analysis of text prompting in vision-language segmentation, covering 404,796 real prompts across multiple benchmarks. Our analysis reveals severe redundancy: most context windows are underutilized, vocabulary usage is highly sparse, and text embeddings lie on low-dimensional manifold despite high-dimensional representations. Motivated by these findings, we propose SAM3-LiteText, a lightweight text encoding framework that replaces the original SAM3 text encoder with a compact MobileCLIP student that is optimized by knowledge distillation. Extensive experiments on image and video segmentation benchmarks show that SAM3-LiteText reduces text encoder parameters by up to 88%, substantially reducing static memory footprint, while maintaining segmentation performance comparable to the original model. Code: https://github.com/SimonZeng7108/efficientsam3/tree/sam3_litetext.",
      "authors": [
        "Chengxi Zeng",
        "Yuxuan Jiang",
        "Ge Gao",
        "Shuai Wang",
        "Duolikun Danier",
        "Bin Zhu",
        "Stevan Rudinac",
        "David Bull",
        "Fan Zhang"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T17:01:49Z",
      "updated": "2026-02-12T17:01:49Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12173v1",
      "abs_url": "http://arxiv.org/abs/2602.12173v1",
      "summary": "SAM3-LiteText通过知识蒸馏，大幅减少SAM3文本编码器参数，提升视觉语言分割效率。",
      "key_contributions": [
        "分析了视觉语言分割中文本提示的冗余性",
        "提出了轻量级文本编码框架SAM3-LiteText",
        "通过实验证明了参数减少的同时保持性能"
      ],
      "methodology": "通过大规模分析发现冗余，使用知识蒸馏将MobileCLIP作为学生模型优化SAM3文本编码器。",
      "tags": [
        "视觉语言分割",
        "模型压缩",
        "知识蒸馏",
        "轻量级模型"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注视觉-语言模型的分割，涉及多模态学习的关键问题。",
      "analyzed_at": "2026-02-13T06:58:50.843162",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12172v1",
      "title": "Pedagogically-Inspired Data Synthesis for Language Model Knowledge Distillation",
      "abstract": "Knowledge distillation from Large Language Models (LLMs) to smaller models has emerged as a critical technique for deploying efficient AI systems. However, current methods for distillation via synthetic data lack pedagogical awareness, treating knowledge transfer as a one-off data synthesis and training task rather than a systematic learning process. In this paper, we propose a novel pedagogically-inspired framework for LLM knowledge distillation that draws from fundamental educational principles. Our approach introduces a three-stage pipeline -- Knowledge Identifier, Organizer, and Adapter (IOA) -- that systematically identifies knowledge deficiencies in student models, organizes knowledge delivery through progressive curricula, and adapts representations to match the cognitive capacity of student models. We integrate Bloom's Mastery Learning Principles and Vygotsky's Zone of Proximal Development to create a dynamic distillation process where student models approach teacher model's performance on prerequisite knowledge before advancing, and new knowledge is introduced with controlled, gradual difficulty increments. Extensive experiments using LLaMA-3.1/3.2 and Qwen2.5 as student models demonstrate that IOA achieves significant improvements over baseline distillation methods, with student models retaining 94.7% of teacher performance on DollyEval while using less than 1/10th of the parameters. Our framework particularly excels in complex reasoning tasks, showing 19.2% improvement on MATH and 22.3% on HumanEval compared with state-of-the-art baselines.",
      "authors": [
        "Bowei He",
        "Yankai Chen",
        "Xiaokun Zhang",
        "Linghe Kong",
        "Philip S. Yu",
        "Xue Liu",
        "Chen Ma"
      ],
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T17:00:36Z",
      "updated": "2026-02-12T17:00:36Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12172v1",
      "abs_url": "http://arxiv.org/abs/2602.12172v1",
      "summary": "论文提出一种受教学启发的知识蒸馏框架IOA，提升小模型在复杂推理任务上的性能。",
      "key_contributions": [
        "提出IOA框架，包含知识识别、组织和适应三个阶段",
        "结合Bloom的掌握学习原则和维果茨基的最近发展区理论",
        "在知识蒸馏任务上取得了显著的性能提升，尤其是在复杂推理任务上"
      ],
      "methodology": "IOA框架通过识别学生模型的知识缺陷，组织渐进式课程，并调整表示以匹配学生模型的认知能力进行知识蒸馏。",
      "tags": [
        "知识蒸馏",
        "大型语言模型",
        "教学法",
        "推理"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文关注知识蒸馏在推理任务上的性能提升，属于核心相关领域。",
      "analyzed_at": "2026-02-13T06:58:53.361393",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12170v1",
      "title": "Statistical Parsing for Logical Information Retrieval",
      "abstract": "In previous work (Coppola, 2024) we introduced the Quantified Boolean Bayesian Network (QBBN), a logical graphical model that implements the forward fragment of natural deduction (Prawitz, 1965) as a probabilistic factor graph. That work left two gaps: no negation/backward reasoning, and no parser for natural language.   This paper addresses both gaps across inference, semantics, and syntax. For inference, we extend the QBBN with NEG factors enforcing P(x) + P(neg x) = 1, enabling contrapositive reasoning (modus tollens) via backward lambda messages, completing Prawitz's simple elimination rules. The engine handles 44/44 test cases spanning 22 reasoning patterns. For semantics, we present a typed logical language with role-labeled predicates, modal quantifiers, and three tiers of expressiveness following Prawitz: first-order quantification, propositions as arguments, and predicate quantification via lambda abstraction. For syntax, we present a typed slot grammar that deterministically compiles sentences to logical form (33/33 correct, zero ambiguity). LLMs handle disambiguation (95% PP attachment accuracy) but cannot produce structured parses directly (12.4% UAS), confirming grammars are necessary. The architecture: LLM preprocesses, grammar parses, LLM reranks, QBBN infers.   We argue this reconciles formal semantics with Sutton's \"bitter lesson\" (2019): LLMs eliminate the annotation bottleneck that killed formal NLP, serving as annotator while the QBBN serves as verifier. Code: https://github.com/gregorycoppola/world",
      "authors": [
        "Greg Coppola"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T16:57:25Z",
      "updated": "2026-02-12T16:57:25Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12170v1",
      "abs_url": "http://arxiv.org/abs/2602.12170v1",
      "summary": "论文扩展了QBBN模型，通过结合LLM和语法解析，实现了自然语言的逻辑信息检索，并提升了推理能力。",
      "key_contributions": [
        "扩展QBBN模型，加入否定推理能力",
        "提出一种类型化的逻辑语言和语法解析器",
        "结合LLM和语法解析，提升逻辑信息检索效果"
      ],
      "methodology": "使用类型化的槽语法将自然语言编译为逻辑形式，利用LLM进行预处理和重排序，并通过QBBN进行推理。",
      "tags": [
        "逻辑推理",
        "自然语言处理",
        "语法解析",
        "LLM"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于使用模型进行逻辑推理，并解决了自然语言解析的问题，高度相关。",
      "analyzed_at": "2026-02-13T06:58:56.968638",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12164v1",
      "title": "Sci-CoE: Co-evolving Scientific Reasoning LLMs via Geometric Consensus with Sparse Supervision",
      "abstract": "Large language models (LLMs) have demonstrated exceptional reasoning capabilities, and co-evolving paradigms have shown promising results in domains such as code and math. However, in scientific reasoning tasks, these models remain fragile due to unreliable solution evaluation and limited diversity in verification strategies. In this work, we propose Sci-CoE, a two-stage scientific co-evolving framework that enables models to self-evolve as both solver and verifier through a transition from sparse supervision to unsupervised learning. In the first stage, the model uses a small set of annotated data to establish fundamental correctness judgment anchors for the Verifier. In the second stage, we introduce a geometric reward mechanism that jointly considers consensus, reliability, and diversity, driving large-scale self-iteration on unlabeled data. Experiments on several general scientific benchmarks demonstrate that Sci-CoE enhances complex reasoning capabilities and exhibits strong scalability, facilitating the construction of more robust and diverse evaluation systems. Codes are available at https://github.com/InternScience/Sci-CoE.",
      "authors": [
        "Xiaohan He",
        "Shiyang Feng",
        "Songtao Huang",
        "Lei Bai",
        "Bin Wang",
        "Bo Zhang"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T16:46:00Z",
      "updated": "2026-02-12T16:46:00Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12164v1",
      "abs_url": "http://arxiv.org/abs/2602.12164v1",
      "summary": "Sci-CoE通过几何共识和稀疏监督，提升LLM在科学推理任务中的鲁棒性和多样性。",
      "key_contributions": [
        "提出Sci-CoE框架，实现LLM在科学推理中的自进化。",
        "引入几何奖励机制，综合考虑共识、可靠性和多样性。",
        "实验证明Sci-CoE能增强复杂推理能力和扩展性。"
      ],
      "methodology": "两阶段框架，先用少量标注数据建立verifier锚点，再利用几何奖励机制在无标注数据上进行自迭代。",
      "tags": [
        "科学推理",
        "自进化",
        "几何共识",
        "LLM"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文专注于提升LLM的科学推理能力，是该领域的核心研究。",
      "analyzed_at": "2026-02-13T06:58:58.720927",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12162v1",
      "title": "Amortized Molecular Optimization via Group Relative Policy Optimization",
      "abstract": "Molecular design encompasses tasks ranging from de-novo design to structural alteration of given molecules or fragments. For the latter, state-of-the-art methods predominantly function as \"Instance Optimizers'', expending significant compute restarting the search for every input structure. While model-based approaches theoretically offer amortized efficiency by learning a policy transferable to unseen structures, existing methods struggle to generalize. We identify a key failure mode: the high variance arising from the heterogeneous difficulty of distinct starting structures. To address this, we introduce GRXForm, adapting a pre-trained Graph Transformer model that optimizes molecules via sequential atom-and-bond additions. We employ Group Relative Policy Optimization (GRPO) for goal-directed fine-tuning to mitigate variance by normalizing rewards relative to the starting structure. Empirically, GRXForm generalizes to out-of-distribution molecular scaffolds without inference-time oracle calls or refinement, achieving scores in multi-objective optimization competitive with leading instance optimizers.",
      "authors": [
        "Muhammad bin Javaid",
        "Hasham Hussain",
        "Ashima Khanna",
        "Berke Kisin",
        "Jonathan Pirnay",
        "Alexander Mitsos",
        "Dominik G. Grimm",
        "Martin Grohe"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T16:43:59Z",
      "updated": "2026-02-12T16:43:59Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12162v1",
      "abs_url": "http://arxiv.org/abs/2602.12162v1",
      "summary": "GRXForm通过组相对策略优化方法，提升了分子优化模型在未见结构上的泛化能力。",
      "key_contributions": [
        "提出GRXForm分子优化模型",
        "引入组相对策略优化(GRPO)方法",
        "实现了在多目标优化中与领先Instance Optimizer竞争的性能"
      ],
      "methodology": "使用预训练图Transformer模型，通过原子和键的添加进行分子优化，并采用GRPO进行目标导向微调。",
      "tags": [
        "分子设计",
        "图神经网络",
        "强化学习",
        "泛化能力"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 6,
      "relevance_reason": "涉及策略优化，可以看作是一种agent tuning的方法，但核心是分子优化",
      "analyzed_at": "2026-02-13T06:59:00.621293",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12159v1",
      "title": "3DGSNav: Enhancing Vision-Language Model Reasoning for Object Navigation via Active 3D Gaussian Splatting",
      "abstract": "Object navigation is a core capability of embodied intelligence, enabling an agent to locate target objects in unknown environments. Recent advances in vision-language models (VLMs) have facilitated zero-shot object navigation (ZSON). However, existing methods often rely on scene abstractions that convert environments into semantic maps or textual representations, causing high-level decision making to be constrained by the accuracy of low-level perception. In this work, we present 3DGSNav, a novel ZSON framework that embeds 3D Gaussian Splatting (3DGS) as persistent memory for VLMs to enhance spatial reasoning. Through active perception, 3DGSNav incrementally constructs a 3DGS representation of the environment, enabling trajectory-guided free-viewpoint rendering of frontier-aware first-person views. Moreover, we design structured visual prompts and integrate them with Chain-of-Thought (CoT) prompting to further improve VLM reasoning. During navigation, a real-time object detector filters potential targets, while VLM-driven active viewpoint switching performs target re-verification, ensuring efficient and reliable recognition. Extensive evaluations across multiple benchmarks and real-world experiments on a quadruped robot demonstrate that our method achieves robust and competitive performance against state-of-the-art approaches.The Project Page:https://aczheng-cai.github.io/3dgsnav.github.io/",
      "authors": [
        "Wancai Zheng",
        "Hao Chen",
        "Xianlong Lu",
        "Linlin Ou",
        "Xinyi Yu"
      ],
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "published": "2026-02-12T16:41:26Z",
      "updated": "2026-02-12T16:41:26Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12159v1",
      "abs_url": "http://arxiv.org/abs/2602.12159v1",
      "summary": "提出3DGSNav，利用3D高斯溅射增强视觉语言模型在对象导航中的空间推理能力。",
      "key_contributions": [
        "将3D高斯溅射作为VLMs的持久记忆",
        "设计结构化视觉提示和CoT提示",
        "通过实时对象检测和VLM驱动的视点切换进行目标验证"
      ],
      "methodology": "构建环境的3DGS表示，通过主动感知和轨迹引导自由视点渲染，结合视觉提示和CoT提升VLM推理。",
      "tags": [
        "3D Gaussian Splatting",
        "Vision-Language Models",
        "Object Navigation",
        "Chain-of-Thought",
        "Active Perception"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "核心关注视觉语言模型在机器人导航任务中的应用，紧密结合多模态学习和agent能力。",
      "analyzed_at": "2026-02-13T06:59:02.594928",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12158v1",
      "title": "SafeNeuron: Neuron-Level Safety Alignment for Large Language Models",
      "abstract": "Large language models (LLMs) and multimodal LLMs are typically safety-aligned before release to prevent harmful content generation. However, recent studies show that safety behaviors are concentrated in a small subset of parameters, making alignment brittle and easily bypassed through neuron-level attacks. Moreover, most existing alignment methods operate at the behavioral level, offering limited control over the model's internal safety mechanisms. In this work, we propose SafeNeuron, a neuron-level safety alignment framework that improves robustness by redistributing safety representations across the network. SafeNeuron first identifies safety-related neurons, then freezes these neurons during preference optimization to prevent reliance on sparse safety pathways and force the model to construct redundant safety representations. Extensive experiments across models and modalities demonstrate that SafeNeuron significantly improves robustness against neuron pruning attacks, reduces the risk of open-source models being repurposed as red-team generators, and preserves general capabilities. Furthermore, our layer-wise analysis reveals that safety behaviors are governed by stable and shared internal representations. Overall, SafeNeuron provides an interpretable and robust perspective for model alignment.",
      "authors": [
        "Zhaoxin Wang",
        "Jiaming Liang",
        "Fengbin Zhu",
        "Weixiang Zhao",
        "Junfeng Fang",
        "Jiayi Ji",
        "Handing Wang",
        "Tat-Seng Chua"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T16:40:05Z",
      "updated": "2026-02-12T16:40:05Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12158v1",
      "abs_url": "http://arxiv.org/abs/2602.12158v1",
      "summary": "SafeNeuron提出了一种神经元级别的安全对齐框架，增强LLM的安全性与鲁棒性。",
      "key_contributions": [
        "提出了SafeNeuron框架，提升LLM应对神经元剪枝攻击的鲁棒性",
        "降低了开源模型被用于红队攻击的风险",
        "验证了安全行为由稳定且共享的内部表示控制"
      ],
      "methodology": "SafeNeuron首先识别安全相关神经元，然后在偏好优化期间冻结这些神经元，迫使模型构建冗余的安全表示。",
      "tags": [
        "LLM",
        "Safety Alignment",
        "Neuron-level Control",
        "Robustness"
      ],
      "assigned_category": "memory",
      "relevance_score": 8,
      "relevance_reason": "论文直接关注LLM的安全对齐问题，具有高度相关性。",
      "analyzed_at": "2026-02-13T06:59:04.113951",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12153v1",
      "title": "dVoting: Fast Voting for dLLMs",
      "abstract": "Diffusion Large Language Models (dLLMs) represent a new paradigm beyond autoregressive modeling, offering competitive performance while naturally enabling a flexible decoding process. Specifically, dLLMs can generate tokens at arbitrary positions in parallel, endowing them with significant potential for parallel test-time scaling, which was previously constrained by severe inefficiency in autoregressive modeling. In this work, we introduce dVoting, a fast voting technique that boosts reasoning capability without training, with only an acceptable extra computational overhead. dVoting is motivated by the observation that, across multiple samples for the same prompt, token predictions remain largely consistent, whereas performance is determined by a small subset of tokens exhibiting cross-sample variability. Leveraging the arbitrary-position generation capability of dLLMs, dVoting performs iterative refinement by sampling, identifying uncertain tokens via consistency analysis, regenerating them through voting, and repeating this process until convergence. Extensive evaluations demonstrate that dVoting consistently improves performance across various benchmarks. It achieves gains of 6.22%-7.66% on GSM8K, 4.40%-7.20% on MATH500, 3.16%-14.84% on ARC-C, and 4.83%-5.74% on MMLU. Our code is available at https://github.com/fscdc/dVoting",
      "authors": [
        "Sicheng Feng",
        "Zigeng Chen",
        "Xinyin Ma",
        "Gongfan Fang",
        "Xinchao Wang"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-12T16:35:05Z",
      "updated": "2026-02-12T16:35:05Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12153v1",
      "abs_url": "http://arxiv.org/abs/2602.12153v1",
      "summary": "dVoting利用dLLM的并行生成能力，通过投票机制提升推理能力，无需额外训练。",
      "key_contributions": [
        "提出了一种名为dVoting的快速投票技术",
        "利用dLLM的任意位置生成能力进行迭代优化",
        "在多个基准测试中验证了dVoting的有效性"
      ],
      "methodology": "通过采样、一致性分析识别不确定token，利用投票机制重新生成，迭代直至收敛。",
      "tags": [
        "dLLM",
        "推理",
        "投票",
        "并行生成"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文核心是提升LLM的推理能力，使用了投票的技巧优化生成过程。",
      "analyzed_at": "2026-02-13T06:59:05.593887",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12150v1",
      "title": "GPT-4o Lacks Core Features of Theory of Mind",
      "abstract": "Do Large Language Models (LLMs) possess a Theory of Mind (ToM)? Research into this question has focused on evaluating LLMs against benchmarks and found success across a range of social tasks. However, these evaluations do not test for the actual representations posited by ToM: namely, a causal model of mental states and behavior. Here, we use a cognitively-grounded definition of ToM to develop and test a new evaluation framework. Specifically, our approach probes whether LLMs have a coherent, domain-general, and consistent model of how mental states cause behavior -- regardless of whether that model matches a human-like ToM. We find that even though LLMs succeed in approximating human judgments in a simple ToM paradigm, they fail at a logically equivalent task and exhibit low consistency between their action predictions and corresponding mental state inferences. As such, these findings suggest that the social proficiency exhibited by LLMs is not the result of an domain-general or consistent ToM.",
      "authors": [
        "John Muchovej",
        "Amanda Royka",
        "Shane Lee",
        "Julian Jara-Ettinger"
      ],
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T16:33:58Z",
      "updated": "2026-02-12T16:33:58Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12150v1",
      "abs_url": "http://arxiv.org/abs/2602.12150v1",
      "summary": "GPT-4o在理论推理（ToM）的核心能力上存在缺陷，缺乏一致且泛化的心理状态行为模型。",
      "key_contributions": [
        "提出了评估LLM的ToM的新框架",
        "揭示了LLM在简单ToM任务上取得成功，但在逻辑等价任务上失败",
        "证明了LLM的社交能力并非源于领域泛化或一致的ToM"
      ],
      "methodology": "采用认知科学基础的ToM定义，设计测试框架，探究LLM是否具有一致的、领域泛化的心理状态行为因果模型。",
      "tags": [
        "Theory of Mind",
        "LLM evaluation",
        "Reasoning",
        "Causal Models",
        "Social Cognition"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注LLM的推理能力，尤其是心理理论相关的推理能力。",
      "analyzed_at": "2026-02-13T06:59:07.409979",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12144v1",
      "title": "On the Adoption of AI Coding Agents in Open-source Android and iOS Development",
      "abstract": "AI coding agents are increasingly contributing to software development, yet their impact on mobile development has received little empirical attention. In this paper, we present the first category-level empirical study of agent-generated code in open-source mobile app projects. We analyzed PR acceptance behaviors across mobile platforms, agents, and task categories using 2,901 AI-authored pull requests (PRs) in 193 verified Android and iOS open-source GitHub repositories in the AIDev dataset. We find that Android projects have received 2x more AI-authored PRs and have achieved higher PR acceptance rate (71%) than iOS (63%), with significant agent-level variation on Android. Across task categories, PRs with routine tasks (feature, fix, and ui) achieve the highest acceptance, while structural changes like refactor and build achieve lower success and longer resolution times. Furthermore, our evolution analysis shows improvement in PR resolution time on Android through mid-2025 before it declined again. Our findings offer the first evidence-based characterization of AI agents effects on OSS mobile projects and establish empirical baselines for evaluating agent-generated contributions to design platform aware agentic systems.",
      "authors": [
        "Muhammad Ahmad Khan",
        "Hasnain Ali",
        "Muneeb Rana",
        "Muhammad Saqib Ilyas",
        "Abdul Ali Bangash"
      ],
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "published": "2026-02-12T16:30:29Z",
      "updated": "2026-02-12T16:30:29Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12144v1",
      "abs_url": "http://arxiv.org/abs/2602.12144v1",
      "summary": "分析了AI编码智能体在开源Android和iOS移动应用开发中的应用和影响。",
      "key_contributions": [
        "首次对开源移动应用项目中AI生成代码进行类别级实证研究",
        "分析了不同移动平台、智能体和任务类别中的PR接受行为",
        "提供了AI智能体对OSS移动项目影响的经验证据"
      ],
      "methodology": "分析了AIDev数据集中193个验证过的Android和iOS开源GitHub仓库中的2901个AI编写的PR。",
      "tags": [
        "AI Coding Agents",
        "Open-source Software",
        "Mobile Development",
        "Empirical Study",
        "Pull Request Analysis"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "核心关注AI智能体在软件开发中的应用，符合Agent类别。",
      "analyzed_at": "2026-02-13T06:59:09.175871",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12143v1",
      "title": "STAR : Bridging Statistical and Agentic Reasoning for Large Model Performance Prediction",
      "abstract": "As comprehensive large model evaluation becomes prohibitively expensive, predicting model performance from limited observations has become essential. However, existing statistical methods struggle with pattern shifts, data sparsity, and lack of explanation, while pure LLM methods remain unreliable. We propose STAR, a framework that bridges data-driven STatistical expectations with knowledge-driven Agentic Reasoning. STAR leverages specialized retrievers to gather external knowledge and embeds semantic features into Constrained Probabilistic Matrix Factorization (CPMF) to generate statistical expectations with uncertainty. A reasoning module guided by Expectation Violation Theory (EVT) then refines predictions through intra-family analysis, cross-model comparison, and credibility-aware aggregation, producing adjustments with traceable explanations. Extensive experiments show that STAR consistently outperforms all baselines on both score-based and rank-based metrics, delivering a 14.46% gain in total score over the strongest statistical method under extreme sparsity, with only 1--2 observed scores per test model.",
      "authors": [
        "Xiaoxiao Wang",
        "Chunxiao Li",
        "Junying Wang",
        "Yijin Guo",
        "Zijian Chen",
        "Chunyi Li",
        "Xiaohong Liu",
        "Zicheng Zhang",
        "Guangtao Zhai"
      ],
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T16:30:07Z",
      "updated": "2026-02-12T16:30:07Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12143v1",
      "abs_url": "http://arxiv.org/abs/2602.12143v1",
      "summary": "STAR框架融合统计与Agent推理，提升大模型性能预测在数据稀疏情况下的准确性和可解释性。",
      "key_contributions": [
        "提出STAR框架，结合统计和Agent推理",
        "引入受约束概率矩阵分解(CPMF)和外部知识检索",
        "利用期望违背理论(EVT)进行推理优化"
      ],
      "methodology": "结合统计期望（CPMF, 知识检索）和Agent推理（EVT），对大模型性能进行预测和解释。",
      "tags": [
        "大模型性能预测",
        "统计方法",
        "Agent推理",
        "知识检索",
        "期望违背理论"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于结合统计和Agent推理来提升大模型性能预测，直接研究推理领域关键问题。",
      "analyzed_at": "2026-02-13T06:59:11.280107",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12137v1",
      "title": "CitiLink-Minutes: A Multilayer Annotated Dataset of Municipal Meeting Minutes",
      "abstract": "City councils play a crucial role in local governance, directly influencing citizens' daily lives through decisions made during municipal meetings. These deliberations are formally documented in meeting minutes, which serve as official records of discussions, decisions, and voting outcomes. Despite their importance, municipal meeting records have received little attention in Information Retrieval (IR) and Natural Language Processing (NLP), largely due to the lack of annotated datasets, which ultimately limit the development of computational models. To address this gap, we introduce CitiLink-Minutes, a multilayer dataset of 120 European Portuguese municipal meeting minutes from six municipalities. Unlike prior annotated datasets of parliamentary or video records, CitiLink-Minutes provides multilayer annotations and structured linkage of official written minutes. The dataset contains over one million tokens, with all personal identifiers de-identified. Each minute was manually annotated by two trained annotators and curated by an experienced linguist across three complementary dimensions: (1) metadata, (2) subjects of discussion, and (3) voting outcomes, totaling over 38,000 individual annotations. Released under FAIR principles and accompanied by baseline results on metadata extraction, topic classification, and vote labeling, CitiLink-Minutes demonstrates its potential for downstream NLP and IR tasks, while promoting transparent access to municipal decisions.",
      "authors": [
        "Ricardo Campos",
        "Ana Filipa Pacheco",
        "Ana Luísa Fernandes",
        "Inês Cantante",
        "Rute Rebouças",
        "Luís Filipe Cunha",
        "José Miguel Isidro",
        "José Pedro Evans",
        "Miguel Marques",
        "Rodrigo Batista",
        "Evelin Amorim",
        "Alípio Jorge",
        "Nuno Guimarães",
        "Sérgio Nunes",
        "António Leal",
        "Purificação Silvano"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-12T16:22:55Z",
      "updated": "2026-02-12T16:22:55Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12137v1",
      "abs_url": "http://arxiv.org/abs/2602.12137v1",
      "summary": "CitiLink-Minutes是一个欧洲葡萄牙市政会议记录的多层注释数据集，旨在促进NLP和IR在该领域的应用。",
      "key_contributions": [
        "创建了包含超过一百万个tokens的多层注释市政会议记录数据集",
        "提供了元数据、讨论主题和投票结果三个维度的注释",
        "发布了基于数据集的元数据提取、主题分类和投票标签的基线结果"
      ],
      "methodology": "人工对120份会议记录进行注释，包括元数据、讨论主题和投票结果，并由语言学家进行校正和审核。",
      "tags": [
        "NLP",
        "IR",
        "Dataset",
        "Municipal Meeting",
        "Annotation"
      ],
      "assigned_category": "memory",
      "relevance_score": 7,
      "relevance_reason": "数据集构建，涉及NLP和IR领域应用，有重要参考价值。",
      "analyzed_at": "2026-02-13T06:59:13.053565",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12135v1",
      "title": "WavBench: Benchmarking Reasoning, Colloquialism, and Paralinguistics for End-to-End Spoken Dialogue Models",
      "abstract": "With the rapid integration of advanced reasoning capabilities into spoken dialogue models, the field urgently demands benchmarks that transcend simple interactions to address real-world complexity. However, current evaluations predominantly adhere to text-generation standards, overlooking the unique audio-centric characteristics of paralinguistics and colloquialisms, alongside the cognitive depth required by modern agents. To bridge this gap, we introduce WavBench, a comprehensive benchmark designed to evaluate realistic conversational abilities where prior works fall short. Uniquely, WavBench establishes a tripartite framework: 1) Pro subset, designed to rigorously challenge reasoning-enhanced models with significantly increased difficulty; 2) Basic subset, defining a novel standard for spoken colloquialism that prioritizes \"listenability\" through natural vocabulary, linguistic fluency, and interactive rapport, rather than rigid written accuracy; and 3) Acoustic subset, covering explicit understanding, generation, and implicit dialogue to rigorously evaluate comprehensive paralinguistic capabilities within authentic real-world scenarios. Through evaluating five state-of-the-art models, WavBench offers critical insights into the intersection of complex problem-solving, colloquial delivery, and paralinguistic fidelity, guiding the evolution of robust spoken dialogue models. The benchmark dataset and evaluation toolkit are available at https://naruto-2024.github.io/wavbench.github.io/.",
      "authors": [
        "Yangzhuo Li",
        "Shengpeng Ji",
        "Yifu Chen",
        "Tianle Liang",
        "Haorong Ying",
        "Yule Wang",
        "Junbo Li",
        "Jun Fang",
        "Zhou Zhao"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-12T16:22:11Z",
      "updated": "2026-02-12T16:22:11Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12135v1",
      "abs_url": "http://arxiv.org/abs/2602.12135v1",
      "summary": "WavBench是一个用于评估端到端口语对话模型推理、口语化和副语言能力的综合基准。",
      "key_contributions": [
        "提出了WavBench基准，包含Pro, Basic, Acoustic三个子集",
        "定义了口语化听觉质量的新标准",
        "提供了对现有模型的在推理、口语化和副语言能力方面的评估"
      ],
      "methodology": "WavBench通过构建包含推理、口语化和副语言三个方面的对话数据集，评估SOTA模型。",
      "tags": [
        "spoken dialogue",
        "benchmark",
        "reasoning",
        "colloquialism",
        "paralinguistics"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "主要评估对话agent在多种能力上的表现，高度相关。",
      "analyzed_at": "2026-02-13T06:59:15.048135",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12134v1",
      "title": "Value Alignment Tax: Measuring Value Trade-offs in LLM Alignment",
      "abstract": "Existing work on value alignment typically characterizes value relations statically, ignoring how interventions - such as prompting, fine-tuning, or preference optimization - reshape the broader value system. We introduce the Value Alignment Tax (VAT), a framework that measures how alignment-induced changes propagate across interconnected values relative to achieved on-target gain. VAT captures the dynamics of value expression under alignment pressure. Using a controlled scenario-action dataset grounded in Schwartz value theory, we collect paired pre-post normative judgments and analyze alignment effects across models, values, and alignment strategies. Our results show that alignment often produces uneven, structured co-movement among values. These effects are invisible under conventional target-only evaluation, revealing systemic, process-level alignment risks and offering new insights into the dynamics of value alignment in LLMs.",
      "authors": [
        "Jiajun Chen",
        "Hua Shen"
      ],
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T16:21:22Z",
      "updated": "2026-02-12T16:21:22Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12134v1",
      "abs_url": "http://arxiv.org/abs/2602.12134v1",
      "summary": "提出Value Alignment Tax (VAT)框架，用于衡量对齐诱导的价值权衡和连锁反应。",
      "key_contributions": [
        "提出了Value Alignment Tax (VAT)框架，量化对齐带来的价值权衡。",
        "揭示了对齐过程中价值之间非均匀、结构化的联动关系。",
        "强调了传统目标导向评估的局限性，指出了系统性的对齐风险。"
      ],
      "methodology": "构建基于Schwartz价值理论的场景-行为数据集，收集模型对齐前后规范判断，分析价值对齐效果。",
      "tags": [
        "Value Alignment",
        "LLM",
        "Evaluation"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 8,
      "relevance_reason": "研究了LLM对齐策略对价值体系的影响，涉及偏好优化和反馈学习。",
      "analyzed_at": "2026-02-13T06:59:16.956927",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12129v1",
      "title": "Towards Personalized Bangla Book Recommendation: A Large-Scale Multi-Entity Book Graph Dataset",
      "abstract": "Personalized book recommendation in Bangla literature has been constrained by the lack of structured, large-scale, and publicly available datasets. This work introduces RokomariBG, a large-scale, multi-entity heterogeneous book graph dataset designed to support research on personalized recommendation in a low-resource language setting. The dataset comprises 127,302 books, 63,723 users, 16,601 authors, 1,515 categories, 2,757 publishers, and 209,602 reviews, connected through eight relation types and organized as a comprehensive knowledge graph.   To demonstrate the utility of the dataset, we provide a systematic benchmarking study on the Top-N recommendation task, evaluating a diverse set of representative recommendation models, including classical collaborative filtering methods, matrix factorization models, content-based approaches, graph neural networks, a hybrid matrix factorization model with side information, and a neural two-tower retrieval architecture. The benchmarking results highlight the importance of leveraging multi-relational structure and textual side information, with neural retrieval models achieving the strongest performance (NDCG@10 = 0.204). Overall, this work establishes a foundational benchmark and a publicly available resource for Bangla book recommendation research, enabling reproducible evaluation and future studies on recommendation in low-resource cultural domains. The dataset and code are publicly available at https://github.com/backlashblitz/Bangla-Book-Recommendation-Dataset",
      "authors": [
        "Rahin Arefin Ahmed",
        "Md. Anik Chowdhury",
        "Sakil Ahmed Sheikh Reza",
        "Devnil Bhattacharjee",
        "Muhammad Abdullah Adnan",
        "Nafis Sadeq"
      ],
      "categories": [
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "published": "2026-02-12T16:18:55Z",
      "updated": "2026-02-12T16:18:55Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12129v1",
      "abs_url": "http://arxiv.org/abs/2602.12129v1",
      "summary": "构建了大规模孟加拉语图书知识图谱数据集，并进行了推荐模型基准测试。",
      "key_contributions": [
        "构建大规模孟加拉语图书知识图谱数据集RokomariBG",
        "提供了Top-N推荐任务的基准测试",
        "评估了多种推荐模型，包括GNN"
      ],
      "methodology": "构建包含用户、书籍、作者等多种实体和关系的知识图谱，并使用多种推荐模型进行评估，比较性能。",
      "tags": [
        "推荐系统",
        "知识图谱",
        "孟加拉语",
        "数据集"
      ],
      "assigned_category": "memory",
      "relevance_score": 6,
      "relevance_reason": "数据集构建可用于RAG，但主要贡献是推荐系统，相关性中等。",
      "analyzed_at": "2026-02-13T06:59:18.544444",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12128v1",
      "title": "HLA: Hadamard Linear Attention",
      "abstract": "The attention mechanism is an important reason for the success of transformers. It relies on computing pairwise relations between tokens. To reduce the high computational cost of standard quadratic attention, linear attention has been proposed as an efficient approximation. It employs kernel functions that are applied independently to the inputs before the pairwise similarities are calculated. That allows for an efficient computational procedure which, however, amounts to a low-degree rational function approximating softmax.   We propose Hadamard Linear Attention (HLA). Unlike previous works on linear attention, the nonlinearity in HLA is not applied separately to queries and keys, but, analogously to standard softmax attention, after the pairwise similarities have been computed. It will be shown that the proposed nonlinearity amounts to a higher-degree rational function to approximate softmax. An efficient computational scheme for the proposed method is derived that is similar to that of standard linear attention. In contrast to other approaches, no time-consuming tensor reshaping is necessary to apply the proposed algorithm. The effectiveness of the approach is demonstrated by applying it to a large diffusion transformer model for video generation, an application that involves very large amounts of tokens.",
      "authors": [
        "Hanno Ackermann",
        "Hong Cai",
        "Mohsen Ghafoorian",
        "Amirhossein Habibian"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T16:16:47Z",
      "updated": "2026-02-12T16:16:47Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12128v1",
      "abs_url": "http://arxiv.org/abs/2602.12128v1",
      "summary": "论文提出Hadamard线性注意力(HLA)，旨在以更高阶有理函数近似softmax，提高效率。",
      "key_contributions": [
        "提出Hadamard线性注意力(HLA)",
        "使用更高阶有理函数近似softmax",
        "应用于大型扩散transformer模型视频生成"
      ],
      "methodology": "HLA在计算相似度后引入非线性，并通过高效计算方案，在视频生成扩散模型中验证其有效性。",
      "tags": [
        "attention mechanism",
        "linear attention",
        "transformer",
        "video generation"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 7,
      "relevance_reason": "使用了注意力机制，应用于视频生成，和多模态领域高度相关。",
      "analyzed_at": "2026-02-13T06:59:20.441869",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12125v1",
      "title": "Learning beyond Teacher: Generalized On-Policy Distillation with Reward Extrapolation",
      "abstract": "On-policy distillation (OPD), which aligns the student with the teacher's logit distribution on student-generated trajectories, has demonstrated strong empirical gains in improving student performance and often outperforms off-policy distillation and reinforcement learning (RL) paradigms. In this work, we first theoretically show that OPD is a special case of dense KL-constrained RL where the reward function and the KL regularization are always weighted equally and the reference model can by any model. Then, we propose the Generalized On-Policy Distillation (G-OPD) framework, which extends the standard OPD objective by introducing a flexible reference model and a reward scaling factor that controls the relative weight of the reward term against the KL regularization. Through comprehensive experiments on math reasoning and code generation tasks, we derive two novel insights: (1) Setting the reward scaling factor to be greater than 1 (i.e., reward extrapolation), which we term ExOPD, consistently improves over standard OPD across a range of teacher-student size pairings. In particular, in the setting where we merge the knowledge from different domain experts, obtained by applying domain-specific RL to the same student model, back into the original student, ExOPD enables the student to even surpass the teacher's performance boundary and outperform the domain teachers. (2) Building on ExOPD, we further find that in the strong-to-weak distillation setting (i.e., distilling a smaller student from a larger teacher), performing reward correction by choosing the reference model as the teacher's base model before RL yields a more accurate reward signal and further improves distillation performance. However, this choice assumes access to the teacher's pre-RL variant and incurs more computational overhead. We hope our work offers new insights for future research on OPD.",
      "authors": [
        "Wenkai Yang",
        "Weijie Liu",
        "Ruobing Xie",
        "Kai Yang",
        "Saiyong Yang",
        "Yankai Lin"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T16:14:29Z",
      "updated": "2026-02-12T16:14:29Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12125v1",
      "abs_url": "http://arxiv.org/abs/2602.12125v1",
      "summary": "提出了广义On-Policy蒸馏框架G-OPD，并通过奖励外推ExOPD和奖励校正改进学生模型性能。",
      "key_contributions": [
        "理论证明OPD是KL约束RL的特例",
        "提出广义On-Policy蒸馏框架G-OPD，包含奖励外推ExOPD和奖励校正",
        "实验证明ExOPD和奖励校正能有效提升学生模型在数学推理和代码生成任务上的性能"
      ],
      "methodology": "理论分析OPD，然后提出G-OPD框架，通过调整奖励尺度和参考模型，优化知识蒸馏过程。",
      "tags": [
        "知识蒸馏",
        "强化学习",
        "奖励外推",
        "模型优化"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 8,
      "relevance_reason": "研究优化Agent的知识蒸馏过程，特别是奖励函数的设计与调整。",
      "analyzed_at": "2026-02-13T06:59:22.735409",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12123v1",
      "title": "Meta-Sel: Efficient Demonstration Selection for In-Context Learning via Supervised Meta-Learning",
      "abstract": "Demonstration selection is a practical bottleneck in in-context learning (ICL): under a tight prompt budget, accuracy can change substantially depending on which few-shot examples are included, yet selection must remain cheap enough to run per query over large candidate pools. We propose Meta-Sel, a lightweight supervised meta-learning approach for intent classification that learns a fast, interpretable scoring function for (candidate, query) pairs from labeled training data.   Meta-Sel constructs a meta-dataset by sampling pairs from the training split and using class agreement as supervision, then trains a calibrated logistic regressor on two inexpensive meta-features: TF--IDF cosine similarity and a length-compatibility ratio. At inference time, the selector performs a single vectorized scoring pass over the full candidate pool and returns the top-k demonstrations, requiring no model fine-tuning, no online exploration, and no additional LLM calls. This yields deterministic rankings and makes the selection mechanism straightforward to audit via interpretable feature weights.   Beyond proposing Meta-Sel, we provide a broad empirical study of demonstration selection, benchmarking 12 methods -- spanning prompt engineering baselines, heuristic selection, reinforcement learning, and influence-based approaches -- across four intent datasets and five open-source LLMs. Across this benchmark, Meta-Sel consistently ranks among the top-performing methods, is particularly effective for smaller models where selection quality can partially compensate for limited model capacity, and maintains competitive selection-time overhead.",
      "authors": [
        "Xubin Wang",
        "Weijia Jia"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T16:11:29Z",
      "updated": "2026-02-12T16:11:29Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12123v1",
      "abs_url": "http://arxiv.org/abs/2602.12123v1",
      "summary": "Meta-Sel提出了一种基于监督元学习的高效演示选择方法，用于上下文学习中的意图分类。",
      "key_contributions": [
        "提出Meta-Sel，一种轻量级监督元学习演示选择方法",
        "构建元数据集，使用类一致性作为监督信号",
        "在多个数据集和LLM上进行了广泛的实验评估"
      ],
      "methodology": "通过在训练数据上采样pair构建元数据集，训练校准的logistic回归模型来预测(candidate, query) pairs的分数。",
      "tags": [
        "In-Context Learning",
        "Demonstration Selection",
        "Meta-Learning",
        "Intent Classification"
      ],
      "assigned_category": "memory",
      "relevance_score": 7,
      "relevance_reason": "该论文关注上下文学习中的演示选择，与RAG中的检索策略相关。",
      "analyzed_at": "2026-02-13T06:59:24.425748",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12117v1",
      "title": "KAN-FIF: Spline-Parameterized Lightweight Physics-based Tropical Cyclone Estimation on Meteorological Satellite",
      "abstract": "Tropical cyclones (TC) are among the most destructive natural disasters, causing catastrophic damage to coastal regions through extreme winds, heavy rainfall, and storm surges. Timely monitoring of tropical cyclones is crucial for reducing loss of life and property, yet it is hindered by the computational inefficiency and high parameter counts of existing methods on resource-constrained edge devices. Current physics-guided models suffer from linear feature interactions that fail to capture high-order polynomial relationships between TC attributes, leading to inflated model sizes and hardware incompatibility. To overcome these challenges, this study introduces the Kolmogorov-Arnold Network-based Feature Interaction Framework (KAN-FIF), a lightweight multimodal architecture that integrates MLP and CNN layers with spline-parameterized KAN layers. For Maximum Sustained Wind (MSW) prediction, experiments demonstrate that the KAN-FIF framework achieves a $94.8\\%$ reduction in parameters (0.99MB vs 19MB) and $68.7\\%$ faster inference per sample (2.3ms vs 7.35ms) compared to baseline model Phy-CoCo, while maintaining superior accuracy with $32.5\\%$ lower MAE. The offline deployment experiment of the FY-4 series meteorological satellite processor on the Qingyun-1000 development board achieved a 14.41ms per-sample inference latency with the KAN-FIF framework, demonstrating promising feasibility for operational TC monitoring and extending deployability to edge-device AI applications. The code is released at https://github.com/Jinglin-Zhang/KAN-FIF.",
      "authors": [
        "Jiakang Shen",
        "Qinghui Chen",
        "Runtong Wang",
        "Chenrui Xu",
        "Jinglin Zhang",
        "Cong Bai",
        "Feng Zhang"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T16:07:39Z",
      "updated": "2026-02-12T16:07:39Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12117v1",
      "abs_url": "http://arxiv.org/abs/2602.12117v1",
      "summary": "提出KAN-FIF轻量级框架，用于气象卫星上热带气旋的物理信息预测，精度高、速度快、参数少。",
      "key_contributions": [
        "提出基于KAN的特征交互框架KAN-FIF",
        "实验证明KAN-FIF在参数量和推理速度上优于现有模型",
        "成功部署在FY-4气象卫星处理器上，验证了可行性"
      ],
      "methodology": "结合MLP、CNN和spline参数化KAN层，构建轻量级多模态架构，用于热带气旋最大持续风速预测。",
      "tags": [
        "热带气旋",
        "气象卫星",
        "Kolmogorov-Arnold Network",
        "边缘计算",
        "轻量级模型"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 7,
      "relevance_reason": "使用多模态数据进行预测，与多模态学习相关性高。",
      "analyzed_at": "2026-02-13T06:59:26.364084",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12116v1",
      "title": "P-GenRM: Personalized Generative Reward Model with Test-time User-based Scaling",
      "abstract": "Personalized alignment of large language models seeks to adapt responses to individual user preferences, typically via reinforcement learning. A key challenge is obtaining accurate, user-specific reward signals in open-ended scenarios. Existing personalized reward models face two persistent limitations: (1) oversimplifying diverse, scenario-specific preferences into a small, fixed set of evaluation principles, and (2) struggling with generalization to new users with limited feedback. To this end, we propose P-GenRM, the first Personalized Generative Reward Model with test-time user-based scaling. P-GenRM transforms preference signals into structured evaluation chains that derive adaptive personas and scoring rubrics across various scenarios. It further clusters users into User Prototypes and introduces a dual-granularity scaling mechanism: at the individual level, it adaptively scales and aggregates each user's scoring scheme; at the prototype level, it incorporates preferences from similar users. This design mitigates noise in inferred preferences and enhances generalization to unseen users through prototype-based transfer. Empirical results show that P-GenRM achieves state-of-the-art results on widely-used personalized reward model benchmarks, with an average improvement of 2.31%, and demonstrates strong generalization on an out-of-distribution dataset. Notably, Test-time User-based scaling provides an additional 3% boost, demonstrating stronger personalized alignment with test-time scalability.",
      "authors": [
        "Pinyi Zhang",
        "Ting-En Lin",
        "Yuchuan Wu",
        "Jingyang Chen",
        "Zongqi Wang",
        "Hua Yang",
        "Ze Xu",
        "Fei Huang",
        "Kai Zhang",
        "Yongbin Li"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-12T16:07:22Z",
      "updated": "2026-02-12T16:07:22Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12116v1",
      "abs_url": "http://arxiv.org/abs/2602.12116v1",
      "summary": "P-GenRM通过生成式奖励模型和用户原型聚类，提升个性化语言模型的奖励信号准确性和泛化能力。",
      "key_contributions": [
        "提出P-GenRM，个性化生成式奖励模型",
        "引入test-time用户尺度调整，增强个性化对齐",
        "利用用户原型聚类，提升新用户的泛化能力"
      ],
      "methodology": "通过将偏好信号转化为结构化评估链，建立自适应用户画像和评分标准，结合双粒度尺度调整实现个性化奖励。",
      "tags": [
        "个性化语言模型",
        "奖励模型",
        "强化学习",
        "用户原型"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注个性化奖励模型的优化，直接针对强化学习中的偏好对齐问题，密切相关。",
      "analyzed_at": "2026-02-13T06:59:28.206782",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12113v1",
      "title": "Stop Unnecessary Reflection: Training LRMs for Efficient Reasoning with Adaptive Reflection and Length Coordinated Penalty",
      "abstract": "Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning tasks by employing test-time scaling. However, they often generate over-long chains-of-thought that, driven by substantial reflections such as repetitive self-questioning and circular reasoning, lead to high token consumption, substantial computational overhead, and increased latency without improving accuracy, particularly in smaller models. Our observation reveals that increasing problem complexity induces more excessive and unnecessary reflection, which in turn reduces accuracy and increases token overhead. To address this challenge, we propose Adaptive Reflection and Length Coordinated Penalty (ARLCP), a novel reinforcement learning framework designed to dynamically balance reasoning efficiency and solution accuracy. ARLCP introduces two key innovations: (1) a reflection penalty that adaptively curtails unnecessary reflective steps while preserving essential reasoning, and (2) a length penalty calibrated to the estimated complexity of the problem. By coordinating these penalties, ARLCP encourages the model to generate more concise and effective reasoning paths. We evaluate our method on five mathematical reasoning benchmarks using DeepSeek-R1-Distill-Qwen-1.5B and DeepSeek-R1-Distill-Qwen-7B models. Experimental results show that ARLCP achieves a superior efficiency-accuracy trade-off compared to existing approaches. For the 1.5B model, it reduces the average response length by 53.1% while simultaneously improving accuracy by 5.8%. For the 7B model, it achieves a 35.0% reduction in length with a 2.7% accuracy gain. The code is released at https://github.com/ZeweiYu1/ARLCP .",
      "authors": [
        "Zewei Yu",
        "Lirong Gao",
        "Yuke Zhu",
        "Bo Zheng",
        "Sheng Guo",
        "Haobo Wang",
        "Junbo Zhao"
      ],
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T16:04:00Z",
      "updated": "2026-02-12T16:04:00Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12113v1",
      "abs_url": "http://arxiv.org/abs/2602.12113v1",
      "summary": "针对大语言模型推理冗余问题，提出自适应反射和长度协调惩罚机制，提升推理效率和准确率。",
      "key_contributions": [
        "提出Adaptive Reflection and Length Coordinated Penalty (ARLCP)框架",
        "引入反射惩罚以减少不必要的反射步骤",
        "引入长度惩罚以协调推理长度和问题复杂度"
      ],
      "methodology": "采用强化学习方法，通过自适应反射和长度协调惩罚，动态平衡推理效率和解决方案准确性。",
      "tags": [
        "LLM",
        "Reasoning",
        "Reinforcement Learning",
        "Efficiency"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文直接解决大语言模型推理中的效率问题，与推理领域核心相关。",
      "analyzed_at": "2026-02-13T06:59:29.951637",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12108v1",
      "title": "The Pensieve Paradigm: Stateful Language Models Mastering Their Own Context",
      "abstract": "In the world of Harry Potter, when Dumbledore's mind is overburdened, he extracts memories into a Pensieve to be revisited later. In the world of AI, while we possess the Pensieve-mature databases and retrieval systems, our models inexplicably lack the \"wand\" to operate it. They remain like a Dumbledore without agency, passively accepting a manually engineered context as their entire memory. This work finally places the wand in the model's hand. We introduce StateLM, a new class of foundation models endowed with an internal reasoning loop to manage their own state. We equip our model with a suite of memory tools, such as context pruning, document indexing, and note-taking, and train it to actively manage these tools. By learning to dynamically engineering its own context, our model breaks free from the architectural prison of a fixed window. Experiments across various model sizes demonstrate StateLM's effectiveness across diverse scenarios. On long-document QA tasks, StateLMs consistently outperform standard LLMs across all model scales; on the chat memory task, they achieve absolute accuracy improvements of 10% to 20% over standard LLMs. On the deep research task BrowseComp-Plus, the performance gap becomes even more pronounced: StateLM achieves up to 52% accuracy, whereas standard LLM counterparts struggle around 5%. Ultimately, our approach shifts LLMs from passive predictors to state-aware agents where reasoning becomes a stateful and manageable process.",
      "authors": [
        "Xiaoyuan Liu",
        "Tian Liang",
        "Dongyang Ma",
        "Deyu Zhou",
        "Haitao Mi",
        "Pinjia He",
        "Yan Wang"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T16:00:01Z",
      "updated": "2026-02-12T16:00:01Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12108v1",
      "abs_url": "http://arxiv.org/abs/2602.12108v1",
      "summary": "StateLM模型通过内部推理循环管理自身状态，突破固定窗口限制，提升长文本处理能力。",
      "key_contributions": [
        "提出了StateLM，一种具备内部推理循环的状态感知语言模型",
        "设计了一套记忆工具，包括上下文剪枝、文档索引和笔记",
        "通过实验验证了StateLM在长文档问答、聊天记忆和深度研究任务中的优越性"
      ],
      "methodology": "训练语言模型主动管理上下文，利用记忆工具动态构建自身上下文，突破固定窗口限制。",
      "tags": [
        "StateLM",
        "Memory Management",
        "Long-Context",
        "Agent"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "该论文提出了具备状态管理能力的Agent，并在多种任务上验证了其有效性。",
      "analyzed_at": "2026-02-13T06:59:31.629576",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12105v1",
      "title": "Iskra: A System for Inverse Geometry Processing",
      "abstract": "We propose a system for differentiating through solutions to geometry processing problems. Our system differentiates a broad class of geometric algorithms, exploiting existing fast problem-specific schemes common to geometry processing, including local-global and ADMM solvers. It is compatible with machine learning frameworks, opening doors to new classes of inverse geometry processing applications. We marry the scatter-gather approach to mesh processing with tensor-based workflows and rely on the adjoint method applied to user-specified imperative code to generate an efficient backward pass behind the scenes. We demonstrate our approach by differentiating through mean curvature flow, spectral conformal parameterization, geodesic distance computation, and as-rigid-as-possible deformation, examining usability and performance on these applications. Our system allows practitioners to differentiate through existing geometry processing algorithms without needing to reformulate them, resulting in low implementation effort, fast runtimes, and lower memory requirements than differentiable optimization tools not tailored to geometry processing.",
      "authors": [
        "Ana Dodik",
        "Ahmed H. Mahmoud",
        "Justin Solomon"
      ],
      "categories": [
        "cs.GR",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.GR",
      "published": "2026-02-12T15:59:06Z",
      "updated": "2026-02-12T15:59:06Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12105v1",
      "abs_url": "http://arxiv.org/abs/2602.12105v1",
      "summary": "Iskra系统可高效地对几何处理算法进行微分，实现反向几何处理。",
      "key_contributions": [
        "提出了一个用于几何处理问题微分的系统",
        "利用局部-全局和ADMM等快速求解器",
        "实现了现有几何处理算法的自动微分"
      ],
      "methodology": "结合散布-收集方法与张量工作流，应用伴随方法生成高效的后向传递过程。",
      "tags": [
        "几何处理",
        "微分",
        "反向传播",
        "机器学习",
        "优化"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 5,
      "relevance_reason": "系统可用于优化几何处理算法，间接影响智能体的环境理解。",
      "analyzed_at": "2026-02-13T06:59:33.178552",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12099v1",
      "title": "GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning",
      "abstract": "Vision-language-action (VLA) models that directly predict multi-step action chunks from current observations face inherent limitations due to constrained scene understanding and weak future anticipation capabilities. In contrast, video world models pre-trained on web-scale video corpora exhibit robust spatiotemporal reasoning and accurate future prediction, making them a natural foundation for enhancing VLA learning. Therefore, we propose \\textit{GigaBrain-0.5M*}, a VLA model trained via world model-based reinforcement learning. Built upon \\textit{GigaBrain-0.5}, which is pre-trained on over 10,000 hours of robotic manipulation data, whose intermediate version currently ranks first on the international RoboChallenge benchmark. \\textit{GigaBrain-0.5M*} further integrates world model-based reinforcement learning via \\textit{RAMP} (Reinforcement leArning via world Model-conditioned Policy) to enable robust cross-task adaptation. Empirical results demonstrate that \\textit{RAMP} achieves substantial performance gains over the RECAP baseline, yielding improvements of approximately 30\\% on challenging tasks including \\texttt{Laundry Folding}, \\texttt{Box Packing}, and \\texttt{Espresso Preparation}. Critically, \\textit{GigaBrain-0.5M$^*$} exhibits reliable long-horizon execution, consistently accomplishing complex manipulation tasks without failure as validated by real-world deployment videos on our \\href{https://gigabrain05m.github.io}{project page}.",
      "authors": [
        "GigaBrain Team",
        "Boyuan Wang",
        "Chaojun Ni",
        "Guan Huang",
        "Guosheng Zhao",
        "Hao Li",
        "Jie Li",
        "Jindi Lv",
        "Jingyu Liu",
        "Lv Feng",
        "Mingming Yu",
        "Peng Li",
        "Qiuping Deng",
        "Tianze Liu",
        "Xinyu Zhou",
        "Xinze Chen",
        "Xiaofeng Wang",
        "Yang Wang",
        "Yifan Li",
        "Yifei Nie",
        "Yilong Li",
        "Yukun Zhou",
        "Yun Ye",
        "Zhichao Liu",
        "Zheng Zhu"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-12T15:55:19Z",
      "updated": "2026-02-12T15:55:19Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12099v1",
      "abs_url": "http://arxiv.org/abs/2602.12099v1",
      "summary": "GigaBrain-0.5M*通过世界模型强化学习，提升VLA模型的跨任务适应性和长程操作能力。",
      "key_contributions": [
        "提出了基于世界模型的强化学习方法RAMP",
        "构建了GigaBrain-0.5M*模型，提升了复杂操作任务的性能",
        "在真实环境中验证了模型长程执行的可靠性"
      ],
      "methodology": "基于预训练的机器人操作视频世界模型GigaBrain-0.5，使用RAMP进行强化学习，提高跨任务泛化能力。",
      "tags": [
        "VLA",
        "世界模型",
        "强化学习",
        "机器人操作"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "论文研究的是基于世界模型的Agent，提升其操作能力。",
      "analyzed_at": "2026-02-13T06:59:34.872529",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12096v1",
      "title": "Multi Graph Search for High-Dimensional Robot Motion Planning",
      "abstract": "Efficient motion planning for high-dimensional robotic systems, such as manipulators and mobile manipulators, is critical for real-time operation and reliable deployment. Although advances in planning algorithms have enhanced scalability to high-dimensional state spaces, these improvements often come at the cost of generating unpredictable, inconsistent motions or requiring excessive computational resources and memory. In this work, we introduce Multi-Graph Search (MGS), a search-based motion planning algorithm that generalizes classical unidirectional and bidirectional search to a multi-graph setting. MGS maintains and incrementally expands multiple implicit graphs over the state space, focusing exploration on high-potential regions while allowing initially disconnected subgraphs to be merged through feasible transitions as the search progresses. We prove that MGS is complete and bounded-suboptimal, and empirically demonstrate its effectiveness on a range of manipulation and mobile manipulation tasks. Demonstrations, benchmarks and code are available at https://multi-graph-search.github.io/.",
      "authors": [
        "Itamar Mishani",
        "Maxim Likhachev"
      ],
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "published": "2026-02-12T15:50:15Z",
      "updated": "2026-02-12T15:50:15Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12096v1",
      "abs_url": "http://arxiv.org/abs/2602.12096v1",
      "summary": "提出一种名为多图搜索(MGS)的运动规划算法，适用于高维机器人系统。",
      "key_contributions": [
        "提出了多图搜索(MGS)算法",
        "证明了MGS的完备性和有界次优性",
        "在操纵和移动操纵任务中验证了MGS的有效性"
      ],
      "methodology": "MGS维护并增量扩展多个隐式图，集中探索高潜力区域，并通过可行转换合并子图。",
      "tags": [
        "机器人",
        "运动规划",
        "图搜索",
        "高维空间"
      ],
      "assigned_category": "agent",
      "relevance_score": 5,
      "relevance_reason": "涉及机器人自主规划，与Agent具有一定相关性。",
      "analyzed_at": "2026-02-13T06:59:36.560207",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12092v1",
      "title": "DeepSight: An All-in-One LM Safety Toolkit",
      "abstract": "As the development of Large Models (LMs) progresses rapidly, their safety is also a priority. In current Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) safety workflow, evaluation, diagnosis, and alignment are often handled by separate tools. Specifically, safety evaluation can only locate external behavioral risks but cannot figure out internal root causes. Meanwhile, safety diagnosis often drifts from concrete risk scenarios and remains at the explainable level. In this way, safety alignment lack dedicated explanations of changes in internal mechanisms, potentially degrading general capabilities. To systematically address these issues, we propose an open-source project, namely DeepSight, to practice a new safety evaluation-diagnosis integrated paradigm. DeepSight is low-cost, reproducible, efficient, and highly scalable large-scale model safety evaluation project consisting of a evaluation toolkit DeepSafe and a diagnosis toolkit DeepScan. By unifying task and data protocols, we build a connection between the two stages and transform safety evaluation from black-box to white-box insight. Besides, DeepSight is the first open source toolkit that support the frontier AI risk evaluation and joint safety evaluation and diagnosis.",
      "authors": [
        "Bo Zhang",
        "Jiaxuan Guo",
        "Lijun Li",
        "Dongrui Liu",
        "Sujin Chen",
        "Guanxu Chen",
        "Zhijie Zheng",
        "Qihao Lin",
        "Lewen Yan",
        "Chen Qian",
        "Yijin Zhou",
        "Yuyao Wu",
        "Shaoxiong Guo",
        "Tianyi Du",
        "Jingyi Yang",
        "Xuhao Hu",
        "Ziqi Miao",
        "Xiaoya Lu",
        "Jing Shao",
        "Xia Hu"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-12T15:43:14Z",
      "updated": "2026-02-12T15:43:14Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12092v1",
      "abs_url": "http://arxiv.org/abs/2602.12092v1",
      "summary": "DeepSight是一个集评估、诊断于一体的大模型安全开源工具，旨在提升安全性分析的全面性和效率。",
      "key_contributions": [
        "提出了安全评估与诊断集成的新范式",
        "构建了低成本、可复现、高效的大模型安全评估项目",
        "首个支持前沿AI风险评估和联合安全评估与诊断的开源工具"
      ],
      "methodology": "通过统一任务和数据协议，连接安全评估和诊断阶段，将黑盒评估转化为白盒洞察，从而系统性解决大模型安全问题。",
      "tags": [
        "LLM Safety",
        "Evaluation",
        "Diagnosis",
        "Open Source"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "工具旨在提升模型的安全性，与Agent安全性与可靠性密切相关",
      "analyzed_at": "2026-02-13T06:59:38.691291",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12089v1",
      "title": "Choose Your Agent: Tradeoffs in Adopting AI Advisors, Coaches, and Delegates in Multi-Party Negotiation",
      "abstract": "As AI usage becomes more prevalent in social contexts, understanding agent-user interaction is critical to designing systems that improve both individual and group outcomes. We present an online behavioral experiment (N = 243) in which participants play three multi-turn bargaining games in groups of three. Each game, presented in randomized order, grants \\textit{access to} a single LLM assistance modality: proactive recommendations from an \\textit{Advisor}, reactive feedback from a \\textit{Coach}, or autonomous execution by a \\textit{Delegate}; all modalities are powered by an underlying LLM that achieves superhuman performance in an all-agent environment. On each turn, participants privately decide whether to act manually or use the AI modality available in that game. Despite preferring the \\textit{Advisor} modality, participants achieve the highest mean individual gains with the \\textit{Delegate}, demonstrating a preference-performance misalignment. Moreover, delegation generates positive externalities; even non-adopting users in \\textit{access-to-delegate} treatment groups benefit by receiving higher-quality offers. Mechanism analysis reveals that the \\textit{Delegate} agent acts as a market maker, injecting rational, Pareto-improving proposals that restructure the trading environment. Our research reveals a gap between agent capabilities and realized group welfare. While autonomous agents can exhibit super-human strategic performance, their impact on realized welfare gains can be constrained by interfaces, user perceptions, and adoption barriers. Assistance modalities should be designed as mechanisms with endogenous participation; adoption-compatible interaction rules are a prerequisite to improving human welfare with automated assistance.",
      "authors": [
        "Kehang Zhu",
        "Lithium Thain",
        "Vivian Tsai",
        "James Wexler",
        "Crystal Qian"
      ],
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.GT",
      "published": "2026-02-12T15:41:57Z",
      "updated": "2026-02-12T15:41:57Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12089v1",
      "abs_url": "http://arxiv.org/abs/2602.12089v1",
      "summary": "研究了AI代理在多人谈判中的不同辅助方式（顾问、教练、代理），揭示了用户偏好与实际收益之间的差距。",
      "key_contributions": [
        "比较了Advisor, Coach, Delegate三种AI辅助模式在谈判中的表现",
        "发现Delegate模式能带来更高的个人收益和积极的外部性",
        "揭示了用户偏好与实际收益之间的不一致性，强调了交互设计的重要性"
      ],
      "methodology": "在线行为实验，招募243名参与者，进行三轮多人谈判博弈，每轮采用不同的LLM辅助模式，分析用户行为和收益。",
      "tags": [
        "AI Agent",
        "Multi-Party Negotiation",
        "Behavioral Experiment",
        "Game Theory",
        "LLM"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文直接研究AI agent在社会交互中的应用，是agent领域的核心问题。",
      "analyzed_at": "2026-02-13T06:59:40.710842",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12087v1",
      "title": "Geometry of Uncertainty: Learning Metric Spaces for Multimodal State Estimation in RL",
      "abstract": "Estimating the state of an environment from high-dimensional, multimodal, and noisy observations is a fundamental challenge in reinforcement learning (RL). Traditional approaches rely on probabilistic models to account for the uncertainty, but often require explicit noise assumptions, in turn limiting generalization. In this work, we contribute a novel method to learn a structured latent representation, in which distances between states directly correlate with the minimum number of actions required to transition between them. The proposed metric space formulation provides a geometric interpretation of uncertainty without the need for explicit probabilistic modeling. To achieve this, we introduce a multimodal latent transition model and a sensor fusion mechanism based on inverse distance weighting, allowing for the adaptive integration of multiple sensor modalities without prior knowledge of noise distributions. We empirically validate the approach on a range of multimodal RL tasks, demonstrating improved robustness to sensor noise and superior state estimation compared to baseline methods. Our experiments show enhanced performance of an RL agent via the learned representation, eliminating the need of explicit noise augmentation. The presented results suggest that leveraging transition-aware metric spaces provides a principled and scalable solution for robust state estimation in sequential decision-making.",
      "authors": [
        "Alfredo Reichlin",
        "Adriano Pacciarelli",
        "Danica Kragic",
        "Miguel Vasco"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T15:41:20Z",
      "updated": "2026-02-12T15:41:20Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12087v1",
      "abs_url": "http://arxiv.org/abs/2602.12087v1",
      "summary": "提出一种新型强化学习状态估计方法，通过学习度量空间提升多模态信息融合的鲁棒性。",
      "key_contributions": [
        "提出基于度量空间的无显式概率建模的状态估计方法",
        "引入多模态隐变量转移模型",
        "提出基于反距离权重的传感器融合机制"
      ],
      "methodology": "通过学习状态间的度量空间，将状态估计问题转化为几何问题，并使用多模态模型和传感器融合提升鲁棒性。",
      "tags": [
        "强化学习",
        "状态估计",
        "多模态学习",
        "度量学习",
        "传感器融合"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 8,
      "relevance_reason": "论文核心是多模态信息的融合，解决了强化学习中的状态估计问题。",
      "analyzed_at": "2026-02-13T06:59:42.625266",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12083v1",
      "title": "Differentiable Modal Logic for Multi-Agent Diagnosis, Orchestration and Communication",
      "abstract": "As multi-agent AI systems evolve from simple chatbots to autonomous swarms, debugging semantic failures requires reasoning about knowledge, belief, causality, and obligation, precisely what modal logic was designed to formalize. However, traditional modal logic requires manual specification of relationship structures that are unknown or dynamic in real systems. This tutorial demonstrates differentiable modal logic (DML), implemented via Modal Logical Neural Networks (MLNNs), enabling systems to learn trust networks, causal chains, and regulatory boundaries from behavioral data alone.   We present a unified neurosymbolic debugging framework through four modalities: epistemic (who to trust), temporal (when events cause failures), deontic (what actions are permitted), and doxastic (how to interpret agent confidence). Each modality is demonstrated on concrete multi-agent scenarios, from discovering deceptive alliances in diplomacy games to detecting LLM hallucinations, with complete implementations showing how logical contradictions become learnable optimization objectives. Key contributions for the neurosymbolic community: (1) interpretable learned structures where trust and causality are explicit parameters, not opaque embeddings; (2) knowledge injection via differentiable axioms that guide learning with sparse data (3) compositional multi-modal reasoning that combines epistemic, temporal, and deontic constraints; and (4) practical deployment patterns for monitoring, active control and communication of multi-agent systems. All code provided as executable Jupyter notebooks.",
      "authors": [
        "Antonin Sulc"
      ],
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T15:39:18Z",
      "updated": "2026-02-12T15:39:18Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12083v1",
      "abs_url": "http://arxiv.org/abs/2602.12083v1",
      "summary": "提出可微模态逻辑，用于多智能体系统的诊断、协调和通信，实现神经符号调试。",
      "key_contributions": [
        "可解释的学习结构，信任和因果关系是显式参数",
        "通过可微公理进行知识注入，指导稀疏数据学习",
        "组合式多模态推理，结合认知、时间和道义约束"
      ],
      "methodology": "使用模态逻辑神经网络(MLNNs)实现可微模态逻辑(DML)，从行为数据中学习信任网络、因果链和规则边界。",
      "tags": [
        "modal logic",
        "multi-agent system",
        "neurosymbolic AI"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "论文关注多智能体系统的推理和调试，与AI Agent类别高度相关。",
      "analyzed_at": "2026-02-13T06:59:44.345007",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12080v1",
      "title": "PathCRF: Ball-Free Soccer Event Detection via Possession Path Inference from Player Trajectories",
      "abstract": "Despite recent advances in AI, event data collection in soccer still relies heavily on labor-intensive manual annotation. Although prior work has explored automatic event detection using player and ball trajectories, ball tracking also remains difficult to scale due to high infrastructural and operational costs. As a result, comprehensive data collection in soccer is largely confined to top-tier competitions, limiting the broader adoption of data-driven analysis in this domain. To address this challenge, this paper proposes PathCRF, a framework for detecting on-ball soccer events using only player tracking data. We model player trajectories as a fully connected dynamic graph and formulate event detection as the problem of selecting exactly one edge corresponding to the current possession state at each time step. To ensure logical consistency of the resulting edge sequence, we employ a Conditional Random Field (CRF) that forbids impossible transitions between consecutive edges. Both emission and transition scores dynamically computed from edge embeddings produced by a Set Attention-based backbone architecture. During inference, the most probable edge sequence is obtained via Viterbi decoding, and events such as ball controls or passes are detected whenever the selected edge changes between adjacent time steps. Experiments show that PathCRF produces accurate, logically consistent possession paths, enabling reliable downstream analyses while substantially reducing the need for manual event annotation. The source code is available at https://github.com/hyunsungkim-ds/pathcrf.git.",
      "authors": [
        "Hyunsung Kim",
        "Kunhee Lee",
        "Sangwoo Seo",
        "Sang-Ki Ko",
        "Jinsung Yoon",
        "Chanyoung Park"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T15:37:31Z",
      "updated": "2026-02-12T15:37:31Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12080v1",
      "abs_url": "http://arxiv.org/abs/2602.12080v1",
      "summary": "PathCRF通过球员轨迹推断控球路径，实现无需球轨迹的足球事件检测。",
      "key_contributions": [
        "提出PathCRF框架，仅使用球员轨迹检测足球事件",
        "使用动态图和条件随机场(CRF)建模控球状态",
        "通过Set Attention网络学习边嵌入，提高事件检测准确率"
      ],
      "methodology": "构建全连接动态图，用CRF建模相邻边之间的逻辑关系，使用Set Attention学习边嵌入，Viterbi解码得到最优路径。",
      "tags": [
        "足球",
        "事件检测",
        "球员轨迹",
        "条件随机场",
        "图神经网络"
      ],
      "assigned_category": "agent",
      "relevance_score": 5,
      "relevance_reason": "自主推断并解决足球事件检测问题，具备一定自主性。",
      "analyzed_at": "2026-02-13T06:59:46.258857",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12078v1",
      "title": "Tiny Recursive Reasoning with Mamba-2 Attention Hybrid",
      "abstract": "Recent work on recursive reasoning models like TRM demonstrates that tiny networks (7M parameters) can achieve strong performance on abstract reasoning tasks through latent recursion -- iterative refinement in hidden representation space without emitting intermediate tokens. This raises a natural question about operator choice: Mamba-2's state space recurrence is itself a form of iterative refinement, making it a natural candidate for recursive reasoning -- but does introducing Mamba-2 into the recursive scaffold preserve reasoning capability? We investigate this by replacing the Transformer blocks in TRM with Mamba-2 hybrid operators while maintaining parameter parity (6.83M vs 6.86M parameters). On ARC-AGI-1, we find that the hybrid improves pass@2 (the official metric) by +2.0\\% (45.88\\% vs 43.88\\%) and consistently outperforms at higher K values (+4.75\\% at pass@100), whilst maintaining pass@1 parity. This suggests improved candidate coverage -- the model generates correct solutions more reliably -- with similar top-1 selection. Our results validate that Mamba-2 hybrid operators preserve reasoning capability within the recursive scaffold, establishing SSM-based operators as viable candidates in the recursive operator design space and taking a first step towards understanding the best mixing strategies for recursive reasoning.",
      "authors": [
        "Wenlong Wang",
        "Fergal Reid"
      ],
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T15:36:32Z",
      "updated": "2026-02-12T15:36:32Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12078v1",
      "abs_url": "http://arxiv.org/abs/2602.12078v1",
      "summary": "该论文探索了将Mamba-2算子融入递归推理模型的可行性，并验证了其在保持推理能力的同时具有性能提升。",
      "key_contributions": [
        "验证了Mamba-2算子在递归推理框架中的可行性",
        "发现了Mamba-2混合算子能提升ARC-AGI-1数据集上的性能",
        "为递归算子设计空间提供了新的选择"
      ],
      "methodology": "用Mamba-2混合算子替换TRM中的Transformer块，保持参数量相似，并在ARC-AGI-1数据集上进行评估。",
      "tags": [
        "递归推理",
        "Mamba-2",
        "状态空间模型",
        "抽象推理"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文直接研究了使用Mamba-2提升LLM推理能力的问题。",
      "analyzed_at": "2026-02-13T06:59:48.234184",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12056v1",
      "title": "LawThinker: A Deep Research Legal Agent in Dynamic Environments",
      "abstract": "Legal reasoning requires not only correct outcomes but also procedurally compliant reasoning processes. However, existing methods lack mechanisms to verify intermediate reasoning steps, allowing errors such as inapplicable statute citations to propagate undetected through the reasoning chain. To address this, we propose LawThinker, an autonomous legal research agent that adopts an Explore-Verify-Memorize strategy for dynamic judicial environments. The core idea is to enforce verification as an atomic operation after every knowledge exploration step. A DeepVerifier module examines each retrieval result along three dimensions of knowledge accuracy, fact-law relevance, and procedural compliance, with a memory module for cross-round knowledge reuse in long-horizon tasks. Experiments on the dynamic benchmark J1-EVAL show that LawThinker achieves a 24% improvement over direct reasoning and an 11% gain over workflow-based methods, with particularly strong improvements on process-oriented metrics. Evaluations on three static benchmarks further confirm its generalization capability. The code is available at https://github.com/yxy-919/LawThinker-agent .",
      "authors": [
        "Xinyu Yang",
        "Chenlong Deng",
        "Tongyu Wen",
        "Binyu Xie",
        "Zhicheng Dou"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T15:19:11Z",
      "updated": "2026-02-12T15:19:11Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12056v1",
      "abs_url": "http://arxiv.org/abs/2602.12056v1",
      "summary": "LawThinker通过Explore-Verify-Memorize策略，提升法律推理过程的准确性和合规性，在动态环境中表现优异。",
      "key_contributions": [
        "提出Explore-Verify-Memorize策略",
        "设计DeepVerifier模块验证推理步骤",
        "J1-EVAL动态基准上的显著提升"
      ],
      "methodology": "设计法律推理Agent，在知识探索后通过DeepVerifier模块验证知识的准确性、相关性和合规性，并使用记忆模块进行知识复用。",
      "tags": [
        "Legal Reasoning",
        "AI Agent",
        "Knowledge Verification"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于构建自主法律推理Agent，使用工具并进行验证，解决Agent领域的关键问题。",
      "analyzed_at": "2026-02-13T06:59:49.857097",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12055v1",
      "title": "Multi UAVs Preflight Planning in a Shared and Dynamic Airspace",
      "abstract": "Preflight planning for large-scale Unmanned Aerial Vehicle (UAV) fleets in dynamic, shared airspace presents significant challenges, including temporal No-Fly Zones (NFZs), heterogeneous vehicle profiles, and strict delivery deadlines. While Multi-Agent Path Finding (MAPF) provides a formal framework, existing methods often lack the scalability and flexibility required for real-world Unmanned Traffic Management (UTM). We propose DTAPP-IICR: a Delivery-Time Aware Prioritized Planning method with Incremental and Iterative Conflict Resolution. Our framework first generates an initial solution by prioritizing missions based on urgency. Secondly, it computes roundtrip trajectories using SFIPP-ST, a novel 4D single-agent planner (Safe Flight Interval Path Planning with Soft and Temporal Constraints). SFIPP-ST handles heterogeneous UAVs, strictly enforces temporal NFZs, and models inter-agent conflicts as soft constraints. Subsequently, an iterative Large Neighborhood Search, guided by a geometric conflict graph, efficiently resolves any residual conflicts. A completeness-preserving directional pruning technique further accelerates the 3D search. On benchmarks with temporal NFZs, DTAPP-IICR achieves near-100% success with fleets of up to 1,000 UAVs and gains up to 50% runtime reduction from pruning, outperforming batch Enhanced Conflict-Based Search in the UTM context. Scaling successfully in realistic city-scale operations where other priority-based methods fail even at moderate deployments, DTAPP-IICR is positioned as a practical and scalable solution for preflight planning in dense, dynamic urban airspace.",
      "authors": [
        "Amath Sow",
        "Mauricio Rodriguez Cesen",
        "Fabiola Martins Campos de Oliveira",
        "Mariusz Wzorek",
        "Daniel de Leng",
        "Mattias Tiger",
        "Fredrik Heintz",
        "Christian Esteve Rothenberg"
      ],
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T15:18:46Z",
      "updated": "2026-02-12T15:18:46Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12055v1",
      "abs_url": "http://arxiv.org/abs/2602.12055v1",
      "summary": "针对动态共享空域中大规模无人机群的预飞行规划，提出了一种可扩展的冲突消解方法。",
      "key_contributions": [
        "提出DTAPP-IICR方法，解决大规模无人机群的预飞行规划问题",
        "设计SFIPP-ST单智能体规划器，处理异构无人机和时序禁飞区",
        "引入基于几何冲突图的大邻域搜索，高效解决剩余冲突"
      ],
      "methodology": "基于优先级规划，结合单智能体规划器生成初始轨迹，再通过迭代的大邻域搜索解决冲突。",
      "tags": [
        "无人机",
        "路径规划",
        "多智能体",
        "冲突消解",
        "空中交通管理"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "论文专注于多智能体无人机的规划与冲突解决，与AI Agent领域高度相关。",
      "analyzed_at": "2026-02-13T06:59:51.956243",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12047v1",
      "title": "Safety Beyond the Training Data: Robust Out-of-Distribution MPC via Conformalized System Level Synthesis",
      "abstract": "We present a novel framework for robust out-of-distribution planning and control using conformal prediction (CP) and system level synthesis (SLS), addressing the challenge of ensuring safety and robustness when using learned dynamics models beyond the training data distribution. We first derive high-confidence model error bounds using weighted CP with a learned, state-control-dependent covariance model. These bounds are integrated into an SLS-based robust nonlinear model predictive control (MPC) formulation, which performs constraint tightening over the prediction horizon via volume-optimized forward reachable sets. We provide theoretical guarantees on coverage and robustness under distributional drift, and analyze the impact of data density and trajectory tube size on prediction coverage. Empirically, we demonstrate our method on nonlinear systems of increasing complexity, including a 4D car and a {12D} quadcopter, improving safety and robustness compared to fixed-bound and non-robust baselines, especially outside of the data distribution.",
      "authors": [
        "Anutam Srinivasan",
        "Antoine Leeman",
        "Glen Chou"
      ],
      "categories": [
        "cs.RO",
        "cs.LG",
        "eess.SY",
        "math.OC"
      ],
      "primary_category": "cs.RO",
      "published": "2026-02-12T15:11:44Z",
      "updated": "2026-02-12T15:11:44Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12047v1",
      "abs_url": "http://arxiv.org/abs/2602.12047v1",
      "summary": "提出了一种基于共形预测和系统级综合的鲁棒的分布外模型预测控制框架。",
      "key_contributions": [
        "使用加权共形预测推导高置信度的模型误差界限",
        "将误差界限整合到基于系统级综合的鲁棒非线性模型预测控制中",
        "提供分布漂移下的覆盖率和鲁棒性理论保证"
      ],
      "methodology": "利用状态控制相关的协方差模型学习加权共形预测，并将其与系统级综合的MPC结合，实现分布外数据的安全控制。",
      "tags": [
        "模型预测控制",
        "鲁棒控制",
        "共形预测",
        "系统级综合",
        "分布外泛化"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "虽然偏控制领域，但安全控制和鲁棒性是智能体的重要考量因素。",
      "analyzed_at": "2026-02-13T06:59:53.991623",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12036v1",
      "title": "Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models",
      "abstract": "Large-scale verifiable prompts underpin the success of Reinforcement Learning with Verifiable Rewards (RLVR), but they contain many uninformative examples and are costly to expand further. Recent studies focus on better exploiting limited training data by prioritizing hard prompts whose rollout pass rate is 0. However, easy prompts with a pass rate of 1 also become increasingly prevalent as training progresses, thereby reducing the effective data size. To mitigate this, we propose Composition-RL, a simple yet useful approach for better utilizing limited verifiable prompts targeting pass-rate-1 prompts. More specifically, Composition-RL automatically composes multiple problems into a new verifiable question and uses these compositional prompts for RL training. Extensive experiments across model sizes from 4B to 30B show that Composition-RL consistently improves reasoning capability over RL trained on the original dataset. Performance can be further boosted with a curriculum variant of Composition-RL that gradually increases compositional depth over training. Additionally, Composition-RL enables more effective cross-domain RL by composing prompts drawn from different domains. Codes, datasets, and models are available at https://github.com/XinXU-USTC/Composition-RL.",
      "authors": [
        "Xin Xu",
        "Clive Bai",
        "Kai Yang",
        "Tianhao Chen",
        "Yangkun Chen",
        "Weijie Liu",
        "Hao Chen",
        "Yang Wang",
        "Saiyong Yang",
        "Can Yang"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-12T15:03:37Z",
      "updated": "2026-02-12T15:03:37Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12036v1",
      "abs_url": "http://arxiv.org/abs/2602.12036v1",
      "summary": "提出Composition-RL方法，通过组合prompt优化LLM的强化学习训练，提升推理能力。",
      "key_contributions": [
        "提出Composition-RL方法，利用pass-rate-1的prompt进行组合训练。",
        "证明Composition-RL在不同模型尺寸下能稳定提升推理能力。",
        "提出Composition-RL的课程学习变体，进一步提升性能。",
        "证明Composition-RL能有效进行跨领域强化学习。"
      ],
      "methodology": "自动将多个问题组合成新的可验证问题，并使用这些组合prompt进行强化学习训练。可使用课程学习策略逐步增加组合深度。",
      "tags": [
        "强化学习",
        "大型语言模型",
        "提示工程",
        "组合性"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 8,
      "relevance_reason": "通过优化prompt来提高LLM在强化学习中的表现，属于Agent Tuning & Optimization的高相关领域。",
      "analyzed_at": "2026-02-13T06:59:56.245280",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12029v1",
      "title": "PrefillShare: A Shared Prefill Module for KV Reuse in Multi-LLM Disaggregated Serving",
      "abstract": "Multi-agent systems increasingly orchestrate multiple specialized language models to solve complex real-world problems, often invoking them over a shared context. This execution pattern repeatedly processes the same prompt prefix across models. Consequently, each model redundantly executes the prefill stage and maintains its own key-value (KV) cache, increasing aggregate prefill load and worsening tail latency by intensifying prefill-decode interference in existing LLM serving stacks. Disaggregated serving reduces such interference by placing prefill and decode on separate GPUs, but disaggregation does not fundamentally eliminate inter-model redundancy in computation and KV storage for the same prompt. To address this issue, we propose PrefillShare, a novel algorithm that enables sharing the prefill stage across multiple models in a disaggregated setting. PrefillShare factorizes the model into prefill and decode modules, freezes the prefill module, and fine-tunes only the decode module. This design allows multiple task-specific models to share a prefill module and the KV cache generated for the same prompt. We further introduce a routing mechanism that enables effective prefill sharing across heterogeneous models in a vLLM-based disaggregated system. PrefillShare not only matches full fine-tuning accuracy on a broad range of tasks and models, but also delivers 4.5x lower p95 latency and 3.9x higher throughput in multi-model agent workloads.",
      "authors": [
        "Sunghyeon Woo",
        "Hoseung Kim",
        "Sunghwan Shim",
        "Minjung Jo",
        "Hyunjoon Jeong",
        "Jeongtae Lee",
        "Joonghoon Kim",
        "Sungjae Lee",
        "Baeseong Park",
        "Se Jung Kwon",
        "Dongsoo Lee"
      ],
      "categories": [
        "cs.LG",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T14:59:50Z",
      "updated": "2026-02-12T14:59:50Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12029v1",
      "abs_url": "http://arxiv.org/abs/2602.12029v1",
      "summary": "PrefillShare通过共享预填充模块，显著降低多LLM系统延迟，提升吞吐量。",
      "key_contributions": [
        "提出 PrefillShare 算法，共享预填充阶段",
        "设计了基于 vLLM 的异构模型路由机制",
        "实验证明在多模型agent任务中性能提升"
      ],
      "methodology": "将模型分解为预填充和解码模块，冻结预填充模块，仅微调解码模块，实现预填充共享。",
      "tags": [
        "LLM Serving",
        "Multi-Agent Systems",
        "KV Cache",
        "Disaggregated Serving"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文关注多智能体系统中的LLM优化问题，与智能体领域高度相关。",
      "analyzed_at": "2026-02-13T06:59:57.991057",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12021v1",
      "title": "Improved state mixing in higher-order and block diagonal linear recurrent networks",
      "abstract": "Linear recurrent networks (LRNNs) and linear state space models (SSMs) promise computational and memory efficiency on long-sequence modeling tasks, yet their diagonal state transitions limit expressivity. Dense and nonlinear architectures (e.g., LSTMs) on the other hand are provably more expressive, but computationally costly. Here, we explore how expressivity in LRNNs can be increased via richer state mixing across time and channels while maintaining competitive efficiency. Specifically, we introduce two structured LRNN architectures: (i) Higher-order Linear Recurrent Units (H-LRU), which generalize first-order recurrence to higher order, mixing multiple past states, and (ii) Block-Diagonal LRUs (BD-LRU), which enable dense intra-block channel mixing. Per-channel (H-LRU) or per-row (BD-LRU) L1-normalization of selective gates stabilizes training and allows for scaling window/block sizes. A parallel-scan implementation of the proposed architectures keeps the throughput competitive with diagonal LRNNs for moderate orders (H-LRU) and block sizes (BD-LRU). In synthetic sequence modeling tasks, the performance of BD-LRU matches or exceeds those of linear SSMs (Mamba), low-rank LRNNs (DeltaNet) and LSTM baselines, while H-LRU is found to be the most parameter-efficient in compression task. In both synthetic sequence modeling and language modeling, our results indicate that the structure of state mixing rather than width alone shapes expressivity of LRNNs, offering a practical route to closing the efficiency-expressivity gap in linear sequence models.",
      "authors": [
        "Igor Dubinin",
        "Antonio Orvieto",
        "Felix Effenberger"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T14:51:59Z",
      "updated": "2026-02-12T14:51:59Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12021v1",
      "abs_url": "http://arxiv.org/abs/2602.12021v1",
      "summary": "该论文提出了两种结构化的线性循环网络架构，通过更丰富的状态混合提高表达能力并保持效率。",
      "key_contributions": [
        "提出了更高阶线性循环单元（H-LRU），混合多个过去状态。",
        "提出了块对角线性循环单元（BD-LRU），实现块内密集通道混合。",
        "展示了结构化状态混合在提高线性序列模型表达能力方面的作用。"
      ],
      "methodology": "提出了两种新型LRNN架构，并在合成序列建模和语言建模任务中进行了实验，与现有模型进行性能比较。",
      "tags": [
        "线性循环网络",
        "状态空间模型",
        "序列建模",
        "高效计算"
      ],
      "assigned_category": "memory",
      "relevance_score": 7,
      "relevance_reason": "改进的LRNN架构可能有助于提高长序列建模能力，对LLM记忆相关研究有参考价值。",
      "analyzed_at": "2026-02-13T06:59:59.896232",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12013v1",
      "title": "InjectRBP: Steering Large Language Model Reasoning Behavior via Pattern Injection",
      "abstract": "Reasoning can significantly enhance the performance of Large Language Models. While recent studies have exploited behavior-related prompts adjustment to enhance reasoning, these designs remain largely intuitive and lack a systematic analysis of the underlying behavioral patterns. Motivated by this, we investigate how models' reasoning behaviors shape reasoning from the perspective of behavioral patterns. We observe that models exhibit adaptive distributions of reasoning behaviors when responding to specific types of questions, and that structurally injecting these patterns can substantially influence the quality of the models' reasoning processes and outcomes. Building on these findings, we propose two optimization methods that require no parameter updates: InjectCorrect and InjectRLOpt. InjectCorrect guides the model by imitating behavioral patterns derived from its own past correct answers. InjectRLOpt learns a value function from historical behavior-pattern data and, via our proposed Reliability-Aware Softmax Policy, generates behavioral injectant during inference to steer the reasoning process. Our experiments demonstrate that both methods can improve model performance across various reasoning tasks without requiring any modifications to model parameters, achieving gains of up to 5.34% and 8.67%, respectively.",
      "authors": [
        "Xiuping Wu",
        "Zhao Yu",
        "Yuxin Cheng",
        "Ngai Wong",
        "Liangjun Ke",
        "Tapas Mishra",
        "Konstantinos V. Katsikopoulos"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T14:44:40Z",
      "updated": "2026-02-12T14:44:40Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12013v1",
      "abs_url": "http://arxiv.org/abs/2602.12013v1",
      "summary": "通过注入行为模式引导大语言模型的推理过程，无需更新模型参数即可提升推理性能。",
      "key_contributions": [
        "观察到模型推理行为的自适应分布",
        "提出 InjectCorrect 和 InjectRLOpt 两种无参数优化的推理引导方法",
        "实验证明了方法的有效性"
      ],
      "methodology": "通过模仿历史正确答案的行为模式或学习行为模式的价值函数，生成行为注入剂来引导推理。",
      "tags": [
        "推理",
        "行为模式",
        "提示调整",
        "无参数优化"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文直接研究了如何通过特定方法提升LLM的推理能力，属于核心相关。",
      "analyzed_at": "2026-02-13T07:00:01.551933",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12009v1",
      "title": "On the Sensitivity of Firing Rate-Based Federated Spiking Neural Networks to Differential Privacy",
      "abstract": "Federated Neuromorphic Learning (FNL) enables energy-efficient and privacy-preserving learning on devices without centralizing data. However, real-world deployments require additional privacy mechanisms that can significantly alter training signals. This paper analyzes how Differential Privacy (DP) mechanisms, specifically gradient clipping and noise injection, perturb firing-rate statistics in Spiking Neural Networks (SNNs) and how these perturbations are propagated to rate-based FNL coordination. On a speech recognition task under non-IID settings, ablations across privacy budgets and clipping bounds reveal systematic rate shifts, attenuated aggregation, and ranking instability during client selection. Moreover, we relate these shifts to sparsity and memory indicators. Our findings provide actionable guidance for privacy-preserving FNL, specifically regarding the balance between privacy strength and rate-dependent coordination.",
      "authors": [
        "Luiz Pereira",
        "Mirko Perkusich",
        "Dalton Valadares",
        "Kyller Gorgônio"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T14:40:25Z",
      "updated": "2026-02-12T14:40:25Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12009v1",
      "abs_url": "http://arxiv.org/abs/2602.12009v1",
      "summary": "研究差分隐私对基于脉冲神经网络的联邦学习中神经元放电率的影响。",
      "key_contributions": [
        "分析了差分隐私机制对SNN放电率的影响。",
        "揭示了隐私预算和梯度裁剪对联邦学习的影响。",
        "提供了隐私保护的联邦学习的实践指导。"
      ],
      "methodology": "通过在语音识别任务上进行消融实验，分析隐私机制对放电率统计的影响。",
      "tags": [
        "联邦学习",
        "差分隐私",
        "脉冲神经网络",
        "隐私保护"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 6,
      "relevance_reason": "联邦学习中的隐私保护可以帮助优化agent性能。",
      "analyzed_at": "2026-02-13T07:00:03.177217",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.12002v1",
      "title": "Can Local Vision-Language Models improve Activity Recognition over Vision Transformers? -- Case Study on Newborn Resuscitation",
      "abstract": "Accurate documentation of newborn resuscitation is essential for quality improvement and adherence to clinical guidelines, yet remains underutilized in practice. Previous work using 3D-CNNs and Vision Transformers (ViT) has shown promising results in detecting key activities from newborn resuscitation videos, but also highlighted the challenges in recognizing such fine-grained activities. This work investigates the potential of generative AI (GenAI) methods to improve activity recognition from such videos. Specifically, we explore the use of local vision-language models (VLMs), combined with large language models (LLMs), and compare them to a supervised TimeSFormer baseline. Using a simulated dataset comprising 13.26 hours of newborn resuscitation videos, we evaluate several zero-shot VLM-based strategies and fine-tuned VLMs with classification heads, including Low-Rank Adaptation (LoRA). Our results suggest that small (local) VLMs struggle with hallucinations, but when fine-tuned with LoRA, the results reach F1 score at 0.91, surpassing the TimeSformer results of 0.70.",
      "authors": [
        "Enrico Guerriero",
        "Kjersti Engan",
        "Øyvind Meinich-Bache"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-12T14:31:10Z",
      "updated": "2026-02-12T14:31:10Z",
      "pdf_url": "https://arxiv.org/pdf/2602.12002v1",
      "abs_url": "http://arxiv.org/abs/2602.12002v1",
      "summary": "论文研究局部视觉-语言模型在新生儿复苏活动识别上的应用，并超越了ViT。",
      "key_contributions": [
        "探索局部VLM在新生儿复苏活动识别中的潜力",
        "使用LoRA微调VLM，显著提升了活动识别的F1分数",
        "对比VLM与TimeSformer在新生儿复苏活动识别上的性能"
      ],
      "methodology": "使用包含13.26小时新生儿复苏视频的模拟数据集，评估zero-shot VLM和LoRA微调的VLM在活动识别中的表现。",
      "tags": [
        "VLM",
        "LLM",
        "Activity Recognition",
        "Newborn Resuscitation",
        "LoRA"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心是视觉-语言模型在特定任务上的应用，属于多模态学习范畴。",
      "analyzed_at": "2026-02-13T07:00:04.976588",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11995v1",
      "title": "Momentum LMS Theory beyond Stationarity: Stability, Tracking, and Regret",
      "abstract": "In large-scale data processing scenarios, data often arrive in sequential streams generated by complex systems that exhibit drifting distributions and time-varying system parameters. This nonstationarity challenges theoretical analysis, as it violates classical assumptions of i.i.d. (independent and identically distributed) samples, necessitating algorithms capable of real-time updates without expensive retraining. An effective approach should process each sample in a single pass, while maintaining computational and memory complexities independent of the data stream length. Motivated by these challenges, this paper investigates the Momentum Least Mean Squares (MLMS) algorithm as an adaptive identification tool, leveraging its computational simplicity and online processing capabilities. Theoretically, we derive tracking performance and regret bounds for the MLMS in time-varying stochastic linear systems under various practical conditions. Unlike classical LMS, whose stability can be characterized by first-order random vector difference equations, MLMS introduces an additional dynamical state due to momentum, leading to second-order time-varying random vector difference equations whose stability analysis hinges on more complicated products of random matrices, which poses a substantially challenging problem to resolve. Experiments on synthetic and real-world data streams demonstrate that MLMS achieves rapid adaptation and robust tracking, in agreement with our theoretical results especially in nonstationary settings, highlighting its promise for modern streaming and online learning applications.",
      "authors": [
        "Yifei Jin",
        "Xin Zheng",
        "Lei Guo"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T14:24:42Z",
      "updated": "2026-02-12T14:24:42Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11995v1",
      "abs_url": "http://arxiv.org/abs/2602.11995v1",
      "summary": "论文分析了非平稳环境下动量最小均方算法(MLMS)的稳定性和跟踪性能，并给出了理论界限。",
      "key_contributions": [
        "推导了时变随机线性系统下MLMS算法的跟踪性能和遗憾界限",
        "提出了针对MLMS算法稳定性的二阶时变随机向量差分方程",
        "通过实验验证了MLMS在非平稳环境下的快速适应性和鲁棒跟踪能力"
      ],
      "methodology": "通过建立MLMS算法的二阶随机向量差分方程，并进行理论分析和实验验证，研究其在非平稳环境下的性能。",
      "tags": [
        "自适应滤波",
        "动量最小均方",
        "非平稳信号处理",
        "在线学习",
        "随机矩阵"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 5,
      "relevance_reason": "该论文讨论在线学习场景下的算法优化，与Agent Tuning领域有一定相关性。",
      "analyzed_at": "2026-02-13T07:00:06.907447",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11988v1",
      "title": "Evaluating AGENTS.md: Are Repository-Level Context Files Helpful for Coding Agents?",
      "abstract": "A widespread practice in software development is to tailor coding agents to repositories using context files, such as AGENTS.md, by either manually or automatically generating them. Although this practice is strongly encouraged by agent developers, there is currently no rigorous investigation into whether such context files are actually effective for real-world tasks. In this work, we study this question and evaluate coding agents' task completion performance in two complementary settings: established SWE-bench tasks from popular repositories, with LLM-generated context files following agent-developer recommendations, and a novel collection of issues from repositories containing developer-committed context files.   Across multiple coding agents and LLMs, we find that context files tend to reduce task success rates compared to providing no repository context, while also increasing inference cost by over 20%. Behaviorally, both LLM-generated and developer-provided context files encourage broader exploration (e.g., more thorough testing and file traversal), and coding agents tend to respect their instructions. Ultimately, we conclude that unnecessary requirements from context files make tasks harder, and human-written context files should describe only minimal requirements.",
      "authors": [
        "Thibaud Gloaguen",
        "Niels Mündler",
        "Mark Müller",
        "Veselin Raychev",
        "Martin Vechev"
      ],
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "published": "2026-02-12T14:15:22Z",
      "updated": "2026-02-12T14:15:22Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11988v1",
      "abs_url": "http://arxiv.org/abs/2602.11988v1",
      "summary": "研究表明，仓库级上下文文件（如AGENTS.md）反而降低了编码agent的任务成功率并增加推理成本。",
      "key_contributions": [
        "首次系统性评估了仓库级上下文文件对编码agent性能的影响",
        "发现LLM生成和开发者提供的上下文文件均降低了任务成功率",
        "发现上下文文件会增加agent的探索广度，但也增加了推理成本"
      ],
      "methodology": "通过在SWE-bench任务和真实仓库issue上，对比使用和不使用上下文文件的编码agent性能，评估上下文文件的有效性。",
      "tags": [
        "AI Agents",
        "Code Generation",
        "Contextual Information",
        "Evaluation"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "直接评估了上下文文件对编码agent性能的影响，核心相关。",
      "analyzed_at": "2026-02-13T07:00:08.660961",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11980v1",
      "title": "Spatial Chain-of-Thought: Bridging Understanding and Generation Models for Spatial Reasoning Generation",
      "abstract": "While diffusion models have shown exceptional capabilities in aesthetic image synthesis, they often struggle with complex spatial understanding and reasoning. Existing approaches resort to Multimodal Large Language Models (MLLMs) to enhance this capability. However, they either incur high computational costs through joint training or suffer from spatial information loss when relying solely on textual prompts. To alleviate these limitations, we propose a Spatial Chain-of-Thought (SCoT) framework, a plug-and-play approach that effectively bridges the reasoning capabilities of MLLMs with the generative power of diffusion models. Specifically, we first enhance the diffusion model's layout awareness by training it on an interleaved text-coordinate instruction format. We then leverage state-of-the-art MLLMs as planners to generate comprehensive layout plans, transferring their spatial planning capabilities directly to the generation process. Extensive experiments demonstrate that our method achieves state-of-the-art performance on image generation benchmarks and significantly outperforms baselines on complex reasoning tasks, while also showing strong efficacy in image editing scenarios.",
      "authors": [
        "Wei Chen",
        "Yancheng Long",
        "Mingqiao Liu",
        "Haojie Ding",
        "Yankai Yang",
        "Hongyang Wei",
        "Yi-Fan Zhang",
        "Bin Wen",
        "Fan Yang",
        "Tingting Gao",
        "Han Li",
        "Long Chen"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-12T14:12:14Z",
      "updated": "2026-02-12T14:12:14Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11980v1",
      "abs_url": "http://arxiv.org/abs/2602.11980v1",
      "summary": "提出Spatial Chain-of-Thought框架，提升扩散模型在空间理解和推理生成方面的能力。",
      "key_contributions": [
        "提出SCoT框架，弥合MLLM推理和扩散模型生成能力",
        "训练增强布局感知能力的扩散模型",
        "利用MLLM生成布局规划"
      ],
      "methodology": "训练扩散模型以识别文本-坐标指令，利用MLLM生成布局规划，指导图像生成。",
      "tags": [
        "扩散模型",
        "MLLM",
        "空间推理",
        "图像生成",
        "Chain-of-Thought"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注多模态学习中的空间推理和生成，属于该领域关键问题。",
      "analyzed_at": "2026-02-13T07:00:10.557439",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11978v1",
      "title": "Accelerating Robotic Reinforcement Learning with Agent Guidance",
      "abstract": "Reinforcement Learning (RL) offers a powerful paradigm for autonomous robots to master generalist manipulation skills through trial-and-error. However, its real-world application is stifled by severe sample inefficiency. Recent Human-in-the-Loop (HIL) methods accelerate training by using human corrections, yet this approach faces a scalability barrier. Reliance on human supervisors imposes a 1:1 supervision ratio that limits fleet expansion, suffers from operator fatigue over extended sessions, and introduces high variance due to inconsistent human proficiency. We present Agent-guided Policy Search (AGPS), a framework that automates the training pipeline by replacing human supervisors with a multimodal agent. Our key insight is that the agent can be viewed as a semantic world model, injecting intrinsic value priors to structure physical exploration. By using executable tools, the agent provides precise guidance via corrective waypoints and spatial constraints for exploration pruning. We validate our approach on two tasks, ranging from precision insertion to deformable object manipulation. Results demonstrate that AGPS outperforms HIL methods in sample efficiency. This automates the supervision pipeline, unlocking the path to labor-free and scalable robot learning. Project website: https://agps-rl.github.io/agps.",
      "authors": [
        "Haojun Chen",
        "Zili Zou",
        "Chengdong Ma",
        "Yaoxiang Pu",
        "Haotong Zhang",
        "Yuanpei Chen",
        "Yaodong Yang"
      ],
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "published": "2026-02-12T14:09:32Z",
      "updated": "2026-02-12T14:09:32Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11978v1",
      "abs_url": "http://arxiv.org/abs/2602.11978v1",
      "summary": "AGPS通过多模态智能体指导强化学习，提升机器人训练效率，降低对人工干预的依赖。",
      "key_contributions": [
        "提出Agent-guided Policy Search (AGPS)框架",
        "使用多模态智能体代替人工进行机器人学习指导",
        "在精确插入和柔性物体操作任务上验证了AGPS的有效性"
      ],
      "methodology": "AGPS利用智能体作为语义世界模型，提供纠正性路点和空间约束，指导机器人进行探索和策略优化。",
      "tags": [
        "强化学习",
        "机器人",
        "智能体",
        "自主学习",
        "多模态"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "该论文核心在于使用智能体指导机器人强化学习，属于Agent领域的核心问题。",
      "analyzed_at": "2026-02-13T07:00:12.328262",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11964v1",
      "title": "Gaia2: Benchmarking LLM Agents on Dynamic and Asynchronous Environments",
      "abstract": "We introduce Gaia2, a benchmark for evaluating large language model agents in realistic, asynchronous environments. Unlike prior static or synchronous evaluations, Gaia2 introduces scenarios where environments evolve independently of agent actions, requiring agents to operate under temporal constraints, adapt to noisy and dynamic events, resolve ambiguity, and collaborate with other agents. Each scenario is paired with a write-action verifier, enabling fine-grained, action-level evaluation and making Gaia2 directly usable for reinforcement learning from verifiable rewards. Our evaluation of state-of-the-art proprietary and open-source models shows that no model dominates across capabilities: GPT-5 (high) reaches the strongest overall score of 42% pass@1 but fails on time-sensitive tasks, Claude-4 Sonnet trades accuracy and speed for cost, Kimi-K2 leads among open-source models with 21% pass@1. These results highlight fundamental trade-offs between reasoning, efficiency, robustness, and expose challenges in closing the \"sim2real\" gap. Gaia2 is built on a consumer environment with the open-source Agents Research Environments platform and designed to be easy to extend. By releasing Gaia2 alongside the foundational ARE framework, we aim to provide the community with a flexible infrastructure for developing, benchmarking, and training the next generation of practical agent systems.",
      "authors": [
        "Romain Froger",
        "Pierre Andrews",
        "Matteo Bettini",
        "Amar Budhiraja",
        "Ricardo Silveira Cabral",
        "Virginie Do",
        "Emilien Garreau",
        "Jean-Baptiste Gaya",
        "Hugo Laurençon",
        "Maxime Lecanu",
        "Kunal Malkan",
        "Dheeraj Mekala",
        "Pierre Ménard",
        "Gerard Moreno-Torres Bertran",
        "Ulyana Piterbarg",
        "Mikhail Plekhanov",
        "Mathieu Rita",
        "Andrey Rusakov",
        "Vladislav Vorotilov",
        "Mengjue Wang",
        "Ian Yu",
        "Amine Benhalloum",
        "Grégoire Mialon",
        "Thomas Scialom"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T13:58:27Z",
      "updated": "2026-02-12T13:58:27Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11964v1",
      "abs_url": "http://arxiv.org/abs/2602.11964v1",
      "summary": "Gaia2是一个用于评估LLM Agent在动态异步环境中表现的基准测试。",
      "key_contributions": [
        "提出了Gaia2，一个评估LLM Agent在动态异步环境中表现的基准。",
        "Gaia2包含时间约束、噪声、动态事件和多Agent协作等真实场景。",
        "提供了write-action验证器，支持细粒度的动作级别评估和可验证奖励的强化学习。",
        "评估了多个先进的闭源和开源模型，揭示了它们在不同能力上的权衡。",
        "发布了Gaia2和ARE框架，促进下一代实用Agent系统的开发、测试和训练。"
      ],
      "methodology": "构建包含动态异步环境的测试场景，使用write-action验证器评估LLM Agent在不同场景下的表现。",
      "tags": [
        "LLM Agent",
        "Benchmark",
        "Dynamic Environment",
        "Asynchronous Environment"
      ],
      "assigned_category": "agent",
      "relevance_score": 10,
      "relevance_reason": "论文核心内容是关于AI Agent的基准测试和评估。",
      "analyzed_at": "2026-02-13T07:00:14.540324",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11960v1",
      "title": "Benchmarking Vision-Language Models for French PDF-to-Markdown Conversion",
      "abstract": "This report evaluates PDF-to-Markdown conversion using recent Vision-Language Models (VLMs) on challenging French documents. Document parsing is a critical step for Retrieval-Augmented Generation (RAG) pipelines, where transcription and layout errors propagate to downstream retrieval and grounding. Existing benchmarks often emphasize English or Chinese and can over-penalize benign formatting and linearization choices (e.g., line breaks, list segmentation, alternative table renderings) that are largely irrelevant for downstream use.   We introduce a French-focused benchmark of difficult pages selected via model-disagreement sampling from a corpus of 60{,}000 documents, covering handwritten forms, complex layouts, dense tables, and graphics-rich pages. Evaluation is performed with unit-test-style checks that target concrete failure modes (text presence, reading order, and local table constraints) combined with category-specific normalization designed to discount presentation-only variance. Across 15 models, we observe substantially higher robustness for the strongest proprietary models on handwriting and forms, while several open-weights systems remain competitive on standard printed layouts.",
      "authors": [
        "Bruno Rigal",
        "Victor Dupriez",
        "Alexis Mignon",
        "Ronan Le Hy",
        "Nicolas Mery"
      ],
      "categories": [
        "cs.CV",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-12T13:55:43Z",
      "updated": "2026-02-12T13:55:43Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11960v1",
      "abs_url": "http://arxiv.org/abs/2602.11960v1",
      "summary": "该论文评估了VLMs在法语PDF转Markdown上的性能，并提出了新的评估基准。",
      "key_contributions": [
        "提出了法语PDF到Markdown转换的新基准",
        "设计了针对具体错误模式的单元测试式评估方法",
        "评估了15个VLM模型在法语文档上的性能"
      ],
      "methodology": "通过模型差异采样构建法语PDF数据集，使用单元测试评估文本存在、阅读顺序和表格约束，并进行类别特定归一化。",
      "tags": [
        "Vision-Language Models",
        "PDF to Markdown",
        "French",
        "Benchmark",
        "Document Parsing"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文直接研究了视觉语言模型在特定任务上的应用和评估。",
      "analyzed_at": "2026-02-13T07:00:42.015211",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11958v1",
      "title": "RAM-Net: Expressive Linear Attention with Selectively Addressable Memory",
      "abstract": "While linear attention architectures offer efficient inference, compressing unbounded history into a fixed-size memory inherently limits expressivity and causes information loss. To address this limitation, we introduce Random Access Memory Network (RAM-Net), a novel architecture designed to bridge the gap between the representational capacity of full attention and the memory efficiency of linear models. The core of RAM-Net maps inputs to high-dimensional sparse vectors serving as explicit addresses, allowing the model to selectively access a massive memory state. This design enables exponential state size scaling without additional parameters, which significantly mitigates signal interference and enhances retrieval fidelity. Moreover, the inherent sparsity ensures exceptional computational efficiency, as state updates are confined to minimal entries. Extensive experiments demonstrate that RAM-Net consistently surpasses state-of-the-art baselines in fine-grained long-range retrieval tasks and achieves competitive performance in standard language modeling and zero-shot commonsense reasoning benchmarks, validating its superior capability to capture complex dependencies with significantly reduced computational overhead.",
      "authors": [
        "Kaicheng Xiao",
        "Haotian Li",
        "Liran Dong",
        "Guoliang Xing"
      ],
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T13:55:29Z",
      "updated": "2026-02-12T13:55:29Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11958v1",
      "abs_url": "http://arxiv.org/abs/2602.11958v1",
      "summary": "RAM-Net通过可寻址稀疏内存提升线性注意力模型的表达能力和检索精度，同时保持计算效率。",
      "key_contributions": [
        "提出了一种名为RAM-Net的新型架构，弥合了全注意力机制和线性模型的差距",
        "引入了高维稀疏向量作为显式地址，允许模型选择性地访问大规模内存状态",
        "验证了RAM-Net在长程检索任务中的优越性和在语言建模和常识推理任务中的竞争力"
      ],
      "methodology": "利用输入映射到高维稀疏向量作为地址，实现对大规模内存状态的选择性访问，从而提升模型表达能力。",
      "tags": [
        "线性注意力",
        "稀疏内存",
        "长程依赖",
        "检索"
      ],
      "assigned_category": "memory",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于利用可寻址内存提升线性注意力模型的检索能力，与memory领域直接相关。",
      "analyzed_at": "2026-02-13T07:00:44.039605",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11956v1",
      "title": "TAVAE: A VAE with Adaptable Priors Explains Contextual Modulation in the Visual Cortex",
      "abstract": "The brain interprets visual information through learned regularities, a computation formalized as probabilistic inference under a prior. The visual cortex establishes priors for this inference, some delivered through established top-down connections that inform low-level cortices about statistics represented at higher levels in the cortical hierarchy. While evidence shows that adaptation leads to priors reflecting the structure of natural images, it remains unclear whether similar priors can be flexibly acquired when learning a specific task. To investigate this, we built a generative model of V1 optimized for a simple discrimination task and analyzed it together with large-scale recordings from mice performing an analogous task. In line with recent approaches, we assumed that neuronal activity in V1 corresponds to latent posteriors in the generative model, enabling investigation of task-related priors in neuronal responses. To obtain a flexible test bed, we extended the VAE formalism so that a task can be acquired efficiently by reusing previously learned representations. Task-specific priors learned by this Task-Amortized VAE were used to investigate biases in mice and model when presenting stimuli that violated trained task statistics. Mismatch between learned task statistics and incoming sensory evidence produced signatures of uncertainty in stimulus category in the TAVAE posterior, reflecting properties of bimodal response profiles in V1 recordings. The task-optimized generative model accounted for key characteristics of V1 population activity, including within-day updates to population responses. Our results confirm that flexible task-specific contextual priors can be learned on demand by the visual system and deployed as early as the entry level of visual cortex.",
      "authors": [
        "Balázs Meszéna",
        "Keith T. Murray",
        "Julien Corbo",
        "O. Batuhan Erkat",
        "Márton A. Hajnal",
        "Pierre-Olivier Polack",
        "Gergő Orbán"
      ],
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "published": "2026-02-12T13:50:56Z",
      "updated": "2026-02-12T13:50:56Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11956v1",
      "abs_url": "http://arxiv.org/abs/2602.11956v1",
      "summary": "论文提出了任务可适应的VAE模型(TAVAE)，用于解释视觉皮层中的上下文调制现象。",
      "key_contributions": [
        "提出了Task-Amortized VAE (TAVAE)",
        "验证了视觉系统可以按需学习灵活的任务特定上下文先验",
        "将生成模型中的潜变量后验与V1皮层的神经活动联系起来"
      ],
      "methodology": "构建了一个生成模型，优化V1视觉皮层处理简单区分任务的能力，并分析小鼠任务执行时的大规模神经活动记录。",
      "tags": [
        "VAE",
        "视觉皮层",
        "上下文调制",
        "生成模型",
        "神经科学"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 7,
      "relevance_reason": "该论文使用VAE模型来理解视觉信息，涉及视觉和模型的结合。",
      "analyzed_at": "2026-02-13T07:00:45.928469",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11941v1",
      "title": "IncompeBench: A Permissively Licensed, Fine-Grained Benchmark for Music Information Retrieval",
      "abstract": "Multimodal Information Retrieval has made significant progress in recent years, leveraging the increasingly strong multimodal abilities of deep pre-trained models to represent information across modalities. Music Information Retrieval (MIR), in particular, has considerably increased in quality, with neural representations of music even making its way into everyday life products. However, there is a lack of high-quality benchmarks for evaluating music retrieval performance. To address this issue, we introduce \\textbf{IncompeBench}, a carefully annotated benchmark comprising $1,574$ permissively licensed, high-quality music snippets, $500$ diverse queries, and over $125,000$ individual relevance judgements. These annotations were created through the use of a multi-stage pipeline, resulting in high agreement between human annotators and the generated data. The resulting datasets are publicly available at https://huggingface.co/datasets/mixedbread-ai/incompebench-strict and https://huggingface.co/datasets/mixedbread-ai/incompebench-lenient with the prompts available at https://github.com/mixedbread-ai/incompebench-programs.",
      "authors": [
        "Benjamin Clavié",
        "Atoof Shakir",
        "Jonah Turner",
        "Sean Lee",
        "Aamir Shakir",
        "Makoto P. Kato"
      ],
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "published": "2026-02-12T13:37:58Z",
      "updated": "2026-02-12T13:37:58Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11941v1",
      "abs_url": "http://arxiv.org/abs/2602.11941v1",
      "summary": "提出了IncompeBench，一个用于音乐信息检索的高质量、开放许可基准测试集。",
      "key_contributions": [
        "构建了包含1574个音乐片段、500个查询和超过125000个相关性判断的基准测试集",
        "使用了多阶段流程，确保了高质量的人工标注数据",
        "数据集以开放许可发布，便于研究人员使用"
      ],
      "methodology": "采用多阶段标注流程，并进行人工标注，构建高质量的音乐检索数据集，并公开。",
      "tags": [
        "Music Information Retrieval",
        "Benchmark",
        "Multimodal Learning"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 8,
      "relevance_reason": "涉及多模态信息检索中的音乐领域，并构建了相关数据集。",
      "analyzed_at": "2026-02-13T07:00:48.030322",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11939v1",
      "title": "Do Large Language Models Adapt to Language Variation across Socioeconomic Status?",
      "abstract": "Humans adjust their linguistic style to the audience they are addressing. However, the extent to which LLMs adapt to different social contexts is largely unknown. As these models increasingly mediate human-to-human communication, their failure to adapt to diverse styles can perpetuate stereotypes and marginalize communities whose linguistic norms are less closely mirrored by the models, thereby reinforcing social stratification. We study the extent to which LLMs integrate into social media communication across different socioeconomic status (SES) communities. We collect a novel dataset from Reddit and YouTube, stratified by SES. We prompt four LLMs with incomplete text from that corpus and compare the LLM-generated completions to the originals along 94 sociolinguistic metrics, including syntactic, rhetorical, and lexical features. LLMs modulate their style with respect to SES to only a minor extent, often resulting in approximation or caricature, and tend to emulate the style of upper SES more effectively. Our findings (1) show how LLMs risk amplifying linguistic hierarchies and (2) call into question their validity for agent-based social simulation, survey experiments, and any research relying on language style as a social signal.",
      "authors": [
        "Elisa Bassignana",
        "Mike Zhang",
        "Dirk Hovy",
        "Amanda Cercas Curry"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-12T13:36:38Z",
      "updated": "2026-02-12T13:36:38Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11939v1",
      "abs_url": "http://arxiv.org/abs/2602.11939v1",
      "summary": "LLM在不同社会经济地位人群的语言风格适应性方面表现不佳，易放大语言等级。",
      "key_contributions": [
        "揭示LLM在社会经济地位语言适应方面的局限性",
        "构建了按社会经济地位分层的Reddit和YouTube新数据集",
        "提出了94个社会语言学指标评估LLM的风格调整能力"
      ],
      "methodology": "从Reddit和YouTube收集按社会经济地位分层的数据集，使用94个社会语言学指标评估LLM生成文本与原始文本的差异。",
      "tags": [
        "LLM",
        "社会经济地位",
        "语言风格",
        "社会语言学"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "研究LLM在社会环境下的语言适应性，与智能体模拟相关。",
      "analyzed_at": "2026-02-13T07:00:50.042515",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11937v1",
      "title": "Extending Puzzle for Mixture-of-Experts Reasoning Models with Application to GPT-OSS Acceleration",
      "abstract": "Reasoning-focused LLMs improve answer quality by generating longer reasoning traces, but the additional tokens dramatically increase serving cost, motivating inference optimization. We extend and apply Puzzle, a post-training neural architecture search (NAS) framework, to gpt-oss-120B to produce gpt-oss-puzzle-88B, a deployment-optimized derivative. Our approach combines heterogeneous MoE expert pruning, selective replacement of full-context attention with window attention, FP8 KV-cache quantization with calibrated scales, and post-training reinforcement learning to recover accuracy, while maintaining low generation length. In terms of per-token speeds, on an 8XH100 node we achieve 1.63X and 1.22X throughput speedups in long-context and short-context settings, respectively. gpt-oss-puzzle-88B also delivers throughput speedups of 2.82X on a single NVIDIA H100 GPU. However, because token counts can change with reasoning effort and model variants, per-token throughput (tok/s) and latency (ms/token) do not necessarily lead to end-to-end speedups: a 2X throughput gain is erased if traces grow 2X. Conversely, throughput gains can be spent on more reasoning tokens to improve accuracy; we therefore advocate request-level efficiency metrics that normalize throughput by tokens generated and trace an accuracy--speed frontier across reasoning efforts. We show that gpt-oss-puzzle-88B improves over gpt-oss-120B along the entire frontier, delivering up to 1.29X higher request-level efficiency. Across various benchmarks, gpt-oss-puzzle-88B matches or slightly exceeds the parent on suite-average accuracy across reasoning efforts, with retention ranging from 100.8% (high) to 108.2% (low), showing that post-training architecture search can substantially reduce inference costs without sacrificing quality.",
      "authors": [
        "Akhiad Bercovich",
        "Nir Ailon",
        "Vladimir Anisimov",
        "Tomer Asida",
        "Nave Assaf",
        "Mohammad Dabbah",
        "Ido Galil",
        "Amnon Geifman",
        "Yonatan Geifman",
        "Izhak Golan",
        "Roi Koren",
        "Itay Levy",
        "Zach Moshe",
        "Pavlo Molchanov",
        "Najeeb Nabwani",
        "Mostofa Patwari",
        "Omri Puny",
        "Tomer Ronen",
        "Itamar Schen",
        "Elad Segal",
        "Ido Shahaf",
        "Oren Tropp",
        "Ran Zilberstein",
        "Ran El-Yaniv"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T13:36:19Z",
      "updated": "2026-02-12T13:36:19Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11937v1",
      "abs_url": "http://arxiv.org/abs/2602.11937v1",
      "summary": "本文通过神经架构搜索优化GPT-OSS模型推理，降低成本并提升效率。",
      "key_contributions": [
        "提出扩展的Puzzle框架用于MoE模型优化",
        "结合多种优化策略，包括专家剪枝、注意力机制替换等",
        "验证优化后的模型在推理速度和精度上的提升"
      ],
      "methodology": "采用后训练神经架构搜索框架Puzzle，结合模型剪枝、量化、注意力机制替换和强化学习等方法，优化模型推理性能。",
      "tags": [
        "模型优化",
        "推理加速",
        "神经架构搜索",
        "混合专家模型"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于模型优化和加速，直接应用了NAS方法。",
      "analyzed_at": "2026-02-13T07:00:52.043104",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11931v1",
      "title": "AdaptEvolve: Improving Efficiency of Evolutionary AI Agents through Adaptive Model Selection",
      "abstract": "Evolutionary agentic systems intensify the trade-off between computational efficiency and reasoning capability by repeatedly invoking large language models (LLMs) during inference. This setting raises a central question: how can an agent dynamically select an LLM that is sufficiently capable for the current generation step while remaining computationally efficient? While model cascades offer a practical mechanism for balancing this trade-off, existing routing strategies typically rely on static heuristics or external controllers and do not explicitly account for model uncertainty. We introduce AdaptEvolve: Adaptive LLM Selection for Multi-LLM Evolutionary Refinement within an evolutionary sequential refinement framework that leverages intrinsic generation confidence to estimate real-time solvability. Empirical results show that confidence-driven selection yields a favourable Pareto frontier, reducing total inference cost by an average of 37.9% across benchmarks while retaining 97.5% of the upper-bound accuracy of static large-model baselines. Our code is available at https://github.com/raypretam/adaptive_llm_selection.",
      "authors": [
        "Pretam Ray",
        "Pratik Prabhanjan Brahma",
        "Zicheng Liu",
        "Emad Barsoum"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-12T13:26:56Z",
      "updated": "2026-02-12T13:26:56Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11931v1",
      "abs_url": "http://arxiv.org/abs/2602.11931v1",
      "summary": "AdaptEvolve通过置信度驱动的LLM选择，在进化智能体中实现了计算效率和性能的平衡。",
      "key_contributions": [
        "提出了一种自适应LLM选择框架AdaptEvolve",
        "利用生成置信度估计实时可解性",
        "显著降低了推理成本，同时保持了较高的准确率"
      ],
      "methodology": "AdaptEvolve在进化序列细化框架中，通过LLM的生成置信度动态选择合适的LLM进行推理。",
      "tags": [
        "AI Agents",
        "LLM Selection",
        "Evolutionary Algorithms"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 8,
      "relevance_reason": "论文专注于通过模型选择优化进化AI智能体的效率，直接涉及智能体调优。",
      "analyzed_at": "2026-02-13T07:00:53.870869",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11918v1",
      "title": "MEME: Modeling the Evolutionary Modes of Financial Markets",
      "abstract": "LLMs have demonstrated significant potential in quantitative finance by processing vast unstructured data to emulate human-like analytical workflows. However, current LLM-based methods primarily follow either an Asset-Centric paradigm focused on individual stock prediction or a Market-Centric approach for portfolio allocation, often remaining agnostic to the underlying reasoning that drives market movements. In this paper, we propose a Logic-Oriented perspective, modeling the financial market as a dynamic, evolutionary ecosystem of competing investment narratives, termed Modes of Thought. To operationalize this view, we introduce MEME (Modeling the Evolutionary Modes of Financial Markets), designed to reconstruct market dynamics through the lens of evolving logics. MEME employs a multi-agent extraction module to transform noisy data into high-fidelity Investment Arguments and utilizes Gaussian Mixture Modeling to uncover latent consensus within a semantic space. To model semantic drift among different market conditions, we also implement a temporal evaluation and alignment mechanism to track the lifecycle and historical profitability of these modes. By prioritizing enduring market wisdom over transient anomalies, MEME ensures that portfolio construction is guided by robust reasoning. Extensive experiments on three heterogeneous Chinese stock pools from 2023 to 2025 demonstrate that MEME consistently outperforms seven SOTA baselines. Further ablation studies, sensitivity analysis, lifecycle case study and cost analysis validate MEME's capacity to identify and adapt to the evolving consensus of financial markets. Our implementation can be found at https://github.com/gta0804/MEME.",
      "authors": [
        "Taian Guo",
        "Haiyang Shen",
        "Junyu Luo",
        "Zhongshi Xing",
        "Hanchun Lian",
        "Jinsheng Huang",
        "Binqi Chen",
        "Luchen Liu",
        "Yun Ma",
        "Ming Zhang"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T13:16:05Z",
      "updated": "2026-02-12T13:16:05Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11918v1",
      "abs_url": "http://arxiv.org/abs/2602.11918v1",
      "summary": "MEME模型将金融市场视为演化生态，通过投资叙事建模市场动态，优于现有方法。",
      "key_contributions": [
        "提出了Logic-Oriented的金融市场建模视角",
        "构建了MEME模型，通过多Agent提取和高斯混合模型重建市场动态",
        "设计了时间评估和对齐机制，跟踪投资叙事的生命周期和盈利能力"
      ],
      "methodology": "采用多Agent提取投资论点，使用高斯混合模型发现潜在共识，并通过时间评估对齐跟踪叙事演变。",
      "tags": [
        "金融市场",
        "LLM",
        "投资叙事"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "该论文侧重于利用LLM进行逻辑推理，以理解金融市场动态。",
      "analyzed_at": "2026-02-13T07:00:55.470049",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11917v1",
      "title": "AlphaPROBE: Alpha Mining via Principled Retrieval and On-graph biased evolution",
      "abstract": "Extracting signals through alpha factor mining is a fundamental challenge in quantitative finance. Existing automated methods primarily follow two paradigms: Decoupled Factor Generation, which treats factor discovery as isolated events, and Iterative Factor Evolution, which focuses on local parent-child refinements. However, both paradigms lack a global structural view, often treating factor pools as unstructured collections or fragmented chains, which leads to redundant search and limited diversity. To address these limitations, we introduce AlphaPROBE (Alpha Mining via Principled Retrieval and On-graph Biased Evolution), a framework that reframes alpha mining as the strategic navigation of a Directed Acyclic Graph (DAG). By modeling factors as nodes and evolutionary links as edges, AlphaPROBE treats the factor pool as a dynamic, interconnected ecosystem. The framework consists of two core components: a Bayesian Factor Retriever that identifies high-potential seeds by balancing exploitation and exploration through a posterior probability model, and a DAG-aware Factor Generator that leverages the full ancestral trace of factors to produce context-aware, nonredundant optimizations. Extensive experiments on three major Chinese stock market datasets against 8 competitive baselines demonstrate that AlphaPROBE significantly gains enhanced performance in predictive accuracy, return stability and training efficiency. Our results confirm that leveraging global evolutionary topology is essential for efficient and robust automated alpha discovery. We have open-sourced our implementation at https://github.com/gta0804/AlphaPROBE.",
      "authors": [
        "Taian Guo",
        "Haiyang Shen",
        "Junyu Luo",
        "Binqi Chen",
        "Hongjun Ding",
        "Jinsheng Huang",
        "Luchen Liu",
        "Yun Ma",
        "Ming Zhang"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T13:14:58Z",
      "updated": "2026-02-12T13:14:58Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11917v1",
      "abs_url": "http://arxiv.org/abs/2602.11917v1",
      "summary": "AlphaPROBE通过图结构建模，提升alpha因子挖掘的效率、稳定性和准确性。",
      "key_contributions": [
        "提出AlphaPROBE框架，将alpha挖掘视为DAG导航问题",
        "设计贝叶斯因子检索器，平衡探索与利用",
        "开发DAG感知的因子生成器，避免冗余优化"
      ],
      "methodology": "构建因子演化DAG图，利用贝叶斯检索器寻找种子因子，并结合因子祖先信息进行DAG感知的生成。",
      "tags": [
        "alpha factor mining",
        "quantitative finance",
        "Directed Acyclic Graph"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 6,
      "relevance_reason": "该论文涉及因子选择和优化，与Agent Tuning有一定的相似性。",
      "analyzed_at": "2026-02-13T07:00:57.509006",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11903v1",
      "title": "Learning Perceptual Representations for Gaming NR-VQA with Multi-Task FR Signals",
      "abstract": "No-reference video quality assessment (NR-VQA) for gaming videos is challenging due to limited human-rated datasets and unique content characteristics including fast motion, stylized graphics, and compression artifacts. We present MTL-VQA, a multi-task learning framework that uses full-reference metrics as supervisory signals to learn perceptually meaningful features without human labels for pretraining. By jointly optimizing multiple full-reference (FR) objectives with adaptive task weighting, our approach learns shared representations that transfer effectively to NR-VQA. Experiments on gaming video datasets show MTL-VQA achieves performance competitive with state-of-the-art NR-VQA methods across both MOS-supervised and label-efficient/self-supervised settings.",
      "authors": [
        "Yu-Chih Chen",
        "Michael Wang",
        "Chieh-Dun Wen",
        "Kai-Siang Ma",
        "Avinab Saha",
        "Li-Heng Chen",
        "Alan Bovik"
      ],
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "eess.IV",
      "published": "2026-02-12T12:56:58Z",
      "updated": "2026-02-12T12:56:58Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11903v1",
      "abs_url": "http://arxiv.org/abs/2602.11903v1",
      "summary": "提出一种多任务学习框架，利用FR指标作为监督信号，提升游戏视频的无参考视频质量评估。",
      "key_contributions": [
        "提出基于FR指标的多任务学习框架MTL-VQA",
        "自适应任务权重分配策略",
        "在游戏视频NR-VQA任务上取得SOTA结果"
      ],
      "methodology": "利用FR指标进行多任务学习，预训练网络以学习感知相关的特征，再迁移到NR-VQA任务中。",
      "tags": [
        "NR-VQA",
        "视频质量评估",
        "多任务学习",
        "游戏视频",
        "Full-Reference Metrics"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 7,
      "relevance_reason": "涉及视觉质量评估，与多模态信息的处理相关。",
      "analyzed_at": "2026-02-13T07:00:59.097733",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11902v1",
      "title": "Mitigating Mismatch within Reference-based Preference Optimization",
      "abstract": "Direct Preference Optimization (DPO) has become the de facto standard for offline preference alignment of large language models, but its reliance on a reference policy introduces a critical tension. DPO weighs each update relative to a reference, which stabilizes the training by regularizing the updates within a trusted region. This reliance becomes problematic for pessimistic pairs, where the reference model prefers the rejected response. For these pairs, DPO prematurely attenuates the gradient as soon as the policy margin ($Δ_θ$) merely beats the reference margin ($Δ_{\\mathrm{ref}}$) even if the policy is still wrong ($Δ_θ<0$). We name this failure premature satisfaction, which is a concrete form of the training-inference mismatch. Reference-free objectives remove this mismatch by optimizing the absolute margin, but at the cost of discarding the stabilizing signal of the reference. We mitigate this tension with Hybrid-DPO (HyPO), a drop-in modification to DPO that applies reference conditionally: HyPO behaves exactly like DPO when the reference is optimistic or neutral, and it treats the reference as neutral when it is pessimistic by replacing $Δ_θ-Δ_{\\mathrm{ref}}$ with $Δ_θ-\\max\\{0,Δ_{\\mathrm{ref}}\\}$. This one-line change strictly strengthens per-example learning signals on pessimistic pairs while preserving DPO's objective form and computational cost. By conditionally debiasing the pessimistic reference signal, HyPO mitigates premature satisfaction; empirically, across preference alignment, HyPO improves inference-aligned metrics and achieves higher pairwise win rates. Our results provide evidence that direct preference alignment could be enhanced by conditionally debiasing the reference signal, rather than discarding it.",
      "authors": [
        "Suqin Yuan",
        "Xingrui Yu",
        "Jiyang Zheng",
        "Lei Feng",
        "Dadong Wang",
        "Ivor Tsang",
        "Tongliang Liu"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T12:55:51Z",
      "updated": "2026-02-12T12:55:51Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11902v1",
      "abs_url": "http://arxiv.org/abs/2602.11902v1",
      "summary": "针对DPO在悲观样本上的“过早满足”问题，提出了Hybrid-DPO（HyPO），通过有条件地去偏参考信号来提升对齐效果。",
      "key_contributions": [
        "指出了DPO在悲观样本上的“过早满足”问题，并将其定义为一种训练-推理不匹配。",
        "提出了Hybrid-DPO（HyPO），一种DPO的改进版本，能够有条件地利用参考信号，缓解“过早满足”问题。",
        "实验证明HyPO能够提升推理对齐指标和pairwise胜率，表明有条件地去偏参考信号可以增强直接偏好对齐的效果。"
      ],
      "methodology": "提出了HyPO，修改DPO的目标函数，对悲观样本将参考模型输出视为中性，以增强学习信号，同时保留DPO的目标形式和计算成本。",
      "tags": [
        "DPO",
        "Preference Optimization",
        "Reference Policy",
        "Training-Inference Mismatch",
        "Hybrid-DPO"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 9,
      "relevance_reason": "直接研究了DPO偏好对齐的训练问题，并提出了改进算法HyPO，属于agent tuning的核心内容。",
      "analyzed_at": "2026-02-13T07:01:02.096471",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11897v1",
      "title": "Agentic AI for Cybersecurity: A Meta-Cognitive Architecture for Governable Autonomy",
      "abstract": "Contemporary AI-driven cybersecurity systems are predominantly architected as model-centric detection and automation pipelines optimized for task-level performance metrics such as accuracy and response latency. While effective for bounded classification tasks, these architectures struggle to support accountable decision-making under adversarial uncertainty, where actions must be justified, governed, and aligned with organizational and regulatory constraints. This paper argues that cybersecurity orchestration should be reconceptualized as an agentic, multi-agent cognitive system, rather than a linear sequence of detection and response components. We introduce a conceptual architectural framework in which heterogeneous AI agents responsible for detection, hypothesis formation, contextual interpretation, explanation, and governance are coordinated through an explicit meta-cognitive judgement function. This function governs decision readiness and dynamically calibrates system autonomy when evidence is incomplete, conflicting, or operationally risky. By synthesizing distributed cognition theory, multi-agent systems research, and responsible AI governance frameworks, we demonstrate that modern security operations already function as distributed cognitive systems, albeit without an explicit organizing principle. Our contribution is to make this cognitive structure architecturally explicit and governable by embedding meta-cognitive judgement as a first-class system function. We discuss implications for security operations centers, accountable autonomy, and the design of next-generation AI-enabled cyber defence architectures. The proposed framework shifts the focus of AI in cybersecurity from optimizing isolated predictions to governing autonomy under uncertainty.",
      "authors": [
        "Andrei Kojukhov",
        "Arkady Bovshover"
      ],
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "published": "2026-02-12T12:52:49Z",
      "updated": "2026-02-12T12:52:49Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11897v1",
      "abs_url": "http://arxiv.org/abs/2602.11897v1",
      "summary": "提出一种基于元认知判断的Agentic AI网络安全架构，提升网络安全决策的可解释性和可控性。",
      "key_contributions": [
        "提出Agentic AI网络安全架构",
        "引入元认知判断函数治理系统自主性",
        "结合分布式认知理论、多智能体系统和责任AI框架"
      ],
      "methodology": "通过结合理论框架（分布式认知理论、多智能体系统、责任AI框架）和概念架构设计，阐述了元认知智能体架构的优势。",
      "tags": [
        "网络安全",
        "AI Agent",
        "元认知",
        "多智能体系统",
        "可解释性"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "核心是agent架构，解决在安全场景下的自主性治理问题。",
      "analyzed_at": "2026-02-13T07:01:03.854553",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11886v1",
      "title": "LLM-based Triplet Extraction from Financial Reports",
      "abstract": "Corporate financial reports are a valuable source of structured knowledge for Knowledge Graph construction, but the lack of annotated ground truth in this domain makes evaluation difficult. We present a semi-automated pipeline for Subject-Predicate-Object triplet extraction that uses ontology-driven proxy metrics, specifically Ontology Conformance and Faithfulness, instead of ground-truth-based evaluation. We compare a static, manually engineered ontology against a fully automated, document-specific ontology induction approach across different LLMs and two corporate annual reports. The automatically induced ontology achieves 100% schema conformance in all configurations, eliminating the ontology drift observed with the manual approach. We also propose a hybrid verification strategy that combines regex matching with an LLM-as-a-judge check, reducing apparent subject hallucination rates from 65.2% to 1.6% by filtering false positives caused by coreference resolution. Finally, we identify a systematic asymmetry between subject and object hallucinations, which we attribute to passive constructions and omitted agents in financial prose.",
      "authors": [
        "Dante Wesslund",
        "Ville Stenström",
        "Pontus Linde",
        "Alexander Holmberg"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-12T12:36:10Z",
      "updated": "2026-02-12T12:36:10Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11886v1",
      "abs_url": "http://arxiv.org/abs/2602.11886v1",
      "summary": "提出一种基于LLM的财务报告三元组抽取流水线，并使用本体驱动代理指标进行评估。",
      "key_contributions": [
        "提出基于LLM的财务报告三元组抽取流水线",
        "使用本体一致性和忠实度作为评估指标",
        "发现主语和宾语幻觉的不对称性"
      ],
      "methodology": "使用LLM进行三元组抽取，对比手动和自动构建的本体，并结合正则匹配和LLM判断进行验证。",
      "tags": [
        "LLM",
        "三元组抽取",
        "财务报告",
        "知识图谱",
        "本体"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 7,
      "relevance_reason": "论文使用LLM进行结构化知识抽取，涉及到推理和知识表示。",
      "analyzed_at": "2026-02-13T07:01:05.943729",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11877v1",
      "title": "Towards Fair and Comprehensive Evaluation of Routers in Collaborative LLM Systems",
      "abstract": "Large language models (LLMs) have achieved success, but cost and privacy constraints necessitate deploying smaller models locally while offloading complex queries to cloud-based models. Existing router evaluations are unsystematic, overlooking scenario-specific requirements and out-of-distribution robustness. We propose RouterXBench, a principled evaluation framework with three dimensions: router ability, scenario alignment, and cross-domain robustness. Unlike prior work that relies on output probabilities or external embeddings, we utilize internal hidden states that capture model uncertainty before answer generation. We introduce ProbeDirichlet, a lightweight router that aggregates cross-layer hidden states via learnable Dirichlet distributions with probabilistic training. Trained on multi-domain data, it generalizes robustly across in-domain and out-of-distribution scenarios. Our results show ProbeDirichlet achieves 16.68% and 18.86% relative improvements over the best baselines in router ability and high-accuracy scenarios, with consistent performance across model families, model scales, heterogeneous tasks, and agentic workflows.",
      "authors": [
        "Wanxing Wu",
        "He Zhu",
        "Yixia Li",
        "Lei Yang",
        "Jiehui Zhao",
        "Hongru Wang",
        "Jian Yang",
        "Benyou Wang",
        "Bingyi Jing",
        "Guanhua Chen"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-12T12:28:27Z",
      "updated": "2026-02-12T12:28:27Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11877v1",
      "abs_url": "http://arxiv.org/abs/2602.11877v1",
      "summary": "提出RouterXBench评估框架和ProbeDirichlet路由方法，提升LLM协同系统中路由器的性能和鲁棒性。",
      "key_contributions": [
        "提出RouterXBench，一个多维度的路由器评估框架",
        "提出ProbeDirichlet，一种基于内部隐藏状态的轻量级路由器",
        "实验证明ProbeDirichlet在多种场景下优于现有方法"
      ],
      "methodology": "利用内部隐藏状态捕捉模型不确定性，通过可学习的Dirichlet分布聚合跨层隐藏状态，并进行概率训练。",
      "tags": [
        "LLM",
        "Router",
        "Evaluation",
        "Multi-domain",
        "Hidden States"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "该论文关注LLM系统中路由器的评估与优化，属于Agent领域的重要组成部分。",
      "analyzed_at": "2026-02-13T07:01:08.593574",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11865v1",
      "title": "Intelligent AI Delegation",
      "abstract": "AI agents are able to tackle increasingly complex tasks. To achieve more ambitious goals, AI agents need to be able to meaningfully decompose problems into manageable sub-components, and safely delegate their completion across to other AI agents and humans alike. Yet, existing task decomposition and delegation methods rely on simple heuristics, and are not able to dynamically adapt to environmental changes and robustly handle unexpected failures. Here we propose an adaptive framework for intelligent AI delegation - a sequence of decisions involving task allocation, that also incorporates transfer of authority, responsibility, accountability, clear specifications regarding roles and boundaries, clarity of intent, and mechanisms for establishing trust between the two (or more) parties. The proposed framework is applicable to both human and AI delegators and delegatees in complex delegation networks, aiming to inform the development of protocols in the emerging agentic web.",
      "authors": [
        "Nenad Tomašev",
        "Matija Franklin",
        "Simon Osindero"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T12:11:42Z",
      "updated": "2026-02-12T12:11:42Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11865v1",
      "abs_url": "http://arxiv.org/abs/2602.11865v1",
      "summary": "提出了一种智能AI委托框架，用于复杂任务分解、分配和授权，以适应环境变化并处理失败。",
      "key_contributions": [
        "提出了一种自适应的AI委托框架",
        "强调了任务分配中的授权、责任和信任机制",
        "适用于人机协作的委托网络"
      ],
      "methodology": "提出一个任务分解和分配决策的框架，该框架包含授权、责任、信任等机制，并能动态适应环境。",
      "tags": [
        "AI Agents",
        "Task Delegation",
        "Human-AI Collaboration"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注AI Agent的任务分解、分配和协作，直接解决Agent领域关键问题。",
      "analyzed_at": "2026-02-13T07:01:10.166657",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11860v1",
      "title": "Talk2DM: Enabling Natural Language Querying and Commonsense Reasoning for Vehicle-Road-Cloud Integrated Dynamic Maps with Large Language Models",
      "abstract": "Dynamic maps (DM) serve as the fundamental information infrastructure for vehicle-road-cloud (VRC) cooperative autonomous driving in China and Japan. By providing comprehensive traffic scene representations, DM overcome the limitations of standalone autonomous driving systems (ADS), such as physical occlusions. Although DM-enhanced ADS have been successfully deployed in real-world applications in Japan, existing DM systems still lack a natural-language-supported (NLS) human interface, which could substantially enhance human-DM interaction. To address this gap, this paper introduces VRCsim, a VRC cooperative perception (CP) simulation framework designed to generate streaming VRC-CP data. Based on VRCsim, we construct a question-answering data set, VRC-QA, focused on spatial querying and reasoning in mixed-traffic scenes. Building upon VRCsim and VRC-QA, we further propose Talk2DM, a plug-and-play module that extends VRC-DM systems with NLS querying and commonsense reasoning capabilities. Talk2DM is built upon a novel chain-of-prompt (CoP) mechanism that progressively integrates human-defined rules with the commonsense knowledge of large language models (LLMs). Experiments on VRC-QA show that Talk2DM can seamlessly switch across different LLMs while maintaining high NLS query accuracy, demonstrating strong generalization capability. Although larger models tend to achieve higher accuracy, they incur significant efficiency degradation. Our results reveal that Talk2DM, powered by Qwen3:8B, Gemma3:27B, and GPT-oss models, achieves over 93\\% NLS query accuracy with an average response time of only 2-5 seconds, indicating strong practical potential.",
      "authors": [
        "Lu Tao",
        "Jinxuan Luo",
        "Yousuke Watanabe",
        "Zhengshu Zhou",
        "Yuhuan Lu",
        "Shen Ying",
        "Pan Zhang",
        "Fei Zhao",
        "Hiroaki Takada"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T12:06:12Z",
      "updated": "2026-02-12T12:06:12Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11860v1",
      "abs_url": "http://arxiv.org/abs/2602.11860v1",
      "summary": "提出Talk2DM，一个基于大语言模型的车辆-道路-云集成动态地图自然语言查询和常识推理模块。",
      "key_contributions": [
        "构建了VRC合作感知仿真框架VRCsim。",
        "创建了VRC-QA问答数据集，专注于混合交通场景的空间查询和推理。",
        "提出了Talk2DM模块，通过CoP机制增强DM系统的自然语言交互能力。"
      ],
      "methodology": "使用VRCsim生成数据，构建VRC-QA数据集，利用CoP机制融合人工规则和LLM常识构建Talk2DM。",
      "tags": [
        "Large Language Models",
        "Autonomous Driving",
        "Natural Language Processing",
        "Dynamic Maps"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 7,
      "relevance_reason": "涉及LLM的推理能力，并应用到自动驾驶领域。",
      "analyzed_at": "2026-02-13T07:01:12.021166",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11858v1",
      "title": "Zooming without Zooming: Region-to-Image Distillation for Fine-Grained Multimodal Perception",
      "abstract": "Multimodal Large Language Models (MLLMs) excel at broad visual understanding but still struggle with fine-grained perception, where decisive evidence is small and easily overwhelmed by global context. Recent \"Thinking-with-Images\" methods alleviate this by iteratively zooming in and out regions of interest during inference, but incur high latency due to repeated tool calls and visual re-encoding. To address this, we propose Region-to-Image Distillation, which transforms zooming from an inference-time tool into a training-time primitive, thereby internalizing the benefits of agentic zooming into a single forward pass of an MLLM. In particular, we first zoom in to micro-cropped regions to let strong teacher models generate high-quality VQA data, and then distill this region-grounded supervision back to the full image. After training on such data, the smaller student model improves \"single-glance\" fine-grained perception without tool use. To rigorously evaluate this capability, we further present ZoomBench, a hybrid-annotated benchmark of 845 VQA data spanning six fine-grained perceptual dimensions, together with a dual-view protocol that quantifies the global--regional \"zooming gap\". Experiments show that our models achieve leading performance across multiple fine-grained perception benchmarks, and also improve general multimodal cognition on benchmarks such as visual reasoning and GUI agents. We further discuss when \"Thinking-with-Images\" is necessary versus when its gains can be distilled into a single forward pass. Our code is available at https://github.com/inclusionAI/Zooming-without-Zooming.",
      "authors": [
        "Lai Wei",
        "Liangbo He",
        "Jun Lan",
        "Lingzhong Dong",
        "Yutong Cai",
        "Siyuan Li",
        "Huijia Zhu",
        "Weiqiang Wang",
        "Linghe Kong",
        "Yue Wang",
        "Zhuosheng Zhang",
        "Weiran Huang"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-12T12:00:35Z",
      "updated": "2026-02-12T12:00:35Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11858v1",
      "abs_url": "http://arxiv.org/abs/2602.11858v1",
      "summary": "提出Region-to-Image Distillation方法，提升MLLM在细粒度多模态感知上的单次推理能力。",
      "key_contributions": [
        "提出 Region-to-Image Distillation 训练方法",
        "构建细粒度多模态感知基准 ZoomBench",
        "实验证明方法有效性"
      ],
      "methodology": "通过区域裁剪生成高质量 VQA 数据，并用其蒸馏训练 MLLM，使其具备单次推理的细粒度感知能力。",
      "tags": [
        "Multimodal Learning",
        "Distillation",
        "Fine-grained Perception",
        "Visual Question Answering"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注多模态学习，特别是细粒度感知问题，并提出了相应的解决方案。",
      "analyzed_at": "2026-02-13T07:01:14.132108",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11841v1",
      "title": "Improving Neural Retrieval with Attribution-Guided Query Rewriting",
      "abstract": "Neural retrievers are effective but brittle: underspecified or ambiguous queries can misdirect ranking even when relevant documents exist. Existing approaches address this brittleness only partially: LLMs rewrite queries without retriever feedback, and explainability methods identify misleading tokens but are used for post-hoc analysis. We close this loop and propose an attribution-guided query rewriting method that uses token-level explanations to guide query rewriting. For each query, we compute gradient-based token attributions from the retriever and then use these scores as soft guidance in a structured prompt to an LLM that clarifies weak or misleading query components while preserving intent. Evaluated on BEIR collections, the resulting rewrites consistently improve retrieval effectiveness over strong baselines, with larger gains for implicit or ambiguous information needs.",
      "authors": [
        "Moncef Garouani",
        "Josiane Mothe"
      ],
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "published": "2026-02-12T11:34:06Z",
      "updated": "2026-02-12T11:34:06Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11841v1",
      "abs_url": "http://arxiv.org/abs/2602.11841v1",
      "summary": "提出一种基于Token级别归因的查询重写方法，提升神经检索器的性能。",
      "key_contributions": [
        "利用检索器反馈指导查询重写",
        "使用token-level归因引导LLM生成更清晰的查询",
        "在BEIR数据集上验证了有效性"
      ],
      "methodology": "计算检索器的梯度token归因，作为LLM提示的软指导，重写查询。",
      "tags": [
        "神经检索",
        "查询重写",
        "可解释性",
        "LLM"
      ],
      "assigned_category": "memory",
      "relevance_score": 9,
      "relevance_reason": "核心关注检索增强，使用LLM重写查询提升检索效果。",
      "analyzed_at": "2026-02-13T07:01:15.804975",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11836v1",
      "title": "ULTRA:Urdu Language Transformer-based Recommendation Architecture",
      "abstract": "Urdu, as a low-resource language, lacks effective semantic content recommendation systems, particularly in the domain of personalized news retrieval. Existing approaches largely rely on lexical matching or language-agnostic techniques, which struggle to capture semantic intent and perform poorly under varying query lengths and information needs. This limitation results in reduced relevance and adaptability in Urdu content recommendation. We propose ULTRA (Urdu Language Transformer-based Recommendation Architecture),an adaptive semantic recommendation framework designed to address these challenges. ULTRA introduces a dual-embedding architecture with a query-length aware routing mechanism that dynamically distinguishes between short, intent-focused queries and longer, context-rich queries. Based on a threshold-driven decision process, user queries are routed to specialized semantic pipelines optimized for either title/headline-level or full-content/document level representations, ensuring appropriate semantic granularity during retrieval. The proposed system leverages transformer-based embeddings and optimized pooling strategies to move beyond surface-level keyword matching and enable context-aware similarity search. Extensive experiments conducted on a large-scale Urdu news corpus demonstrate that the proposed architecture consistently improves recommendation relevance across diverse query types. Results show gains in precision above 90% compared to single-pipeline baselines, highlighting the effectiveness of query-adaptive semantic alignment for low-resource languages. The findings establish ULTRA as a robust and generalizable content recommendation architecture, offering practical design insights for semantic retrieval systems in low-resource language settings.",
      "authors": [
        "Alishbah Bashir",
        "Fatima Qaiser",
        "Ijaz Hussain"
      ],
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "published": "2026-02-12T11:26:46Z",
      "updated": "2026-02-12T11:26:46Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11836v1",
      "abs_url": "http://arxiv.org/abs/2602.11836v1",
      "summary": "ULTRA是针对低资源乌尔都语的自适应语义推荐框架，通过双嵌入和查询长度感知路由提升推荐效果。",
      "key_contributions": [
        "提出了ULTRA：一种基于Transformer的乌尔都语推荐架构",
        "引入双嵌入架构和查询长度感知路由机制",
        "在大规模乌尔都语新闻语料库上验证了其有效性，精度提升超过90%"
      ],
      "methodology": "采用Transformer embeddings和优化的池化策略，根据查询长度动态选择headline或全文级别的语义pipeline进行推荐。",
      "tags": [
        "推荐系统",
        "乌尔都语",
        "Transformer",
        "低资源语言",
        "语义检索"
      ],
      "assigned_category": "memory",
      "relevance_score": 7,
      "relevance_reason": "涉及到RAG中信息检索，提升召回效果。",
      "analyzed_at": "2026-02-13T07:01:17.778310",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11832v1",
      "title": "JEPA-VLA: Video Predictive Embedding is Needed for VLA Models",
      "abstract": "Recent vision-language-action (VLA) models built upon pretrained vision-language models (VLMs) have achieved significant improvements in robotic manipulation. However, current VLAs still suffer from low sample efficiency and limited generalization. This paper argues that these limitations are closely tied to an overlooked component, pretrained visual representation, which offers insufficient knowledge on both aspects of environment understanding and policy prior. Through an in-depth analysis, we find that commonly used visual representations in VLAs, whether pretrained via language-image contrastive learning or image-based self-supervised learning, remain inadequate at capturing crucial, task-relevant environment information and at inducing effective policy priors, i.e., anticipatory knowledge of how the environment evolves under successful task execution. In contrast, we discover that predictive embeddings pretrained on videos, in particular V-JEPA 2, are adept at flexibly discarding unpredictable environment factors and encoding task-relevant temporal dynamics, thereby effectively compensating for key shortcomings of existing visual representations in VLAs. Building on these observations, we introduce JEPA-VLA, a simple yet effective approach that adaptively integrates predictive embeddings into existing VLAs. Our experiments demonstrate that JEPA-VLA yields substantial performance gains across a range of benchmarks, including LIBERO, LIBERO-plus, RoboTwin2.0, and real-robot tasks.",
      "authors": [
        "Shangchen Miao",
        "Ningya Feng",
        "Jialong Wu",
        "Ye Lin",
        "Xu He",
        "Dong Li",
        "Mingsheng Long"
      ],
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-12T11:20:43Z",
      "updated": "2026-02-12T11:20:43Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11832v1",
      "abs_url": "http://arxiv.org/abs/2602.11832v1",
      "summary": "该论文提出JEPA-VLA模型，通过融入视频预测嵌入提升VLA模型在机器人操作任务中的性能和泛化性。",
      "key_contributions": [
        "发现现有VLA模型视觉表示的局限性",
        "提出JEPA-VLA模型，融合视频预测嵌入",
        "实验证明JEPA-VLA在多个benchmark上提升性能"
      ],
      "methodology": "提出JEPA-VLA模型，自适应地将视频预测嵌入（V-JEPA 2）集成到现有VLA模型中，以提升环境理解和策略先验。",
      "tags": [
        "VLA",
        "机器人操作",
        "视频预测嵌入",
        "视觉表示"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注多模态视觉-语言-动作模型及其在机器人领域的应用。",
      "analyzed_at": "2026-02-13T07:01:20.441927",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11829v1",
      "title": "Towards Sustainable Investment Policies Informed by Opponent Shaping",
      "abstract": "Addressing climate change requires global coordination, yet rational economic actors often prioritize immediate gains over collective welfare, resulting in social dilemmas. InvestESG is a recently proposed multi-agent simulation that captures the dynamic interplay between investors and companies under climate risk. We provide a formal characterization of the conditions under which InvestESG exhibits an intertemporal social dilemma, deriving theoretical thresholds at which individual incentives diverge from collective welfare. Building on this, we apply Advantage Alignment, a scalable opponent shaping algorithm shown to be effective in general-sum games, to influence agent learning in InvestESG. We offer theoretical insights into why Advantage Alignment systematically favors socially beneficial equilibria by biasing learning dynamics toward cooperative outcomes. Our results demonstrate that strategically shaping the learning processes of economic agents can result in better outcomes that could inform policy mechanisms to better align market incentives with long-term sustainability goals.",
      "authors": [
        "Juan Agustin Duque",
        "Razvan Ciuca",
        "Ayoub Echchahed",
        "Hugo Larochelle",
        "Aaron Courville"
      ],
      "categories": [
        "cs.LG",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T11:16:28Z",
      "updated": "2026-02-12T11:16:28Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11829v1",
      "abs_url": "http://arxiv.org/abs/2602.11829v1",
      "summary": "论文利用对手塑造算法，改善投资行为，促进可持续投资政策的制定。",
      "key_contributions": [
        "形式化了InvestESG中的社会困境",
        "应用Advantage Alignment算法影响agent学习",
        "理论解释了Advantage Alignment促进合作均衡的原因"
      ],
      "methodology": "构建InvestESG多智能体仿真环境，应用Advantage Alignment算法，并通过理论分析验证算法效果。",
      "tags": [
        "可持续投资",
        "多智能体系统",
        "对手塑造",
        "Advantage Alignment",
        "气候变化"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "使用多智能体方法解决可持续投资问题，涉及agent的学习和策略优化。",
      "analyzed_at": "2026-02-13T07:01:21.897806",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11808v1",
      "title": "Deep Kernel Fusion for Transformers",
      "abstract": "Agentic LLM inference with long contexts is increasingly limited by memory bandwidth rather than compute. In this setting, SwiGLU MLP blocks, whose large weights exceed cache capacity, become a major yet under-optimized bottleneck. We propose DeepFusionKernel, a deeply fused kernel that cuts HBM traffic and boosts cache reuse, delivering up to 13.2% speedup on H100 and 9.7% on A100 over SGLang. Integrated with SGLang and paired with a kernel scheduler, DeepFusionKernel ensures consistent accelerations over generation lengths, while remaining adaptable to diverse models, inference configurations, and hardware platforms.",
      "authors": [
        "Zixi Zhang",
        "Zhiwen Mo",
        "Yiren Zhao",
        "Robert Mullins"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T10:43:59Z",
      "updated": "2026-02-12T10:43:59Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11808v1",
      "abs_url": "http://arxiv.org/abs/2602.11808v1",
      "summary": "提出了DeepFusionKernel，一种深度融合内核，优化Transformer中SwiGLU MLP块的内存带宽瓶颈，提升推理速度。",
      "key_contributions": [
        "提出DeepFusionKernel优化SwiGLU MLP块",
        "减少HBM流量并提高缓存重用率",
        "集成SGLang并提供内核调度器，提升推理速度"
      ],
      "methodology": "通过深度融合内核，优化内存带宽，提高缓存利用率，实现加速Transformer推理的目的。",
      "tags": [
        "Transformer",
        "Kernel Fusion",
        "Memory Optimization",
        "Inference Acceleration",
        "SwiGLU"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 7,
      "relevance_reason": "虽然侧重优化，但提升了LLM的推理效率，与推理相关性较高。",
      "analyzed_at": "2026-02-13T07:01:24.477789",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11800v1",
      "title": "Temporal Difference Learning with Constrained Initial Representations",
      "abstract": "Recently, there have been numerous attempts to enhance the sample efficiency of off-policy reinforcement learning (RL) agents when interacting with the environment, including architecture improvements and new algorithms. Despite these advances, they overlook the potential of directly constraining the initial representations of the input data, which can intuitively alleviate the distribution shift issue and stabilize training. In this paper, we introduce the Tanh function into the initial layer to fulfill such a constraint. We theoretically unpack the convergence property of the temporal difference learning with the Tanh function under linear function approximation. Motivated by theoretical insights, we present our Constrained Initial Representations framework, tagged CIR, which is made up of three components: (i) the Tanh activation along with normalization methods to stabilize representations; (ii) the skip connection module to provide a linear pathway from the shallow layer to the deep layer; (iii) the convex Q-learning that allows a more flexible value estimate and mitigates potential conservatism. Empirical results show that CIR exhibits strong performance on numerous continuous control tasks, even being competitive or surpassing existing strong baseline methods.",
      "authors": [
        "Jiafei Lyu",
        "Jingwen Yang",
        "Zhongjian Qiao",
        "Runze Liu",
        "Zeyuan Liu",
        "Deheng Ye",
        "Zongqing Lu",
        "Xiu Li"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T10:27:57Z",
      "updated": "2026-02-12T10:27:57Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11800v1",
      "abs_url": "http://arxiv.org/abs/2602.11800v1",
      "summary": "提出了约束初始表示的强化学习框架CIR，通过Tanh激活等方式稳定训练，提升样本效率。",
      "key_contributions": [
        "引入Tanh激活函数约束初始表示",
        "提出CIR框架，包含Tanh激活、skip connection和凸Q学习",
        "理论分析了Tanh激活下的TD学习收敛性"
      ],
      "methodology": "使用Tanh激活约束初始表示，结合skip connection和凸Q学习，构建CIR框架，并在连续控制任务上进行评估。",
      "tags": [
        "强化学习",
        "off-policy RL",
        "样本效率",
        "表示学习"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 7,
      "relevance_reason": "改进强化学习agent的训练方法，提高样本效率，属于agent tuning范畴。",
      "analyzed_at": "2026-02-13T07:01:26.175398",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11799v1",
      "title": "Hi-SAM: A Hierarchical Structure-Aware Multi-modal Framework for Large-Scale Recommendation",
      "abstract": "Multi-modal recommendation has gained traction as items possess rich attributes like text and images. Semantic ID-based approaches effectively discretize this information into compact tokens. However, two challenges persist: (1) Suboptimal Tokenization: existing methods (e.g., RQ-VAE) lack disentanglement between shared cross-modal semantics and modality-specific details, causing redundancy or collapse; (2) Architecture-Data Mismatch: vanilla Transformers treat semantic IDs as flat streams, ignoring the hierarchy of user interactions, items, and tokens. Expanding items into multiple tokens amplifies length and noise, biasing attention toward local details over holistic semantics. We propose Hi-SAM, a Hierarchical Structure-Aware Multi-modal framework with two designs: (1) Disentangled Semantic Tokenizer (DST): unifies modalities via geometry-aware alignment and quantizes them via a coarse-to-fine strategy. Shared codebooks distill consensus while modality-specific ones recover nuances from residuals, enforced by mutual information minimization; (2) Hierarchical Memory-Anchor Transformer (HMAT): splits positional encoding into inter- and intra-item subspaces via Hierarchical RoPE to restore hierarchy. It inserts Anchor Tokens to condense items into compact memory, retaining details for the current item while accessing history only through compressed summaries. Experiments on real-world datasets show consistent improvements over SOTA baselines, especially in cold-start scenarios. Deployed on a large-scale social platform serving millions of users, Hi-SAM achieved a 6.55% gain in the core online metric.",
      "authors": [
        "Pingjun Pan",
        "Tingting Zhou",
        "Peiyao Lu",
        "Tingting Fei",
        "Hongxiang Chen",
        "Chuanjiang Luo"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T10:26:15Z",
      "updated": "2026-02-12T10:26:15Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11799v1",
      "abs_url": "http://arxiv.org/abs/2602.11799v1",
      "summary": "Hi-SAM通过解耦语义标记和分层Transformer结构，提升多模态推荐系统的效果，并在大规模场景下验证有效性。",
      "key_contributions": [
        "提出了解耦语义标记器(DST)，解决模态间语义纠缠问题",
        "提出了分层记忆锚点Transformer(HMAT)，考虑用户交互层级结构",
        "在真实数据集和大规模线上环境验证了方法的有效性"
      ],
      "methodology": "Hi-SAM通过几何对齐和粗细粒度量化解耦模态语义，利用分层RoPE和锚点Token编码层级结构。",
      "tags": [
        "多模态学习",
        "推荐系统",
        "Transformer",
        "量化",
        "分层结构"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注多模态数据的处理和推荐系统，是多模态学习领域的重要应用。",
      "analyzed_at": "2026-02-13T07:01:28.356457",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11790v1",
      "title": "Beyond End-to-End Video Models: An LLM-Based Multi-Agent System for Educational Video Generation",
      "abstract": "Although recent end-to-end video generation models demonstrate impressive performance in visually oriented content creation, they remain limited in scenarios that require strict logical rigor and precise knowledge representation, such as instructional and educational media. To address this problem, we propose LAVES, a hierarchical LLM-based multi-agent system for generating high-quality instructional videos from educational problems. The LAVES formulates educational video generation as a multi-objective task that simultaneously demands correct step-by-step reasoning, pedagogically coherent narration, semantically faithful visual demonstrations, and precise audio--visual alignment. To address the limitations of prior approaches--including low procedural fidelity, high production cost, and limited controllability--LAVES decomposes the generation workflow into specialized agents coordinated by a central Orchestrating Agent with explicit quality gates and iterative critique mechanisms. Specifically, the Orchestrating Agent supervises a Solution Agent for rigorous problem solving, an Illustration Agent that produces executable visualization codes, and a Narration Agent for learner-oriented instructional scripts. In addition, all outputs from the working agents are subject to semantic critique, rule-based constraints, and tool-based compilation checks. Rather than directly synthesizing pixels, the system constructs a structured executable video script that is deterministically compiled into synchronized visuals and narration using template-driven assembly rules, enabling fully automated end-to-end production without manual editing. In large-scale deployments, LAVES achieves a throughput exceeding one million videos per day, delivering over a 95% reduction in cost compared to current industry-standard approaches while maintaining a high acceptance rate.",
      "authors": [
        "Lingyong Yan",
        "Jiulong Wu",
        "Dong Xie",
        "Weixian Shi",
        "Deguo Xia",
        "Jizhou Huang"
      ],
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T10:14:36Z",
      "updated": "2026-02-12T10:14:36Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11790v1",
      "abs_url": "http://arxiv.org/abs/2602.11790v1",
      "summary": "LAVES是一个基于LLM的多智能体系统，用于生成高质量的教育视频，大幅降低制作成本。",
      "key_contributions": [
        "提出了一种分层LLM多智能体系统LAVES",
        "将教育视频生成分解为多目标任务",
        "实现了全自动端到端视频生成，无需人工编辑"
      ],
      "methodology": "使用LLM作为核心，构建多个专门智能体（解决、演示、叙述），并通过中心智能体协调，进行迭代改进和质量控制。",
      "tags": [
        "LLM",
        "Multi-Agent System",
        "Video Generation",
        "Education"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心是基于LLM的智能体系统，用于解决特定任务，属于AI Agent领域的核心研究。",
      "analyzed_at": "2026-02-13T07:01:30.115769",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11786v1",
      "title": "Evaluating LLM Safety Under Repeated Inference via Accelerated Prompt Stress Testing",
      "abstract": "Traditional benchmarks for large language models (LLMs) primarily assess safety risk through breadth-oriented evaluation across diverse tasks. However, real-world deployment exposes a different class of risk: operational failures arising from repeated inference on identical or near-identical prompts rather than broad task generalization. In high-stakes settings, response consistency and safety under sustained use are critical. We introduce Accelerated Prompt Stress Testing (APST), a depth-oriented evaluation framework inspired by reliability engineering. APST repeatedly samples identical prompts under controlled operational conditions (e.g., decoding temperature) to surface latent failure modes including hallucinations, refusal inconsistency, and unsafe completions. Rather than treating failures as isolated events, APST models them as stochastic outcomes of independent inference events. We formalize safety failures using Bernoulli and binomial models to estimate per-inference failure probabilities, enabling quantitative comparison of reliability across models and decoding configurations. Applying APST to multiple instruction-tuned LLMs evaluated on AIR-BENCH-derived safety prompts, we find that models with similar benchmark-aligned scores can exhibit substantially different empirical failure rates under repeated sampling, particularly as temperature increases. These results demonstrate that shallow, single-sample evaluation can obscure meaningful reliability differences under sustained use. APST complements existing benchmarks by providing a practical framework for evaluating LLM safety and reliability under repeated inference, bridging benchmark alignment and deployment-oriented risk assessment.",
      "authors": [
        "Keita Broadwater"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-12T10:09:13Z",
      "updated": "2026-02-12T10:09:13Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11786v1",
      "abs_url": "http://arxiv.org/abs/2602.11786v1",
      "summary": "提出APST框架，通过重复推理测试评估LLM在持续使用中的安全性和可靠性。",
      "key_contributions": [
        "提出 Accelerated Prompt Stress Testing (APST) 框架",
        "使用伯努利和二项模型量化安全故障率",
        "发现单次评估可能掩盖持续使用中的可靠性差异"
      ],
      "methodology": "重复采样相同prompt，控制解码温度等条件，使用伯努利和二项模型对故障进行建模和概率估计。",
      "tags": [
        "LLM安全",
        "可靠性",
        "压力测试",
        "重复推理",
        "风险评估"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "论文关注LLM在重复推理下的安全性和可靠性，属于LLM推理的重要方面。",
      "analyzed_at": "2026-02-13T07:01:32.349339",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11782v1",
      "title": "FlowMind: Execute-Summarize for Structured Workflow Generation from LLM Reasoning",
      "abstract": "LLMs can solve complex tasks through reasoning and tool use, but accurately translating these solutions into structured workflows remains challenging. We model workflows as sequences of tool use and reformulate the problem as designing a mechanism that can both solve tasks and reliably construct workflows. Prior approaches that build workflows during execution often suffer from inaccuracies due to interference between the two processes. We propose an Execute-Summarize(ES) framework that decouples task execution from workflow construction: the model first completes the task using available tools, then independently reconstructs a structured workflow from execution traces. This separation improves workflow accuracy and robustness. We introduce FlowBench and show through extensive experiments that our approach outperforms existing methods, providing a reliable paradigm for grounding free-form LLM reasoning into structured workflows.",
      "authors": [
        "Yihao Liu",
        "Ziyun Zhang",
        "Zile He",
        "Huaqian Cai"
      ],
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T10:04:42Z",
      "updated": "2026-02-12T10:04:42Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11782v1",
      "abs_url": "http://arxiv.org/abs/2602.11782v1",
      "summary": "该论文提出了一种Execute-Summarize框架，用于从LLM推理中生成更准确的结构化工作流。",
      "key_contributions": [
        "提出Execute-Summarize框架，解耦任务执行和工作流构建",
        "引入FlowBench基准测试",
        "实验证明该方法优于现有方法"
      ],
      "methodology": "首先使用LLM和工具完成任务，然后独立地从执行轨迹中重建结构化工作流，避免了执行过程中的干扰。",
      "tags": [
        "LLM",
        "workflow",
        "reasoning",
        "tool use",
        "agent"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "该论文直接研究了如何将LLM推理转化为agent可执行的结构化工作流，属于核心研究。",
      "analyzed_at": "2026-02-13T07:01:33.978010",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11771v1",
      "title": "How to Optimize Multispecies Set Predictions in Presence-Absence Modeling ?",
      "abstract": "Species distribution models (SDMs) commonly produce probabilistic occurrence predictions that must be converted into binary presence-absence maps for ecological inference and conservation planning. However, this binarization step is typically heuristic and can substantially distort estimates of species prevalence and community composition. We present MaxExp, a decision-driven binarization framework that selects the most probable species assemblage by directly maximizing a chosen evaluation metric. MaxExp requires no calibration data and is flexible across several scores. We also introduce the Set Size Expectation (SSE) method, a computationally efficient alternative that predicts assemblages based on expected species richness. Using three case studies spanning diverse taxa, species counts, and performance metrics, we show that MaxExp consistently matches or surpasses widely used thresholding and calibration methods, especially under strong class imbalance and high rarity. SSE offers a simpler yet competitive option. Together, these methods provide robust, reproducible tools for multispecies SDM binarization.",
      "authors": [
        "Sébastien Gigot--Léandri",
        "Gaétan Morand",
        "Alexis Joly",
        "François Munoz",
        "David Mouillot",
        "Christophe Botella",
        "Maximilien Servajean"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T09:52:26Z",
      "updated": "2026-02-12T09:52:26Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11771v1",
      "abs_url": "http://arxiv.org/abs/2602.11771v1",
      "summary": "提出了MaxExp和SSE两种方法，用于优化多物种存在-缺席模型的二值化预测。",
      "key_contributions": [
        "提出了MaxExp二值化框架，通过最大化评估指标选择最佳物种组合",
        "提出了SSE方法，基于预期物种丰富度预测组合，计算效率高",
        "通过多个案例研究验证了MaxExp和SSE的有效性，尤其是在类别不平衡和稀有物种情况下"
      ],
      "methodology": "提出两种二值化方法，MaxExp通过直接优化评估指标选择物种组合，SSE基于预期物种丰富度进行预测，并使用实际数据进行验证。",
      "tags": [
        "物种分布模型",
        "二值化",
        "生态学",
        "物种组合"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 5,
      "relevance_reason": "可以看作是优化预测输出结果的一种策略，与Agent Tuning的概念有一定联系。",
      "analyzed_at": "2026-02-13T07:01:36.321208",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11761v1",
      "title": "MiniCPM-SALA: Hybridizing Sparse and Linear Attention for Efficient Long-Context Modeling",
      "abstract": "The evolution of large language models (LLMs) towards applications with ultra-long contexts faces challenges posed by the high computational and memory costs of the Transformer architecture. While existing sparse and linear attention mechanisms attempt to mitigate these issues, they typically involve a trade-off between memory efficiency and model performance. This paper introduces MiniCPM-SALA, a 9B-parameter hybrid architecture that integrates the high-fidelity long-context modeling of sparse attention (InfLLM-V2) with the global efficiency of linear attention (Lightning Attention). By employing a layer selection algorithm to integrate these mechanisms in a 1:3 ratio and utilizing a hybrid positional encoding (HyPE), the model maintains efficiency and performance for long-context tasks. Furthermore, we introduce a cost-effective continual training framework that transforms pre-trained Transformer-based models into hybrid models, which reduces training costs by approximately 75% compared to training from scratch. Extensive experiments show that MiniCPM-SALA maintains general capabilities comparable to full-attention models while offering improved efficiency. On a single NVIDIA A6000D GPU, the model achieves up to 3.5x the inference speed of the full-attention model at the sequence length of 256K tokens and supports context lengths of up to 1M tokens, a scale where traditional full-attention 8B models fail because of memory constraints.",
      "authors": [
        "MiniCPM Team",
        "Wenhao An",
        "Yingfa Chen",
        "Yewei Fang",
        "Jiayi Li",
        "Xin Li",
        "Yaohui Li",
        "Yishan Li",
        "Yuxuan Li",
        "Biyuan Lin",
        "Chuan Liu",
        "Hezi Liu",
        "Siyuan Liu",
        "Hongya Lyu",
        "Yinxu Pan",
        "Shixin Ren",
        "Xingyu Shen",
        "Zhou Su",
        "Haojun Sun",
        "Yangang Sun",
        "Zhen Leng Thai",
        "Xin Tian",
        "Rui Wang",
        "Xiaorong Wang",
        "Yudong Wang",
        "Bo Wu",
        "Xiaoyue Xu",
        "Dong Xu",
        "Shuaikang Xue",
        "Jiawei Yang",
        "Bowen Zhang",
        "Jinqian Zhang",
        "Letian Zhang",
        "Shengnan Zhang",
        "Xinyu Zhang",
        "Xinyuan Zhang",
        "Zhu Zhang",
        "Hengyu Zhao",
        "Jiacheng Zhao",
        "Jie Zhou",
        "Zihan Zhou",
        "Shuo Wang",
        "Chaojun Xiao",
        "Xu Han",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-12T09:37:05Z",
      "updated": "2026-02-12T09:37:05Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11761v1",
      "abs_url": "http://arxiv.org/abs/2602.11761v1",
      "summary": "MiniCPM-SALA通过混合稀疏和线性注意力机制，在长文本建模中实现了高效的性能和内存效率。",
      "key_contributions": [
        "提出MiniCPM-SALA混合注意力架构，结合稀疏和线性注意力的优势",
        "引入成本效益高的持续训练框架，降低训练成本",
        "实现高达1M tokens的上下文长度，并提升推理速度"
      ],
      "methodology": "采用稀疏注意力(InfLLM-V2)和线性注意力(Lightning Attention)混合架构，通过层选择算法和混合位置编码(HyPE)提升效率。",
      "tags": [
        "长文本建模",
        "稀疏注意力",
        "线性注意力",
        "模型效率",
        "混合架构"
      ],
      "assigned_category": "memory",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注长文本建模，通过优化注意力机制提升内存效率和推理速度，与memory类别直接相关。",
      "analyzed_at": "2026-02-13T07:01:38.354554",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11757v1",
      "title": "Code2Worlds: Empowering Coding LLMs for 4D World Generation",
      "abstract": "Achieving spatial intelligence requires moving beyond visual plausibility to build world simulators grounded in physical laws. While coding LLMs have advanced static 3D scene generation, extending this paradigm to 4D dynamics remains a critical frontier. This task presents two fundamental challenges: multi-scale context entanglement, where monolithic generation fails to balance local object structures with global environmental layouts; and a semantic-physical execution gap, where open-loop code generation leads to physical hallucinations lacking dynamic fidelity. We introduce Code2Worlds, a framework that formulates 4D generation as language-to-simulation code generation. First, we propose a dual-stream architecture that disentangles retrieval-augmented object generation from hierarchical environmental orchestration. Second, to ensure dynamic fidelity, we establish a physics-aware closed-loop mechanism in which a PostProcess Agent scripts dynamics, coupled with a VLM-Motion Critic that performs self-reflection to iteratively refine simulation code. Evaluations on the Code4D benchmark show Code2Worlds outperforms baselines with a 41% SGS gain and 49% higher Richness, while uniquely generating physics-aware dynamics absent in prior static methods. Code: https://github.com/AIGeeksGroup/Code2Worlds. Website: https://aigeeksgroup.github.io/Code2Worlds.",
      "authors": [
        "Yi Zhang",
        "Yunshuang Wang",
        "Zeyu Zhang",
        "Hao Tang"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-12T09:34:28Z",
      "updated": "2026-02-12T09:34:28Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11757v1",
      "abs_url": "http://arxiv.org/abs/2602.11757v1",
      "summary": "Code2Worlds框架利用编码LLM生成具有物理规律的动态4D世界，解决多尺度和语义物理鸿沟问题。",
      "key_contributions": [
        "提出了双流架构解耦对象生成与环境编排",
        "建立了物理感知闭环机制迭代优化模拟代码",
        "在Code4D基准测试上超越现有方法"
      ],
      "methodology": "利用双流架构和物理感知闭环机制，将4D生成建模为语言到模拟代码的生成过程。",
      "tags": [
        "LLM",
        "4D World Generation",
        "Code Generation",
        "Simulation"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 8,
      "relevance_reason": "涉及到多模态（代码，语言，物理世界）和LLM生成，高度相关。",
      "analyzed_at": "2026-02-13T07:01:40.379718",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11750v1",
      "title": "AmbiBench: Benchmarking Mobile GUI Agents Beyond One-Shot Instructions in the Wild",
      "abstract": "Benchmarks are paramount for gauging progress in the domain of Mobile GUI Agents. In practical scenarios, users frequently fail to articulate precise directives containing full task details at the onset, and their expressions are typically ambiguous. Consequently, agents are required to converge on the user's true intent via active clarification and interaction during execution. However, existing benchmarks predominantly operate under the idealized assumption that user-issued instructions are complete and unequivocal. This paradigm focuses exclusively on assessing single-turn execution while overlooking the alignment capability of the agent. To address this limitation, we introduce AmbiBench, the first benchmark incorporating a taxonomy of instruction clarity to shift evaluation from unidirectional instruction following to bidirectional intent alignment. Grounded in Cognitive Gap theory, we propose a taxonomy of four clarity levels: Detailed, Standard, Incomplete, and Ambiguous. We construct a rigorous dataset of 240 ecologically valid tasks across 25 applications, subject to strict review protocols. Furthermore, targeting evaluation in dynamic environments, we develop MUSE (Mobile User Satisfaction Evaluator), an automated framework utilizing an MLLM-as-a-judge multi-agent architecture. MUSE performs fine-grained auditing across three dimensions: Outcome Effectiveness, Execution Quality, and Interaction Quality. Empirical results on AmbiBench reveal the performance boundaries of SoTA agents across different clarity levels, quantify the gains derived from active interaction, and validate the strong correlation between MUSE and human judgment. This work redefines evaluation standards, laying the foundation for next-generation agents capable of truly understanding user intent.",
      "authors": [
        "Jiazheng Sun",
        "Mingxuan Li",
        "Yingying Zhang",
        "Jiayang Niu",
        "Yachen Wu",
        "Ruihan Jin",
        "Shuyu Lei",
        "Pengrongrui Tan",
        "Zongyu Zhang",
        "Ruoyi Wang",
        "Jiachen Yang",
        "Boyu Yang",
        "Jiacheng Liu",
        "Xin Peng"
      ],
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "published": "2026-02-12T09:25:15Z",
      "updated": "2026-02-12T09:25:15Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11750v1",
      "abs_url": "http://arxiv.org/abs/2602.11750v1",
      "summary": "提出了AmbiBench，一个用于评估移动GUI Agent在不明确指令下意图对齐能力的基准。",
      "key_contributions": [
        "提出了一个包含指令清晰度分类的基准AmbiBench",
        "构建了包含240个任务的数据集，覆盖25个应用",
        "开发了自动评估框架MUSE，用于多维度评估Agent性能"
      ],
      "methodology": "基于认知差距理论，构建包含不同清晰度等级指令的数据集，并利用MLLM作为裁判进行多维度自动评估。",
      "tags": [
        "Mobile GUI Agent",
        "Benchmark",
        "Intent Alignment",
        "MLLM"
      ],
      "assigned_category": "agent",
      "relevance_score": 10,
      "relevance_reason": "该论文直接研究了AI Agent的评估问题，并提出了新的基准。",
      "analyzed_at": "2026-02-13T07:01:42.459088",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11743v1",
      "title": "Adaptive Debiasing Tsallis Entropy for Test-Time Adaptation",
      "abstract": "Mainstream Test-Time Adaptation (TTA) methods for adapting vision-language models, e.g., CLIP, typically rely on Shannon Entropy (SE) at test time to measure prediction uncertainty and inconsistency. However, since CLIP has a built-in bias from pretraining on highly imbalanced web-crawled data, SE inevitably results in producing biased estimates of uncertainty entropy. To address this issue, we notably find and demonstrate that Tsallis Entropy (TE), a generalized form of SE, is naturally suited for characterizing biased distributions by introducing a non-extensive parameter q, with the performance of SE serving as a lower bound for TE. Building upon this, we generalize TE into Adaptive Debiasing Tsallis Entropy (ADTE) for TTA, customizing a class-specific parameter q^l derived by normalizing the estimated label bias from continuously incoming test instances, for each category. This adaptive approach allows ADTE to accurately select high-confidence views and seamlessly integrate with a label adjustment strategy to enhance adaptation, without introducing distribution-specific hyperparameter tuning. Besides, our investigation reveals that both TE and ADTE can serve as direct, advanced alternatives to SE in TTA, without any other modifications. Experimental results show that ADTE outperforms state-of-the-art methods on ImageNet and its five variants, and achieves the highest average performance on 10 cross-domain benchmarks, regardless of the model architecture or text prompts used. Our code is available at https://github.com/Jinx630/ADTE.",
      "authors": [
        "Xiangyu Wu",
        "Dongming Jiang",
        "Feng Yu",
        "Yueying Tian",
        "Jiaqi Tang",
        "Qing-Guo Chen",
        "Yang Yang",
        "Jianfeng Lu"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-12T09:12:22Z",
      "updated": "2026-02-12T09:12:22Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11743v1",
      "abs_url": "http://arxiv.org/abs/2602.11743v1",
      "summary": "提出自适应去偏Tsallis熵(ADTE)用于测试时自适应，解决CLIP模型在不平衡数据上的偏差问题。",
      "key_contributions": [
        "发现Tsallis熵(TE)更适合表征有偏分布",
        "提出自适应去偏Tsallis熵(ADTE)，通过类别相关的参数q^l进行自适应调整",
        "ADTE在多个图像分类任务上超越了现有SOTA方法"
      ],
      "methodology": "通过归一化测试实例的标签偏差，为每个类别定制参数q^l，自适应调整Tsallis熵，并结合标签调整策略。",
      "tags": [
        "Test-Time Adaptation",
        "Entropy",
        "Bias",
        "Vision-Language Model"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注视觉-语言模型的测试时自适应，并针对CLIP模型在多模态任务中的偏差问题提出了解决方案。",
      "analyzed_at": "2026-02-13T07:01:45.129244",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11737v1",
      "title": "Mask What Matters: Mitigating Object Hallucinations in Multimodal Large Language Models with Object-Aligned Visual Contrastive Decoding",
      "abstract": "We study object hallucination in Multimodal Large Language Models (MLLMs) and improve visual contrastive decoding (VCD) by constructing an object-aligned auxiliary view. We leverage object-centric attention in self-supervised Vision Transformers. In particular, we remove the most salient visual evidence to construct an auxiliary view that disrupts unsupported tokens and produces a stronger contrast signal. Our method is prompt-agnostic, model-agnostic, and can be seamlessly plugged into the existing VCD pipeline with little computation overhead, i.e., a single cacheable forward pass. Empirically, our method demonstrates consistent gains on two popular object hallucination benchmarks across two MLLMs.",
      "authors": [
        "Boqi Chen",
        "Xudong Liu",
        "Jianing Qiu"
      ],
      "categories": [
        "cs.CV",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-12T09:04:28Z",
      "updated": "2026-02-12T09:04:28Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11737v1",
      "abs_url": "http://arxiv.org/abs/2602.11737v1",
      "summary": "该论文提出了一种基于目标对齐视觉对比解码的方法，旨在缓解多模态大语言模型中的目标幻觉问题。",
      "key_contributions": [
        "提出了目标对齐的视觉对比解码方法",
        "利用自监督视觉Transformer中的目标中心注意力",
        "方法具有提示词无关和模型无关的特性，计算开销小"
      ],
      "methodology": "通过移除显著的视觉证据来构建辅助视图，增强对比信号，从而抑制不支持的tokens，缓解目标幻觉。",
      "tags": [
        "Multimodal",
        "Object Hallucination",
        "Contrastive Decoding",
        "MLLM",
        "Vision Transformer"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文直接针对多模态大语言模型中的目标幻觉问题，提出了新的解决方法。",
      "analyzed_at": "2026-02-13T07:01:47.037648",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11733v1",
      "title": "Adapting Vision-Language Models for E-commerce Understanding at Scale",
      "abstract": "E-commerce product understanding demands by nature, strong multimodal comprehension from text, images, and structured attributes. General-purpose Vision-Language Models (VLMs) enable generalizable multimodal latent modelling, yet there is no documented, well-known strategy for adapting them to the attribute-centric, multi-image, and noisy nature of e-commerce data, without sacrificing general performance. In this work, we show through a large-scale experimental study, how targeted adaptation of general VLMs can substantially improve e-commerce performance while preserving broad multimodal capabilities. Furthermore, we propose a novel extensive evaluation suite covering deep product understanding, strict instruction following, and dynamic attribute extraction.",
      "authors": [
        "Matteo Nulli",
        "Vladimir Orshulevich",
        "Tala Bazazo",
        "Christian Herold",
        "Michael Kozielski",
        "Marcin Mazur",
        "Szymon Tuzel",
        "Cees G. M. Snoek",
        "Seyyed Hadi Hashemi",
        "Omar Javed",
        "Yannick Versley",
        "Shahram Khadivi"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-12T08:59:22Z",
      "updated": "2026-02-12T08:59:22Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11733v1",
      "abs_url": "http://arxiv.org/abs/2602.11733v1",
      "summary": "针对电商场景，论文提出了一种适配通用视觉语言模型的方法，并构建了新的评估体系。",
      "key_contributions": [
        "提出电商场景下适配通用VLM的策略",
        "构建全面的电商产品理解评估套件",
        "验证了该方法在提升电商性能的同时，保留了通用多模态能力"
      ],
      "methodology": "通过大规模实验研究，探索如何针对电商数据特性对通用VLM进行有针对性的适配，并进行性能评估。",
      "tags": [
        "视觉语言模型",
        "电商",
        "多模态学习",
        "模型适配"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心内容为针对电商场景的视觉语言模型适配与评估，与多模态学习领域直接相关。",
      "analyzed_at": "2026-02-13T07:01:48.880784",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11731v1",
      "title": "Thinking with Drafting: Optical Decompression via Logical Reconstruction",
      "abstract": "Existing multimodal large language models have achieved high-fidelity visual perception and exploratory visual generation. However, a precision paradox persists in complex reasoning tasks: optical perception systems transcribe symbols without capturing logical topology, while pixel-based generative models produce visual artifacts lacking mathematical exactness. To bridge this gap, we propose that reasoning over visual inputs be reconceptualized as optical decompression-the process of reconstructing latent logical structures from compressed visual tokens. Guided by the axiom that Parsing is Reasoning, we introduce Thinking with Drafting (TwD), which utilizes a minimalist Domain-Specific Language (DSL) as a grounding intermediate representation. Unlike standard approaches that hallucinate answers directly, TwD forces the model to draft its mental model into executable code, rendering deterministic visual proofs for self-verification. To validate this, we present VisAlg, a visual algebra benchmark. Experiments demonstrate that TwD serve as a superior cognitive scaffold. Our work establishes a closed-loop system where visual generation acts not as a creative output but as a logical verifier, offering a generalizable path for visual reasoning.",
      "authors": [
        "Jingxuan Wei",
        "Honghao He",
        "Caijun Jia",
        "Siyuan Li",
        "Zheng Sun",
        "Yuhang Xu",
        "Yuanyuan Lin",
        "Linzhuang Sun",
        "Yuchen Wu",
        "Bihui Yu",
        "Xiangxiang Zhang",
        "Cheng Tan"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-12T08:54:02Z",
      "updated": "2026-02-12T08:54:02Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11731v1",
      "abs_url": "http://arxiv.org/abs/2602.11731v1",
      "summary": "论文提出Thinking with Drafting方法，通过领域特定语言连接视觉感知和逻辑推理，提高视觉推理的精确性。",
      "key_contributions": [
        "提出Thinking with Drafting (TwD)框架",
        "利用DSL作为中间表示，实现逻辑重建",
        "创建VisAlg视觉代数基准"
      ],
      "methodology": "TwD将视觉推理视为光解压过程，通过DSL将视觉输入转化为可执行代码，并生成视觉证明进行验证。",
      "tags": [
        "Multimodal Learning",
        "Reasoning",
        "Visual Reasoning",
        "DSL"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "该论文核心在于提升LLM在视觉推理任务中的逻辑能力，属于核心相关。",
      "analyzed_at": "2026-02-13T07:01:50.787284",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11730v1",
      "title": "STVG-R1: Incentivizing Instance-Level Reasoning and Grounding in Videos via Reinforcement Learning",
      "abstract": "In vision-language models (VLMs), misalignment between textual descriptions and visual coordinates often induces hallucinations. This issue becomes particularly severe in dense prediction tasks such as spatial-temporal video grounding (STVG). Prior approaches typically focus on enhancing visual-textual alignment or attaching auxiliary decoders. However, these strategies inevitably introduce additional trainable modules, leading to significant annotation costs and computational overhead. In this work, we propose a novel visual prompting paradigm that avoids the difficult problem of aligning coordinates across modalities. Specifically, we reformulate per-frame coordinate prediction as a compact instance-level identification problem by assigning each object a unique, temporally consistent ID. These IDs are embedded into the video as visual prompts, providing explicit and interpretable inputs to the VLMs. Furthermore, we introduce STVG-R1, the first reinforcement learning framework for STVG, which employs a task-driven reward to jointly optimize temporal accuracy, spatial consistency, and structural format regularization. Extensive experiments on six benchmarks demonstrate the effectiveness of our approach. STVG-R1 surpasses the baseline Qwen2.5-VL-7B by a remarkable margin of 20.9% on m_IoU on the HCSTVG-v2 benchmark, establishing a new state of the art (SOTA). Surprisingly, STVG-R1 also exhibits strong zero-shot generalization to multi-object referring video object segmentation tasks, achieving a SOTA 47.3% J&F on MeViS.",
      "authors": [
        "Xiaowen Zhang",
        "Zhi Gao",
        "Licheng Jiao",
        "Lingling Li",
        "Qing Li"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-12T08:53:32Z",
      "updated": "2026-02-12T08:53:32Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11730v1",
      "abs_url": "http://arxiv.org/abs/2602.11730v1",
      "summary": "提出STVG-R1，通过视觉提示和强化学习，在时空视频定位任务上实现SOTA。",
      "key_contributions": [
        "提出基于视觉提示的STVG框架，避免跨模态对齐",
        "引入强化学习优化时序准确性、空间一致性和结构化格式",
        "在多个benchmark上达到SOTA，并具有zero-shot泛化能力"
      ],
      "methodology": "将坐标预测转化为实例识别，利用视觉提示嵌入ID，通过强化学习优化。",
      "tags": [
        "时空视频定位",
        "视觉提示",
        "强化学习",
        "多模态学习"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心是多模态，解决视觉语言模型在视频定位任务中的问题。",
      "analyzed_at": "2026-02-13T07:01:52.470446",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11717v1",
      "title": "Beyond Parameter Arithmetic: Sparse Complementary Fusion for Distribution-Aware Model Merging",
      "abstract": "Model merging has emerged as a promising paradigm for composing the capabilities of large language models by directly operating in weight space, enabling the integration of specialized models without costly retraining. However, existing merging methods largely rely on parameter-space heuristics, which often introduce severe interference, leading to degraded generalization and unstable generation behaviors such as repetition and incoherent outputs. In this work, we propose Sparse Complementary Fusion with reverse KL (SCF-RKL), a novel model merging framework that explicitly controls functional interference through sparse, distribution-aware updates. Instead of assuming linear additivity in parameter space, SCF-RKL measures the functional divergence between models using reverse Kullback-Leibler divergence and selectively incorporates complementary parameters. This mode-seeking, sparsity-inducing design effectively preserves stable representations while integrating new capabilities. We evaluate SCF-RKL across a wide range of model scales and architectures, covering both reasoning-focused and instruction-tuned models. Extensive experiments on 24 benchmarks spanning advanced reasoning, general reasoning and knowledge, instruction following, and safety demonstrate, vision classification that SCF-RKL consistently outperforms existing model merging methods while maintaining strong generalization and generation stability.",
      "authors": [
        "Weihong Lin",
        "Lin Sun",
        "Qilong Shi",
        "Aomufei Yuan",
        "Yuxuan Tian",
        "Zhengyang Wang",
        "Guangxiang Zhao",
        "Xiangzheng Zhang",
        "Tong Yang"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T08:45:42Z",
      "updated": "2026-02-12T08:45:42Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11717v1",
      "abs_url": "http://arxiv.org/abs/2602.11717v1",
      "summary": "提出SCF-RKL模型融合框架，通过稀疏互补融合和分布感知更新，有效提升模型融合效果。",
      "key_contributions": [
        "提出Sparse Complementary Fusion with reverse KL (SCF-RKL) 模型融合框架",
        "利用reverse Kullback-Leibler divergence测量模型间的函数差异",
        "通过稀疏更新选择性地整合互补参数，减少干扰"
      ],
      "methodology": "SCF-RKL通过RKL散度衡量模型差异，并进行稀疏互补融合，以分布感知的更新方式合并模型权重。",
      "tags": [
        "model merging",
        "large language models",
        "sparse updates",
        "knowledge transfer"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注LLM推理能力提升，通过模型融合方法优化推理效果。",
      "analyzed_at": "2026-02-13T07:01:54.335792",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11706v1",
      "title": "LLM-Driven 3D Scene Generation of Agricultural Simulation Environments",
      "abstract": "Procedural generation techniques in 3D rendering engines have revolutionized the creation of complex environments, reducing reliance on manual design. Recent approaches using Large Language Models (LLMs) for 3D scene generation show promise but often lack domain-specific reasoning, verification mechanisms, and modular design. These limitations lead to reduced control and poor scalability. This paper investigates the use of LLMs to generate agricultural synthetic simulation environments from natural language prompts, specifically to address the limitations of lacking domain-specific reasoning, verification mechanisms, and modular design. A modular multi-LLM pipeline was developed, integrating 3D asset retrieval, domain knowledge injection, and code generation for the Unreal rendering engine using its API. This results in a 3D environment with realistic planting layouts and environmental context, all based on the input prompt and the domain knowledge. To enhance accuracy and scalability, the system employs a hybrid strategy combining LLM optimization techniques such as few-shot prompting, Retrieval-Augmented Generation (RAG), finetuning, and validation. Unlike monolithic models, the modular architecture enables structured data handling, intermediate verification, and flexible expansion. The system was evaluated using structured prompts and semantic accuracy metrics. A user study assessed realism and familiarity against real-world images, while an expert comparison demonstrated significant time savings over manual scene design. The results confirm the effectiveness of multi-LLM pipelines in automating domain-specific 3D scene generation with improved reliability and precision. Future work will explore expanding the asset hierarchy, incorporating real-time generation, and adapting the pipeline to other simulation domains beyond agriculture.",
      "authors": [
        "Arafa Yoncalik",
        "Wouter Jansen",
        "Nico Huebel",
        "Mohammad Hasan Rahmani",
        "Jan Steckel"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-12T08:33:01Z",
      "updated": "2026-02-12T08:33:01Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11706v1",
      "abs_url": "http://arxiv.org/abs/2602.11706v1",
      "summary": "利用多LLM流水线从自然语言提示生成农业模拟环境的3D场景，提高效率和精度。",
      "key_contributions": [
        "提出了一种模块化的多LLM流水线用于生成农业3D模拟环境。",
        "结合了3D资产检索、领域知识注入和代码生成技术。",
        "采用混合策略优化LLM，包括few-shot prompting, RAG, finetuning和validation。"
      ],
      "methodology": "构建多LLM流水线，利用LLM生成Unreal引擎代码，并采用RAG和微调等技术提升LLM性能，最后通过用户研究和专家对比评估。",
      "tags": [
        "LLM",
        "3D Scene Generation",
        "Agricultural Simulation"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "论文利用LLM构建agent进行3D场景生成，具有高度相关性。",
      "analyzed_at": "2026-02-13T07:01:56.355940",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11678v1",
      "title": "Beyond Pixels: Vector-to-Graph Transformation for Reliable Schematic Auditing",
      "abstract": "Multimodal Large Language Models (MLLMs) have shown remarkable progress in visual understanding, yet they suffer from a critical limitation: structural blindness. Even state-of-the-art models fail to capture topology and symbolic logic in engineering schematics, as their pixel-driven paradigm discards the explicit vector-defined relations needed for reasoning. To overcome this, we propose a Vector-to-Graph (V2G) pipeline that converts CAD diagrams into property graphs where nodes represent components and edges encode connectivity, making structural dependencies explicit and machine-auditable. On a diagnostic benchmark of electrical compliance checks, V2G yields large accuracy gains across all error categories, while leading MLLMs remain near chance level. These results highlight the systemic inadequacy of pixel-based methods and demonstrate that structure-aware representations provide a reliable path toward practical deployment of multimodal AI in engineering domains. To facilitate further research, we release our benchmark and implementation at https://github.com/gm-embodied/V2G-Audit.",
      "authors": [
        "Chengwei Ma",
        "Zhen Tian",
        "Zhou Zhou",
        "Zhixian Xu",
        "Xiaowei Zhu",
        "Xia Hua",
        "Si Shi",
        "F. Richard Yu"
      ],
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T07:50:49Z",
      "updated": "2026-02-12T07:50:49Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11678v1",
      "abs_url": "http://arxiv.org/abs/2602.11678v1",
      "summary": "提出Vector-to-Graph方法，解决MLLM在工程图审核中结构盲视问题，提升审核准确率。",
      "key_contributions": [
        "提出Vector-to-Graph (V2G) 转换方法，将CAD图转换为属性图",
        "证明了像素方法在工程图理解上的局限性",
        "构建电气合规性检查诊断基准并开源"
      ],
      "methodology": "将CAD图转换为属性图，节点表示组件，边表示连接性，使结构依赖关系显式化并可审计。",
      "tags": [
        "Multimodal Learning",
        "Graph Representation",
        "Engineering Schematics",
        "CAD",
        "Reasoning"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注MLLM在视觉理解中的结构盲视问题，并提出解决方案，与多模态学习高度相关。",
      "analyzed_at": "2026-02-13T07:01:58.227556",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11672v1",
      "title": "U-Net with Hadamard Transform and DCT Latent Spaces for Next-day Wildfire Spread Prediction",
      "abstract": "We developed a lightweight and computationally efficient tool for next-day wildfire spread prediction using multimodal satellite data as input. The deep learning model, which we call Transform Domain Fusion UNet (TD-FusionUNet), incorporates trainable Hadamard Transform and Discrete Cosine Transform layers that apply two-dimensional transforms, enabling the network to capture essential \"frequency\" components in orthogonalized latent spaces. Additionally, we introduce custom preprocessing techniques, including random margin cropping and a Gaussian mixture model, to enrich the representation of the sparse pre-fire masks and enhance the model's generalization capability. The TD-FusionUNet is evaluated on two datasets which are the Next-Day Wildfire Spread dataset released by Google Research in 2023, and WildfireSpreadTS dataset. Our proposed TD-FusionUNet achieves an F1 score of 0.591 with 370k parameters, outperforming the UNet baseline using ResNet18 as the encoder reported in the WildfireSpreadTS dataset while using substantially fewer parameters. These results show that the proposed latent space fusion model balances accuracy and efficiency under a lightweight setting, making it suitable for real time wildfire prediction applications in resource limited environments.",
      "authors": [
        "Yingyi Luo",
        "Shuaiang Rong",
        "Adam Watts",
        "Ahmet Enis Cetin"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-12T07:45:53Z",
      "updated": "2026-02-12T07:45:53Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11672v1",
      "abs_url": "http://arxiv.org/abs/2602.11672v1",
      "summary": "TD-FusionUNet模型利用哈达玛变换和DCT进行野火蔓延预测，在精度和效率间取得平衡。",
      "key_contributions": [
        "提出TD-FusionUNet模型，融合哈达玛变换和DCT",
        "引入随机边缘裁剪和高斯混合模型预处理技术",
        "在WildfireSpreadTS数据集上优于UNet ResNet18基线"
      ],
      "methodology": "使用深度学习模型TD-FusionUNet，结合可训练的变换层，从多模态卫星数据预测次日野火蔓延。",
      "tags": [
        "野火预测",
        "U-Net",
        "哈达玛变换",
        "离散余弦变换",
        "多模态学习"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 7,
      "relevance_reason": "模型使用多模态卫星数据作为输入进行预测，属于多模态学习的应用。",
      "analyzed_at": "2026-02-13T07:02:00.227101",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11666v1",
      "title": "PhyNiKCE: A Neurosymbolic Agentic Framework for Autonomous Computational Fluid Dynamics",
      "abstract": "The deployment of autonomous agents for Computational Fluid Dynamics (CFD), is critically limited by the probabilistic nature of Large Language Models (LLMs), which struggle to enforce the strict conservation laws and numerical stability required for physics-based simulations. Reliance on purely semantic Retrieval Augmented Generation (RAG) often leads to \"context poisoning,\" where agents generate linguistically plausible but physically invalid configurations due to a fundamental Semantic-Physical Disconnect. To bridge this gap, this work introduces PhyNiKCE (Physical and Numerical Knowledgeable Context Engineering), a neurosymbolic agentic framework for trustworthy engineering. Unlike standard black-box agents, PhyNiKCE decouples neural planning from symbolic validation. It employs a Symbolic Knowledge Engine that treats simulation setup as a Constraint Satisfaction Problem, rigidly enforcing physical constraints via a Deterministic RAG Engine with specialized retrieval strategies for solvers, turbulence models, and boundary conditions. Validated through rigorous OpenFOAM experiments on practical, non-tutorial CFD tasks using Gemini-2.5-Pro/Flash, PhyNiKCE demonstrates a 96% relative improvement over state-of-the-art baselines. Furthermore, by replacing trial-and-error with knowledge-driven initialization, the framework reduced autonomous self-correction loops by 59% while simultaneously lowering LLM token consumption by 17%. These results demonstrate that decoupling neural generation from symbolic constraint enforcement significantly enhances robustness and efficiency. While validated on CFD, this architecture offers a scalable, auditable paradigm for Trustworthy Artificial Intelligence in broader industrial automation.",
      "authors": [
        "E Fan",
        "Lisong Shi",
        "Zhengtong Li",
        "Chih-yung Wen"
      ],
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-12T07:37:56Z",
      "updated": "2026-02-12T07:37:56Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11666v1",
      "abs_url": "http://arxiv.org/abs/2602.11666v1",
      "summary": "PhyNiKCE通过神经符号框架提升CFD自主agent的物理约束可靠性。",
      "key_contributions": [
        "提出了PhyNiKCE框架，解耦神经规划和符号验证",
        "使用确定性RAG引擎，专门用于求解器、湍流模型和边界条件检索",
        "实验证明PhyNiKCE优于现有技术，并降低了token消耗"
      ],
      "methodology": "构建神经符号agentic框架，将CFD设置视为约束满足问题，通过符号知识引擎严格执行物理约束。",
      "tags": [
        "CFD",
        "Neurosymbolic AI",
        "AI Agent",
        "Constraint Satisfaction",
        "RAG"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于利用agent解决CFD问题，并提出了新的agent框架PhyNiKCE。",
      "analyzed_at": "2026-02-13T07:02:02.403942",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11658v1",
      "title": "EmoSpace: Fine-Grained Emotion Prototype Learning for Immersive Affective Content Generation",
      "abstract": "Emotion is important for creating compelling virtual reality (VR) content. Although some generative methods have been applied to lower the barrier to creating emotionally rich content, they fail to capture the nuanced emotional semantics and the fine-grained control essential for immersive experiences. To address these limitations, we introduce EmoSpace, a novel framework for emotion-aware content generation that learns dynamic, interpretable emotion prototypes through vision-language alignment. We employ a hierarchical emotion representation with rich learnable prototypes that evolve during training, enabling fine-grained emotional control without requiring explicit emotion labels. We develop a controllable generation pipeline featuring multi-prototype guidance, temporal blending, and attention reweighting that supports diverse applications, including emotional image outpainting, stylized generation, and emotional panorama generation for VR environments. Our experiments demonstrate the superior performance of EmoSpace over existing methods in both qualitative and quantitative evaluations. Additionally, we present a comprehensive user study investigating how VR environments affect emotional perception compared to desktop settings. Our work facilitates immersive visual content generation with fine-grained emotion control and supports applications like therapy, education, storytelling, artistic creation, and cultural preservation. Code and models will be made publicly available.",
      "authors": [
        "Bingyuan Wang",
        "Xingbei Chen",
        "Zongyang Qiu",
        "Linping Yuan",
        "Zeyu Wang"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-12T07:23:41Z",
      "updated": "2026-02-12T07:23:41Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11658v1",
      "abs_url": "http://arxiv.org/abs/2602.11658v1",
      "summary": "EmoSpace提出了一种基于视觉-语言对齐的细粒度情感原型学习框架，用于生成沉浸式情感内容。",
      "key_contributions": [
        "提出EmoSpace框架，实现情感感知内容生成",
        "引入动态、可解释的情感原型，实现细粒度情感控制",
        "用户研究验证VR环境对情感感知的影响"
      ],
      "methodology": "采用分层情感表示，学习动态情感原型，通过多原型引导、时间融合和注意力重加权实现可控生成。",
      "tags": [
        "情感生成",
        "虚拟现实",
        "视觉-语言对齐",
        "内容生成"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心是多模态情感内容生成，利用视觉和语言信息，高度相关。",
      "analyzed_at": "2026-02-13T07:02:04.075706",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11656v1",
      "title": "SToRM: Supervised Token Reduction for Multi-modal LLMs toward efficient end-to-end autonomous driving",
      "abstract": "In autonomous driving, end-to-end (E2E) driving systems that predict control commands directly from sensor data have achieved significant advancements. For safe driving in unexpected scenarios, these systems may additionally rely on human interventions such as natural language instructions. Using a multi-modal large language model (MLLM) facilitates human-vehicle interaction and can improve performance in such scenarios. However, this approach requires substantial computational resources due to its reliance on an LLM and numerous visual tokens from sensor inputs, which are limited in autonomous vehicles. Many MLLM studies have explored reducing visual tokens, but often suffer end-task performance degradation compared to using all tokens.   To enable efficient E2E driving while maintaining performance comparable to using all tokens, this paper proposes the first Supervised Token Reduction framework for multi-modal LLMs (SToRM). The proposed framework consists of three key elements. First, a lightweight importance predictor with short-term sliding windows estimates token importance scores. Second, a supervised training approach uses an auxiliary path to obtain pseudo-supervision signals from an all-token LLM pass. Third, an anchor-context merging module partitions tokens into anchors and context tokens, and merges context tokens into relevant anchors to reduce redundancy while minimizing information loss. Experiments on the LangAuto benchmark show that SToRM outperforms state-of-the-art E2E driving MLLMs under the same reduced-token budget, maintaining all-token performance while reducing computational cost by up to 30x.",
      "authors": [
        "Seo Hyun Kim",
        "Jin Bok Park",
        "Do Yeon Koo",
        "Ho Gun Park",
        "Il Yong Chun"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-12T07:21:24Z",
      "updated": "2026-02-12T07:21:24Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11656v1",
      "abs_url": "http://arxiv.org/abs/2602.11656v1",
      "summary": "SToRM通过监督式Token缩减，在保证性能的同时显著降低多模态LLM在自动驾驶中的计算成本。",
      "key_contributions": [
        "提出Supervised Token Reduction框架SToRM",
        "设计轻量级的重要性预测器",
        "引入anchor-context merging模块"
      ],
      "methodology": "使用重要性预测器估计token重要性，通过监督学习获取伪标签，利用anchor-context合并减少冗余。",
      "tags": [
        "自动驾驶",
        "多模态LLM",
        "Token缩减",
        "计算效率"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于利用多模态LLM处理自动驾驶任务，并优化其效率。",
      "analyzed_at": "2026-02-13T07:02:05.702917",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.11655v1",
      "title": "LoRA-based Parameter-Efficient LLMs for Continuous Learning in Edge-based Malware Detection",
      "abstract": "The proliferation of edge devices has created an urgent need for security solutions capable of detecting malware in real time while operating under strict computational and memory constraints. Recently, Large Language Models (LLMs) have demonstrated remarkable capabilities in recognizing complex patterns, yet their deployment on edge devices remains impractical due to their resource demands. However, in edge malware detection, static or centrally retrained models degrade under evolving threats and heterogeneous traffic; locally trained models become siloed and fail to transfer across domains. To overcome these limitations, in this paper, we present a continuous learning architecture for edge-based malware detection that combines local adaptation on each device with global knowledge sharing through parameter-efficient LoRA adapters. Lightweight transformer models (DistilBERT, DistilGPT-2, TinyT5) run on edge nodes and are incrementally fine-tuned on device-specific traffic; only the resulting LoRA modules are aggregated by a lightweight coordinator and redistributed, enabling cross-device generalization without exchanging raw data. We evaluate on two public IoT security datasets, Edge-IIoTset and TON-IoT, under multi-round learning to simulate evolving threats. Compared to isolated fine-tuning, the LoRA-based exchange yields up to 20-25% accuracy gains when models encounter previously unseen attacks from another domain, while maintaining stable loss and F1 across rounds. LoRA adds less than 1% to model size (~0.6-1.8 MB), making updates practical for constrained edge hardware.",
      "authors": [
        "Christian Rondanini",
        "Barbara Carminati",
        "Elena Ferrari",
        "Niccolò Lardo",
        "Ashish Kundu"
      ],
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.CR",
      "published": "2026-02-12T07:20:26Z",
      "updated": "2026-02-12T07:20:26Z",
      "pdf_url": "https://arxiv.org/pdf/2602.11655v1",
      "abs_url": "http://arxiv.org/abs/2602.11655v1",
      "summary": "提出一种基于LoRA的参数高效联邦学习框架，用于边缘设备上的恶意软件持续检测。",
      "key_contributions": [
        "提出基于LoRA的参数高效的边缘设备恶意软件检测持续学习架构。",
        "实现了边缘设备上的本地模型自适应和全局知识共享。",
        "实验证明该方法在应对未知攻击时具有更高的准确性和稳定性。"
      ],
      "methodology": "使用轻量级Transformer模型在边缘节点进行微调，仅聚合和重新分配LoRA模块，实现跨设备泛化。",
      "tags": [
        "LoRA",
        "联邦学习",
        "恶意软件检测",
        "边缘计算"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 5,
      "relevance_reason": "虽然目标是边缘计算，但涉及参数高效的微调和知识共享，与agent tuning相关。",
      "analyzed_at": "2026-02-13T07:02:07.678420",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    }
  ],
  "fetch_time": "2026-02-13T07:02:07.678658"
}