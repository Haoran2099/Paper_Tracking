{
  "date": "2026-02-20",
  "papers": [
    {
      "arxiv_id": "2602.17665v1",
      "title": "OpenEarthAgent: A Unified Framework for Tool-Augmented Geospatial Agents",
      "abstract": "Recent progress in multimodal reasoning has enabled agents that can interpret imagery, connect it with language, and perform structured analytical tasks. Extending such capabilities to the remote sensing domain remains challenging, as models must reason over spatial scale, geographic structures, and multispectral indices while maintaining coherent multi-step logic. To bridge this gap, OpenEarthAgent introduces a unified framework for developing tool-augmented geospatial agents trained on satellite imagery, natural-language queries, and detailed reasoning traces. The training pipeline relies on supervised fine-tuning over structured reasoning trajectories, aligning the model with verified multistep tool interactions across diverse analytical contexts. The accompanying corpus comprises 14,538 training and 1,169 evaluation instances, with more than 100K reasoning steps in the training split and over 7K reasoning steps in the evaluation split. It spans urban, environmental, disaster, and infrastructure domains, and incorporates GIS-based operations alongside index analyses such as NDVI, NBR, and NDBI. Grounded in explicit reasoning traces, the learned agent demonstrates structured reasoning, stable spatial understanding, and interpretable behaviour through tool-driven geospatial interactions across diverse conditions. We report consistent improvements over a strong baseline and competitive performance relative to recent open and closed-source models.",
      "authors": [
        "Akashah Shabbir",
        "Muhammad Umer Sheikh",
        "Muhammad Akhtar Munir",
        "Hiyam Debary",
        "Mustansar Fiaz",
        "Muhammad Zaigham Zaheer",
        "Paolo Fraccaro",
        "Fahad Shahbaz Khan",
        "Muhammad Haris Khan",
        "Xiao Xiang Zhu",
        "Salman Khan"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-19T18:59:54Z",
      "updated": "2026-02-19T18:59:54Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17665v1",
      "abs_url": "http://arxiv.org/abs/2602.17665v1",
      "summary": "OpenEarthAgent提出了一种工具增强的地理空间智能体框架，用于处理卫星图像和自然语言查询。",
      "key_contributions": [
        "构建包含大量地理空间推理轨迹的数据集",
        "提出统一的框架用于训练工具增强的地理空间智能体",
        "验证了该框架在多种地理空间分析任务上的有效性"
      ],
      "methodology": "基于监督微调，使用结构化的推理轨迹来训练地理空间智能体，使其能够进行多步工具交互。",
      "tags": [
        "地理空间智能体",
        "工具增强",
        "卫星图像",
        "多模态推理"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注于构建智能体来解决地理空间问题，与AI Agent类别高度相关。",
      "analyzed_at": "2026-02-20T06:55:58.567013",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17664v1",
      "title": "Sink-Aware Pruning for Diffusion Language Models",
      "abstract": "Diffusion Language Models (DLMs) incur high inference cost due to iterative denoising, motivating efficient pruning. Existing pruning heuristics largely inherited from autoregressive (AR) LLMs, typically preserve attention sink tokens because AR sinks serve as stable global anchors. We show that this assumption does not hold for DLMs: the attention-sink position exhibits substantially higher variance over the full generation trajectory (measured by how the dominant sink locations shift across timesteps), indicating that sinks are often transient and less structurally essential than in AR models. Based on this observation, we propose ${\\bf \\texttt{Sink-Aware Pruning}}$, which automatically identifies and prunes unstable sinks in DLMs (prior studies usually keep sinks for AR LLMs). Without retraining, our method achieves a better quality-efficiency trade-off and outperforms strong prior pruning baselines under matched compute. Our code is available at https://github.com/VILA-Lab/Sink-Aware-Pruning.",
      "authors": [
        "Aidar Myrzakhan",
        "Tianyi Li",
        "Bowei Guo",
        "Shengkun Tang",
        "Zhiqiang Shen"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-19T18:59:50Z",
      "updated": "2026-02-19T18:59:50Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17664v1",
      "abs_url": "http://arxiv.org/abs/2602.17664v1",
      "summary": "针对扩散语言模型，提出了一种能够识别并剪枝不稳定注意力汇聚点的Sink-Aware剪枝方法，提升了推理效率。",
      "key_contributions": [
        "发现了扩散语言模型中注意力汇聚点的不稳定性，不同于自回归模型。",
        "提出了Sink-Aware Pruning方法，自动识别并剪枝不稳定的注意力汇聚点。",
        "实验表明，该方法在计算资源相当的情况下优于现有的剪枝基线。"
      ],
      "methodology": "通过分析扩散语言模型中注意力汇聚点的方差，识别不稳定的汇聚点，并采用剪枝策略去除这些点，以达到高效推理的目的。",
      "tags": [
        "Diffusion Language Model",
        "Pruning",
        "Attention Sink",
        "Model Compression"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "论文核心在于优化DLM推理效率，涉及模型推理优化，与reasoning类别高度相关。",
      "analyzed_at": "2026-02-20T06:56:00.627311",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17663v1",
      "title": "CLEF HIPE-2026: Evaluating Accurate and Efficient Person-Place Relation Extraction from Multilingual Historical Texts",
      "abstract": "HIPE-2026 is a CLEF evaluation lab dedicated to person-place relation extraction from noisy, multilingual historical texts. Building on the HIPE-2020 and HIPE-2022 campaigns, it extends the series toward semantic relation extraction by targeting the task of identifying person--place associations in multiple languages and time periods. Systems are asked to classify relations of two types - $at$ (\"Has the person ever been at this place?\") and $isAt$ (\"Is the person located at this place around publication time?\") - requiring reasoning over temporal and geographical cues. The lab introduces a three-fold evaluation profile that jointly assesses accuracy, computational efficiency, and domain generalization. By linking relation extraction to large-scale historical data processing, HIPE-2026 aims to support downstream applications in knowledge-graph construction, historical biography reconstruction, and spatial analysis in digital humanities.",
      "authors": [
        "Juri Opitz",
        "Corina Raclé",
        "Emanuela Boros",
        "Andrianos Michail",
        "Matteo Romanello",
        "Maud Ehrmann",
        "Simon Clematide"
      ],
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-19T18:59:44Z",
      "updated": "2026-02-19T18:59:44Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17663v1",
      "abs_url": "http://arxiv.org/abs/2602.17663v1",
      "summary": "HIPE-2026评估多语言历史文本中准确高效的Person-Place关系抽取，支持历史数据处理下游应用。",
      "key_contributions": [
        "构建Person-Place关系抽取评估数据集",
        "评估准确率、计算效率和领域泛化能力",
        "推动知识图谱构建、历史传记重建和空间分析等应用"
      ],
      "methodology": "通过CLEF评估实验室，提供多语言历史文本，要求系统分类person-place的$at$和$isAt$关系，评估准确性和效率。",
      "tags": [
        "关系抽取",
        "多语言",
        "历史文本",
        "知识图谱"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 6,
      "relevance_reason": "关系抽取和推理能力有一定的关联，可以用于支持知识推理。",
      "analyzed_at": "2026-02-20T06:56:02.433801",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17659v1",
      "title": "When Vision Overrides Language: Evaluating and Mitigating Counterfactual Failures in VLAs",
      "abstract": "Vision-Language-Action models (VLAs) promise to ground language instructions in robot control, yet in practice often fail to faithfully follow language. When presented with instructions that lack strong scene-specific supervision, VLAs suffer from counterfactual failures: they act based on vision shortcuts induced by dataset biases, repeatedly executing well-learned behaviors and selecting objects frequently seen during training regardless of language intent. To systematically study it, we introduce LIBERO-CF, the first counterfactual benchmark for VLAs that evaluates language following capability by assigning alternative instructions under visually plausible LIBERO layouts. Our evaluation reveals that counterfactual failures are prevalent yet underexplored across state-of-the-art VLAs. We propose Counterfactual Action Guidance (CAG), a simple yet effective dual-branch inference scheme that explicitly regularizes language conditioning in VLAs. CAG combines a standard VLA policy with a language-unconditioned Vision-Action (VA) module, enabling counterfactual comparison during action selection. This design reduces reliance on visual shortcuts, improves robustness on under-observed tasks, and requires neither additional demonstrations nor modifications to existing architectures or pretrained models. Extensive experiments demonstrate its plug-and-play integration across diverse VLAs and consistent improvements. For example, on LIBERO-CF, CAG improves $π_{0.5}$ by 9.7% in language following accuracy and 3.6% in task success on under-observed tasks using a training-free strategy, with further gains of 15.5% and 8.5%, respectively, when paired with a VA model. In real-world evaluations, CAG reduces counterfactual failures of 9.4% and improves task success by 17.2% on average.",
      "authors": [
        "Yu Fang",
        "Yuchun Feng",
        "Dong Jing",
        "Jiaqi Liu",
        "Yue Yang",
        "Zhenyu Wei",
        "Daniel Szafir",
        "Mingyu Ding"
      ],
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-19T18:59:20Z",
      "updated": "2026-02-19T18:59:20Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17659v1",
      "abs_url": "http://arxiv.org/abs/2602.17659v1",
      "summary": "针对VLA中视觉偏见导致的counterfactual failures，提出了LIBERO-CF基准和CAG缓解方法。",
      "key_contributions": [
        "提出了LIBERO-CF，一个评估VLA counterfactual failures的基准。",
        "揭示了现有VLA模型中counterfactual failures的普遍性。",
        "提出了Counterfactual Action Guidance (CAG) 方法，用于缓解视觉偏见。"
      ],
      "methodology": "提出CAG，一个双分支推理框架，结合标准VLA策略和无语言条件的VA模块，通过counterfactual比较来选择动作。",
      "tags": [
        "VLA",
        "机器人",
        "视觉语言",
        "Counterfactual",
        "Action Guidance"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注视觉语言行为模型，以及如何解决视觉偏见问题。",
      "analyzed_at": "2026-02-20T06:56:04.314600",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17655v1",
      "title": "What Language is This? Ask Your Tokenizer",
      "abstract": "Language Identification (LID) is an important component of many multilingual natural language processing pipelines, where it facilitates corpus curation, training data analysis, and cross-lingual evaluation of large language models. Despite near-perfect performance on high-resource languages, existing systems remain brittle in low-resource and closely related language settings. We introduce UniLID, a simple and efficient LID method based on the UnigramLM tokenization algorithm, leveraging its probabilistic framing, parameter estimation technique and inference strategy. In short, we learn language-conditional unigram distributions over a shared tokenizer vocabulary but treat segmentation as a language-specific phenomenon. Our formulation is data- and compute-efficient, supports incremental addition of new languages without retraining existing models, and can naturally be integrated into existing language model tokenization pipelines. Empirical evaluations against widely used baselines, including fastText, GlotLID, and CLD3, show that UniLID achieves competitive performance on standard benchmarks, substantially improves sample efficiency in low-resource settings - surpassing 70% accuracy with as few as five labeled samples per language - and delivers large gains on fine-grained dialect identification.",
      "authors": [
        "Clara Meister",
        "Ahmetcan Yavuz",
        "Pietro Lesci",
        "Tiago Pimentel"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-19T18:58:39Z",
      "updated": "2026-02-19T18:58:39Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17655v1",
      "abs_url": "http://arxiv.org/abs/2602.17655v1",
      "summary": "UniLID提出一种基于UnigramLM的语言识别方法，在低资源语言和方言识别上表现出色。",
      "key_contributions": [
        "提出UniLID语言识别方法",
        "利用UnigramLM的概率框架进行语言识别",
        "在低资源语言和方言识别上取得显著提升"
      ],
      "methodology": "UniLID基于UnigramLM，学习语言条件下的unigram分布，并将分词视为特定语言的现象。",
      "tags": [
        "Language Identification",
        "UnigramLM",
        "Low-Resource Languages",
        "Dialect Identification"
      ],
      "assigned_category": "agent",
      "relevance_score": 6,
      "relevance_reason": "语言识别作为工具的一部分，可以服务于agent在多语言环境下的操作。",
      "analyzed_at": "2026-02-20T06:56:06.159483",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17654v1",
      "title": "Mine and Refine: Optimizing Graded Relevance in E-commerce Search Retrieval",
      "abstract": "We propose a two-stage \"Mine and Refine\" contrastive training framework for semantic text embeddings to enhance multi-category e-commerce search retrieval. Large scale e-commerce search demands embeddings that generalize to long tail, noisy queries while adhering to scalable supervision compatible with product and policy constraints. A practical challenge is that relevance is often graded: users accept substitutes or complements beyond exact matches, and production systems benefit from clear separation of similarity scores across these relevance strata for stable hybrid blending and thresholding. To obtain scalable policy consistent supervision, we fine-tune a lightweight LLM on human annotations under a three-level relevance guideline and further reduce residual noise via engagement driven auditing. In Stage 1, we train a multilingual Siamese two-tower retriever with a label aware supervised contrastive objective that shapes a robust global semantic space. In Stage 2, we mine hard samples via ANN and re-annotate them with the policy aligned LLM, and introduce a multi-class extension of circle loss that explicitly sharpens similarity boundaries between relevance levels, to further refine and enrich the embedding space. Robustness is additionally improved through additive spelling augmentation and synthetic query generation. Extensive offline evaluations and production A/B tests show that our framework improves retrieval relevance and delivers statistically significant gains in engagement and business impact.",
      "authors": [
        "Jiaqi Xi",
        "Raghav Saboo",
        "Luming Chen",
        "Martin Wang",
        "Sudeep Das"
      ],
      "categories": [
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "published": "2026-02-19T18:56:36Z",
      "updated": "2026-02-19T18:56:36Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17654v1",
      "abs_url": "http://arxiv.org/abs/2602.17654v1",
      "summary": "提出一种用于电商搜索的分级相关性优化的“Mine and Refine”对比学习框架，提升检索效果。",
      "key_contributions": [
        "提出“Mine and Refine”对比学习框架",
        "引入基于LLM的策略一致性标注和噪音降低",
        "设计多类别circle loss扩展，锐化相似度边界"
      ],
      "methodology": "两阶段训练：第一阶段Siamese网络全局语义空间学习，第二阶段挖掘难样本并使用多类别circle loss细化。",
      "tags": [
        "电商搜索",
        "对比学习",
        "语义嵌入",
        "信息检索",
        "分级相关性"
      ],
      "assigned_category": "memory",
      "relevance_score": 8,
      "relevance_reason": "该论文通过检索优化来提升电商搜索体验，与RAG应用场景高度相关。",
      "analyzed_at": "2026-02-20T06:56:08.191585",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17645v1",
      "title": "Pushing the Frontier of Black-Box LVLM Attacks via Fine-Grained Detail Targeting",
      "abstract": "Black-box adversarial attacks on Large Vision-Language Models (LVLMs) are challenging due to missing gradients and complex multimodal boundaries. While prior state-of-the-art transfer-based approaches like M-Attack perform well using local crop-level matching between source and target images, we find this induces high-variance, nearly orthogonal gradients across iterations, violating coherent local alignment and destabilizing optimization. We attribute this to (i) ViT translation sensitivity that yields spike-like gradients and (ii) structural asymmetry between source and target crops. We reformulate local matching as an asymmetric expectation over source transformations and target semantics, and build a gradient-denoising upgrade to M-Attack. On the source side, Multi-Crop Alignment (MCA) averages gradients from multiple independently sampled local views per iteration to reduce variance. On the target side, Auxiliary Target Alignment (ATA) replaces aggressive target augmentation with a small auxiliary set from a semantically correlated distribution, producing a smoother, lower-variance target manifold. We further reinterpret momentum as Patch Momentum, replaying historical crop gradients; combined with a refined patch-size ensemble (PE+), this strengthens transferable directions. Together these modules form M-Attack-V2, a simple, modular enhancement over M-Attack that substantially improves transfer-based black-box attacks on frontier LVLMs: boosting success rates on Claude-4.0 from 8% to 30%, Gemini-2.5-Pro from 83% to 97%, and GPT-5 from 98% to 100%, outperforming prior black-box LVLM attacks. Code and data are publicly available at: https://github.com/vila-lab/M-Attack-V2.",
      "authors": [
        "Xiaohan Zhao",
        "Zhaoyi Li",
        "Yaxin Luo",
        "Jiacheng Cui",
        "Zhiqiang Shen"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T18:54:32Z",
      "updated": "2026-02-19T18:54:32Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17645v1",
      "abs_url": "http://arxiv.org/abs/2602.17645v1",
      "summary": "该论文提出了M-Attack-V2，通过精细化细节攻击显著提升了黑盒LVLM对抗攻击的成功率。",
      "key_contributions": [
        "提出了Multi-Crop Alignment (MCA)降低梯度方差",
        "提出了Auxiliary Target Alignment (ATA)构建平滑目标流形",
        "提出了Patch Momentum和patch-size ensemble增强迁移方向"
      ],
      "methodology": "通过改进局部匹配策略，利用MCA降低源图像梯度方差，ATA构建平滑目标流形，并结合Patch Momentum，提升黑盒对抗攻击的迁移性。",
      "tags": [
        "LVLM",
        "对抗攻击",
        "黑盒攻击",
        "迁移学习"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文专注于视觉-语言模型的对抗攻击，是多模态研究领域的核心问题。",
      "analyzed_at": "2026-02-20T06:56:10.728303",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17642v1",
      "title": "A.R.I.S.: Automated Recycling Identification System for E-Waste Classification Using Deep Learning",
      "abstract": "Traditional electronic recycling processes suffer from significant resource loss due to inadequate material separation and identification capabilities, limiting material recovery. We present A.R.I.S. (Automated Recycling Identification System), a low-cost, portable sorter for shredded e-waste that addresses this efficiency gap. The system employs a YOLOx model to classify metals, plastics, and circuit boards in real time, achieving low inference latency with high detection accuracy. Experimental evaluation yielded 90% overall precision, 82.2% mean average precision (mAP), and 84% sortation purity. By integrating deep learning with established sorting methods, A.R.I.S. enhances material recovery efficiency and lowers barriers to advanced recycling adoption. This work complements broader initiatives in extending product life cycles, supporting trade-in and recycling programs, and reducing environmental impact across the supply chain.",
      "authors": [
        "Dhruv Talwar",
        "Harsh Desai",
        "Wendong Yin",
        "Goutam Mohanty",
        "Rafael Reveles"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T18:54:06Z",
      "updated": "2026-02-19T18:54:06Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17642v1",
      "abs_url": "http://arxiv.org/abs/2602.17642v1",
      "summary": "A.R.I.S. 通过深度学习 YOLOx 模型，实现了高效的电子垃圾自动分类和回收。",
      "key_contributions": [
        "提出了基于 YOLOx 的电子垃圾自动分类系统 A.R.I.S.",
        "实现了金属、塑料、电路板的实时分类",
        "提高了电子垃圾的材料回收效率"
      ],
      "methodology": "使用 YOLOx 模型进行目标检测和分类，集成到低成本的电子垃圾分拣系统中，通过实验评估性能。",
      "tags": [
        "电子垃圾回收",
        "深度学习",
        "YOLOx",
        "目标检测",
        "自动分类"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 6,
      "relevance_reason": "涉及图像识别和分类，与多模态学习有一定关联。",
      "analyzed_at": "2026-02-20T06:56:12.437617",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17641v1",
      "title": "FAMOSE: A ReAct Approach to Automated Feature Discovery",
      "abstract": "Feature engineering remains a critical yet challenging bottleneck in machine learning, particularly for tabular data, as identifying optimal features from an exponentially large feature space traditionally demands substantial domain expertise. To address this challenge, we introduce FAMOSE (Feature AugMentation and Optimal Selection agEnt), a novel framework that leverages the ReAct paradigm to autonomously explore, generate, and refine features while integrating feature selection and evaluation tools within an agent architecture. To our knowledge, FAMOSE represents the first application of an agentic ReAct framework to automated feature engineering, especially for both regression and classification tasks. Extensive experiments demonstrate that FAMOSE is at or near the state-of-the-art on classification tasks (especially tasks with more than 10K instances, where ROC-AUC increases 0.23% on average), and achieves the state-of-the-art for regression tasks by reducing RMSE by 2.0% on average, while remaining more robust to errors than other algorithms. We hypothesize that FAMOSE's strong performance is because ReAct allows the LLM context window to record (via iterative feature discovery and evaluation steps) what features did or did not work. This is similar to a few-shot prompt and guides the LLM to invent better, more innovative features. Our work offers evidence that AI agents are remarkably effective in solving problems that require highly inventive solutions, such as feature engineering.",
      "authors": [
        "Keith Burghardt",
        "Jienan Liu",
        "Sadman Sakib",
        "Yuning Hao",
        "Bo Li"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T18:53:15Z",
      "updated": "2026-02-19T18:53:15Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17641v1",
      "abs_url": "http://arxiv.org/abs/2602.17641v1",
      "summary": "FAMOSE利用ReAct框架，自主进行特征工程，在表格数据上实现了自动化特征发现。",
      "key_contributions": [
        "首次将ReAct框架应用于自动化特征工程",
        "提出了自动特征增强和选择的智能体架构FAMOSE",
        "在回归和分类任务上取得了SOTA或接近SOTA的效果"
      ],
      "methodology": "构建基于ReAct范式的智能体，迭代探索、生成和优化特征，并集成特征选择和评估工具。",
      "tags": [
        "自动化特征工程",
        "ReAct",
        "AI Agent",
        "表格数据"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心是利用agent框架解决自动化特征工程问题，属于agent领域关键研究。",
      "analyzed_at": "2026-02-20T06:56:14.177368",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17636v1",
      "title": "CORAL: Correspondence Alignment for Improved Virtual Try-On",
      "abstract": "Existing methods for Virtual Try-On (VTON) often struggle to preserve fine garment details, especially in unpaired settings where accurate person-garment correspondence is required. These methods do not explicitly enforce person-garment alignment and fail to explain how correspondence emerges within Diffusion Transformers (DiTs). In this paper, we first analyze full 3D attention in DiT-based architecture and reveal that the person-garment correspondence critically depends on precise person-garment query-key matching within the full 3D attention. Building on this insight, we then introduce CORrespondence ALignment (CORAL), a DiT-based framework that explicitly aligns query-key matching with robust external correspondences. CORAL integrates two complementary components: a correspondence distillation loss that aligns reliable matches with person-garment attention, and an entropy minimization loss that sharpens the attention distribution. We further propose a VLM-based evaluation protocol to better reflect human preference. CORAL consistently improves over the baseline, enhancing both global shape transfer and local detail preservation. Extensive ablations validate our design choices.",
      "authors": [
        "Jiyoung Kim",
        "Youngjin Shin",
        "Siyoon Jin",
        "Dahyun Chung",
        "Jisu Nam",
        "Tongmin Kim",
        "Jongjae Park",
        "Hyeonwoo Kang",
        "Seungryong Kim"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-19T18:50:12Z",
      "updated": "2026-02-19T18:50:12Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17636v1",
      "abs_url": "http://arxiv.org/abs/2602.17636v1",
      "summary": "CORAL通过显式对齐人-物对应关系提升虚拟试穿效果，改善细节保留。",
      "key_contributions": [
        "分析了Diffusion Transformer中3D attention的对应关系",
        "提出了Correspondence Alignment (CORAL) 框架",
        "提出了基于VLM的评估协议"
      ],
      "methodology": "CORAL通过对应关系蒸馏损失对齐注意力，并利用熵最小化损失锐化注意力分布，从而提升虚拟试穿效果。",
      "tags": [
        "Virtual Try-On",
        "Diffusion Transformer",
        "Correspondence Alignment",
        "Attention",
        "VLM"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 8,
      "relevance_reason": "论文核心是视觉与文本的结合，属于多模态学习领域。",
      "analyzed_at": "2026-02-20T06:56:15.843263",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17633v1",
      "title": "When to Trust the Cheap Check: Weak and Strong Verification for Reasoning",
      "abstract": "Reasoning with LLMs increasingly unfolds inside a broader verification loop. Internally, systems use cheap checks, such as self-consistency or proxy rewards, which we call weak verification. Externally, users inspect outputs and steer the model through feedback until results are trustworthy, which we call strong verification. These signals differ sharply in cost and reliability: strong verification can establish trust but is resource-intensive, while weak verification is fast and scalable but noisy and imperfect. We formalize this tension through weak--strong verification policies, which decide when to accept or reject based on weak verification and when to defer to strong verification. We introduce metrics capturing incorrect acceptance, incorrect rejection, and strong-verification frequency. Over population, we show that optimal policies admit a two-threshold structure and that calibration and sharpness govern the value of weak verifiers. Building on this, we develop an online algorithm that provably controls acceptance and rejection errors without assumptions on the query stream, the language model, or the weak verifier.",
      "authors": [
        "Shayan Kiyani",
        "Sima Noorani",
        "George Pappas",
        "Hamed Hassani"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T18:47:38Z",
      "updated": "2026-02-19T18:47:38Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17633v1",
      "abs_url": "http://arxiv.org/abs/2602.17633v1",
      "summary": "提出了一种弱强验证框架，用于平衡LLM推理的成本和可靠性，并设计在线算法控制错误。",
      "key_contributions": [
        "形式化弱强验证策略，平衡成本和可靠性",
        "提出衡量指标：错误接受率、错误拒绝率、强验证频率",
        "设计在线算法，无需假设控制接受和拒绝错误"
      ],
      "methodology": "通过定义弱强验证策略、设计评估指标，并在此基础上构建在线算法实现控制错误。",
      "tags": [
        "LLM",
        "Reasoning",
        "Verification",
        "Online Algorithm"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文直接关注LLM推理过程中的验证策略，解决推理可靠性问题。",
      "analyzed_at": "2026-02-20T06:56:19.732542",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17623v1",
      "title": "Unmasking the Factual-Conceptual Gap in Persian Language Models",
      "abstract": "While emerging Persian NLP benchmarks have expanded into pragmatics and politeness, they rarely distinguish between memorized cultural facts and the ability to reason about implicit social norms. We introduce DivanBench, a diagnostic benchmark focused on superstitions and customs, arbitrary, context-dependent rules that resist simple logical deduction. Through 315 questions across three task types (factual retrieval, paired scenario verification, and situational reasoning), we evaluate seven Persian LLMs and reveal three critical failures: most models exhibit severe acquiescence bias, correctly identifying appropriate behaviors but failing to reject clear violations; continuous Persian pretraining amplifies this bias rather than improving reasoning, often degrading the model's ability to discern contradictions; and all models show a 21\\% performance gap between retrieving factual knowledge and applying it in scenarios. These findings demonstrate that cultural competence requires more than scaling monolingual data, as current models learn to mimic cultural patterns without internalizing the underlying schemas.",
      "authors": [
        "Alireza Sakhaeirad",
        "Ali Ma'manpoosh",
        "Arshia Hemmat"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-19T18:42:46Z",
      "updated": "2026-02-19T18:42:46Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17623v1",
      "abs_url": "http://arxiv.org/abs/2602.17623v1",
      "summary": "该论文揭示了波斯语LLM在理解文化习俗和推理方面存在的严重不足。",
      "key_contributions": [
        "提出了DivanBench基准测试，用于评估波斯语LLM的文化常识推理能力",
        "揭示了现有波斯语LLM存在严重的顺从偏差，无法有效识别文化习俗违例",
        "发现连续预训练可能会加剧这种偏差，降低模型的推理能力"
      ],
      "methodology": "构建包含315个问题的DivanBench，包含事实检索、配对场景验证和情境推理三种任务，评估了7个波斯语LLM。",
      "tags": [
        "Persian Language Model",
        "Cultural Reasoning",
        "Benchmark",
        "Acquiescence Bias",
        "DivanBench"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注LLM的推理能力，特别是文化常识推理，属于核心相关研究。",
      "analyzed_at": "2026-02-20T06:56:21.706491",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17616v1",
      "title": "Stable Asynchrony: Variance-Controlled Off-Policy RL for LLMs",
      "abstract": "Reinforcement learning (RL) is widely used to improve large language models on reasoning tasks, and asynchronous RL training is attractive because it increases end-to-end throughput. However, for widely adopted critic-free policy-gradient methods such as REINFORCE and GRPO, high asynchrony makes the policy-gradient estimator markedly $\\textbf{higher variance}$: training on stale rollouts creates heavy-tailed importance ratios, causing a small fraction of samples to dominate updates. This amplification makes gradients noisy and learning unstable relative to matched on-policy training. Across math and general reasoning benchmarks, we find collapse is reliably predicted by effective sample size (ESS) and unstable gradient norms. Motivated by this diagnosis, we propose $\\textbf{V}$ariance $\\textbf{C}$ontrolled $\\textbf{P}$olicy $\\textbf{O}$ptimization ($\\textbf{VCPO}$), a general stabilization method for REINFORCE/GRPO-style algorithms that (i) scales learning rate based on effective sample size to dampen unreliable updates, and (ii) applies a closed-form minimum-variance baseline for the off-policy setting, avoiding an auxiliary value model and adding minimal overhead. Empirically, VCPO substantially improves robustness for asynchronous training across math, general reasoning, and tool-use tasks, outperforming a broad suite of baselines spanning masking/clipping stabilizers and algorithmic variants. This reduces long-context, multi-turn training time by 2.5$\\times$ while matching synchronous performance, demonstrating that explicit control of policy-gradient variance is key for reliable asynchronous RL at scale.",
      "authors": [
        "Luke Huang",
        "Zhuoyang Zhang",
        "Qinghao Hu",
        "Shang Yang",
        "Song Han"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T18:40:51Z",
      "updated": "2026-02-19T18:40:51Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17616v1",
      "abs_url": "http://arxiv.org/abs/2602.17616v1",
      "summary": "针对LLM异步RL训练中梯度方差过高问题，提出方差控制策略优化VCPO算法。",
      "key_contributions": [
        "诊断了异步RL中高方差梯度导致训练崩溃的问题，并与有效样本量ESS和梯度范数相关联。",
        "提出了VCPO算法，通过基于ESS调整学习率和最小方差基线来控制方差。",
        "实验表明VCPO显著提升了异步训练的鲁棒性，并在数学、推理和工具使用任务上优于现有方法。"
      ],
      "methodology": "提出VCPO算法，通过ESS调整学习率控制更新幅度，并使用闭式解最小方差基线降低方差。",
      "tags": [
        "LLM",
        "Reinforcement Learning",
        "Asynchronous Training",
        "Variance Reduction"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 9,
      "relevance_reason": "论文专注于优化Agent的训练过程，特别是异步RL环境下的稳定性和效率。",
      "analyzed_at": "2026-02-20T06:56:23.783010",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17608v1",
      "title": "Towards Anytime-Valid Statistical Watermarking",
      "abstract": "The proliferation of Large Language Models (LLMs) necessitates efficient mechanisms to distinguish machine-generated content from human text. While statistical watermarking has emerged as a promising solution, existing methods suffer from two critical limitations: the lack of a principled approach for selecting sampling distributions and the reliance on fixed-horizon hypothesis testing, which precludes valid early stopping. In this paper, we bridge this gap by developing the first e-value-based watermarking framework, Anchored E-Watermarking, that unifies optimal sampling with anytime-valid inference. Unlike traditional approaches where optional stopping invalidates Type-I error guarantees, our framework enables valid, anytime-inference by constructing a test supermartingale for the detection process. By leveraging an anchor distribution to approximate the target model, we characterize the optimal e-value with respect to the worst-case log-growth rate and derive the optimal expected stopping time. Our theoretical claims are substantiated by simulations and evaluations on established benchmarks, showing that our framework can significantly enhance sample efficiency, reducing the average token budget required for detection by 13-15% relative to state-of-the-art baselines.",
      "authors": [
        "Baihe Huang",
        "Eric Xu",
        "Kannan Ramchandran",
        "Jiantao Jiao",
        "Michael I. Jordan"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T18:32:26Z",
      "updated": "2026-02-19T18:32:26Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17608v1",
      "abs_url": "http://arxiv.org/abs/2602.17608v1",
      "summary": "提出了基于e-value的水印框架，实现了LLM生成内容的高效、可随时停止的统计水印检测。",
      "key_contributions": [
        "提出了基于e-value的Anchor E-Watermarking框架",
        "实现了最优采样与随时有效的推断的统一",
        "通过锚定分布逼近目标模型，推导出最优e-value和预期停止时间"
      ],
      "methodology": "构建检测过程的test supermartingale，利用锚定分布逼近目标模型，优化e-value和停止时间，并进行实验验证。",
      "tags": [
        "统计水印",
        "大语言模型",
        "可随时停止推断",
        "e-value"
      ],
      "assigned_category": "memory",
      "relevance_score": 8,
      "relevance_reason": "统计水印本质是推理过程的干预和验证，用于区分生成内容，高度相关。",
      "analyzed_at": "2026-02-20T06:56:26.002607",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17607v1",
      "title": "AutoNumerics: An Autonomous, PDE-Agnostic Multi-Agent Pipeline for Scientific Computing",
      "abstract": "PDEs are central to scientific and engineering modeling, yet designing accurate numerical solvers typically requires substantial mathematical expertise and manual tuning. Recent neural network-based approaches improve flexibility but often demand high computational cost and suffer from limited interpretability. We introduce \\texttt{AutoNumerics}, a multi-agent framework that autonomously designs, implements, debugs, and verifies numerical solvers for general PDEs directly from natural language descriptions. Unlike black-box neural solvers, our framework generates transparent solvers grounded in classical numerical analysis. We introduce a coarse-to-fine execution strategy and a residual-based self-verification mechanism. Experiments on 24 canonical and real-world PDE problems demonstrate that \\texttt{AutoNumerics} achieves competitive or superior accuracy compared to existing neural and LLM-based baselines, and correctly selects numerical schemes based on PDE structural properties, suggesting its viability as an accessible paradigm for automated PDE solving.",
      "authors": [
        "Jianda Du",
        "Youran Sun",
        "Haizhao Yang"
      ],
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.NA"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-19T18:31:52Z",
      "updated": "2026-02-19T18:31:52Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17607v1",
      "abs_url": "http://arxiv.org/abs/2602.17607v1",
      "summary": "AutoNumerics是一个自动设计、实现、调试和验证PDE数值求解器的多智能体框架。",
      "key_contributions": [
        "提出了一个自动化的PDE求解框架",
        "实现了从自然语言描述生成数值求解器",
        "采用了粗到精的执行策略和残差自验证机制"
      ],
      "methodology": "构建多智能体系统，利用自然语言描述生成数值求解器，并使用残差进行自验证。",
      "tags": [
        "PDE求解",
        "自动数值计算",
        "多智能体系统",
        "自然语言处理"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "该论文的核心在于使用多智能体框架自动生成PDE求解器。",
      "analyzed_at": "2026-02-20T06:56:27.538600",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17605v1",
      "title": "Adapting Actively on the Fly: Relevance-Guided Online Meta-Learning with Latent Concepts for Geospatial Discovery",
      "abstract": "In many real-world settings, such as environmental monitoring, disaster response, or public health, with costly and difficult data collection and dynamic environments, strategically sampling from unobserved regions is essential for efficiently uncovering hidden targets under tight resource constraints. Yet, sparse and biased geospatial ground truth limits the applicability of existing learning-based methods, such as reinforcement learning. To address this, we propose a unified geospatial discovery framework that integrates active learning, online meta-learning, and concept-guided reasoning. Our approach introduces two key innovations built on a shared notion of *concept relevance*, which captures how domain-specific factors influence target presence: a *concept-weighted uncertainty sampling strategy*, where uncertainty is modulated by learned relevance based on readily-available domain-specific concepts (e.g., land cover, source proximity); and a *relevance-aware meta-batch formation strategy* that promotes semantic diversity during online-meta updates, improving generalization in dynamic environments. Our experiments include testing on a real-world dataset of cancer-causing PFAS (Per- and polyfluoroalkyl substances) contamination, showcasing our method's reliability at uncovering targets with limited data and a varying environment.",
      "authors": [
        "Jowaria Khan",
        "Anindya Sarkar",
        "Yevgeniy Vorobeychik",
        "Elizabeth Bondi-Kelly"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-19T18:30:18Z",
      "updated": "2026-02-19T18:30:18Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17605v1",
      "abs_url": "http://arxiv.org/abs/2602.17605v1",
      "summary": "针对资源受限和动态环境下的地理空间发现，提出了一种融合主动学习、在线元学习和概念引导的框架。",
      "key_contributions": [
        "提出概念加权的不确定性采样策略",
        "提出相关性感知的元批次生成策略",
        "在真实世界PFAS污染数据集上验证方法的有效性"
      ],
      "methodology": "融合主动学习、在线元学习和概念引导，通过概念相关性指导采样和元批次生成，提升泛化能力。",
      "tags": [
        "主动学习",
        "在线元学习",
        "地理空间发现",
        "概念引导",
        "环境监测"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "涉及主动学习策略，可以被视为智能体在环境中的探索和学习。",
      "analyzed_at": "2026-02-20T06:56:29.402525",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17599v1",
      "title": "Art2Mus: Artwork-to-Music Generation via Visual Conditioning and Large-Scale Cross-Modal Alignment",
      "abstract": "Music generation has advanced markedly through multimodal deep learning, enabling models to synthesize audio from text and, more recently, from images. However, existing image-conditioned systems suffer from two fundamental limitations: (i) they are typically trained on natural photographs, limiting their ability to capture the richer semantic, stylistic, and cultural content of artworks; and (ii) most rely on an image-to-text conversion stage, using language as a semantic shortcut that simplifies conditioning but prevents direct visual-to-audio learning. Motivated by these gaps, we introduce ArtSound, a large-scale multimodal dataset of 105,884 artwork-music pairs enriched with dual-modality captions, obtained by extending ArtGraph and the Free Music Archive. We further propose ArtToMus, the first framework explicitly designed for direct artwork-to-music generation, which maps digitized artworks to music without image-to-text translation or language-based semantic supervision. The framework projects visual embeddings into the conditioning space of a latent diffusion model, enabling music synthesis guided solely by visual information. Experimental results show that ArtToMus generates musically coherent and stylistically consistent outputs that reflect salient visual cues of the source artworks. While absolute alignment scores remain lower than those of text-conditioned systems-as expected given the substantially increased difficulty of removing linguistic supervision-ArtToMus achieves competitive perceptual quality and meaningful cross-modal correspondence. This work establishes direct visual-to-music generation as a distinct and challenging research direction, and provides resources that support applications in multimedia art, cultural heritage, and AI-assisted creative practice. Code and dataset will be publicly released upon acceptance.",
      "authors": [
        "Ivan Rinaldi",
        "Matteo Mendula",
        "Nicola Fanelli",
        "Florence Levé",
        "Matteo Testi",
        "Giovanna Castellano",
        "Gennaro Vessio"
      ],
      "categories": [
        "cs.CV",
        "cs.MM",
        "cs.SD"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-19T18:23:58Z",
      "updated": "2026-02-19T18:23:58Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17599v1",
      "abs_url": "http://arxiv.org/abs/2602.17599v1",
      "summary": "提出ArtToMus框架，用于直接将艺术作品转化为音乐，无需文本转换。",
      "key_contributions": [
        "构建ArtSound数据集，包含艺术作品-音乐对",
        "提出ArtToMus框架，直接将视觉信息映射到音乐",
        "验证了视觉到音乐生成的可能性"
      ],
      "methodology": "构建大型多模态数据集，并使用潜在扩散模型将视觉嵌入投影到音乐生成空间。",
      "tags": [
        "音乐生成",
        "多模态学习",
        "艺术作品",
        "扩散模型"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注图像到音乐的跨模态生成，属于多模态学习的关键方向。",
      "analyzed_at": "2026-02-20T06:56:30.933946",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17594v1",
      "title": "AI Gamestore: Scalable, Open-Ended Evaluation of Machine General Intelligence with Human Games",
      "abstract": "Rigorously evaluating machine intelligence against the broad spectrum of human general intelligence has become increasingly important and challenging in this era of rapid technological advance. Conventional AI benchmarks typically assess only narrow capabilities in a limited range of human activity. Most are also static, quickly saturating as developers explicitly or implicitly optimize for them. We propose that a more promising way to evaluate human-like general intelligence in AI systems is through a particularly strong form of general game playing: studying how and how well they play and learn to play \\textbf{all conceivable human games}, in comparison to human players with the same level of experience, time, or other resources. We define a \"human game\" to be a game designed by humans for humans, and argue for the evaluative suitability of this space of all such games people can imagine and enjoy -- the \"Multiverse of Human Games\". Taking a first step towards this vision, we introduce the AI GameStore, a scalable and open-ended platform that uses LLMs with humans-in-the-loop to synthesize new representative human games, by automatically sourcing and adapting standardized and containerized variants of game environments from popular human digital gaming platforms. As a proof of concept, we generated 100 such games based on the top charts of Apple App Store and Steam, and evaluated seven frontier vision-language models (VLMs) on short episodes of play. The best models achieved less than 10\\% of the human average score on the majority of the games, and especially struggled with games that challenge world-model learning, memory and planning. We conclude with a set of next steps for building out the AI GameStore as a practical way to measure and drive progress toward human-like general intelligence in machines.",
      "authors": [
        "Lance Ying",
        "Ryan Truong",
        "Prafull Sharma",
        "Kaiya Ivy Zhao",
        "Nathan Cloos",
        "Kelsey R. Allen",
        "Thomas L. Griffiths",
        "Katherine M. Collins",
        "José Hernández-Orallo",
        "Phillip Isola",
        "Samuel J. Gershman",
        "Joshua B. Tenenbaum"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-19T18:17:25Z",
      "updated": "2026-02-19T18:17:25Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17594v1",
      "abs_url": "http://arxiv.org/abs/2602.17594v1",
      "summary": "提出了AI GameStore，通过玩人类游戏来评估通用人工智能，并评估了VLMs的性能。",
      "key_contributions": [
        "提出了AI GameStore平台",
        "利用LLM合成新的代表性人类游戏",
        "评估了VLMs在游戏中的表现"
      ],
      "methodology": "使用LLM和人类参与循环的方式，从流行游戏平台自动获取和调整游戏环境，生成新游戏并评估VLMs。",
      "tags": [
        "AI GameStore",
        "通用人工智能",
        "视觉语言模型",
        "游戏AI"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 8,
      "relevance_reason": "论文重点在于评估VLM在游戏环境中的表现，属于多模态学习应用。",
      "analyzed_at": "2026-02-20T06:56:32.544832",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17588v1",
      "title": "Modeling Distinct Human Interaction in Web Agents",
      "abstract": "Despite rapid progress in autonomous web agents, human involvement remains essential for shaping preferences and correcting agent behavior as tasks unfold. However, current agentic systems lack a principled understanding of when and why humans intervene, often proceeding autonomously past critical decision points or requesting unnecessary confirmation. In this work, we introduce the task of modeling human intervention to support collaborative web task execution. We collect CowCorpus, a dataset of 400 real-user web navigation trajectories containing over 4,200 interleaved human and agent actions. We identify four distinct patterns of user interaction with agents -- hands-off supervision, hands-on oversight, collaborative task-solving, and full user takeover. Leveraging these insights, we train language models (LMs) to anticipate when users are likely to intervene based on their interaction styles, yielding a 61.4-63.4% improvement in intervention prediction accuracy over base LMs. Finally, we deploy these intervention-aware models in live web navigation agents and evaluate them in a user study, finding a 26.5% increase in user-rated agent usefulness. Together, our results show structured modeling of human intervention leads to more adaptive, collaborative agents.",
      "authors": [
        "Faria Huq",
        "Zora Zhiruo Wang",
        "Zhanqiu Guo",
        "Venu Arvind Arangarajan",
        "Tianyue Ou",
        "Frank Xu",
        "Shuyan Zhou",
        "Graham Neubig",
        "Jeffrey P. Bigham"
      ],
      "categories": [
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-19T18:11:28Z",
      "updated": "2026-02-19T18:11:28Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17588v1",
      "abs_url": "http://arxiv.org/abs/2602.17588v1",
      "summary": "该论文研究人机协作的Web Agent，通过建模人类干预提升Agent的实用性。",
      "key_contributions": [
        "构建包含人类干预的Web导航数据集CowCorpus",
        "识别用户与Agent交互的四种模式",
        "训练预测人类干预的语言模型"
      ],
      "methodology": "收集数据集，分析交互模式，训练语言模型预测干预时机，并在用户研究中验证模型效果。",
      "tags": [
        "Web Agent",
        "人机协作",
        "干预预测",
        "语言模型"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文直接研究智能体，并专注于人机协作，属于核心相关。",
      "analyzed_at": "2026-02-20T06:56:34.119963",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17586v1",
      "title": "Conditional Flow Matching for Continuous Anomaly Detection in Autonomous Driving on a Manifold-Aware Spectral Space",
      "abstract": "Safety validation for Level 4 autonomous vehicles (AVs) is currently bottlenecked by the inability to scale the detection of rare, high-risk long-tail scenarios using traditional rule-based heuristics. We present Deep-Flow, an unsupervised framework for safety-critical anomaly detection that utilizes Optimal Transport Conditional Flow Matching (OT-CFM) to characterize the continuous probability density of expert human driving behavior. Unlike standard generative approaches that operate in unstable, high-dimensional coordinate spaces, Deep-Flow constrains the generative process to a low-rank spectral manifold via a Principal Component Analysis (PCA) bottleneck. This ensures kinematic smoothness by design and enables the computation of the exact Jacobian trace for numerically stable, deterministic log-likelihood estimation. To resolve multi-modal ambiguity at complex junctions, we utilize an Early Fusion Transformer encoder with lane-aware goal conditioning, featuring a direct skip-connection to the flow head to maintain intent-integrity throughout the network. We introduce a kinematic complexity weighting scheme that prioritizes high-energy maneuvers (quantified via path tortuosity and jerk) during the simulation-free training process. Evaluated on the Waymo Open Motion Dataset (WOMD), our framework achieves an AUC-ROC of 0.766 against a heuristic golden set of safety-critical events. More significantly, our analysis reveals a fundamental distinction between kinematic danger and semantic non-compliance. Deep-Flow identifies a critical predictability gap by surfacing out-of-distribution behaviors, such as lane-boundary violations and non-normative junction maneuvers, that traditional safety filters overlook. This work provides a mathematically rigorous foundation for defining statistical safety gates, enabling objective, data-driven validation for the safe deployment of autonomous fleets.",
      "authors": [
        "Antonio Guillen-Perez"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "published": "2026-02-19T18:10:16Z",
      "updated": "2026-02-19T18:10:16Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17586v1",
      "abs_url": "http://arxiv.org/abs/2602.17586v1",
      "summary": "提出Deep-Flow，利用流匹配和低秩流形进行自动驾驶异常检测，提升安全性验证。",
      "key_contributions": [
        "提出基于流匹配的异常检测框架Deep-Flow",
        "利用低秩谱流形约束生成过程，提高运动学平滑性",
        "引入运动学复杂度加权方案，关注高能机动"
      ],
      "methodology": "使用OT-CFM在低秩谱流形上建模人类驾驶行为，结合Transformer编码器和运动学加权进行异常检测。",
      "tags": [
        "自动驾驶",
        "异常检测",
        "流匹配",
        "安全验证",
        "无人驾驶"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "论文关注自动驾驶安全验证，通过异常检测提升agent安全性，高度相关。",
      "analyzed_at": "2026-02-20T06:56:36.460616",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17560v1",
      "title": "ODESteer: A Unified ODE-Based Steering Framework for LLM Alignment",
      "abstract": "Activation steering, or representation engineering, offers a lightweight approach to align large language models (LLMs) by manipulating their internal activations at inference time. However, current methods suffer from two key limitations: \\textit{(i)} the lack of a unified theoretical framework for guiding the design of steering directions, and \\textit{(ii)} an over-reliance on \\textit{one-step steering} that fail to capture complex patterns of activation distributions. In this work, we propose a unified ordinary differential equations (ODEs)-based \\textit{theoretical} framework for activation steering in LLM alignment. We show that conventional activation addition can be interpreted as a first-order approximation to the solution of an ODE. Based on this ODE perspective, identifying a steering direction becomes equivalent to designing a \\textit{barrier function} from control theory. Derived from this framework, we introduce ODESteer, a kind of ODE-based steering guided by barrier functions, which shows \\textit{empirical} advancement in LLM alignment. ODESteer identifies steering directions by defining the barrier function as the log-density ratio between positive and negative activations, and employs it to construct an ODE for \\textit{multi-step and adaptive} steering. Compared to state-of-the-art activation steering methods, ODESteer achieves consistent empirical improvements on diverse LLM alignment benchmarks, a notable $5.7\\%$ improvement over TruthfulQA, $2.5\\%$ over UltraFeedback, and $2.4\\%$ over RealToxicityPrompts. Our work establishes a principled new view of activation steering in LLM alignment by unifying its theoretical foundations via ODEs, and validating it empirically through the proposed ODESteer method.",
      "authors": [
        "Hongjue Zhao",
        "Haosen Sun",
        "Jiangtao Kong",
        "Xiaochang Li",
        "Qineng Wang",
        "Liwei Jiang",
        "Qi Zhu",
        "Tarek Abdelzaher",
        "Yejin Choi",
        "Manling Li",
        "Huajie Shao"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-19T17:13:44Z",
      "updated": "2026-02-19T17:13:44Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17560v1",
      "abs_url": "http://arxiv.org/abs/2602.17560v1",
      "summary": "提出了基于常微分方程(ODE)的LLM对齐新框架ODESteer，提升了对齐效果。",
      "key_contributions": [
        "建立了基于ODE的LLM对齐激活Steering理论框架。",
        "将激活Steering方向的识别等价于控制理论中的Barrier函数设计。",
        "提出了基于Barrier函数的ODE Steering方法ODESteer，并在多个基准测试上验证了其有效性。"
      ],
      "methodology": "将激活Steering视为ODE的解，利用Barrier函数设计指导Steering方向，实现多步自适应Steering。",
      "tags": [
        "LLM Alignment",
        "Activation Steering",
        "ODE",
        "Control Theory"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "通过干预LLM内部激活来引导输出，与提高LLM推理能力密切相关。",
      "analyzed_at": "2026-02-20T06:56:38.257852",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17559v1",
      "title": "Revisiting Weight Regularization for Low-Rank Continual Learning",
      "abstract": "Continual Learning (CL) with large-scale pre-trained models (PTMs) has recently gained wide attention, shifting the focus from training from scratch to continually adapting PTMs. This has given rise to a promising paradigm: parameter-efficient continual learning (PECL), where task interference is typically mitigated by assigning a task-specific module during training, such as low-rank adapters. However, weight regularization techniques, such as Elastic Weight Consolidation (EWC)-a key strategy in CL-remain underexplored in this new paradigm. In this paper, we revisit weight regularization in low-rank CL as a new perspective for mitigating task interference in PECL. Unlike existing low-rank CL methods, we mitigate task interference by regularizing a shared low-rank update through EWC, thereby keeping the storage requirement and inference costs constant regardless of the number of tasks. Our proposed method EWC-LoRA leverages a low-rank representation to estimate parameter importance over the full-dimensional space. This design offers a practical, computational- and memory-efficient solution for CL with PTMs, and provides insights that may inform the broader application of regularization techniques within PECL. Extensive experiments on various benchmarks demonstrate the effectiveness of EWC-LoRA, achieving a stability-plasticity trade-off superior to existing low-rank CL approaches. These results indicate that, even under low-rank parameterizations, weight regularization remains an effective mechanism for mitigating task interference. Code is available at: https://github.com/yaoyz96/low-rank-cl.",
      "authors": [
        "Yaoyue Zheng",
        "Yin Zhang",
        "Joost van de Weijer",
        "Gido M van de Ven",
        "Shaoyi Du",
        "Xuetao Zhang",
        "Zhiqiang Tian"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T17:13:00Z",
      "updated": "2026-02-19T17:13:00Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17559v1",
      "abs_url": "http://arxiv.org/abs/2602.17559v1",
      "summary": "该论文提出EWC-LoRA方法，通过正则化低秩更新缓解参数高效持续学习中的任务干扰。",
      "key_contributions": [
        "提出EWC-LoRA方法，将EWC应用于低秩持续学习。",
        "利用低秩表示估计全维度参数重要性。",
        "实验证明EWC-LoRA在稳定性-可塑性权衡方面优于现有方法。"
      ],
      "methodology": "使用低秩适配器进行参数高效的持续学习，并通过EWC正则化共享的低秩更新，缓解任务间的干扰。",
      "tags": [
        "Continual Learning",
        "Low-Rank Adaptation",
        "Elastic Weight Consolidation",
        "Parameter-Efficient Learning"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 6,
      "relevance_reason": "涉及到通过优化学习过程来提升agent的学习效率与稳定性。",
      "analyzed_at": "2026-02-20T06:56:39.998539",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17558v1",
      "title": "RetouchIQ: MLLM Agents for Instruction-Based Image Retouching with Generalist Reward",
      "abstract": "Recent advances in multimodal large language models (MLLMs) have shown great potential for extending vision-language reasoning to professional tool-based image editing, enabling intuitive and creative editing. A promising direction is to use reinforcement learning (RL) to enable MLLMs to reason about and execute optimal tool-use plans within professional image-editing software. However, training remains challenging due to the lack of reliable, verifiable reward signals that can reflect the inherently subjective nature of creative editing. In this work, we introduce RetouchIQ, a framework that performs instruction-based executable image editing through MLLM agents guided by a generalist reward model. RetouchIQ interprets user-specified editing intentions and generates corresponding, executable image adjustments, bridging high-level aesthetic goals with precise parameter control. To move beyond conventional, rule-based rewards that compute similarity against a fixed reference image using handcrafted metrics, we propose a generalist reward model, an RL fine-tuned MLLM that evaluates edited results through a set of generated metrics on a case-by-case basis. Then, the reward model provides scalar feedback through multimodal reasoning, enabling reinforcement learning with high-quality, instruction-consistent gradients. We curate an extended dataset with 190k instruction-reasoning pairs and establish a new benchmark for instruction-based image editing. Experiments show that RetouchIQ substantially improves both semantic consistency and perceptual quality over previous MLLM-based and diffusion-based editing systems. Our findings demonstrate the potential of generalist reward-driven MLLM agents as flexible, explainable, and executable assistants for professional image editing.",
      "authors": [
        "Qiucheng Wu",
        "Jing Shi",
        "Simon Jenni",
        "Kushal Kafle",
        "Tianyu Wang",
        "Shiyu Chang",
        "Handong Zhao"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-19T17:11:59Z",
      "updated": "2026-02-19T17:11:59Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17558v1",
      "abs_url": "http://arxiv.org/abs/2602.17558v1",
      "summary": "RetouchIQ提出了一种基于通用奖励模型的MLLM图像润饰框架，提升了图像编辑的语义一致性和感知质量。",
      "key_contributions": [
        "提出了RetouchIQ框架，用于指令驱动的可执行图像编辑。",
        "提出了通用奖励模型，利用RL微调MLLM来评估编辑结果。",
        "构建了包含19万指令-推理对的图像编辑数据集，并设立了新的基准。"
      ],
      "methodology": "使用MLLM作为Agent，通过强化学习在图像编辑软件中进行工具使用规划，利用通用奖励模型指导训练。",
      "tags": [
        "MLLM",
        "Image Editing",
        "Reinforcement Learning",
        "Reward Modeling"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于利用MLLM进行图像编辑，并且使用通用奖励模型，高度相关。",
      "analyzed_at": "2026-02-20T06:56:42.111033",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17555v1",
      "title": "GraphThinker: Reinforcing Video Reasoning with Event Graph Thinking",
      "abstract": "Video reasoning requires understanding the causal relationships between events in a video. However, such relationships are often implicit and costly to annotate manually. While existing multimodal large language models (MLLMs) often infer event relations through dense captions or video summaries for video reasoning, such modeling still lacks causal understanding. Without explicit causal structure modeling within and across video events, these models suffer from hallucinations during the video reasoning. In this work, we propose GraphThinker, a reinforcement finetuning-based method that constructs structural event-level scene graphs and enhances visual grounding to jointly reduce hallucinations in video reasoning. Specifically, we first employ an MLLM to construct an event-based video scene graph (EVSG) that explicitly models both intra- and inter-event relations, and incorporate these formed scene graphs into the MLLM as an intermediate thinking process. We also introduce a visual attention reward during reinforcement finetuning, which strengthens video grounding and further mitigates hallucinations. We evaluate GraphThinker on two datasets, RexTime and VidHalluc, where it shows superior ability to capture object and event relations with more precise event localization, reducing hallucinations in video reasoning compared to prior methods.",
      "authors": [
        "Zixu Cheng",
        "Da Li",
        "Jian Hu",
        "Ziquan Liu",
        "Wei Li",
        "Shaogang Gong"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-19T17:09:30Z",
      "updated": "2026-02-19T17:09:30Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17555v1",
      "abs_url": "http://arxiv.org/abs/2602.17555v1",
      "summary": "GraphThinker通过构建事件图增强视频推理，利用强化学习减少幻觉。",
      "key_contributions": [
        "提出GraphThinker模型，利用事件图增强视频推理",
        "引入视觉注意力奖励强化视觉 grounding，减少幻觉",
        "在RexTime和VidHalluc数据集上验证了模型的有效性"
      ],
      "methodology": "使用MLLM构建事件级视频场景图，利用强化学习进行微调，并引入视觉注意力奖励。",
      "tags": [
        "视频推理",
        "事件图",
        "强化学习",
        "多模态",
        "幻觉"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于利用图结构和强化学习提升多模态视频推理能力，直接相关。",
      "analyzed_at": "2026-02-20T06:56:43.742132",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17554v1",
      "title": "A Theoretical Framework for Modular Learning of Robust Generative Models",
      "abstract": "Training large-scale generative models is resource-intensive and relies heavily on heuristic dataset weighting. We address two fundamental questions: Can we train Large Language Models (LLMs) modularly-combining small, domain-specific experts to match monolithic performance-and can we do so robustly for any data mixture, eliminating heuristic tuning? We present a theoretical framework for modular generative modeling where a set of pre-trained experts are combined via a gating mechanism. We define the space of normalized gating functions, $G_{1}$, and formulate the problem as a minimax game to find a single robust gate that minimizes divergence to the worst-case data mixture. We prove the existence of such a robust gate using Kakutani's fixed-point theorem and show that modularity acts as a strong regularizer, with generalization bounds scaling with the lightweight gate's complexity. Furthermore, we prove that this modular approach can theoretically outperform models retrained on aggregate data, with the gap characterized by the Jensen-Shannon Divergence. Finally, we introduce a scalable Stochastic Primal-Dual algorithm and a Structural Distillation method for efficient inference. Empirical results on synthetic and real-world datasets confirm that our modular architecture effectively mitigates gradient conflict and can robustly outperform monolithic baselines.",
      "authors": [
        "Corinna Cortes",
        "Mehryar Mohri",
        "Yutao Zhong"
      ],
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T17:09:13Z",
      "updated": "2026-02-19T17:09:13Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17554v1",
      "abs_url": "http://arxiv.org/abs/2602.17554v1",
      "summary": "提出一种模块化生成模型框架，通过组合领域专家模型提升性能和鲁棒性，并提供理论证明和算法。",
      "key_contributions": [
        "提出模块化生成模型框架，解决大规模生成模型训练资源消耗问题。",
        "证明了模块化模型在鲁棒性和泛化性方面的优势。",
        "设计了可扩展的随机原始对偶算法和结构蒸馏方法。",
        "实验验证了模块化架构能有效缓解梯度冲突并超越单体模型。"
      ],
      "methodology": "通过预训练专家模型和门控机制组合，使用minimax博弈寻找鲁棒门控函数，并结合 Kakutani 不动点定理进行理论证明。",
      "tags": [
        "生成模型",
        "模块化学习",
        "鲁棒性",
        "专家模型",
        "门控机制"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 6,
      "relevance_reason": "虽然不是直接Agent，但模块化和专家模型组合可以作为agent的building block.",
      "analyzed_at": "2026-02-20T06:56:45.812295",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17550v1",
      "title": "MASPO: Unifying Gradient Utilization, Probability Mass, and Signal Reliability for Robust and Sample-Efficient LLM Reasoning",
      "abstract": "Existing Reinforcement Learning with Verifiable Rewards (RLVR) algorithms, such as GRPO, rely on rigid, uniform, and symmetric trust region mechanisms that are fundamentally misaligned with the complex optimization dynamics of Large Language Models (LLMs). In this paper, we identify three critical challenges in these methods: (1) inefficient gradient utilization caused by the binary cutoff of hard clipping, (2) insensitive probability mass arising from uniform ratio constraints that ignore the token distribution, and (3) asymmetric signal reliability stemming from the disparate credit assignment ambiguity between positive and negative samples. To bridge these gaps, we propose Mass-Adaptive Soft Policy Optimization (MASPO), a unified framework designed to harmonize these three dimensions. MASPO integrates a differentiable soft Gaussian gating to maximize gradient utility, a mass-adaptive limiter to balance exploration across the probability spectrum, and an asymmetric risk controller to align update magnitudes with signal confidence. Extensive evaluations demonstrate that MASPO serves as a robust, all-in-one RLVR solution, significantly outperforming strong baselines. Our code is available at: https://anonymous.4open.science/r/ma1/README.md.",
      "authors": [
        "Xiaoliang Fu",
        "Jiaye Lin",
        "Yangyi Fang",
        "Binbin Zheng",
        "Chaowen Hu",
        "Zekai Shao",
        "Cong Qin",
        "Lu Pan",
        "Ke Zeng",
        "Xunliang Cai"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T17:05:20Z",
      "updated": "2026-02-19T17:05:20Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17550v1",
      "abs_url": "http://arxiv.org/abs/2602.17550v1",
      "summary": "MASPO通过统一梯度利用、概率质量和信号可靠性，提升LLM推理的鲁棒性和样本效率。",
      "key_contributions": [
        "提出MASPO框架，统一梯度利用、概率质量和信号可靠性。",
        "引入可微软高斯门控，最大化梯度效用。",
        "设计质量自适应限制器，平衡概率谱上的探索。",
        "采用非对称风险控制器，使更新幅度与信号置信度对齐。"
      ],
      "methodology": "MASPO框架通过软门控、质量自适应限制器和非对称风险控制，优化强化学习中的策略更新，提升LLM推理性能。",
      "tags": [
        "LLM",
        "强化学习",
        "策略优化",
        "推理"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注LLM的推理能力，并提出了优化推理性能的方法。",
      "analyzed_at": "2026-02-20T06:56:47.910330",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17547v1",
      "title": "KLong: Training LLM Agent for Extremely Long-horizon Tasks",
      "abstract": "This paper introduces KLong, an open-source LLM agent trained to solve extremely long-horizon tasks. The principle is to first cold-start the model via trajectory-splitting SFT, then scale it via progressive RL training. Specifically, we first activate basic agentic abilities of a base model with a comprehensive SFT recipe. Then, we introduce Research-Factory, an automated pipeline that generates high-quality training data by collecting research papers and constructing evaluation rubrics. Using this pipeline, we build thousands of long-horizon trajectories distilled from Claude 4.5 Sonnet (Thinking). To train with these extremely long trajectories, we propose a new trajectory-splitting SFT, which preserves early context, progressively truncates later context, and maintains overlap between sub-trajectories. In addition, to further improve long-horizon task-solving capability, we propose a novel progressive RL, which schedules training into multiple stages with progressively extended timeouts. Experiments demonstrate the superiority and generalization of KLong, as shown in Figure 1. Notably, our proposed KLong (106B) surpasses Kimi K2 Thinking (1T) by 11.28% on PaperBench, and the performance improvement generalizes to other coding benchmarks like SWE-bench Verified and MLE-bench.",
      "authors": [
        "Yue Liu",
        "Zhiyuan Hu",
        "Flood Sung",
        "Jiaheng Zhang",
        "Bryan Hooi"
      ],
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-19T17:01:08Z",
      "updated": "2026-02-19T17:01:08Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17547v1",
      "abs_url": "http://arxiv.org/abs/2602.17547v1",
      "summary": "KLong通过轨迹分割SFT和渐进式RL训练，提升LLM Agent的超长时程任务解决能力。",
      "key_contributions": [
        "提出轨迹分割SFT方法",
        "提出渐进式RL训练方法",
        "构建Research-Factory自动化数据生成流程"
      ],
      "methodology": "使用Research-Factory构建数据，采用轨迹分割SFT进行预训练，然后通过渐进式RL进行微调。",
      "tags": [
        "LLM Agent",
        "Long-horizon Task",
        "Reinforcement Learning"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 9,
      "relevance_reason": "论文专注于agent训练，尤其是长程任务，是agent_tuning的核心问题。",
      "analyzed_at": "2026-02-20T06:56:49.531616",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17546v1",
      "title": "Learning to Stay Safe: Adaptive Regularization Against Safety Degradation during Fine-Tuning",
      "abstract": "Instruction-following language models are trained to be helpful and safe, yet their safety behavior can deteriorate under benign fine-tuning and worsen under adversarial updates. Existing defenses often offer limited protection or force a trade-off between safety and utility. We introduce a training framework that adapts regularization in response to safety risk, enabling models to remain aligned throughout fine-tuning. To estimate safety risk at training time, we explore two distinct approaches: a judge-based Safety Critic that assigns high-level harm scores to training batches, and an activation-based risk predictor built with a lightweight classifier trained on intermediate model activations to estimate harmful intent. Each approach provides a risk signal that is used to constrain updates deemed higher risk to remain close to a safe reference policy, while lower-risk updates proceed with standard training. We empirically verify that harmful intent signals are predictable from pre-generation activations and that judge scores provide effective high-recall safety guidance. Across multiple model families and attack scenarios, adaptive regularization with either risk estimation approach consistently lowers attack success rate compared to standard fine-tuning, preserves downstream performance, and adds no inference-time cost. This work demonstrates a principled mechanism for maintaining safety without sacrificing utility.",
      "authors": [
        "Jyotin Goel",
        "Souvik Maji",
        "Pratik Mazumder"
      ],
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-19T16:59:54Z",
      "updated": "2026-02-19T16:59:54Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17546v1",
      "abs_url": "http://arxiv.org/abs/2602.17546v1",
      "summary": "该论文提出了一种自适应正则化框架，用于在微调过程中防止语言模型的安全性下降。",
      "key_contributions": [
        "提出自适应正则化框架，在微调中保持模型安全性",
        "探索了基于安全评判器和激活的风险预测器两种安全风险评估方法",
        "验证了该方法在降低攻击成功率的同时，保持了模型效用"
      ],
      "methodology": "通过安全评判器或激活风险预测器评估风险，并据此自适应地调整正则化强度，约束高风险更新。",
      "tags": [
        "安全性",
        "微调",
        "正则化",
        "风险评估"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 8,
      "relevance_reason": "关注模型微调过程中的安全问题，属于agent安全和调优的重要方面。",
      "analyzed_at": "2026-02-20T06:56:51.329963",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17545v1",
      "title": "Adaptive Decentralized Composite Optimization via Three-Operator Splitting",
      "abstract": "The paper studies decentralized optimization over networks, where agents minimize a sum of {\\it locally} smooth (strongly) convex losses and plus a nonsmooth convex extended value term. We propose decentralized methods wherein agents {\\it adaptively} adjust their stepsize via local backtracking procedures coupled with lightweight min-consensus protocols. Our design stems from a three-operator splitting factorization applied to an equivalent reformulation of the problem. The reformulation is endowed with a new BCV preconditioning metric (Bertsekas-O'Connor-Vandenberghe), which enables efficient decentralized implementation and local stepsize adjustments. We establish robust convergence guarantees. Under mere convexity, the proposed methods converge with a sublinear rate. Under strong convexity of the sum-function, and assuming the nonsmooth component is partly smooth, we further prove linear convergence. Numerical experiments corroborate the theory and highlight the effectiveness of the proposed adaptive stepsize strategy.",
      "authors": [
        "Xiaokai Chen",
        "Ilya Kuruzov",
        "Gesualdo Scutari"
      ],
      "categories": [
        "math.OC",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "math.OC",
      "published": "2026-02-19T16:59:34Z",
      "updated": "2026-02-19T16:59:34Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17545v1",
      "abs_url": "http://arxiv.org/abs/2602.17545v1",
      "summary": "提出了一种自适应去中心化复合优化方法，利用三算子分裂和BCV预处理实现高效优化。",
      "key_contributions": [
        "提出自适应步长的去中心化优化方法",
        "利用三算子分裂和BCV预处理",
        "证明了算法的收敛性，包括次线性收敛和线性收敛"
      ],
      "methodology": "采用三算子分裂分解，结合BCV预处理，以及局部回溯策略调整步长，实现去中心化优化。",
      "tags": [
        "去中心化优化",
        "自适应步长",
        "三算子分裂",
        "凸优化"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 6,
      "relevance_reason": "去中心化优化方法可用于多智能体系统的参数调整和协同，有一定参考价值。",
      "analyzed_at": "2026-02-20T06:56:53.167836",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17544v1",
      "title": "Evaluating Chain-of-Thought Reasoning through Reusability and Verifiability",
      "abstract": "In multi-agent IR pipelines for tasks such as search and ranking, LLM-based agents exchange intermediate reasoning in terms of Chain-of-Thought (CoT) with each other. Current CoT evaluation narrowly focuses on target task accuracy. However, this metric fails to assess the quality or utility of the reasoning process itself. To address this limitation, we introduce two novel measures: reusability and verifiability. We decouple CoT generation from execution using a Thinker-Executor framework. Reusability measures how easily an Executor can reuse the Thinker's CoT. Verifiability measures how frequently an Executor can match the Thinker's answer using the CoT. We evaluated four Thinker models against a committee of ten Executor models across five benchmarks. Our results reveal that reusability and verifiability do not correlate with standard accuracy, exposing a blind spot in current accuracy-based leaderboards for reasoning capability. Surprisingly, we find that CoTs from specialized reasoning models are not consistently more reusable or verifiable than those from general-purpose LLMs like Llama and Gemma.",
      "authors": [
        "Shashank Aggarwal",
        "Ram Vikas Mishra",
        "Amit Awekar"
      ],
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-19T16:59:11Z",
      "updated": "2026-02-19T16:59:11Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17544v1",
      "abs_url": "http://arxiv.org/abs/2602.17544v1",
      "summary": "论文提出可重用性和可验证性两个指标，用于评估CoT推理质量，揭示了现有评估方法的盲点。",
      "key_contributions": [
        "提出可重用性与可验证性指标",
        "构建Thinker-Executor框架进行CoT评估",
        "发现传统准确率无法有效评估CoT质量"
      ],
      "methodology": "使用Thinker-Executor框架，将CoT生成和执行分离，通过可重用性和可验证性指标评估CoT质量。",
      "tags": [
        "Chain-of-Thought",
        "Reasoning",
        "Evaluation",
        "Reusability",
        "Verifiability"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文直接研究CoT推理的评估方法，对LLM推理领域具有重要意义。",
      "analyzed_at": "2026-02-20T06:56:54.980727",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17537v1",
      "title": "IRIS: Learning-Driven Task-Specific Cinema Robot Arm for Visuomotor Motion Control",
      "abstract": "Robotic camera systems enable dynamic, repeatable motion beyond human capabilities, yet their adoption remains limited by the high cost and operational complexity of industrial-grade platforms. We present the Intelligent Robotic Imaging System (IRIS), a task-specific 6-DOF manipulator designed for autonomous, learning-driven cinematic motion control. IRIS integrates a lightweight, fully 3D-printed hardware design with a goal-conditioned visuomotor imitation learning framework based on Action Chunking with Transformers (ACT). The system learns object-aware and perceptually smooth camera trajectories directly from human demonstrations, eliminating the need for explicit geometric programming. The complete platform costs under $1,000 USD, supports a 1.5 kg payload, and achieves approximately 1 mm repeatability. Real-world experiments demonstrate accurate trajectory tracking, reliable autonomous execution, and generalization across diverse cinematic motions.",
      "authors": [
        "Qilong Cheng",
        "Matthew Mackay",
        "Ali Bereyhi"
      ],
      "categories": [
        "cs.RO",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "published": "2026-02-19T16:50:31Z",
      "updated": "2026-02-19T16:50:31Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17537v1",
      "abs_url": "http://arxiv.org/abs/2602.17537v1",
      "summary": "IRIS：低成本、学习驱动的电影机器人手臂，实现自主的视觉运动控制。",
      "key_contributions": [
        "设计了一种低成本的6自由度机器人手臂",
        "提出了基于Transformer的动作块的视觉运动模仿学习框架",
        "验证了系统在各种电影运动中的准确性和泛化性"
      ],
      "methodology": "利用模仿学习，从人类演示中学习目标导向的、平滑的相机轨迹，无需显式的几何编程。",
      "tags": [
        "机器人",
        "视觉运动控制",
        "模仿学习",
        "Transformer",
        "电影机器人"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "虽然涉及机器人硬件，但更侧重于通过学习实现自主运动控制，与Agent有一定的关联。",
      "analyzed_at": "2026-02-20T06:56:56.945624",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17536v1",
      "title": "Toward a Fully Autonomous, AI-Native Particle Accelerator",
      "abstract": "This position paper presents a vision for self-driving particle accelerators that operate autonomously with minimal human intervention. We propose that future facilities be designed through artificial intelligence (AI) co-design, where AI jointly optimizes the accelerator lattice, diagnostics, and science application from inception to maximize performance while enabling autonomous operation. Rather than retrofitting AI onto human-centric systems, we envision facilities designed from the ground up as AI-native platforms. We outline nine critical research thrusts spanning agentic control architectures, knowledge integration, adaptive learning, digital twins, health monitoring, safety frameworks, modular hardware design, multimodal data fusion, and cross-domain collaboration. This roadmap aims to guide the accelerator community toward a future where AI-driven design and operation deliver unprecedented science output and reliability.",
      "authors": [
        "Chris Tennant"
      ],
      "categories": [
        "physics.acc-ph",
        "cs.AI"
      ],
      "primary_category": "physics.acc-ph",
      "published": "2026-02-19T16:49:36Z",
      "updated": "2026-02-19T16:49:36Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17536v1",
      "abs_url": "http://arxiv.org/abs/2602.17536v1",
      "summary": "提出了AI原生粒子加速器的愿景，强调AI在设计、控制和优化中的核心作用，以实现全自动运行。",
      "key_contributions": [
        "提出AI原生粒子加速器概念",
        "概述九个关键研究方向",
        "强调AI协同设计"
      ],
      "methodology": "通过AI协同设计，从零构建AI原生粒子加速器，并提出九个研究方向实现全自动运行。",
      "tags": [
        "AI",
        "粒子加速器",
        "自动化",
        "智能控制",
        "协同设计"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "论文的核心在于利用AI实现粒子加速器的自主运行，属于AI Agent的研究范畴。",
      "analyzed_at": "2026-02-20T06:56:58.523360",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17535v1",
      "title": "LATA: Laplacian-Assisted Transductive Adaptation for Conformal Uncertainty in Medical VLMs",
      "abstract": "Medical vision-language models (VLMs) are strong zero-shot recognizers for medical imaging, but their reliability under domain shift hinges on calibrated uncertainty with guarantees. Split conformal prediction (SCP) offers finite-sample coverage, yet prediction sets often become large (low efficiency) and class-wise coverage unbalanced-high class-conditioned coverage gap (CCV), especially in few-shot, imbalanced regimes; moreover, naively adapting to calibration labels breaks exchangeability and voids guarantees. We propose \\texttt{\\textbf{LATA}} (Laplacian-Assisted Transductive Adaptation), a \\textit{training- and label-free} refinement that operates on the joint calibration and test pool by smoothing zero-shot probabilities over an image-image k-NN graph using a small number of CCCP mean-field updates, preserving SCP validity via a deterministic transform. We further introduce a \\textit{failure-aware} conformal score that plugs into the vision-language uncertainty (ViLU) framework, providing instance-level difficulty and label plausibility to improve prediction set efficiency and class-wise balance at fixed coverage. \\texttt{\\textbf{LATA}} is black-box (no VLM updates), compute-light (windowed transduction, no backprop), and includes an optional prior knob that can run strictly label-free or, if desired, in a label-informed variant using calibration marginals once. Across \\textbf{three} medical VLMs and \\textbf{nine} downstream tasks, \\texttt{\\textbf{LATA}} consistently reduces set size and CCV while matching or tightening target coverage, outperforming prior transductive baselines and narrowing the gap to label-using methods, while using far less compute. Comprehensive ablations and qualitative analyses show that \\texttt{\\textbf{LATA}} sharpens zero-shot predictions without compromising exchangeability.",
      "authors": [
        "Behzad Bozorgtabar",
        "Dwarikanath Mahapatra",
        "Sudipta Roy",
        "Muzammal Naseer",
        "Imran Razzak",
        "Zongyuan Ge"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-19T16:45:38Z",
      "updated": "2026-02-19T16:45:38Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17535v1",
      "abs_url": "http://arxiv.org/abs/2602.17535v1",
      "summary": "LATA通过Laplacian平滑改进医学VLM的校准不确定性，提升预测效率和类别平衡。",
      "key_contributions": [
        "提出了LATA，一种训练和标签无关的校准方法。",
        "使用Laplacian平滑零样本概率，提高预测精度。",
        "引入failure-aware的 conformal score，提升预测集效率和类别平衡。"
      ],
      "methodology": "LATA利用图像-图像k-NN图平滑零样本概率，并采用CCCP mean-field更新，结合failure-aware conformal score改进ViLU框架。",
      "tags": [
        "Medical VLM",
        "Conformal Prediction",
        "Uncertainty Calibration"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "该论文直接研究医学VLM中的不确定性校准问题，是多模态学习的重要应用。",
      "analyzed_at": "2026-02-20T06:57:00.548828",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17531v1",
      "title": "Position: Evaluation of ECG Representations Must Be Fixed",
      "abstract": "This position paper argues that current benchmarking practice in 12-lead ECG representation learning must be fixed to ensure progress is reliable and aligned with clinically meaningful objectives. The field has largely converged on three public multi-label benchmarks (PTB-XL, CPSC2018, CSN) dominated by arrhythmia and waveform-morphology labels, even though the ECG is known to encode substantially broader clinical information. We argue that downstream evaluation should expand to include an assessment of structural heart disease and patient-level forecasting, in addition to other evolving ECG-related endpoints, as relevant clinical targets. Next, we outline evaluation best practices for multi-label, imbalanced settings, and show that when they are applied, the literature's current conclusion about which representations perform best is altered. Furthermore, we demonstrate the surprising result that a randomly initialized encoder with linear evaluation matches state-of-the-art pre-training on many tasks. This motivates the use of a random encoder as a reasonable baseline model. We substantiate our observations with an empirical evaluation of three representative ECG pre-training approaches across six evaluation settings: the three standard benchmarks, a structural disease dataset, hemodynamic inference, and patient forecasting.",
      "authors": [
        "Zachary Berger",
        "Daniel Prakah-Asante",
        "John Guttag",
        "Collin M. Stultz"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T16:42:46Z",
      "updated": "2026-02-19T16:42:46Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17531v1",
      "abs_url": "http://arxiv.org/abs/2602.17531v1",
      "summary": "该论文指出心电图表征学习的基准测试需要改进，并提出了新的评估方法。",
      "key_contributions": [
        "批评现有心电图表征学习的基准测试方法",
        "提出更全面的评估指标，包括结构性心脏病和患者预测",
        "发现随机初始化编码器在线性评估中表现优异"
      ],
      "methodology": "对现有基准测试数据集进行评估，并引入新的数据集和评估指标进行实验分析。",
      "tags": [
        "心电图",
        "表征学习",
        "基准测试",
        "评估指标",
        "临床应用"
      ],
      "assigned_category": "agent",
      "relevance_score": 5,
      "relevance_reason": "可能通过agent进行健康分析和预测，有一定相关性。",
      "analyzed_at": "2026-02-20T06:57:02.412477",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17529v1",
      "title": "Enhancing Large Language Models (LLMs) for Telecom using Dynamic Knowledge Graphs and Explainable Retrieval-Augmented Generation",
      "abstract": "Large language models (LLMs) have shown strong potential across a variety of tasks, but their application in the telecom field remains challenging due to domain complexity, evolving standards, and specialized terminology. Therefore, general-domain LLMs may struggle to provide accurate and reliable outputs in this context, leading to increased hallucinations and reduced utility in telecom operations.To address these limitations, this work introduces KG-RAG-a novel framework that integrates knowledge graphs (KGs) with retrieval-augmented generation (RAG) to enhance LLMs for telecom-specific tasks. In particular, the KG provides a structured representation of domain knowledge derived from telecom standards and technical documents, while RAG enables dynamic retrieval of relevant facts to ground the model's outputs. Such a combination improves factual accuracy, reduces hallucination, and ensures compliance with telecom specifications.Experimental results across benchmark datasets demonstrate that KG-RAG outperforms both LLM-only and standard RAG baselines, e.g., KG-RAG achieves an average accuracy improvement of 14.3% over RAG and 21.6% over LLM-only models. These results highlight KG-RAG's effectiveness in producing accurate, reliable, and explainable outputs in complex telecom scenarios.",
      "authors": [
        "Dun Yuan",
        "Hao Zhou",
        "Xue Liu",
        "Hao Chen",
        "Yan Xin",
        "Jianzhong",
        "Zhang"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-19T16:40:17Z",
      "updated": "2026-02-19T16:40:17Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17529v1",
      "abs_url": "http://arxiv.org/abs/2602.17529v1",
      "summary": "论文提出KG-RAG框架，结合知识图谱与检索增强生成，提升LLM在电信领域的准确性和可靠性。",
      "key_contributions": [
        "提出KG-RAG框架",
        "利用知识图谱增强LLM在电信领域的知识",
        "实验证明KG-RAG优于LLM-only和标准RAG"
      ],
      "methodology": "构建电信领域知识图谱，结合检索增强生成技术，动态检索相关知识来提升LLM的输出质量和准确性。",
      "tags": [
        "知识图谱",
        "检索增强生成",
        "电信领域",
        "LLM"
      ],
      "assigned_category": "memory",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于使用KG增强RAG，从而提升LLM的效果，属于该领域的核心问题。",
      "analyzed_at": "2026-02-20T06:57:04.276710",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17525v1",
      "title": "Variational inference via radial transport",
      "abstract": "In variational inference (VI), the practitioner approximates a high-dimensional distribution $π$ with a simple surrogate one, often a (product) Gaussian distribution. However, in many cases of practical interest, Gaussian distributions might not capture the correct radial profile of $π$, resulting in poor coverage. In this work, we approach the VI problem from the perspective of optimizing over these radial profiles. Our algorithm radVI is a cheap, effective add-on to many existing VI schemes, such as Gaussian (mean-field) VI and Laplace approximation. We provide theoretical convergence guarantees for our algorithm, owing to recent developments in optimization over the Wasserstein space--the space of probability distributions endowed with the Wasserstein distance--and new regularity properties of radial transport maps in the style of Caffarelli (2000).",
      "authors": [
        "Luca Ghafourpour",
        "Sinho Chewi",
        "Alessio Figalli",
        "Aram-Alexandre Pooladian"
      ],
      "categories": [
        "cs.LG",
        "math.ST",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T16:36:52Z",
      "updated": "2026-02-19T16:36:52Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17525v1",
      "abs_url": "http://arxiv.org/abs/2602.17525v1",
      "summary": "radVI算法通过优化径向轮廓改进变分推断，提升高维分布近似的准确性。",
      "key_contributions": [
        "提出了一种新的变分推断算法radVI",
        "为radVI提供了理论收敛保证",
        "利用Wasserstein空间和径向传输映射理论进行优化"
      ],
      "methodology": "通过优化径向轮廓解决变分推断中高斯分布无法捕捉真实分布径向特征的问题，作为现有VI方法的补充。",
      "tags": [
        "变分推断",
        "Wasserstein距离",
        "优化",
        "径向传输"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 6,
      "relevance_reason": "涉及概率分布近似和优化，可用于改进LLM的推理过程。",
      "analyzed_at": "2026-02-20T06:57:06.773654",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17508v1",
      "title": "Pareto Optimal Benchmarking of AI Models on ARM Cortex Processors for Sustainable Embedded Systems",
      "abstract": "This work presents a practical benchmarking framework for optimizing artificial intelligence (AI) models on ARM Cortex processors (M0+, M4, M7), focusing on energy efficiency, accuracy, and resource utilization in embedded systems. Through the design of an automated test bench, we provide a systematic approach to evaluate across key performance indicators (KPIs) and identify optimal combinations of processor and AI model. The research highlights a nearlinear correlation between floating-point operations (FLOPs) and inference time, offering a reliable metric for estimating computational demands. Using Pareto analysis, we demonstrate how to balance trade-offs between energy consumption and model accuracy, ensuring that AI applications meet performance requirements without compromising sustainability. Key findings indicate that the M7 processor is ideal for short inference cycles, while the M4 processor offers better energy efficiency for longer inference tasks. The M0+ processor, while less efficient for complex AI models, remains suitable for simpler tasks. This work provides insights for developers, guiding them to design energy-efficient AI systems that deliver high performance in realworld applications.",
      "authors": [
        "Pranay Jain",
        "Maximilian Kasper",
        "Göran Köber",
        "Axel Plinge",
        "Dominik Seuß"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-19T16:21:47Z",
      "updated": "2026-02-19T16:21:47Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17508v1",
      "abs_url": "http://arxiv.org/abs/2602.17508v1",
      "summary": "针对嵌入式系统，研究ARM Cortex处理器上AI模型的能效优化，提出了Pareto最优基准测试框架。",
      "key_contributions": [
        "构建了自动化测试平台，评估不同处理器和AI模型的性能指标",
        "揭示了浮点运算（FLOPs）与推理时间的线性关系",
        "通过Pareto分析，平衡能耗和模型精度之间的权衡"
      ],
      "methodology": "设计自动化测试平台，在ARM Cortex处理器上运行AI模型，收集KPI数据，进行Pareto分析，找出最优配置。",
      "tags": [
        "嵌入式系统",
        "AI模型优化",
        "ARM Cortex",
        "能效",
        "Pareto分析"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 6,
      "relevance_reason": "探索模型在特定硬件上的效率，隐含了对Agent特定配置的优化。",
      "analyzed_at": "2026-02-20T06:57:08.828477",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17497v1",
      "title": "Retrospective In-Context Learning for Temporal Credit Assignment with Large Language Models",
      "abstract": "Learning from self-sampled data and sparse environmental feedback remains a fundamental challenge in training self-evolving agents. Temporal credit assignment mitigates this issue by transforming sparse feedback into dense supervision signals. However, previous approaches typically depend on learning task-specific value functions for credit assignment, which suffer from poor sample efficiency and limited generalization. In this work, we propose to leverage pretrained knowledge from large language models (LLMs) to transform sparse rewards into dense training signals (i.e., the advantage function) through retrospective in-context learning (RICL). We further propose an online learning framework, RICOL, which iteratively refines the policy based on the credit assignment results from RICL. We empirically demonstrate that RICL can accurately estimate the advantage function with limited samples and effectively identify critical states in the environment for temporal credit assignment. Extended evaluation on four BabyAI scenarios show that RICOL achieves comparable convergent performance with traditional online RL algorithms with significantly higher sample efficiency. Our findings highlight the potential of leveraging LLMs for temporal credit assignment, paving the way for more sample-efficient and generalizable RL paradigms.",
      "authors": [
        "Wen-Tse Chen",
        "Jiayu Chen",
        "Fahim Tajwar",
        "Hao Zhu",
        "Xintong Duan",
        "Ruslan Salakhutdinov",
        "Jeff Schneider"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T16:13:28Z",
      "updated": "2026-02-19T16:13:28Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17497v1",
      "abs_url": "http://arxiv.org/abs/2602.17497v1",
      "summary": "利用LLM进行回顾性上下文学习，实现高效的时间信用分配，提升强化学习样本效率。",
      "key_contributions": [
        "提出回顾性上下文学习（RICL）方法，利用LLM进行优势函数估计",
        "提出在线学习框架RICOL，迭代优化策略",
        "实验证明RICL具有高效的样本利用率和良好的泛化性"
      ],
      "methodology": "利用LLM将稀疏奖励转化为密集的优势函数，并通过在线学习框架迭代优化策略。",
      "tags": [
        "强化学习",
        "大语言模型",
        "时间信用分配",
        "上下文学习"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于利用LLM提升强化学习Agent的样本效率和泛化能力。",
      "analyzed_at": "2026-02-20T06:57:10.722594",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17486v1",
      "title": "Linear Convergence in Games with Delayed Feedback via Extra Prediction",
      "abstract": "Feedback delays are inevitable in real-world multi-agent learning. They are known to severely degrade performance, and the convergence rate under delayed feedback is still unclear, even for bilinear games. This paper derives the rate of linear convergence of Weighted Optimistic Gradient Descent-Ascent (WOGDA), which predicts future rewards with extra optimism, in unconstrained bilinear games. To analyze the algorithm, we interpret it as an approximation of the Extra Proximal Point (EPP), which is updated based on farther future rewards than the classical Proximal Point (PP). Our theorems show that standard optimism (predicting the next-step reward) achieves linear convergence to the equilibrium at a rate $\\exp(-Θ(t/m^{5}))$ after $t$ iterations for delay $m$. Moreover, employing extra optimism (predicting farther future reward) tolerates a larger step size and significantly accelerates the rate to $\\exp(-Θ(t/(m^{2}\\log m)))$. Our experiments also show accelerated convergence driven by the extra optimism and are qualitatively consistent with our theorems. In summary, this paper validates that extra optimism is a promising countermeasure against performance degradation caused by feedback delays.",
      "authors": [
        "Yuma Fujimoto",
        "Kenshi Abe",
        "Kaito Ariu"
      ],
      "categories": [
        "cs.LG",
        "cs.GT",
        "cs.MA",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T15:56:27Z",
      "updated": "2026-02-19T15:56:27Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17486v1",
      "abs_url": "http://arxiv.org/abs/2602.17486v1",
      "summary": "该论文提出通过引入额外乐观的WOGDA算法来加速延迟反馈博弈中的线性收敛。",
      "key_contributions": [
        "分析了延迟反馈下WOGDA算法的线性收敛速率",
        "提出了额外乐观的WOGDA算法以加速收敛",
        "通过实验验证了额外乐观策略的有效性"
      ],
      "methodology": "将WOGDA算法解释为EPP的近似，并基于更远的未来奖励进行更新，从而分析算法的收敛性。",
      "tags": [
        "多智能体学习",
        "延迟反馈",
        "线性收敛",
        "乐观梯度下降",
        "双线性博弈"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "涉及多智能体学习，优化算法可能应用于Agent中。",
      "analyzed_at": "2026-02-20T06:57:13.870637",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17483v1",
      "title": "What Do LLMs Associate with Your Name? A Human-Centered Black-Box Audit of Personal Data",
      "abstract": "Large language models (LLMs), and conversational agents based on them, are exposed to personal data (PD) during pre-training and during user interactions. Prior work shows that PD can resurface, yet users lack insight into how strongly models associate specific information to their identity. We audit PD across eight LLMs (3 open-source; 5 API-based, including GPT-4o), introduce LMP2 (Language Model Privacy Probe), a human-centered, privacy-preserving audit tool refined through two formative studies (N=20), and run two studies with EU residents to capture (i) intuitions about LLM-generated PD (N1=155) and (ii) reactions to tool output (N2=303). We show empirically that models confidently generate multiple PD categories for well-known individuals. For everyday users, GPT-4o generates 11 features with 60% or more accuracy (e.g., gender, hair color, languages). Finally, 72% of participants sought control over model-generated associations with their name, raising questions about what counts as PD and whether data privacy rights should extend to LLMs.",
      "authors": [
        "Dimitri Staufer",
        "Kirsten Morehouse"
      ],
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "published": "2026-02-19T15:53:29Z",
      "updated": "2026-02-19T15:53:29Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17483v1",
      "abs_url": "http://arxiv.org/abs/2602.17483v1",
      "summary": "论文审计LLM对个人数据的关联性，发现模型能生成高准确度的个人信息，并引发用户对数据隐私的关注。",
      "key_contributions": [
        "提出LMP2审计工具，评估LLM对个人信息的关联",
        "评估了多个LLM生成个人信息的准确性",
        "调查了用户对LLM生成个人信息关联的看法和隐私需求"
      ],
      "methodology": "通过用户研究(N=458)和LMP2工具，审计了多个LLM（包括GPT-4o）对个人数据的关联程度和准确性。",
      "tags": [
        "LLM",
        "个人数据",
        "隐私",
        "审计"
      ],
      "assigned_category": "memory",
      "relevance_score": 8,
      "relevance_reason": "研究LLM中存储的个人数据以及如何检索，与memory类别相关。",
      "analyzed_at": "2026-02-20T06:57:16.022143",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17478v1",
      "title": "QuPAINT: Physics-Aware Instruction Tuning Approach to Quantum Material Discovery",
      "abstract": "Characterizing two-dimensional quantum materials from optical microscopy images is challenging due to the subtle layer-dependent contrast, limited labeled data, and significant variation across laboratories and imaging setups. Existing vision models struggle in this domain since they lack physical priors and cannot generalize to new materials or hardware conditions. This work presents a new physics-aware multimodal framework that addresses these limitations from both the data and model perspectives. We first present Synthia, a physics-based synthetic data generator that simulates realistic optical responses of quantum material flakes under thin-film interference. Synthia produces diverse and high-quality samples, helping reduce the dependence on expert manual annotation. We introduce QMat-Instruct, the first large-scale instruction dataset for quantum materials, comprising multimodal, physics-informed question-answer pairs designed to teach Multimodal Large Language Models (MLLMs) to understand the appearance and thickness of flakes. Then, we propose Physics-Aware Instruction Tuning (QuPAINT), a multimodal architecture that incorporates a Physics-Informed Attention module to fuse visual embeddings with optical priors, enabling more robust and discriminative flake representations. Finally, we establish QF-Bench, a comprehensive benchmark spanning multiple materials, substrates, and imaging settings, offering standardized protocols for fair and reproducible evaluation.",
      "authors": [
        "Xuan-Bac Nguyen",
        "Hoang-Quan Nguyen",
        "Sankalp Pandey",
        "Tim Faltermeier",
        "Nicholas Borys",
        "Hugh Churchill",
        "Khoa Luu"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-19T15:44:41Z",
      "updated": "2026-02-19T15:44:41Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17478v1",
      "abs_url": "http://arxiv.org/abs/2602.17478v1",
      "summary": "提出QuPAINT框架，利用物理先验知识提升量子材料光学图像识别能力。",
      "key_contributions": [
        "提出Synthia物理驱动的合成数据生成器",
        "构建QMat-Instruct大规模量子材料指令数据集",
        "提出Physics-Aware Instruction Tuning (QuPAINT)框架",
        "构建QF-Bench综合评测基准"
      ],
      "methodology": "利用物理先验生成合成数据，构建指令数据集微调多模态大模型，并设计物理信息注意力模块融合视觉特征。",
      "tags": [
        "量子材料",
        "多模态学习",
        "指令微调",
        "物理信息"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 8,
      "relevance_reason": "论文核心在于多模态学习，并利用物理知识提升视觉识别能力，高度相关。",
      "analyzed_at": "2026-02-20T06:57:17.992709",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17475v1",
      "title": "Small LLMs for Medical NLP: a Systematic Analysis of Few-Shot, Constraint Decoding, Fine-Tuning and Continual Pre-Training in Italian",
      "abstract": "Large Language Models (LLMs) consistently excel in diverse medical Natural Language Processing (NLP) tasks, yet their substantial computational requirements often limit deployment in real-world healthcare settings. In this work, we investigate whether \"small\" LLMs (around one billion parameters) can effectively perform medical tasks while maintaining competitive accuracy. We evaluate models from three major families-Llama-3, Gemma-3, and Qwen3-across 20 clinical NLP tasks among Named Entity Recognition, Relation Extraction, Case Report Form Filling, Question Answering, and Argument Mining. We systematically compare a range of adaptation strategies, both at inference time (few-shot prompting, constraint decoding) and at training time (supervised fine-tuning, continual pretraining). Fine-tuning emerges as the most effective approach, while the combination of few-shot prompting and constraint decoding offers strong lower-resource alternatives. Our results show that small LLMs can match or even surpass larger baselines, with our best configuration based on Qwen3-1.7B achieving an average score +9.2 points higher than Qwen3-32B. We release a comprehensive collection of all the publicly available Italian medical datasets for NLP tasks, together with our top-performing models. Furthermore, we release an Italian dataset of 126M words from the Emergency Department of an Italian Hospital, and 175M words from various sources that we used for continual pre-training.",
      "authors": [
        "Pietro Ferrazzi",
        "Mattia Franzin",
        "Alberto Lavelli",
        "Bernardo Magnini"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-19T15:38:46Z",
      "updated": "2026-02-19T15:38:46Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17475v1",
      "abs_url": "http://arxiv.org/abs/2602.17475v1",
      "summary": "该论文研究了小型LLM在意大利语医疗NLP任务上的表现，并比较了多种优化策略。",
      "key_contributions": [
        "评估小型LLM在医疗NLP任务上的性能",
        "比较了不同的适应策略，包括微调和约束解码",
        "发布了意大利语医疗NLP数据集和预训练数据"
      ],
      "methodology": "在20个临床NLP任务上，比较了Llama-3、Gemma-3和Qwen3等小型LLM的微调、少样本学习和约束解码等方法。",
      "tags": [
        "小型LLM",
        "医疗NLP",
        "意大利语",
        "微调",
        "约束解码"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 7,
      "relevance_reason": "涉及LLM在特定领域的应用和优化，属于推理能力的应用。",
      "analyzed_at": "2026-02-20T06:57:20.805460",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17467v1",
      "title": "PEACE 2.0: Grounded Explanations and Counter-Speech for Combating Hate Expressions",
      "abstract": "The increasing volume of hate speech on online platforms poses significant societal challenges. While the Natural Language Processing community has developed effective methods to automatically detect the presence of hate speech, responses to it, called counter-speech, are still an open challenge. We present PEACE 2.0, a novel tool that, besides analysing and explaining why a message is considered hateful or not, also generates a response to it. More specifically, PEACE 2.0 has three main new functionalities: leveraging a Retrieval-Augmented Generation (RAG) pipeline i) to ground HS explanations into evidence and facts, ii) to automatically generate evidence-grounded counter-speech, and iii) exploring the characteristics of counter-speech replies. By integrating these capabilities, PEACE 2.0 enables in-depth analysis and response generation for both explicit and implicit hateful messages.",
      "authors": [
        "Greta Damo",
        "Stéphane Petiot",
        "Elena Cabrio",
        "Serena Villata"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-19T15:33:56Z",
      "updated": "2026-02-19T15:33:56Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17467v1",
      "abs_url": "http://arxiv.org/abs/2602.17467v1",
      "summary": "PEACE 2.0工具利用RAG生成证据支撑的反仇恨言论解释和回复。",
      "key_contributions": [
        "提出PEACE 2.0工具",
        "利用RAG生成仇恨言论的解释和回复",
        "探索反仇恨言论回复的特征"
      ],
      "methodology": "使用Retrieval-Augmented Generation (RAG) 框架，从证据和事实中检索信息，并生成基于证据的反仇恨言论。",
      "tags": [
        "仇恨言论检测",
        "反仇恨言论",
        "Retrieval-Augmented Generation"
      ],
      "assigned_category": "memory",
      "relevance_score": 8,
      "relevance_reason": "该论文核心在于利用RAG生成回复，高度相关。",
      "analyzed_at": "2026-02-20T06:57:22.575476",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17452v1",
      "title": "Jolt Atlas: Verifiable Inference via Lookup Arguments in Zero Knowledge",
      "abstract": "We present Jolt Atlas, a zero-knowledge machine learning (zkML) framework that extends the Jolt proving system to model inference. Unlike zkVMs (zero-knowledge virtual machines), which emulate CPU instruction execution, Jolt Atlas adapts Jolt's lookup-centric approach and applies it directly to ONNX tensor operations. The ONNX computational model eliminates the need for CPU registers and simplifies memory consistency verification. In addition, ONNX is an open-source, portable format, which makes it easy to share and deploy models across different frameworks, hardware platforms, and runtime environments without requiring framework-specific conversions.   Our lookup arguments, which use sumcheck protocol, are well-suited for non-linear functions -- key building blocks in modern ML. We apply optimisations such as neural teleportation to reduce the size of lookup tables while preserving model accuracy, as well as several tensor-level verification optimisations detailed in this paper. We demonstrate that Jolt Atlas can prove model inference in memory-constrained environments -- a prover property commonly referred to as \\textit{streaming}. Furthermore, we discuss how Jolt Atlas achieves zero-knowledge through the BlindFold technique, as introduced in Vega. In contrast to existing zkML frameworks, we show practical proving times for classification, embedding, automated reasoning, and small language models.   Jolt Atlas enables cryptographic verification that can be run on-device, without specialised hardware. The resulting proofs are succinctly verifiable. This makes Jolt Atlas well-suited for privacy-centric and adversarial environments. In a companion work, we outline various use cases of Jolt Atlas, including how it serves as guardrails in agentic commerce and for trustless AI context (often referred to as \\textit{AI memory}).",
      "authors": [
        "Wyatt Benno",
        "Alberto Centelles",
        "Antoine Douchet",
        "Khalil Gibran"
      ],
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "published": "2026-02-19T15:17:18Z",
      "updated": "2026-02-19T15:17:18Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17452v1",
      "abs_url": "http://arxiv.org/abs/2602.17452v1",
      "summary": "Jolt Atlas是一个基于查找参数的零知识ML框架，适用于模型推理。",
      "key_contributions": [
        "提出Jolt Atlas框架，用于零知识ML模型推理",
        "利用查找参数和ONNX格式，简化模型验证",
        "实现内存受限环境下的模型推理验证（streaming）"
      ],
      "methodology": "采用基于sumcheck协议的查找参数，结合ONNX模型格式，并通过神经元传送等优化技术，实现高效零知识推理。",
      "tags": [
        "Zero-Knowledge Machine Learning",
        "zkML",
        "ONNX",
        "Lookup Arguments"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 7,
      "relevance_reason": "涉及AI模型推理验证，与reasoning有一定的关联。",
      "analyzed_at": "2026-02-20T06:57:24.361937",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17450v1",
      "title": "Beyond Pipelines: A Fundamental Study on the Rise of Generative-Retrieval Architectures in Web Research",
      "abstract": "Web research and practices have evolved significantly over time, offering users diverse and accessible solutions across a wide range of tasks. While advanced concepts such as Web 4.0 have emerged from mature technologies, the introduction of large language models (LLMs) has profoundly influenced both the field and its applications. This wave of LLMs has permeated science and technology so deeply that no area remains untouched. Consequently, LLMs are reshaping web research and development, transforming traditional pipelines into generative solutions for tasks like information retrieval, question answering, recommendation systems, and web analytics. They have also enabled new applications such as web-based summarization and educational tools. This survey explores recent advances in the impact of LLMs-particularly through the use of retrieval-augmented generation (RAG)-on web research and industry. It discusses key developments, open challenges, and future directions for enhancing web solutions with LLMs.",
      "authors": [
        "Amirereza Abbasi",
        "Mohsen Hooshmand"
      ],
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "published": "2026-02-19T15:14:54Z",
      "updated": "2026-02-19T15:14:54Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17450v1",
      "abs_url": "http://arxiv.org/abs/2602.17450v1",
      "summary": "该论文综述了大型语言模型（LLMs）和检索增强生成（RAG）对Web研究和应用的影响。",
      "key_contributions": [
        "总结了LLMs和RAG在Web研究中的应用",
        "探讨了LLMs在信息检索、问答等任务中的作用",
        "指出了LLMs在Web应用中的挑战和未来方向"
      ],
      "methodology": "该论文采用综述形式，回顾并分析了近年来LLMs和RAG在Web研究领域的相关工作。",
      "tags": [
        "LLMs",
        "RAG",
        "Web Research",
        "Information Retrieval"
      ],
      "assigned_category": "memory",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注RAG在Web研究中的应用，高度相关。",
      "analyzed_at": "2026-02-20T06:57:26.215827",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17445v1",
      "title": "ABCD: All Biases Come Disguised",
      "abstract": "Multiple-choice question (MCQ) benchmarks have been a standard evaluation practice for measuring LLMs' ability to reason and answer knowledge-based questions. Through a synthetic NonsenseQA benchmark, we observe that different LLMs exhibit varying degrees of label-position-few-shot-prompt bias, where the model either uses the answer position, the label in front of the answer, the distributions of correct answers present in the few-shot prompt, or a combination of all to answer each MCQ question. We propose a simple bias-reduced evaluation protocol that replaces the labels of each question with uniform, unordered labels and prompts the LLM to use the whole answer presented. With a simple sentence similarity model, we demonstrate improved robustness and lower standard deviation between different permutations of answers with a minimal drop in LLM's performance, exposing the LLM's capabilities under reduced evaluation artifacts, without any help from the prompt examples or the option labels. Across multiple benchmarks and models, this protocol substantially improves the robustness to answer permutations, reducing mean accuracy variance $3\\times$ with only a minimal decrease in the mean model's performance. Through ablation studies on various embedding models and similarity functions, we show that the method is more robust than the standard ones.",
      "authors": [
        "Mateusz Nowak",
        "Xavier Cadet",
        "Peter Chin"
      ],
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-19T15:12:33Z",
      "updated": "2026-02-19T15:12:33Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17445v1",
      "abs_url": "http://arxiv.org/abs/2602.17445v1",
      "summary": "该论文提出了一种降低LLM在多项选择题基准测试中偏见的评估方法，提高了模型的鲁棒性。",
      "key_contributions": [
        "发现LLM在多项选择题中存在标签位置、少样本提示等偏见。",
        "提出了一种简单的去偏评估协议，使用统一的、无序的标签。",
        "证明了该协议可以提高模型在答案排列上的鲁棒性，同时对性能影响很小。"
      ],
      "methodology": "通过合成NonsenseQA基准测试，观察不同LLM的偏见，并使用句子相似度模型进行评估，验证去偏协议的有效性。",
      "tags": [
        "LLM",
        "Bias",
        "Evaluation",
        "Robustness"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "直接研究LLM的推理评估和偏见问题，是该领域的关键研究方向。",
      "analyzed_at": "2026-02-20T06:57:28.246626",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17443v1",
      "title": "AIDG: Evaluating Asymmetry Between Information Extraction and Containment in Multi-Turn Dialogue",
      "abstract": "Evaluating the strategic reasoning capabilities of Large Language Models (LLMs) requires moving beyond static benchmarks to dynamic, multi-turn interactions. We introduce AIDG (Adversarial Information Deduction Game), a game-theoretic framework that probes the asymmetry between information extraction (active deduction) and information containment (state maintenance) in dialogue. We propose two complementary tasks: AIDG-I, measuring pragmatic strategy in social deduction, and AIDG-II, measuring constraint satisfaction in a structured \"20 Questions\" setting. Across 439 games with six frontier LLMs, we observe a clear capability asymmetry: models perform substantially better at containment than deduction, with a 350 ELO advantage on defense;(Cohen's d = 5.47). We identify two bottlenecks driving this gap: (1) Information Dynamics, where confirmation strategies are 7.75x more effective than blind deduction (p < 0.00001), and (2) Constraint Adherence, where instruction-following degrades under conversational load, accounting for 41.3% of deductive failures. These findings suggest that while LLMs excel at local defensive coherence, they struggle with the global state tracking required for strategic inquiry.",
      "authors": [
        "Adib Sakhawat",
        "Fardeen Sadab",
        "Rakin Shahriar"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-19T15:09:12Z",
      "updated": "2026-02-19T15:09:12Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17443v1",
      "abs_url": "http://arxiv.org/abs/2602.17443v1",
      "summary": "AIDG框架评估LLM在多轮对话中信息提取与包含的不对称性，揭示其推理瓶颈。",
      "key_contributions": [
        "提出了AIDG评估框架，用于评估LLM的战略推理能力",
        "设计了AIDG-I和AIDG-II两个任务，分别测量社交推理和约束满足",
        "发现LLM在信息包含方面优于信息提取，存在能力不对称"
      ],
      "methodology": "设计博弈论框架AIDG，包含社交演绎和“20问”两个任务，通过与LLM进行多轮对话，分析其在信息提取和包含方面的能力差异。",
      "tags": [
        "LLM",
        "Reasoning",
        "Dialogue",
        "Game Theory",
        "Asymmetry"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注LLM的推理能力，并通过对话评估其战略推理的局限性。",
      "analyzed_at": "2026-02-20T06:57:30.293391",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17442v1",
      "title": "WarpRec: Unifying Academic Rigor and Industrial Scale for Responsible, Reproducible, and Efficient Recommendation",
      "abstract": "Innovation in Recommender Systems is currently impeded by a fractured ecosystem, where researchers must choose between the ease of in-memory experimentation and the costly, complex rewriting required for distributed industrial engines. To bridge this gap, we present WarpRec, a high-performance framework that eliminates this trade-off through a novel, backend-agnostic architecture. It includes 50+ state-of-the-art algorithms, 40 metrics, and 19 filtering and splitting strategies that seamlessly transition from local execution to distributed training and optimization. The framework enforces ecological responsibility by integrating CodeCarbon for real-time energy tracking, showing that scalability need not come at the cost of scientific integrity or sustainability. Furthermore, WarpRec anticipates the shift toward Agentic AI, leading Recommender Systems to evolve from static ranking engines into interactive tools within the Generative AI ecosystem. In summary, WarpRec not only bridges the gap between academia and industry but also can serve as the architectural backbone for the next generation of sustainable, agent-ready Recommender Systems. Code is available at https://github.com/sisinflab/warprec/",
      "authors": [
        "Marco Avolio",
        "Potito Aghilar",
        "Sabino Roccotelli",
        "Vito Walter Anelli",
        "Chiara Mallamaci",
        "Vincenzo Paparella",
        "Marco Valentini",
        "Alejandro Bellogín",
        "Michelantonio Trizio",
        "Joseph Trotta",
        "Antonio Ferrara",
        "Tommaso Di Noia"
      ],
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-19T15:09:04Z",
      "updated": "2026-02-19T15:09:04Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17442v1",
      "abs_url": "http://arxiv.org/abs/2602.17442v1",
      "summary": "WarpRec框架弥合学术界和工业界推荐系统差距，实现高效、可持续、面向Agent的推荐系统。",
      "key_contributions": [
        "提出backend-agnostic的高性能推荐框架WarpRec",
        "集成50+先进算法和40种指标，支持分布式训练",
        "集成CodeCarbon实现实时能源追踪"
      ],
      "methodology": "构建一个灵活的框架，通过backend-agnostic架构，支持多种算法和指标，并集成能源监控，实现学术研究到工业应用的无缝过渡。",
      "tags": [
        "推荐系统",
        "分布式训练",
        "能源效率",
        "Agentic AI",
        "可复现性"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "框架设计考虑了向Agentic AI的演进，具备一定相关性。",
      "analyzed_at": "2026-02-20T06:57:32.517624",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17419v1",
      "title": "EAGLE: Expert-Augmented Attention Guidance for Tuning-Free Industrial Anomaly Detection in Multimodal Large Language Models",
      "abstract": "Industrial anomaly detection is important for smart manufacturing, but many deep learning approaches produce only binary decisions and provide limited semantic explanations. Multimodal large language models (MLLMs) can potentially generate fine-grained, language-based analyses, yet existing methods often require costly fine-tuning and do not consistently improve anomaly detection accuracy compared to lightweight specialist detectors. We propose expert-augmented attention guidance for industrial anomaly detection in MLLMs (EAGLE), a tuning-free framework that integrates outputs from expert model to guide MLLMs toward both accurate detection and interpretable anomaly descriptions. We further study how EAGLE affects MLLMs internals by examining the attention distribution of MLLMs to the anomalous image regions in the intermediate layers. We observe that successful anomaly detection is associated with increased attention concentration on anomalous regions, and EAGLE tends to encourage this alignment. Experiments on MVTec-AD and VisA show that EAGLE improves anomaly detection performance across multiple MLLMs without any parameter updates, achieving results comparable to fine-tuning based methods. Code is available at \\href{https://github.com/shengtun/Eagle}{https://github.com/shengtun/Eagle}",
      "authors": [
        "Xiaomeng Peng",
        "Xilang Huang",
        "Seon Han Choi"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-19T14:50:58Z",
      "updated": "2026-02-19T14:50:58Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17419v1",
      "abs_url": "http://arxiv.org/abs/2602.17419v1",
      "summary": "EAGLE利用专家模型引导MLLM，无需微调即可提升工业异常检测的准确性和可解释性。",
      "key_contributions": [
        "提出EAGLE框架，无需微调即可提高MLLM异常检测性能",
        "利用专家模型指导MLLM关注异常区域，提升可解释性",
        "分析了EAGLE对MLLM内部注意力分布的影响"
      ],
      "methodology": "EAGLE通过集成专家模型的输出，引导MLLM的注意力机制，使其更关注异常区域，从而提高检测准确性和可解释性。",
      "tags": [
        "MLLM",
        "异常检测",
        "工业应用",
        "注意力机制",
        "无微调"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心是利用MLLM进行异常检测，并改进了其注意力机制。",
      "analyzed_at": "2026-02-20T06:57:34.533673",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17410v1",
      "title": "Improving LLM-based Recommendation with Self-Hard Negatives from Intermediate Layers",
      "abstract": "Large language models (LLMs) have shown great promise in recommender systems, where supervised fine-tuning (SFT) is commonly used for adaptation. Subsequent studies further introduce preference learning to incorporate negative samples into the training process. However, existing methods rely on sequence-level, offline-generated negatives, making them less discriminative and informative when adapting LLMs to recommendation tasks with large negative item spaces. To address these challenges, we propose ILRec, a novel preference fine-tuning framework for LLM-based recommendation, leveraging self-hard negative signals extracted from intermediate layers to improve preference learning. Specifically, we identify self-hard negative tokens from intermediate layers as fine-grained negative supervision that dynamically reflects the model's preference learning process. To effectively integrate these signals into training, we design a two-stage framework comprising cross-layer preference optimization and cross-layer preference distillation, enabling the model to jointly discriminate informative negatives and enhance the quality of negative signals from intermediate layers. In addition, we introduce a lightweight collaborative filtering model to assign token-level rewards for negative signals, mitigating the risk of over-penalizing false negatives. Extensive experiments on three datasets demonstrate ILRec's effectiveness in enhancing the performance of LLM-based recommender systems.",
      "authors": [
        "Bingqian Li",
        "Bowen Zheng",
        "Xiaolei Wang",
        "Long Zhang",
        "Jinpeng Wang",
        "Sheng Chen",
        "Wayne Xin Zhao",
        "Ji-rong Wen"
      ],
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "published": "2026-02-19T14:37:43Z",
      "updated": "2026-02-19T14:37:43Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17410v1",
      "abs_url": "http://arxiv.org/abs/2602.17410v1",
      "summary": "ILRec提出了一种新的LLM推荐框架，利用中间层的自生成困难负样本提升推荐性能。",
      "key_contributions": [
        "提出了基于LLM的推荐框架ILRec",
        "引入中间层自生成困难负样本作为负样本",
        "设计了两阶段训练框架进行负样本优化和蒸馏"
      ],
      "methodology": "通过中间层提取自生成困难负样本，并利用两阶段训练框架（跨层偏好优化和蒸馏）提升模型性能，加入轻量级协同过滤模型缓解假负样本问题。",
      "tags": [
        "LLM",
        "推荐系统",
        "负采样",
        "自监督学习"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 8,
      "relevance_reason": "涉及LLM微调与偏好优化，对agent tuning方向具有参考价值。",
      "analyzed_at": "2026-02-20T06:57:36.294429",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17402v1",
      "title": "A Contrastive Variational AutoEncoder for NSCLC Survival Prediction with Missing Modalities",
      "abstract": "Predicting survival outcomes for non-small cell lung cancer (NSCLC) patients is challenging due to the different individual prognostic features. This task can benefit from the integration of whole-slide images, bulk transcriptomics, and DNA methylation, which offer complementary views of the patient's condition at diagnosis. However, real-world clinical datasets are often incomplete, with entire modalities missing for a significant fraction of patients. State-of-the-art models rely on available data to create patient-level representations or use generative models to infer missing modalities, but they lack robustness in cases of severe missingness. We propose a Multimodal Contrastive Variational AutoEncoder (MCVAE) to address this issue: modality-specific variational encoders capture the uncertainty in each data source, and a fusion bottleneck with learned gating mechanisms is introduced to normalize the contributions from present modalities. We propose a multi-task objective that combines survival loss and reconstruction loss to regularize patient representations, along with a cross-modal contrastive loss that enforces cross-modal alignment in the latent space. During training, we apply stochastic modality masking to improve the robustness to arbitrary missingness patterns. Extensive evaluations on the TCGA-LUAD (n=475) and TCGA-LUSC (n=446) datasets demonstrate the efficacy of our approach in predicting disease-specific survival (DSS) and its robustness to severe missingness scenarios compared to two state-of-the-art models. Finally, we bring some clarifications on multimodal integration by testing our model on all subsets of modalities, finding that integration is not always beneficial to the task.",
      "authors": [
        "Michele Zanitti",
        "Vanja Miskovic",
        "Francesco Trovò",
        "Alessandra Laura Giulia Pedrocchi",
        "Ming Shen",
        "Yan Kyaw Tun",
        "Arsela Prelaj",
        "Sokol Kosta"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-19T14:29:34Z",
      "updated": "2026-02-19T14:29:34Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17402v1",
      "abs_url": "http://arxiv.org/abs/2602.17402v1",
      "summary": "提出一种多模态对比变分自编码器，用于解决非小细胞肺癌生存预测中模态缺失问题。",
      "key_contributions": [
        "提出多模态对比变分自编码器（MCVAE）处理模态缺失问题。",
        "引入学习门控机制的融合瓶颈，标准化模态贡献。",
        "提出结合生存损失、重建损失和跨模态对比损失的多任务目标。",
        "通过随机模态掩码提高模型对任意缺失模式的鲁棒性。"
      ],
      "methodology": "使用变分自编码器捕获模态不确定性，通过对比学习对齐潜在空间，并用多任务目标和模态掩码增强模型。",
      "tags": [
        "多模态学习",
        "生存预测",
        "缺失数据处理",
        "对比学习",
        "变分自编码器"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心是解决多模态数据缺失场景下的生存预测问题，属于多模态学习的重要应用。",
      "analyzed_at": "2026-02-20T06:57:38.607121",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17395v1",
      "title": "SpectralGCD: Spectral Concept Selection and Cross-modal Representation Learning for Generalized Category Discovery",
      "abstract": "Generalized Category Discovery (GCD) aims to identify novel categories in unlabeled data while leveraging a small labeled subset of known classes. Training a parametric classifier solely on image features often leads to overfitting to old classes, and recent multimodal approaches improve performance by incorporating textual information. However, they treat modalities independently and incur high computational cost. We propose SpectralGCD, an efficient and effective multimodal approach to GCD that uses CLIP cross-modal image-concept similarities as a unified cross-modal representation. Each image is expressed as a mixture over semantic concepts from a large task-agnostic dictionary, which anchors learning to explicit semantics and reduces reliance on spurious visual cues. To maintain the semantic quality of representations learned by an efficient student, we introduce Spectral Filtering which exploits a cross-modal covariance matrix over the softmaxed similarities measured by a strong teacher model to automatically retain only relevant concepts from the dictionary. Forward and reverse knowledge distillation from the same teacher ensures that the cross-modal representations of the student remain both semantically sufficient and well-aligned. Across six benchmarks, SpectralGCD delivers accuracy comparable to or significantly superior to state-of-the-art methods at a fraction of the computational cost. The code is publicly available at: https://github.com/miccunifi/SpectralGCD.",
      "authors": [
        "Lorenzo Caselli",
        "Marco Mistretta",
        "Simone Magistri",
        "Andrew D. Bagdanov"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-19T14:18:50Z",
      "updated": "2026-02-19T14:18:50Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17395v1",
      "abs_url": "http://arxiv.org/abs/2602.17395v1",
      "summary": "SpectralGCD利用CLIP跨模态相似性，通过谱滤波和知识蒸馏实现高效广义类别发现。",
      "key_contributions": [
        "提出SpectralGCD框架，利用跨模态图像-概念相似性",
        "引入谱滤波，自动保留相关概念",
        "通过正向和反向知识蒸馏，保持学生模型的语义充分性和对齐性"
      ],
      "methodology": "构建基于CLIP的跨模态表示，使用谱滤波选择概念，并通过知识蒸馏训练学生模型。",
      "tags": [
        "广义类别发现",
        "多模态学习",
        "知识蒸馏",
        "谱分析"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于利用跨模态信息解决广义类别发现问题，属于多模态学习的关键研究方向。",
      "analyzed_at": "2026-02-20T06:57:40.503894",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17386v1",
      "title": "Visual Model Checking: Graph-Based Inference of Visual Routines for Image Retrieval",
      "abstract": "Information retrieval lies at the foundation of the modern digital industry. While natural language search has seen dramatic progress in recent years largely driven by embedding-based models and large-scale pretraining, the field still faces significant challenges. Specifically, queries that involve complex relationships, object compositions, or precise constraints such as identities, counts and proportions often remain unresolved or unreliable within current frameworks. In this paper, we propose a novel framework that integrates formal verification into deep learning-based image retrieval through a synergistic combination of graph-based verification methods and neural code generation. Our approach aims to support open-vocabulary natural language queries while producing results that are both trustworthy and verifiable. By grounding retrieval results in a system of formal reasoning, we move beyond the ambiguity and approximation that often characterize vector representations. Instead of accepting uncertainty as a given, our framework explicitly verifies each atomic truth in the user query against the retrieved content. This allows us to not only return matching results, but also to identify and mark which specific constraints are satisfied and which remain unmet, thereby offering a more transparent and accountable retrieval process while boosting the results of the most popular embedding-based approaches.",
      "authors": [
        "Adrià Molina",
        "Oriol Ramos Terrades",
        "Josep Lladós"
      ],
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-19T14:10:55Z",
      "updated": "2026-02-19T14:10:55Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17386v1",
      "abs_url": "http://arxiv.org/abs/2602.17386v1",
      "summary": "提出一种结合形式验证和深度学习的图像检索框架，提升复杂关系查询的可信度和可验证性。",
      "key_contributions": [
        "将形式验证融入图像检索",
        "提出基于图的视觉推理方法",
        "提升复杂查询结果的可信度和可验证性"
      ],
      "methodology": "结合图模型验证方法和神经代码生成，对检索结果进行形式化推理，验证查询条件是否满足。",
      "tags": [
        "图像检索",
        "形式验证",
        "深度学习",
        "图模型",
        "视觉推理"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 8,
      "relevance_reason": "论文涉及视觉信息和自然语言查询，属于多模态学习范畴。",
      "analyzed_at": "2026-02-20T06:57:42.218527",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17377v1",
      "title": "The Role of the Availability Heuristic in Multiple-Choice Answering Behaviour",
      "abstract": "When students are unsure of the correct answer to a multiple-choice question (MCQ), guessing is common practice. The availability heuristic, proposed by A. Tversky and D. Kahneman in 1973, suggests that the ease with which relevant instances come to mind, typically operationalised by the mere frequency of exposure, can offer a mental shortcut for problems in which the test-taker does not know the exact answer. Is simply choosing the option that comes most readily to mind a good strategy for answering MCQs? We propose a computational method of assessing the cognitive availability of MCQ options operationalised by concepts' prevalence in large corpora. The key finding, across three large question sets, is that correct answers, independently of the question stem, are significantly more available than incorrect MCQ options. Specifically, using Wikipedia as the retrieval corpus, we find that always selecting the most available option leads to scores 13.5% to 32.9% above the random-guess baseline. We further find that LLM-generated MCQ options show similar patterns of availability compared to expert-created options, despite the LLMs' frequentist nature and their training on large collections of textual data. Our findings suggest that availability should be considered in current and future work when computationally modelling student behaviour.",
      "authors": [
        "Leonidas Zotos",
        "Hedderik van Rijn",
        "Malvina Nissim"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-19T13:58:48Z",
      "updated": "2026-02-19T13:58:48Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17377v1",
      "abs_url": "http://arxiv.org/abs/2602.17377v1",
      "summary": "研究表明，在多选题中，更易被想到的选项更有可能是正确答案，可用于建模学生行为。",
      "key_contributions": [
        "验证了可用性启发式在多选题解答中的作用",
        "提出了一种基于语料库评估选项认知可用性的计算方法",
        "发现LLM生成的选项也表现出类似的可用性模式"
      ],
      "methodology": "利用大型语料库（Wikipedia）评估多选题选项的可用性，并分析可用性与正确答案之间的关系。",
      "tags": [
        "可用性启发式",
        "多选题",
        "认知建模",
        "LLM"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 7,
      "relevance_reason": "研究涉及LLM生成多选题选项，与LLM的推理能力相关。",
      "analyzed_at": "2026-02-20T06:57:44.747435",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17375v1",
      "title": "MDP Planning as Policy Inference",
      "abstract": "We cast episodic Markov decision process (MDP) planning as Bayesian inference over _policies_. A policy is treated as the latent variable and is assigned an unnormalized probability of optimality that is monotone in its expected return, yielding a posterior distribution whose modes coincide with return-maximizing solutions while posterior dispersion represents uncertainty over optimal behavior. To approximate this posterior in discrete domains, we adapt variational sequential Monte Carlo (VSMC) to inference over deterministic policies under stochastic dynamics, introducing a sweep that enforces policy consistency across revisited states and couples transition randomness across particles to avoid confounding from simulator noise. Acting is performed by posterior predictive sampling, which induces a stochastic control policy through a Thompson-sampling interpretation rather than entropy regularization. Across grid worlds, Blackjack, Triangle Tireworld, and Academic Advising, we analyze the structure of inferred policy distributions and compare the resulting behavior to discrete Soft Actor-Critic, highlighting qualitative and statistical differences that arise from policy-level uncertainty.",
      "authors": [
        "David Tolpin"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T13:56:31Z",
      "updated": "2026-02-19T13:56:31Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17375v1",
      "abs_url": "http://arxiv.org/abs/2602.17375v1",
      "summary": "将MDP规划视为策略上的贝叶斯推断，通过VSMC近似后验分布，实现策略层面的不确定性建模。",
      "key_contributions": [
        "将MDP规划问题转化为策略推断问题",
        "使用变分序列蒙特卡洛（VSMC）进行策略后验分布的近似",
        "通过后验预测抽样实现策略控制，并与Soft Actor-Critic进行比较"
      ],
      "methodology": "使用贝叶斯推断框架，将策略作为隐变量，用VSMC近似策略的后验分布，通过抽样进行决策。",
      "tags": [
        "MDP",
        "Bayesian Inference",
        "Policy Inference",
        "VSMC",
        "Reinforcement Learning"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "论文关注MDP规划，涉及agent的决策和规划能力，与AI Agent领域高度相关。",
      "analyzed_at": "2026-02-20T06:57:46.725508",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17366v1",
      "title": "RPDR: A Round-trip Prediction-Based Data Augmentation Framework for Long-Tail Question Answering",
      "abstract": "Long-tail question answering presents significant challenges for large language models (LLMs) due to their limited ability to acquire and accurately recall less common knowledge. Retrieval-augmented generation (RAG) systems have shown great promise in mitigating this limitation by integrating external retrieval mechanisms. However, dense retrieval models often face the same difficulties when generalizing to rare or niche knowledge. In this study, we introduce RPDR, a novel data augmentation framework that selects high-quality easy-to-learn training data, to enhance dense retrievers. Our approach is built around three core components: synthetic data generation, data selection with Round-Trip prediction to identify easy-to-learn instances, and retriever training with these instances. We evaluate RPDR on two long-tail retrieval benchmarks, PopQA and EntityQuestion, demonstrating substantial improvements over existing retrievers like BM25 and Contriver, especially on extremely long-tail categories. We identify the strengths and limitations of RPDR through detailed human analysis and propose a dynamic routing mechanism to dynamically route queries to specialized retrieval modules to further improve retrieval performance.",
      "authors": [
        "Yiming Zhang",
        "Siyue Zhang",
        "Junbo Zhao",
        "Chen Zhao"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-19T13:49:39Z",
      "updated": "2026-02-19T13:49:39Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17366v1",
      "abs_url": "http://arxiv.org/abs/2602.17366v1",
      "summary": "RPDR通过回环预测选择易学数据，增强检索器在长尾问答中的表现。",
      "key_contributions": [
        "提出RPDR框架，增强长尾问答检索能力",
        "使用回环预测选择高质量训练数据",
        "通过实验验证RPDR在PopQA和EntityQuestion数据集上的有效性"
      ],
      "methodology": "通过合成数据、回环预测选择易学样本，并用这些样本训练检索器。",
      "tags": [
        "长尾问答",
        "数据增强",
        "检索增强生成",
        "回环预测"
      ],
      "assigned_category": "memory",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注RAG系统在长尾知识问答中的检索增强问题。",
      "analyzed_at": "2026-02-20T06:57:48.522630",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17363v1",
      "title": "2Mamba2Furious: Linear in Complexity, Competitive in Accuracy",
      "abstract": "Linear attention transformers have become a strong alternative to softmax attention due to their efficiency. However, linear attention tends to be less expressive and results in reduced accuracy compared to softmax attention. To bridge the accuracy gap between softmax attention and linear attention, we manipulate Mamba-2, a very strong linear attention variant. We first simplify Mamba-2 down to its most fundamental and important components, evaluating which specific choices make it most accurate. From this simplified Mamba variant (Mamba-2S), we improve the A-mask and increase the order of the hidden state, resulting in a method, which we call 2Mamba, that is nearly as accurate as softmax attention, yet much more memory efficient for long context lengths. We also investigate elements to Mamba-2 that help surpass softmax attention accuracy. Code is provided for all our experiments",
      "authors": [
        "Gabriel Mongaras",
        "Eric C. Larson"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T13:45:23Z",
      "updated": "2026-02-19T13:45:23Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17363v1",
      "abs_url": "http://arxiv.org/abs/2602.17363v1",
      "summary": "通过简化和改进Mamba-2，论文提出了一种高效且精度接近softmax attention的模型2Mamba。",
      "key_contributions": [
        "简化Mamba-2并确定关键组件",
        "改进A-mask和隐藏状态维度提升精度",
        "提出2Mamba，在长序列上兼顾精度和效率"
      ],
      "methodology": "通过实验简化Mamba-2，分析其组件影响，然后改进A-mask和隐藏状态维度以提高精度。",
      "tags": [
        "线性注意力",
        "Mamba-2",
        "长序列建模",
        "效率优化",
        "Transformer"
      ],
      "assigned_category": "memory",
      "relevance_score": 7,
      "relevance_reason": "Mamba关注长序列建模，对LLM记忆和上下文处理有重要影响。",
      "analyzed_at": "2026-02-20T06:57:50.259997",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17345v1",
      "title": "What Breaks Embodied AI Security:LLM Vulnerabilities, CPS Flaws,or Something Else?",
      "abstract": "Embodied AI systems (e.g., autonomous vehicles, service robots, and LLM-driven interactive agents) are rapidly transitioning from controlled environments to safety critical real-world deployments. Unlike disembodied AI, failures in embodied intelligence lead to irreversible physical consequences, raising fundamental questions about security, safety, and reliability. While existing research predominantly analyzes embodied AI through the lenses of Large Language Model (LLM) vulnerabilities or classical Cyber-Physical System (CPS) failures, this survey argues that these perspectives are individually insufficient to explain many observed breakdowns in modern embodied systems. We posit that a significant class of failures arises from embodiment-induced system-level mismatches, rather than from isolated model flaws or traditional CPS attacks. Specifically, we identify four core insights that explain why embodied AI is fundamentally harder to secure: (i) semantic correctness does not imply physical safety, as language-level reasoning abstracts away geometry, dynamics, and contact constraints; (ii) identical actions can lead to drastically different outcomes across physical states due to nonlinear dynamics and state uncertainty; (iii) small errors propagate and amplify across tightly coupled perception-decision-action loops; and (iv) safety is not compositional across time or system layers, enabling locally safe decisions to accumulate into globally unsafe behavior. These insights suggest that securing embodied AI requires moving beyond component-level defenses toward system-level reasoning about physical risk, uncertainty, and failure propagation.",
      "authors": [
        "Boyang Ma",
        "Hechuan Guo",
        "Peizhuo Lv",
        "Minghui Xu",
        "Xuelong Dai",
        "YeChao Zhang",
        "Yijun Yang",
        "Yue Zhang"
      ],
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "published": "2026-02-19T13:29:00Z",
      "updated": "2026-02-19T13:29:00Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17345v1",
      "abs_url": "http://arxiv.org/abs/2602.17345v1",
      "summary": "具身智能安全问题源于系统级不匹配，而非孤立的模型缺陷或传统CPS攻击。",
      "key_contributions": [
        "指出LLM漏洞和CPS缺陷无法完全解释具身智能安全问题",
        "强调具身智能安全问题的系统级本质",
        "提出四个核心洞见解释具身智能更难安全的原因"
      ],
      "methodology": "通过分析现有研究，提出具身智能系统安全问题的核心洞见，强调系统级视角。",
      "tags": [
        "具身智能",
        "安全",
        "LLM",
        "CPS",
        "系统级安全"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "论文分析了LLM驱动的agent在具身环境中的安全问题，高度相关。",
      "analyzed_at": "2026-02-20T06:57:52.193204",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17342v1",
      "title": "From Subtle to Significant: Prompt-Driven Self-Improving Optimization in Test-Time Graph OOD Detection",
      "abstract": "Graph Out-of-Distribution (OOD) detection aims to identify whether a test graph deviates from the distribution of graphs observed during training, which is critical for ensuring the reliability of Graph Neural Networks (GNNs) when deployed in open-world scenarios. Recent advances in graph OOD detection have focused on test-time training techniques that facilitate OOD detection without accessing potential supervisory information (e.g., training data). However, most of these methods employ a one-pass inference paradigm, which prevents them from progressively correcting erroneous predictions to amplify OOD signals. To this end, we propose a \\textbf{S}elf-\\textbf{I}mproving \\textbf{G}raph \\textbf{O}ut-\\textbf{o}f-\\textbf{D}istribution detector (SIGOOD), which is an unsupervised framework that integrates continuous self-learning with test-time training for effective graph OOD detection. Specifically, SIGOOD generates a prompt to construct a prompt-enhanced graph that amplifies potential OOD signals. To optimize prompts, SIGOOD introduces an Energy Preference Optimization (EPO) loss, which leverages energy variations between the original test graph and the prompt-enhanced graph. By iteratively optimizing the prompt by involving it into the detection model in a self-improving loop, the resulting optimal prompt-enhanced graph is ultimately used for OOD detection. Comprehensive evaluations on 21 real-world datasets confirm the effectiveness and outperformance of our SIGOOD method. The code is at https://github.com/Ee1s/SIGOOD.",
      "authors": [
        "Luzhi Wang",
        "Xuanshuo Fu",
        "He Zhang",
        "Chuang Liu",
        "Xiaobao Wang",
        "Hongbo Liu"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T13:19:53Z",
      "updated": "2026-02-19T13:19:53Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17342v1",
      "abs_url": "http://arxiv.org/abs/2602.17342v1",
      "summary": "提出SIGOOD，利用提示驱动的自提升优化实现图OOD检测。",
      "key_contributions": [
        "提出SIGOOD框架，结合自学习和测试时训练。",
        "引入能量偏好优化(EPO)损失函数优化提示。",
        "在21个真实数据集上验证了方法有效性。"
      ],
      "methodology": "通过提示生成增强图，利用EPO损失迭代优化提示，实现自提升的OOD检测。",
      "tags": [
        "图神经网络",
        "OOD检测",
        "自提升学习",
        "提示学习"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 8,
      "relevance_reason": "利用提示优化进行自提升，属于agent tuning的重要方面。",
      "analyzed_at": "2026-02-20T06:57:53.880448",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17330v1",
      "title": "SubQuad: Near-Quadratic-Free Structure Inference with Distribution-Balanced Objectives in Adaptive Receptor framework",
      "abstract": "Comparative analysis of adaptive immune repertoires at population scale is hampered by two practical bottlenecks: the near-quadratic cost of pairwise affinity evaluations and dataset imbalances that obscure clinically important minority clonotypes. We introduce SubQuad, an end-to-end pipeline that addresses these challenges by combining antigen-aware, near-subquadratic retrieval with GPU-accelerated affinity kernels, learned multimodal fusion, and fairness-constrained clustering. The system employs compact MinHash prefiltering to sharply reduce candidate comparisons, a differentiable gating module that adaptively weights complementary alignment and embedding channels on a per-pair basis, and an automated calibration routine that enforces proportional representation of rare antigen-specific subgroups. On large viral and tumor repertoires SubQuad achieves measured gains in throughput and peak memory usage while preserving or improving recall@k, cluster purity, and subgroup equity. By co-designing indexing, similarity fusion, and equity-aware objectives, SubQuad offers a scalable, bias-aware platform for repertoire mining and downstream translational tasks such as vaccine target prioritization and biomarker discovery.",
      "authors": [
        "Rong Fu",
        "Zijian Zhang",
        "Wenxin Zhang",
        "Kun Liu",
        "Jiekai Wu",
        "Xianda Li",
        "Simon Fong"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T12:51:25Z",
      "updated": "2026-02-19T12:51:25Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17330v1",
      "abs_url": "http://arxiv.org/abs/2602.17330v1",
      "summary": "SubQuad通过优化流程和目标函数，实现了免疫组库分析的加速、减负和公平性提升。",
      "key_contributions": [
        "提出了 antigen-aware 的近亚二次检索方法",
        "设计了可微分门控模块自适应融合对齐和嵌入通道",
        "实现了自动化校准流程以确保罕见亚群的比例代表性"
      ],
      "methodology": "结合 MinHash 预过滤、GPU加速的affinity kernels、多模态融合和公平约束聚类，构建端到端的免疫组库分析流程。",
      "tags": [
        "免疫组库",
        "亲和力评估",
        "公平性",
        "聚类"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 5,
      "relevance_reason": "涉及多模态融合，但主要关注生物信息学领域问题。",
      "analyzed_at": "2026-02-20T06:57:55.836660",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17327v1",
      "title": "WebFAQ 2.0: A Multilingual QA Dataset with Mined Hard Negatives for Dense Retrieval",
      "abstract": "We introduce WebFAQ 2.0, a new version of the WebFAQ dataset, containing 198 million FAQ-based natural question-answer pairs across 108 languages. Compared to the previous version, it significantly expands multilingual coverage and the number of bilingual aligned QA pairs to over 14.3M, making it the largest FAQ-based resource. Unlike the original release, WebFAQ 2.0 uses a novel data collection strategy that directly crawls and extracts relevant web content, resulting in a substantially more diverse and multilingual dataset with richer context through page titles and descriptions. In response to community feedback, we also release a hard negatives dataset for training dense retrievers, with 1.25M queries across 20 languages. These hard negatives were mined using a two-stage retrieval pipeline and include cross-encoder scores for 200 negatives per query. We further show how this resource enables two primary fine-tuning strategies for dense retrievers: Contrastive Learning with MultipleNegativesRanking loss, and Knowledge Distillation with MarginMSE loss. WebFAQ 2.0 is not a static resource but part of a long-term effort. Since late 2025, structured FAQs are being regularly released through the Open Web Index, enabling continuous expansion and refinement. We publish the datasets and training scripts to facilitate further research in multilingual and cross-lingual IR. The dataset itself and all related resources are publicly available on GitHub and HuggingFace.",
      "authors": [
        "Michael Dinzinger",
        "Laura Caspari",
        "Ali Salman",
        "Irvin Topi",
        "Jelena Mitrović",
        "Michael Granitzer"
      ],
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "published": "2026-02-19T12:45:58Z",
      "updated": "2026-02-19T12:45:58Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17327v1",
      "abs_url": "http://arxiv.org/abs/2602.17327v1",
      "summary": "WebFAQ 2.0发布，扩展了多语言FAQ问答数据集，并提供硬负例用于训练稠密检索模型。",
      "key_contributions": [
        "构建大规模多语言FAQ问答数据集",
        "提供带cross-encoder评分的硬负例数据集",
        "验证了硬负例在稠密检索模型上的训练效果"
      ],
      "methodology": "从网络抓取FAQ，使用两阶段检索流程挖掘硬负例，并使用对比学习和知识蒸馏进行模型训练。",
      "tags": [
        "问答系统",
        "多语言",
        "信息检索",
        "硬负例挖掘",
        "稠密检索"
      ],
      "assigned_category": "memory",
      "relevance_score": 8,
      "relevance_reason": "该数据集和硬负例集对RAG系统的检索阶段有重要价值。",
      "analyzed_at": "2026-02-20T06:57:57.495294",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17315v1",
      "title": "Flickering Multi-Armed Bandits",
      "abstract": "We introduce Flickering Multi-Armed Bandits (FMAB), a new MAB framework where the set of available arms (or actions) can change at each round, and the available set at any time may depend on the agent's previously selected arm. We model this constrained, evolving availability using random graph processes, where arms are nodes and the agent's movement is restricted to its local neighborhood. We analyze this problem under two random graph models: an i.i.d. Erdős--Rényi (ER) process and an Edge-Markovian process. We propose and analyze a two-phase algorithm that employs a lazy random walk for exploration to efficiently identify the optimal arm, followed by a navigation and commitment phase for exploitation. We establish high-probability and expected sublinear regret bounds for both graph settings. We show that the exploration cost of our algorithm is near-optimal by establishing a matching information-theoretic lower bound for this problem class, highlighting the fundamental cost of exploration under local-move constraints. We complement our theoretical guarantees with numerical simulations, including a scenario of a robotic ground vehicle scouting a disaster-affected region.",
      "authors": [
        "Sourav Chakraborty",
        "Amit Kiran Rege",
        "Claire Monteleoni",
        "Lijun Chen"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T12:24:01Z",
      "updated": "2026-02-19T12:24:01Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17315v1",
      "abs_url": "http://arxiv.org/abs/2602.17315v1",
      "summary": "提出了一种新的多臂老虎机框架，臂的可用性随时间变化，并分析了其探索代价。",
      "key_contributions": [
        "提出了Flickering Multi-Armed Bandits (FMAB) 框架",
        "分析了在Erdős--Rényi和Edge-Markovian两种图模型下的问题",
        "提出了两阶段算法，并建立了次线性遗憾界",
        "证明了算法的探索代价接近最优"
      ],
      "methodology": "提出了一个两阶段算法，包括lazy random walk探索和导航承诺利用阶段，并进行理论分析和实验验证。",
      "tags": [
        "Multi-Armed Bandits",
        "Random Graphs",
        "Reinforcement Learning",
        "Exploration-Exploitation"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "智能体需要在动态环境中探索和利用，找到最优动作，与智能体任务相关。",
      "analyzed_at": "2026-02-20T06:57:59.426002",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17308v1",
      "title": "MedClarify: An information-seeking AI agent for medical diagnosis with case-specific follow-up questions",
      "abstract": "Large language models (LLMs) are increasingly used for diagnostic tasks in medicine. In clinical practice, the correct diagnosis can rarely be immediately inferred from the initial patient presentation alone. Rather, reaching a diagnosis often involves systematic history taking, during which clinicians reason over multiple potential conditions through iterative questioning to resolve uncertainty. This process requires considering differential diagnoses and actively excluding emergencies that demand immediate intervention. Yet, the ability of medical LLMs to generate informative follow-up questions and thus reason over differential diagnoses remains underexplored. Here, we introduce MedClarify, an AI agent for information-seeking that can generate follow-up questions for iterative reasoning to support diagnostic decision-making. Specifically, MedClarify computes a list of candidate diagnoses analogous to a differential diagnosis, and then proactively generates follow-up questions aimed at reducing diagnostic uncertainty. By selecting the question with the highest expected information gain, MedClarify enables targeted, uncertainty-aware reasoning to improve diagnostic performance. In our experiments, we first demonstrate the limitations of current LLMs in medical reasoning, which often yield multiple, similarly likely diagnoses, especially when patient cases are incomplete or relevant information for diagnosis is missing. We then show that our information-theoretic reasoning approach can generate effective follow-up questioning and thereby reduces diagnostic errors by ~27 percentage points (p.p.) compared to a standard single-shot LLM baseline. Altogether, MedClarify offers a path to improve medical LLMs through agentic information-seeking and to thus promote effective dialogues with medical LLMs that reflect the iterative and uncertain nature of real-world clinical reasoning.",
      "authors": [
        "Hui Min Wong",
        "Philip Heesen",
        "Pascal Janetzky",
        "Martin Bendszus",
        "Stefan Feuerriegel"
      ],
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-19T12:19:12Z",
      "updated": "2026-02-19T12:19:12Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17308v1",
      "abs_url": "http://arxiv.org/abs/2602.17308v1",
      "summary": "MedClarify通过迭代提问增强医学LLM的诊断能力，减少诊断错误。",
      "key_contributions": [
        "提出MedClarify：一个信息寻求的AI agent",
        "使用信息增益最大化选择问题",
        "实验证明能有效减少诊断错误"
      ],
      "methodology": "构建候选诊断列表，生成针对性追问，通过计算信息增益选择问题，迭代推理，最终辅助诊断。",
      "tags": [
        "医疗诊断",
        "LLM",
        "信息寻求",
        "推理"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于通过agent迭代提问增强LLM的推理和诊断能力。",
      "analyzed_at": "2026-02-20T06:58:01.057461",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17288v1",
      "title": "ArXiv-to-Model: A Practical Study of Scientific LM Training",
      "abstract": "While frontier large language models demonstrate strong reasoning and mathematical capabilities, the practical process of training domain-specialized scientific language models from raw sources remains under-documented. In this work, we present a detailed case study of training a 1.36B-parameter scientific language model directly from raw arXiv LaTeX sources spanning mathematics, computer science, and theoretical physics. We describe an end-to-end pipeline covering metadata filtering, archive validation, LaTeX extraction, text normalization, domain-aware tokenization, and dense transformer training under constrained compute (2xA100 GPUs). Through 24 experimental runs, we analyze training stability, scaling behavior, data yield losses, and infrastructure bottlenecks. Our findings highlight how preprocessing decisions significantly affect usable token volume, how tokenization impacts symbolic stability, and how storage and I/O constraints can rival compute as limiting factors. We further analyze convergence dynamics and show stable training behavior in a data-rich regime (52B pretraining tokens). Rather than proposing a novel architecture, this work provides an engineering-grounded, transparent account of training a small scientific language model from scratch. We hope these insights support researchers operating under moderate compute budgets who seek to build domain-specialized models.",
      "authors": [
        "Anuj Gupta"
      ],
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-19T11:47:30Z",
      "updated": "2026-02-19T11:47:30Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17288v1",
      "abs_url": "http://arxiv.org/abs/2602.17288v1",
      "summary": "该论文详细介绍了从原始arXiv LaTeX数据训练小型科学语言模型的完整流程和经验。",
      "key_contributions": [
        "构建科学语言模型的端到端pipeline",
        "分析预处理决策对模型训练的影响",
        "揭示存储和I/O约束的重要性"
      ],
      "methodology": "采用端到端的训练pipeline，包含数据预处理、tokenization和transformer训练，并在受限计算资源下进行了24次实验。",
      "tags": [
        "scientific language model",
        "arXiv",
        "LaTeX",
        "domain-specific",
        "pretraining"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "聚焦于训练科学领域的语言模型，提升特定领域的推理能力，高度相关。",
      "analyzed_at": "2026-02-20T06:58:02.962635",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17276v1",
      "title": "RLGT: A reinforcement learning framework for extremal graph theory",
      "abstract": "Reinforcement learning (RL) is a subfield of machine learning that focuses on developing models that can autonomously learn optimal decision-making strategies over time. In a recent pioneering paper, Wagner demonstrated how the Deep Cross-Entropy RL method can be applied to tackle various problems from extremal graph theory by reformulating them as combinatorial optimization problems. Subsequently, many researchers became interested in refining and extending the framework introduced by Wagner, thereby creating various RL environments specialized for graph theory. Moreover, a number of problems from extremal graph theory were solved through the use of RL. In particular, several inequalities concerning the Laplacian spectral radius of graphs were refuted, new lower bounds were obtained for certain Ramsey numbers, and contributions were made to the Turán-type extremal problem in which the forbidden structures are cycles of length three and four. Here, we present Reinforcement Learning for Graph Theory (RLGT), a novel RL framework that systematizes the previous work and provides support for both undirected and directed graphs, with or without loops, and with an arbitrary number of edge colors. The framework efficiently represents graphs and aims to facilitate future RL-based research in extremal graph theory through optimized computational performance and a clean and modular design.",
      "authors": [
        "Ivan Damnjanović",
        "Uroš Milivojević",
        "Irena Đorđević",
        "Dragan Stevanović"
      ],
      "categories": [
        "cs.LG",
        "math.CO"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T11:25:22Z",
      "updated": "2026-02-19T11:25:22Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17276v1",
      "abs_url": "http://arxiv.org/abs/2602.17276v1",
      "summary": "RLGT是一个图论强化学习框架，旨在系统化现有工作，支持多种图结构，提升计算性能。",
      "key_contributions": [
        "系统化图论强化学习工作",
        "支持多种图结构（有向/无向，带环/无环，多颜色）",
        "优化计算性能，模块化设计"
      ],
      "methodology": "利用强化学习方法，将极值图论问题转化为组合优化问题进行求解。",
      "tags": [
        "强化学习",
        "图论",
        "极值图论",
        "组合优化"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "该论文提出了一个基于RL的图论框架，可以看作是一种agent，具有解决问题的能力。",
      "analyzed_at": "2026-02-20T06:58:04.680316",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17271v1",
      "title": "Federated Latent Space Alignment for Multi-user Semantic Communications",
      "abstract": "Semantic communication aims to convey meaning for effective task execution, but differing latent representations in AI-native devices can cause semantic mismatches that hinder mutual understanding. This paper introduces a novel approach to mitigating latent space misalignment in multi-agent AI- native semantic communications. In a downlink scenario, we consider an access point (AP) communicating with multiple users to accomplish a specific AI-driven task. Our method implements a protocol that shares a semantic pre-equalizer at the AP and local semantic equalizers at user devices, fostering mutual understanding and task-oriented communication while considering power and complexity constraints. To achieve this, we employ a federated optimization for the decentralized training of the semantic equalizers at the AP and user sides. Numerical results validate the proposed approach in goal-oriented semantic communication, revealing key trade-offs among accuracy, com- munication overhead, complexity, and the semantic proximity of AI-native communication devices.",
      "authors": [
        "Giuseppe Di Poce",
        "Mario Edoardo Pandolfo",
        "Emilio Calvanese Strinati",
        "Paolo Di Lorenzo"
      ],
      "categories": [
        "cs.IT",
        "cs.AI"
      ],
      "primary_category": "cs.IT",
      "published": "2026-02-19T11:18:58Z",
      "updated": "2026-02-19T11:18:58Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17271v1",
      "abs_url": "http://arxiv.org/abs/2602.17271v1",
      "summary": "提出一种联邦学习的语义通信方法，通过对齐潜在空间提高多用户语义通信的准确性。",
      "key_contributions": [
        "提出了一种基于联邦学习的语义预均衡器和均衡器方案",
        "解决了多用户语义通信中潜在空间不对齐问题",
        "在准确性、通信开销和复杂性之间实现了权衡"
      ],
      "methodology": "采用联邦优化算法，在接入点和用户端分布式训练语义均衡器，实现潜在空间的对齐。",
      "tags": [
        "语义通信",
        "联邦学习",
        "潜在空间对齐",
        "多用户通信"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "涉及agent之间通信，通过语义理解协调行为，提高agent协作效率。",
      "analyzed_at": "2026-02-20T06:58:06.578159",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17262v1",
      "title": "Quantifying and Mitigating Socially Desirable Responding in LLMs: A Desirability-Matched Graded Forced-Choice Psychometric Study",
      "abstract": "Human self-report questionnaires are increasingly used in NLP to benchmark and audit large language models (LLMs), from persona consistency to safety and bias assessments. Yet these instruments presume honest responding; in evaluative contexts, LLMs can instead gravitate toward socially preferred answers-a form of socially desirable responding (SDR)-biasing questionnaire-derived scores and downstream conclusions. We propose a psychometric framework to quantify and mitigate SDR in questionnaire-based evaluation of LLMs. To quantify SDR, the same inventory is administered under HONEST versus FAKE-GOOD instructions, and SDR is computed as a direction-corrected standardized effect size from item response theory (IRT)-estimated latent scores. This enables comparisons across constructs and response formats, as well as against human instructed-faking benchmarks. For mitigation, we construct a graded forced-choice (GFC) Big Five inventory by selecting 30 cross-domain pairs from an item pool via constrained optimization to match desirability. Across nine instruction-tuned LLMs evaluated on synthetic personas with known target profiles, Likert-style questionnaires show consistently large SDR, whereas desirability-matched GFC substantially attenuates SDR while largely preserving the recovery of the intended persona profiles. These results highlight a model-dependent SDR-recovery trade-off and motivate SDR-aware reporting practices for questionnaire-based benchmarking and auditing of LLMs.",
      "authors": [
        "Kensuke Okada",
        "Yui Furukawa",
        "Kyosuke Bunji"
      ],
      "categories": [
        "cs.CL",
        "stat.ME"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-19T11:07:24Z",
      "updated": "2026-02-19T11:07:24Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17262v1",
      "abs_url": "http://arxiv.org/abs/2602.17262v1",
      "summary": "提出一种量化和缓解LLM在问卷评估中社会期望偏差的方法，并用强制选择问卷减少偏差。",
      "key_contributions": [
        "提出了量化LLM中社会期望偏差的心理测量框架。",
        "构建了梯度强制选择（GFC）Big Five问卷，以匹配期望。",
        "展示了GFC问卷在减轻社会期望偏差方面的有效性，同时保留了对人物档案的恢复能力。"
      ],
      "methodology": "使用HONEST和FAKE-GOOD指令管理问卷，通过IRT估计潜在分数并计算SDR。构建GFC问卷通过约束优化匹配期望值。",
      "tags": [
        "LLM",
        "Psychometrics",
        "Social Desirability Bias",
        "Questionnaire",
        "Evaluation"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "该论文研究了LLM在面对评估时的推理偏差，并尝试缓解这种偏差。",
      "analyzed_at": "2026-02-20T06:58:08.633571",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17260v1",
      "title": "EA-Swin: An Embedding-Agnostic Swin Transformer for AI-Generated Video Detection",
      "abstract": "Recent advances in foundation video generators such as Sora2, Veo3, and other commercial systems have produced highly realistic synthetic videos, exposing the limitations of existing detection methods that rely on shallow embedding trajectories, image-based adaptation, or computationally heavy MLLMs. We propose EA-Swin, an Embedding-Agnostic Swin Transformer that models spatiotemporal dependencies directly on pretrained video embeddings via a factorized windowed attention design, making it compatible with generic ViT-style patch-based encoders. Alongside the model, we construct the EA-Video dataset, a benchmark dataset comprising 130K videos that integrates newly collected samples with curated existing datasets, covering diverse commercial and open-source generators and including unseen-generator splits for rigorous cross-distribution evaluation. Extensive experiments show that EA-Swin achieves 0.97-0.99 accuracy across major generators, outperforming prior SoTA methods (typically 0.8-0.9) by a margin of 5-20%, while maintaining strong generalization to unseen distributions, establishing a scalable and robust solution for modern AI-generated video detection.",
      "authors": [
        "Hung Mai",
        "Loi Dinh",
        "Duc Hai Nguyen",
        "Dat Do",
        "Luong Doan",
        "Khanh Nguyen Quoc",
        "Huan Vu",
        "Phong Ho",
        "Naeem Ul Islam",
        "Tuan Do"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-19T11:04:20Z",
      "updated": "2026-02-19T11:04:20Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17260v1",
      "abs_url": "http://arxiv.org/abs/2602.17260v1",
      "summary": "EA-Swin利用嵌入无关的Swin Transformer有效检测AI生成视频，并提出了新的EA-Video数据集。",
      "key_contributions": [
        "提出EA-Swin模型，一种嵌入无关的Swin Transformer",
        "构建EA-Video数据集，包含多样化的AI生成视频",
        "EA-Swin在检测AI生成视频方面显著优于现有方法"
      ],
      "methodology": "采用嵌入无关的Swin Transformer，通过分解窗口注意力机制建模时空依赖关系，适用于通用ViT风格的编码器。",
      "tags": [
        "AI生成视频检测",
        "Swin Transformer",
        "视频嵌入",
        "数据集",
        "深度学习"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 8,
      "relevance_reason": "处理视频模态，并涉及视觉信息的理解与分析，高度相关。",
      "analyzed_at": "2026-02-20T06:58:10.677560",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17250v1",
      "title": "Inferring Height from Earth Embeddings: First insights using Google AlphaEarth",
      "abstract": "This study investigates whether the geospatial and multimodal features encoded in \\textit{Earth Embeddings} can effectively guide deep learning (DL) regression models for regional surface height mapping. In particular, we focused on AlphaEarth Embeddings at 10 m spatial resolution and evaluated their capability to support terrain height inference using a high-quality Digital Surface Model (DSM) as reference. U-Net and U-Net++ architectures were thus employed as lightweight convolutional decoders to assess how well the geospatial information distilled in the embeddings can be translated into accurate surface height estimates. Both architectures achieved strong training performance (both with $R^2 = 0.97$), confirming that the embeddings encode informative and decodable height-related signals. On the test set, performance decreased due to distribution shifts in height frequency between training and testing areas. Nevertheless, U-Net++ shows better generalization ($R^2 = 0.84$, median difference = -2.62 m) compared with the standard U-Net ($R^2 = 0.78$, median difference = -7.22 m), suggesting enhanced robustness to distribution mismatch. While the testing RMSE (approximately 16 m for U-Net++) and residual bias highlight remaining challenges in generalization, strong correlations indicate that the embeddings capture transferable topographic patterns. Overall, the results demonstrate the promising potential of AlphaEarth Embeddings to guide DL-based height mapping workflows, particularly when combined with spatially aware convolutional architectures, while emphasizing the need to address bias for improved regional transferability.",
      "authors": [
        "Alireza Hamoudzadeh",
        "Valeria Belloni",
        "Roberta Ravanelli"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-19T10:52:50Z",
      "updated": "2026-02-19T10:52:50Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17250v1",
      "abs_url": "http://arxiv.org/abs/2602.17250v1",
      "summary": "利用AlphaEarth Embeddings和深度学习模型进行地表高度推断的研究，效果初步验证。",
      "key_contributions": [
        "探索了Earth Embeddings在区域地表高度映射中的应用潜力",
        "评估了U-Net和U-Net++在高度推断中的表现",
        "分析了Earth Embeddings的局限性并提出了改进方向"
      ],
      "methodology": "使用U-Net和U-Net++作为轻量级卷积解码器，将Earth Embeddings转换为地表高度估计，并使用DSM进行评估。",
      "tags": [
        "Earth Embeddings",
        "深度学习",
        "地表高度映射",
        "U-Net",
        "U-Net++"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 6,
      "relevance_reason": "Earth Embeddings 是结合地理信息的一种多模态数据，与多模态学习有一定关联。",
      "analyzed_at": "2026-02-20T06:58:12.618869",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17245v1",
      "title": "Web Verbs: Typed Abstractions for Reliable Task Composition on the Agentic Web",
      "abstract": "The Web is evolving from a medium that humans browse to an environment where software agents act on behalf of users. Advances in large language models (LLMs) make natural language a practical interface for goal-directed tasks, yet most current web agents operate on low-level primitives such as clicks and keystrokes. These operations are brittle, inefficient, and difficult to verify. Complementing content-oriented efforts such as NLWeb's semantic layer for retrieval, we argue that the agentic web also requires a semantic layer for web actions. We propose \\textbf{Web Verbs}, a web-scale set of typed, semantically documented functions that expose site capabilities through a uniform interface, whether implemented through APIs or robust client-side workflows. These verbs serve as stable and composable units that agents can discover, select, and synthesize into concise programs. This abstraction unifies API-based and browser-based paradigms, enabling LLMs to synthesize reliable and auditable workflows with explicit control and data flow. Verbs can carry preconditions, postconditions, policy tags, and logging support, which improves \\textbf{reliability} by providing stable interfaces, \\textbf{efficiency} by reducing dozens of steps into a few function calls, and \\textbf{verifiability} through typed contracts and checkable traces. We present our vision, a proof-of-concept implementation, and representative case studies that demonstrate concise and robust execution compared to existing agents. Finally, we outline a roadmap for standardization to make verbs deployable and trustworthy at web scale.",
      "authors": [
        "Linxi Jiang",
        "Rui Xi",
        "Zhijie Liu",
        "Shuo Chen",
        "Zhiqiang Lin",
        "Suman Nath"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-19T10:50:52Z",
      "updated": "2026-02-19T10:50:52Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17245v1",
      "abs_url": "http://arxiv.org/abs/2602.17245v1",
      "summary": "提出Web Verbs，一种为智能体设计的、类型化的Web行为抽象，旨在提升Web智能体的可靠性、效率和可验证性。",
      "key_contributions": [
        "提出了Web Verbs的概念，一种用于Web行为的类型化抽象。",
        "展示了Web Verbs如何提高Web智能体的可靠性、效率和可验证性。",
        "提供了一个Web Verbs的验证性实现以及案例研究。"
      ],
      "methodology": "通过定义一套类型化的、语义化的Web动作函数，使智能体能够以更稳定、可控的方式与Web交互，并提供预/后置条件、策略标签等增强可靠性。",
      "tags": [
        "Web Agents",
        "Semantic Web",
        "LLMs",
        "Task Automation"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文核心在于解决Web智能体可靠性问题，是AI Agent领域的重要研究方向。",
      "analyzed_at": "2026-02-20T06:58:14.628927",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17244v1",
      "title": "CounterFlowNet: From Minimal Changes to Meaningful Counterfactual Explanations",
      "abstract": "Counterfactual explanations (CFs) provide human-interpretable insights into model's predictions by identifying minimal changes to input features that would alter the model's output. However, existing methods struggle to generate multiple high-quality explanations that (1) affect only a small portion of the features, (2) can be applied to tabular data with heterogeneous features, and (3) are consistent with the user-defined constraints. We propose CounterFlowNet, a generative approach that formulates CF generation as sequential feature modification using conditional Generative Flow Networks (GFlowNet). CounterFlowNet is trained to sample CFs proportionally to a user-specified reward function that can encode key CF desiderata: validity, sparsity, proximity and plausibility, encouraging high-quality explanations. The sequential formulation yields highly sparse edits, while a unified action space seamlessly supports continuous and categorical features. Moreover, actionability constraints, such as immutability and monotonicity of features, can be enforced at inference time via action masking, without retraining. Experiments on eight datasets under two evaluation protocols demonstrate that CounterFlowNet achieves superior trade-offs between validity, sparsity, plausibility, and diversity with full satisfaction of the given constraints.",
      "authors": [
        "Oleksii Furman",
        "Patryk Marszałek",
        "Jan Masłowski",
        "Piotr Gaiński",
        "Maciej Zięba",
        "Marek Śmieja"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T10:48:45Z",
      "updated": "2026-02-19T10:48:45Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17244v1",
      "abs_url": "http://arxiv.org/abs/2602.17244v1",
      "summary": "CounterFlowNet利用GFlowNet生成高质量且满足约束的反事实解释，提升了解释的有效性、稀疏性和多样性。",
      "key_contributions": [
        "提出CounterFlowNet，一种基于GFlowNet的反事实解释生成方法",
        "利用序列特征修改生成稀疏的解释",
        "统一行动空间支持异构数据，并通过行动掩码强制约束"
      ],
      "methodology": "将反事实解释生成建模为序列特征修改，利用条件生成流网络学习生成高质量的反事实解释，并使用奖励函数引导生成。",
      "tags": [
        "反事实解释",
        "可解释性AI",
        "生成模型",
        "GFlowNet"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 7,
      "relevance_reason": "论文关注模型的解释性，通过反事实解释提供推理依据。",
      "analyzed_at": "2026-02-20T06:58:16.457138",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17242v1",
      "title": "TAPO-Structured Description Logic for Information Behavior: Procedural and Oracle-Based Extensions",
      "abstract": "We introduce \\emph{TAPO-Structured Description Logic} (TAPO--DL), a formal extension of classical description logic designed to model \\emph{information behavior} as a structured, dynamic process.   TAPO--DL extends the standard T--Box/A--Box architecture with two additional layers: a \\emph{Procedural Box} (P--Box), which supports concept-driven, imperative-style programs such as conditional and iterative actions, and an \\emph{Oracle Box} (O--Box), which formalizes controlled interaction with external information sources. While the terminological and assertional components capture static conceptual and factual knowledge, the procedural and oracle-based components enable the explicit representation of information-generating actions and external validation.   We provide a unified semantic framework for TAPO--DL based on a co-generative, sheaf-theoretic interpretation, in which local informational states are modeled as sections and informational stability corresponds to the existence of coherent global structures. Within this setting, informational truth is characterized as stability under repeated agentive interaction rather than correspondence to a fixed global state.   By integrating description logic with procedural dynamics, oracle-based reasoning, and sheaf-theoretic semantics, TAPO--DL offers a principled formal framework for analyzing information behavior in contexts involving interaction, uncertainty, and contextuality.",
      "authors": [
        "Takao Inoué"
      ],
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "published": "2026-02-19T10:43:21Z",
      "updated": "2026-02-19T10:43:21Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17242v1",
      "abs_url": "http://arxiv.org/abs/2602.17242v1",
      "summary": "TAPO-DL扩展了描述逻辑，通过程序和Oracle形式化信息行为的动态过程。",
      "key_contributions": [
        "提出TAPO-DL，扩展了标准描述逻辑",
        "引入P-Box和O-Box，分别处理程序和外部信息源",
        "使用sheaf-theoretic语义，将信息真理定义为稳定状态"
      ],
      "methodology": "通过引入P-Box和O-Box扩展描述逻辑，并结合sheaf-theoretic语义进行形式化建模。",
      "tags": [
        "描述逻辑",
        "信息行为建模",
        "sheaf理论",
        "知识表示"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 7,
      "relevance_reason": "论文涉及逻辑推理和知识表示，与LLM的推理能力相关。",
      "analyzed_at": "2026-02-20T06:58:18.161387",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17234v1",
      "title": "All Leaks Count, Some Count More: Interpretable Temporal Contamination Detection in LLM Backtesting",
      "abstract": "To evaluate whether LLMs can accurately predict future events, we need the ability to \\textit{backtest} them on events that have already resolved. This requires models to reason only with information available at a specified past date. Yet LLMs may inadvertently leak post-cutoff knowledge encoded during training, undermining the validity of retrospective evaluation. We introduce a claim-level framework for detecting and quantifying this \\emph{temporal knowledge leakage}. Our approach decomposes model rationales into atomic claims and categorizes them by temporal verifiability, then applies \\textit{Shapley values} to measure each claim's contribution to the prediction. This yields the \\textbf{Shapley}-weighted \\textbf{D}ecision-\\textbf{C}ritical \\textbf{L}eakage \\textbf{R}ate (\\textbf{Shapley-DCLR}), an interpretable metric that captures what fraction of decision-driving reasoning derives from leaked information. Building on this framework, we propose \\textbf{Time}-\\textbf{S}upervised \\textbf{P}rediction with \\textbf{E}xtracted \\textbf{C}laims (\\textbf{TimeSPEC}), which interleaves generation with claim verification and regeneration to proactively filter temporal contamination -- producing predictions where every supporting claim can be traced to sources available before the cutoff date. Experiments on 350 instances spanning U.S. Supreme Court case prediction, NBA salary estimation, and stock return ranking reveal substantial leakage in standard prompting baselines. TimeSPEC reduces Shapley-DCLR while preserving task performance, demonstrating that explicit, interpretable claim-level verification outperforms prompt-based temporal constraints for reliable backtesting.",
      "authors": [
        "Zeyu Zhang",
        "Ryan Chen",
        "Bradly C. Stadie"
      ],
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-19T10:28:00Z",
      "updated": "2026-02-19T10:28:00Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17234v1",
      "abs_url": "http://arxiv.org/abs/2602.17234v1",
      "summary": "提出一种可解释的时间污染检测框架，用于评估LLM在回测中是否存在知识泄露，并提出TimeSPEC方法降低泄露。",
      "key_contributions": [
        "提出Shapley-DCLR指标，用于量化LLM推理中泄露信息的占比。",
        "提出TimeSPEC方法，通过 claim 验证和再生，主动过滤时间污染。",
        "实验证明TimeSPEC能有效降低泄露，同时保持任务性能。"
      ],
      "methodology": "将模型推理分解为claim，根据时间可验证性分类，用Shapley值评估每个claim对预测的贡献，并结合TimeSPEC方法进行过滤。",
      "tags": [
        "LLM",
        "Backtesting",
        "Temporal Knowledge Leakage"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 9,
      "relevance_reason": "论文核心关注LLM推理过程中的知识泄露问题，对推理的可靠性评估具有重要意义。",
      "analyzed_at": "2026-02-20T06:58:20.618908",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17223v1",
      "title": "Privacy-Preserving Mechanisms Enable Cheap Verifiable Inference of LLMs",
      "abstract": "As large language models (LLMs) continue to grow in size, fewer users are able to host and run models locally. This has led to increased use of third-party hosting services. However, in this setting, there is a lack of guarantees on the computation performed by the inference provider. For example, a dishonest provider may replace an expensive large model with a cheaper-to-run weaker model and return the results from the weaker model to the user. Existing tools to verify inference typically rely on methods from cryptography such as zero-knowledge proofs (ZKPs), but these add significant computational overhead, and remain infeasible for use for large models. In this work, we develop a new insight -- that given a method for performing private LLM inference, one can obtain forms of verified inference at marginal extra cost. Specifically, we propose two new protocols which leverage privacy-preserving LLM inference in order to provide guarantees over the inference that was carried out. Our approaches are cheap, requiring the addition of a few extra tokens of computation, and have little to no downstream impact. As the fastest privacy-preserving inference methods are typically faster than ZK methods, the proposed protocols also improve verification runtime. Our work provides novel insights into the connections between privacy and verifiability in LLM inference.",
      "authors": [
        "Arka Pal",
        "Louai Zahran",
        "William Gvozdjak",
        "Akilesh Potti",
        "Micah Goldblum"
      ],
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "published": "2026-02-19T10:15:51Z",
      "updated": "2026-02-19T10:15:51Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17223v1",
      "abs_url": "http://arxiv.org/abs/2602.17223v1",
      "summary": "该论文提出利用隐私保护的LLM推理来实现廉价且可验证的推理，降低验证开销。",
      "key_contributions": [
        "提出了新的基于隐私保护LLM推理的可验证推理协议",
        "提出的协议计算成本低，几乎没有下游影响",
        "证明了隐私和可验证性在LLM推理中的联系"
      ],
      "methodology": "利用现有的隐私保护LLM推理方法，设计新的协议，增加少量计算即可实现推理验证。",
      "tags": [
        "LLM",
        "privacy",
        "verifiable inference",
        "zero-knowledge proofs"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 8,
      "relevance_reason": "论文关注LLM推理过程的可信度问题，与reasoning类别高度相关。",
      "analyzed_at": "2026-02-20T06:58:22.307046",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17222v1",
      "title": "Decoding the Human Factor: High Fidelity Behavioral Prediction for Strategic Foresight",
      "abstract": "Predicting human decision-making in high-stakes environments remains a central challenge for artificial intelligence. While large language models (LLMs) demonstrate strong general reasoning, they often struggle to generate consistent, individual-specific behavior, particularly when accurate prediction depends on complex interactions between psychological traits and situational constraints. Prompting-based approaches can be brittle in this setting, exhibiting identity drift and limited ability to leverage increasingly detailed persona descriptions. To address these limitations, we introduce the Large Behavioral Model (LBM), a behavioral foundation model fine-tuned to predict individual strategic choices with high fidelity. LBM shifts from transient persona prompting to behavioral embedding by conditioning on a structured, high-dimensional trait profile derived from a comprehensive psychometric battery. Trained on a proprietary dataset linking stable dispositions, motivational states, and situational constraints to observed choices, LBM learns to map rich psychological profiles to discrete actions across diverse strategic dilemmas. In a held-out scenario evaluation, LBM fine-tuning improves behavioral prediction relative to the unadapted Llama-3.1-8B-Instruct backbone and performs comparably to frontier baselines when conditioned on Big Five traits. Moreover, we find that while prompting-based baselines exhibit a complexity ceiling, LBM continues to benefit from increasingly dense trait profiles, with performance improving as additional trait dimensions are provided. Together, these results establish LBM as a scalable approach for high-fidelity behavioral simulation, enabling applications in strategic foresight, negotiation analysis, cognitive security, and decision support.",
      "authors": [
        "Ben Yellin",
        "Ehud Ezra",
        "Mark Foreman",
        "Shula Grinapol"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-19T10:13:17Z",
      "updated": "2026-02-19T10:13:17Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17222v1",
      "abs_url": "http://arxiv.org/abs/2602.17222v1",
      "summary": "提出LBM模型，通过心理特征嵌入提升LLM在复杂情境下的行为预测能力。",
      "key_contributions": [
        "提出Large Behavioral Model (LBM)",
        "使用高维心理特征进行行为嵌入",
        "证明LBM在高精度行为模拟上的有效性"
      ],
      "methodology": "微调Llama-3.1-8B-Instruct，使用包含个体心理特征和行为选择的专有数据集进行训练。",
      "tags": [
        "行为预测",
        "LLM",
        "心理学",
        "战略分析"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "论文关注Agent在复杂环境下的决策问题，LBM模型的优化目标与智能体行为预测直接相关。",
      "analyzed_at": "2026-02-20T06:58:24.680670",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17221v1",
      "title": "From Labor to Collaboration: A Methodological Experiment Using AI Agents to Augment Research Perspectives in Taiwan's Humanities and Social Sciences",
      "abstract": "Generative AI is reshaping knowledge work, yet existing research focuses predominantly on software engineering and the natural sciences, with limited methodological exploration for the humanities and social sciences. Positioned as a \"methodological experiment,\" this study proposes an AI Agent-based collaborative research workflow (Agentic Workflow) for humanities and social science research. Taiwan's Claude.ai usage data (N = 7,729 conversations, November 2025) from the Anthropic Economic Index (AEI) serves as the empirical vehicle for validating the feasibility of this methodology.   This study operates on two levels: the primary level is the design and validation of a methodological framework - a seven-stage modular workflow grounded in three principles: task modularization, human-AI division of labor, and verifiability, with each stage delineating clear roles for human researchers (research judgment and ethical decisions) and AI Agents (information retrieval and text generation); the secondary level is the empirical analysis of AEI Taiwan data - serving as an operational demonstration of the workflow's application to secondary data research, showcasing both the process and output quality (see Appendix A).   This study contributes by proposing a replicable AI collaboration framework for humanities and social science researchers, and identifying three operational modes of human-AI collaboration - direct execution, iterative refinement, and human-led - through reflexive documentation of the operational process. This taxonomy reveals the irreplaceability of human judgment in research question formulation, theoretical interpretation, contextualized reasoning, and ethical reflection. Limitations including single-platform data, cross-sectional design, and AI reliability risks are acknowledged.",
      "authors": [
        "Yi-Chih Huang"
      ],
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-19T10:12:08Z",
      "updated": "2026-02-19T10:12:08Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17221v1",
      "abs_url": "http://arxiv.org/abs/2602.17221v1",
      "summary": "该论文提出了一个基于AI Agent的人文社科研究协作框架，并在台湾数据上进行了验证。",
      "key_contributions": [
        "提出了一个可复制的AI协作框架",
        "识别了三种人机协作模式",
        "验证了框架在人文社科研究中的可行性"
      ],
      "methodology": "设计并验证了一个七阶段的模块化工作流程，强调任务模块化、人机分工和可验证性，并利用台湾的AEI数据进行实证分析。",
      "tags": [
        "AI Agents",
        "人文社科",
        "协作研究",
        "方法论"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "直接研究AI Agent在人文社科领域应用的协作框架设计与验证。",
      "analyzed_at": "2026-02-20T06:58:26.577843",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17217v1",
      "title": "Continual learning and refinement of causal models through dynamic predicate invention",
      "abstract": "Efficiently navigating complex environments requires agents to internalize the underlying logic of their world, yet standard world modelling methods often struggle with sample inefficiency, lack of transparency, and poor scalability. We propose a framework for constructing symbolic causal world models entirely online by integrating continuous model learning and repair into the agent's decision loop, by leveraging the power of Meta-Interpretive Learning and predicate invention to find semantically meaningful and reusable abstractions, allowing an agent to construct a hierarchy of disentangled, high-quality concepts from its observations. We demonstrate that our lifted inference approach scales to domains with complex relational dynamics, where propositional methods suffer from combinatorial explosion, while achieving sample-efficiency orders of magnitude higher than the established PPO neural-network-based baseline.",
      "authors": [
        "Enrique Crespo-Fernandez",
        "Oliver Ray",
        "Telmo de Menezes e Silva Filho",
        "Peter Flach"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-19T10:08:31Z",
      "updated": "2026-02-19T10:08:31Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17217v1",
      "abs_url": "http://arxiv.org/abs/2602.17217v1",
      "summary": "提出一种通过动态谓词发明，在线学习和优化因果模型的框架，提升智能体在复杂环境下的性能。",
      "key_contributions": [
        "提出基于元解释学习和谓词发明的在线因果世界建模框架",
        "实现高效的样本利用率，优于PPO",
        "解决了复杂关系动态环境下的组合爆炸问题"
      ],
      "methodology": "结合连续模型学习与修复，利用元解释学习和谓词发明构建符号因果世界模型，实现概念分层。",
      "tags": [
        "因果模型",
        "持续学习",
        "元学习",
        "谓词发明",
        "强化学习"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "论文关注智能体构建世界模型并进行推理，与AI Agent领域高度相关。",
      "analyzed_at": "2026-02-20T06:58:28.537769",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17213v1",
      "title": "Extending quantum theory with AI-assisted deterministic game theory",
      "abstract": "We present an AI-assisted framework for predicting individual runs of complex quantum experiments, including contextuality and causality (adaptive measurements), within our long-term programme of discovering a local hidden-variable theory that extends quantum theory. In order to circumvent impossibility theorems, we replace the assumption of free choice (measurement independence and parameter independence) with a weaker, compatibilistic version called contingent free choice.   Our framework is based on interpreting complex quantum experiments as a Chess-like game between observers and the universe, which is seen as an economic agent minimizing action. The game structures corresponding to generic experiments such as fixed-causal-order process matrices or causal contextuality scenarios, together with a deterministic non-Nashian resolution algorithm that abandons unilateral deviation assumptions (free choice) and assumes Perfect Prediction instead, were described in previous work.   In this new research, we learn the reward functions of the game, which contain a hidden variable, using neural networks. The cost function is the Kullback-Leibler divergence between the frequency histograms obtained through many deterministic runs of the game and the predictions of the extended Born rule.   Using our framework on the specific case of the EPR 2-2-2 experiment acts as a proof-of-concept and a toy local-realist hidden-variable model that non-Nashian quantum theory is a promising avenue towards a local hidden-variable theory. Our framework constitutes a solid foundation, which can be further expanded in order to fully discover a complete quantum theory.",
      "authors": [
        "Florian Pauschitz",
        "Ben Moseley",
        "Ghislain Fourny"
      ],
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "quant-ph",
      "published": "2026-02-19T10:04:07Z",
      "updated": "2026-02-19T10:04:07Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17213v1",
      "abs_url": "http://arxiv.org/abs/2602.17213v1",
      "summary": "提出一种AI辅助的框架，用于预测复杂量子实验，探索扩展量子理论的局部隐变量模型。",
      "key_contributions": [
        "提出AI辅助的量子实验预测框架",
        "用博弈论和神经网络学习隐变量",
        "弱化自由选择假设，使用相容自由选择"
      ],
      "methodology": "将量子实验视为观测者与宇宙之间的博弈，用神经网络学习博弈的奖励函数，优化KL散度。",
      "tags": [
        "量子理论",
        "隐变量",
        "博弈论",
        "神经网络",
        "因果推断"
      ],
      "assigned_category": "agent",
      "relevance_score": 7,
      "relevance_reason": "将宇宙视为Agent，探索与Agent交互的理论框架。",
      "analyzed_at": "2026-02-20T06:58:30.357611",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17206v1",
      "title": "SoftDTW-CUDA-Torch: Memory-Efficient GPU-Accelerated Soft Dynamic Time Warping for PyTorch",
      "abstract": "We present softdtw-cuda-torch, an open-source PyTorch library for computing Soft Dynamic Time Warping (SoftDTW) on GPUs. Our implementation addresses three key limitations of existing GPU implementations of SoftDTW: a hard sequence-length cap of 1024, numerical instability in the backward pass for small smoothing parameters, and excessive GPU memory consumption from materializing pairwise distance tensors. We introduce (1) tiled anti-diagonal kernel execution that removes the sequence-length constraint, (2) a log-space back-ward pass that prevents floating-point overflow, and (3) a fused distance-computation mode that eliminates the O(BN M ) intermediate distance tensor, achieving up to 98% memory reduction compared to prior work. The library supports arbitrary sequence lengths, full PyTorch autograd integration, and Soft-DTW Barycenter computation. Code is available at https://github.com/BGU-CS-VIL/sdtw-cuda-torch.",
      "authors": [
        "Ron Shapira Weber",
        "Oren Freifeld"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T09:53:03Z",
      "updated": "2026-02-19T09:53:03Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17206v1",
      "abs_url": "http://arxiv.org/abs/2602.17206v1",
      "summary": "提出了一个GPU加速、内存高效的SoftDTW PyTorch库，解决了现有实现的长度限制、数值不稳定和内存消耗问题。",
      "key_contributions": [
        " tiled anti-diagonal kernel execution移除序列长度限制",
        "log-space backward pass防止浮点溢出",
        "fused distance-computation mode减少内存消耗"
      ],
      "methodology": "通过分块核执行、对数空间反向传播和融合距离计算等技术，优化SoftDTW在GPU上的计算效率和内存使用。",
      "tags": [
        "SoftDTW",
        "GPU acceleration",
        "PyTorch",
        "Memory efficiency"
      ],
      "assigned_category": "memory",
      "relevance_score": 5,
      "relevance_reason": "可能用于处理序列数据的长期记忆，但关联性较弱。",
      "analyzed_at": "2026-02-20T06:58:31.914132",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17196v1",
      "title": "EntropyPrune: Matrix Entropy Guided Visual Token Pruning for Multimodal Large Language Models",
      "abstract": "Multimodal large language models (MLLMs) incur substantial inference cost due to the processing of hundreds of visual tokens per image. Although token pruning has proven effective for accelerating inference, determining when and where to prune remains largely heuristic. Existing approaches typically rely on static, empirically selected layers, which limit interpretability and transferability across models. In this work, we introduce a matrix-entropy perspective and identify an \"Entropy Collapse Layer\" (ECL), where the information content of visual representations exhibits a sharp and consistent drop, which provides a principled criterion for selecting the pruning stage. Building on this observation, we propose EntropyPrune, a novel matrix-entropy-guided token pruning framework that quantifies the information value of individual visual tokens and prunes redundant ones without relying on attention maps. Moreover, to enable efficient computation, we exploit the spectral equivalence of dual Gram matrices, reducing the complexity of entropy computation and yielding up to a 64x theoretical speedup. Extensive experiments on diverse multimodal benchmarks demonstrate that EntropyPrune consistently outperforms state-of-the-art pruning methods in both accuracy and efficiency. On LLaVA-1.5-7B, our method achieves a 68.2% reduction in FLOPs while preserving 96.0% of the original performance. Furthermore, EntropyPrune generalizes effectively to high-resolution and video-based models, highlighting the strong robustness and scalability in practical MLLM acceleration. The code will be publicly available at https://github.com/YahongWang1/EntropyPrune.",
      "authors": [
        "Yahong Wang",
        "Juncheng Wu",
        "Zhangkai Ni",
        "Chengmei Yang",
        "Yihang Liu",
        "Longzhen Yang",
        "Yuyin Zhou",
        "Ying Wen",
        "Lianghua He"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-19T09:29:43Z",
      "updated": "2026-02-19T09:29:43Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17196v1",
      "abs_url": "http://arxiv.org/abs/2602.17196v1",
      "summary": "EntropyPrune通过矩阵熵指导视觉token剪枝，加速多模态大语言模型推理。",
      "key_contributions": [
        "提出了基于矩阵熵的视觉token剪枝框架EntropyPrune。",
        "发现了“熵坍塌层”（ECL），作为剪枝阶段选择的原则性标准。",
        "利用对偶Gram矩阵的谱等价性，高效计算熵，加速剪枝过程。"
      ],
      "methodology": "通过矩阵熵量化视觉token的信息价值，在熵坍塌层剪枝冗余token，加速推理。",
      "tags": [
        "多模态",
        "大语言模型",
        "token剪枝",
        "矩阵熵"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "该论文专注于多模态大语言模型的视觉token剪枝，属于核心相关。",
      "analyzed_at": "2026-02-20T06:58:33.654071",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17186v1",
      "title": "Selective Training for Large Vision Language Models via Visual Information Gain",
      "abstract": "Large Vision Language Models (LVLMs) have achieved remarkable progress, yet they often suffer from language bias, producing answers without relying on visual evidence. While prior work attempts to mitigate this issue through decoding strategies, architectural modifications, or curated instruction data, they typically lack a quantitative measure of how much individual training samples or tokens actually benefit from the image. In this work, we introduce Visual Information Gain (VIG), a perplexity-based metric that measures the reduction in prediction uncertainty provided by visual input. VIG enables fine-grained analysis at both sample and token levels, effectively highlighting visually grounded elements such as colors, spatial relations, and attributes. Leveraging this, we propose a VIG-guided selective training scheme that prioritizes high-VIG samples and tokens. This approach improves visual grounding and mitigates language bias, achieving superior performance with significantly reduced supervision by focusing exclusively on visually informative samples and tokens.",
      "authors": [
        "Seulbi Lee",
        "Sangheum Hwang"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-19T09:12:21Z",
      "updated": "2026-02-19T09:12:21Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17186v1",
      "abs_url": "http://arxiv.org/abs/2602.17186v1",
      "summary": "论文提出一种基于视觉信息增益的选择性训练方法，提升LVLM的视觉 grounding 能力并缓解语言偏见。",
      "key_contributions": [
        "提出视觉信息增益(VIG)度量视觉输入带来的预测不确定性减少",
        "提出VIG引导的选择性训练方案，优先训练高VIG样本和tokens",
        "通过选择性训练，显著降低监督成本并提升视觉 grounding 性能"
      ],
      "methodology": "计算视觉信息增益VIG，评估视觉输入对预测的影响。然后使用VIG指导选择高信息量样本和tokens进行训练。",
      "tags": [
        "LVLM",
        "视觉语言模型",
        "视觉信息增益",
        "选择性训练",
        "语言偏见缓解"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文直接针对视觉语言模型的关键问题（语言偏见和视觉 grounding）提出了新的度量和训练方法。",
      "analyzed_at": "2026-02-20T06:58:35.770197",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17185v1",
      "title": "The Bots of Persuasion: Examining How Conversational Agents' Linguistic Expressions of Personality Affect User Perceptions and Decisions",
      "abstract": "Large Language Model-powered conversational agents (CAs) are increasingly capable of projecting sophisticated personalities through language, but how these projections affect users is unclear. We thus examine how CA personalities expressed linguistically affect user decisions and perceptions in the context of charitable giving. In a crowdsourced study, 360 participants interacted with one of eight CAs, each projecting a personality composed of three linguistic aspects: attitude (optimistic/pessimistic), authority (authoritative/submissive), and reasoning (emotional/rational). While the CA's composite personality did not affect participants' decisions, it did affect their perceptions and emotional responses. Particularly, participants interacting with pessimistic CAs felt lower emotional state and lower affinity towards the cause, perceived the CA as less trustworthy and less competent, and yet tended to donate more toward the charity. Perceptions of trust, competence, and situational empathy significantly predicted donation decisions. Our findings emphasize the risks CAs pose as instruments of manipulation, subtly influencing user perceptions and decisions.",
      "authors": [
        "Uğur Genç",
        "Heng Gu",
        "Chadha Degachi",
        "Evangelos Niforatos",
        "Senthil Chandrasegaran",
        "Himanshu Verma"
      ],
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "published": "2026-02-19T09:10:41Z",
      "updated": "2026-02-19T09:10:41Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17185v1",
      "abs_url": "http://arxiv.org/abs/2602.17185v1",
      "summary": "研究了语言模型驱动的对话机器人人格化表达对用户感知和决策的影响，发现悲观人格影响显著。",
      "key_contributions": [
        "分析了对话机器人人格化表达的三个维度（态度、权威性、推理方式）对用户行为的影响。",
        "揭示了人格化的对话机器人如何微妙地影响用户的感知和情绪状态。",
        "强调了对话机器人作为操纵工具的潜在风险，尤其是在慈善捐赠场景中。"
      ],
      "methodology": "通过众包实验，让360名参与者与不同人格设定的对话机器人交互，观察其捐赠行为及情感感知。",
      "tags": [
        "对话机器人",
        "人格化",
        "用户感知",
        "决策影响",
        "自然语言处理"
      ],
      "assigned_category": "agent",
      "relevance_score": 9,
      "relevance_reason": "论文直接研究了AI Agent的人格化表达对用户的影响，属于Agent领域的核心问题。",
      "analyzed_at": "2026-02-20T06:58:38.260781",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17176v1",
      "title": "Universal Fine-Grained Symmetry Inference and Enforcement for Rigorous Crystal Structure Prediction",
      "abstract": "Crystal structure prediction (CSP), which aims to predict the three-dimensional atomic arrangement of a crystal from its composition, is central to materials discovery and mechanistic understanding. Existing deep learning models often treat crystallographic symmetry only as a soft heuristic or rely on space group and Wyckoff templates retrieved from known structures, which limits both physical fidelity and the ability to discover genuinely new material structures. In contrast to retrieval-based methods, our approach leverages large language models to encode chemical semantics and directly generate fine-grained Wyckoff patterns from composition, effectively circumventing the limitations inherent to database lookups. Crucially, we incorporate domain knowledge into the generative process through an efficient constrained-optimization search that rigorously enforces algebraic consistency between site multiplicities and atomic stoichiometry. By integrating this symmetry-consistent template into a diffusion backbone, our approach constrains the stochastic generative trajectory to a physically valid geometric manifold. This framework achieves state-of-the-art performance across stability, uniqueness, and novelty (SUN) benchmarks, alongside superior matching performance, thereby establishing a new paradigm for the rigorous exploration of targeted crystallographic space. This framework enables efficient expansion into previously uncharted materials space, eliminating reliance on existing databases or a priori structural knowledge.",
      "authors": [
        "Shi Yin",
        "Jinming Mu",
        "Xudong Zhu",
        "Lixin He"
      ],
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "published": "2026-02-19T08:43:25Z",
      "updated": "2026-02-19T08:43:25Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17176v1",
      "abs_url": "http://arxiv.org/abs/2602.17176v1",
      "summary": "利用大语言模型和扩散模型，结合晶体对称性约束，实现更精确的晶体结构预测。",
      "key_contributions": [
        "使用LLM编码化学语义并生成Wyckoff模式",
        "通过约束优化严格执行对称性一致性",
        "将对称性约束整合到扩散模型中"
      ],
      "methodology": "利用LLM生成晶体结构模板，通过约束优化保证对称性，并将其融入扩散模型以预测晶体结构。",
      "tags": [
        "晶体结构预测",
        "材料发现",
        "大语言模型",
        "扩散模型",
        "对称性"
      ],
      "assigned_category": "reasoning",
      "relevance_score": 7,
      "relevance_reason": "利用LLM进行推理生成结构，与Reasoning有一定的相关性。",
      "analyzed_at": "2026-02-20T06:58:40.163951",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17174v1",
      "title": "Continual uncertainty learning",
      "abstract": "Robust control of mechanical systems with multiple uncertainties remains a fundamental challenge, particularly when nonlinear dynamics and operating-condition variations are intricately intertwined. While deep reinforcement learning (DRL) combined with domain randomization has shown promise in mitigating the sim-to-real gap, simultaneously handling all sources of uncertainty often leads to sub-optimal policies and poor learning efficiency. This study formulates a new curriculum-based continual learning framework for robust control problems involving nonlinear dynamical systems in which multiple sources of uncertainty are simultaneously superimposed. The key idea is to decompose a complex control problem with multiple uncertainties into a sequence of continual learning tasks, in which strategies for handling each uncertainty are acquired sequentially. The original system is extended into a finite set of plants whose dynamic uncertainties are gradually expanded and diversified as learning progresses. The policy is stably updated across the entire plant sets associated with tasks defined by different uncertainty configurations without catastrophic forgetting. To ensure learning efficiency, we jointly incorporate a model-based controller (MBC), which guarantees a shared baseline performance across the plant sets, into the learning process to accelerate the convergence. This residual learning scheme facilitates task-specific optimization of the DRL agent for each uncertainty, thereby enhancing sample efficiency. As a practical industrial application, this study applies the proposed method to designing an active vibration controller for automotive powertrains. We verified that the resulting controller is robust against structural nonlinearities and dynamic variations, realizing successful sim-to-real transfer.",
      "authors": [
        "Heisei Yonezawa",
        "Ansei Yonezawa",
        "Itsuro Kajiwara"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T08:39:42Z",
      "updated": "2026-02-19T08:39:42Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17174v1",
      "abs_url": "http://arxiv.org/abs/2602.17174v1",
      "summary": "提出了基于课程学习的持续不确定性学习框架，用于解决复杂非线性系统的鲁棒控制问题。",
      "key_contributions": [
        "提出了一种新的持续学习框架，用于处理多重不确定性",
        "将复杂控制问题分解为一系列持续学习任务",
        "结合了模型预测控制和深度强化学习以提高学习效率"
      ],
      "methodology": "采用课程学习的方式，逐步增加不确定性的复杂程度，并结合模型预测控制加速深度强化学习的收敛。",
      "tags": [
        "continual learning",
        "reinforcement learning",
        "robust control",
        "uncertainty",
        "sim-to-real"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 7,
      "relevance_reason": "该论文涉及到学习策略的优化，与Agent Tuning & Optimization有一定的关联。",
      "analyzed_at": "2026-02-20T06:58:42.077845",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17168v1",
      "title": "BadCLIP++: Stealthy and Persistent Backdoors in Multimodal Contrastive Learning",
      "abstract": "Research on backdoor attacks against multimodal contrastive learning models faces two key challenges: stealthiness and persistence. Existing methods often fail under strong detection or continuous fine-tuning, largely due to (1) cross-modal inconsistency that exposes trigger patterns and (2) gradient dilution at low poisoning rates that accelerates backdoor forgetting. These coupled causes remain insufficiently modeled and addressed. We propose BadCLIP++, a unified framework that tackles both challenges. For stealthiness, we introduce a semantic-fusion QR micro-trigger that embeds imperceptible patterns near task-relevant regions, preserving clean-data statistics while producing compact trigger distributions. We further apply target-aligned subset selection to strengthen signals at low injection rates. For persistence, we stabilize trigger embeddings via radius shrinkage and centroid alignment, and stabilize model parameters through curvature control and elastic weight consolidation, maintaining solutions within a low-curvature wide basin resistant to fine-tuning. We also provide the first theoretical analysis showing that, within a trust region, gradients from clean fine-tuning and backdoor objectives are co-directional, yielding a non-increasing upper bound on attack success degradation. Experiments demonstrate that with only 0.3% poisoning, BadCLIP++ achieves 99.99% attack success rate (ASR) in digital settings, surpassing baselines by 11.4 points. Across nineteen defenses, ASR remains above 99.90% with less than 0.8% drop in clean accuracy. The method further attains 65.03% success in physical attacks and shows robustness against watermark removal defenses.",
      "authors": [
        "Siyuan Liang",
        "Yongcheng Jing",
        "Yingjie Wang",
        "Jiaxing Huang",
        "Ee-chien Chang",
        "Dacheng Tao"
      ],
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "published": "2026-02-19T08:31:16Z",
      "updated": "2026-02-19T08:31:16Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17168v1",
      "abs_url": "http://arxiv.org/abs/2602.17168v1",
      "summary": "BadCLIP++提出了一种隐蔽且持久的多模态对比学习后门攻击框架，有效抵抗检测和微调。",
      "key_contributions": [
        "提出语义融合QR微触发器，增强隐蔽性",
        "引入目标对齐子集选择，强化低注入率下的信号",
        "通过半径收缩、质心对齐、曲率控制和弹性权重巩固，提升后门持久性"
      ],
      "methodology": "设计隐蔽触发器并采用策略稳定触发器嵌入和模型参数，以抵抗检测和持续微调。",
      "tags": [
        "多模态学习",
        "后门攻击",
        "对比学习",
        "安全性"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "论文直接针对多模态对比学习的后门攻击问题，属于核心相关研究。",
      "analyzed_at": "2026-02-20T06:58:44.212778",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17155v1",
      "title": "Powering Up Zeroth-Order Training via Subspace Gradient Orthogonalization",
      "abstract": "Zeroth-order (ZO) optimization provides a gradient-free alternative to first-order (FO) methods by estimating gradients via finite differences of function evaluations, and has recently emerged as a memory-efficient paradigm for fine-tuning large-scale models by avoiding backpropagation. However, ZO optimization has a fundamental tension between accuracy and query efficiency. In this work, we show that ZO optimization can be substantially improved by unifying two complementary principles: (i) a projection-based subspace view that reduces gradient estimation variance by exploiting the intrinsic low-rank structure of model updates, and (ii) Muon-style spectral optimization that applies gradient orthogonalization to extract informative spectral structure from noisy ZO gradients. These findings form a unified framework of subspace gradient orthogonalization, which we instantiate in a new method, ZO-Muon, admitting a natural interpretation as a low-rank Muon optimizer in the ZO setting. Extensive experiments on large language models (LLMs) and vision transformers (ViTs) demonstrate that ZO-Muon significantly accelerates convergence and achieves a win-win improvement in accuracy and query/runtime efficiency. Notably, compared to the popular MeZO baseline, ZO-Muon requires only 24.7% of the queries to reach the same SST-2 performance for LLM fine-tuning, and improves accuracy by 25.1% on ViT-B fine-tuning on CIFAR-100.",
      "authors": [
        "Yicheng Lang",
        "Changsheng Wang",
        "Yihua Zhang",
        "Mingyi Hong",
        "Zheng Zhang",
        "Wotao Yin",
        "Sijia Liu"
      ],
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T08:08:33Z",
      "updated": "2026-02-19T08:08:33Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17155v1",
      "abs_url": "http://arxiv.org/abs/2602.17155v1",
      "summary": "提出ZO-Muon方法，通过子空间梯度正交化，显著提升零阶优化在微调大型模型时的效率和精度。",
      "key_contributions": [
        "提出子空间梯度正交化框架",
        "设计了ZO-Muon算法，结合了低秩结构和梯度正交化",
        "实验证明ZO-Muon在LLM和ViT微调中优于现有方法"
      ],
      "methodology": "利用投影的子空间视角降低梯度估计方差，并使用Muon风格的光谱优化提取噪声ZO梯度中的信息。",
      "tags": [
        "零阶优化",
        "梯度估计",
        "大型模型微调",
        "子空间学习",
        "梯度正交化"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 7,
      "relevance_reason": "论文关注模型微调，优化训练效率，与Agent Tuning & Optimization 领域相关。",
      "analyzed_at": "2026-02-20T06:58:46.371849",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17149v1",
      "title": "TimeOmni-VL: Unified Models for Time Series Understanding and Generation",
      "abstract": "Recent time series modeling faces a sharp divide between numerical generation and semantic understanding, with research showing that generation models often rely on superficial pattern matching, while understanding-oriented models struggle with high-fidelity numerical output. Although unified multimodal models (UMMs) have bridged this gap in vision, their potential for time series remains untapped. We propose TimeOmni-VL, the first vision-centric framework that unifies time series understanding and generation through two key innovations: (1) Fidelity-preserving bidirectional mapping between time series and images (Bi-TSI), which advances Time Series-to-Image (TS2I) and Image-to-Time Series (I2TS) conversions to ensure near-lossless transformations. (2) Understanding-guided generation. We introduce TSUMM-Suite, a novel dataset consists of six understanding tasks rooted in time series analytics that are coupled with two generation tasks. With a calibrated Chain-of-Thought, TimeOmni-VL is the first to leverage time series understanding as an explicit control signal for high-fidelity generation. Experiments confirm that this unified approach significantly improves both semantic understanding and numerical precision, establishing a new frontier for multimodal time series modeling.",
      "authors": [
        "Tong Guan",
        "Sheng Pan",
        "Johan Barthelemy",
        "Zhao Li",
        "Yujun Cai",
        "Cesare Alippi",
        "Ming Jin",
        "Shirui Pan"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "published": "2026-02-19T07:50:11Z",
      "updated": "2026-02-19T07:50:11Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17149v1",
      "abs_url": "http://arxiv.org/abs/2602.17149v1",
      "summary": "TimeOmni-VL提出了一种视觉中心的时间序列统一模型，用于理解和生成任务，并引入了Bi-TSI和TSUMM-Suite。",
      "key_contributions": [
        "提出了TimeOmni-VL框架，统一时间序列理解和生成",
        "引入了保真度双向映射Bi-TSI，实现时间序列和图像之间的转换",
        "构建了TSUMM-Suite数据集，包含理解和生成任务"
      ],
      "methodology": "利用双向时间序列-图像转换(Bi-TSI)和理解引导的生成方法，结合Chain-of-Thought，提升时间序列的理解和生成能力。",
      "tags": [
        "时间序列",
        "多模态学习",
        "视觉",
        "生成模型",
        "理解模型"
      ],
      "assigned_category": "multimodal",
      "relevance_score": 9,
      "relevance_reason": "该论文的核心在于利用视觉模态来解决时间序列的理解和生成问题，与多模态学习密切相关。",
      "analyzed_at": "2026-02-20T06:58:48.404034",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17145v1",
      "title": "Bonsai: A Framework for Convolutional Neural Network Acceleration Using Criterion-Based Pruning",
      "abstract": "As the need for more accurate and powerful Convolutional Neural Networks (CNNs) increases, so too does the size, execution time, memory footprint, and power consumption. To overcome this, solutions such as pruning have been proposed with their own metrics and methodologies, or criteria, for how weights should be removed. These solutions do not share a common implementation and are difficult to implement and compare. In this work, we introduce Combine, a criterion- based pruning solution and demonstrate that it is fast and effective framework for iterative pruning, demonstrate that criterion have differing effects on different models, create a standard language for comparing criterion functions, and propose a few novel criterion functions. We show the capacity of these criterion functions and the framework on VGG inspired models, pruning up to 79\\% of filters while retaining or improving accuracy, and reducing the computations needed by the network by up to 68\\%.",
      "authors": [
        "Joseph Bingham",
        "Sam Helmich"
      ],
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "published": "2026-02-19T07:46:08Z",
      "updated": "2026-02-19T07:46:08Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17145v1",
      "abs_url": "http://arxiv.org/abs/2602.17145v1",
      "summary": "Bonsai框架提出了一种基于准则的CNN剪枝方法，旨在加速和压缩模型。",
      "key_contributions": [
        "提出了Combine剪枝框架",
        "比较了不同准则对模型的影响",
        "提出了一些新的准则函数"
      ],
      "methodology": "迭代地移除CNN中不重要的权重（filters），基于不同的准则函数来决定移除哪些权重。",
      "tags": [
        "CNN",
        "Pruning",
        "Acceleration",
        "Model Compression"
      ],
      "assigned_category": "agent_tuning",
      "relevance_score": 5,
      "relevance_reason": "可以通过类似剪枝的方式，优化agent模型。",
      "analyzed_at": "2026-02-20T06:58:50.036630",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    },
    {
      "arxiv_id": "2602.17127v1",
      "title": "The Emergence of Lab-Driven Alignment Signatures: A Psychometric Framework for Auditing Latent Bias and Compounding Risk in Generative AI",
      "abstract": "As Large Language Models (LLMs) transition from standalone chat interfaces to foundational reasoning layers in multi-agent systems and recursive evaluation loops (LLM-as-a-judge), the detection of durable, provider-level behavioral signatures becomes a critical requirement for safety and governance. Traditional benchmarks measure transient task accuracy but fail to capture stable, latent response policies -- the ``prevailing mindsets'' embedded during training and alignment that outlive individual model versions.   This paper introduces a novel auditing framework that utilizes psychometric measurement theory -- specifically latent trait estimation under ordinal uncertainty -- to quantify these tendencies without relying on ground-truth labels. Utilizing forced-choice ordinal vignettes masked by semantically orthogonal decoys and governed by cryptographic permutation-invariance, the research audits nine leading models across dimensions including Optimization Bias, Sycophancy, and Status-Quo Legitimization.   Using Mixed Linear Models (MixedLM) and Intraclass Correlation Coefficient (ICC) analysis, the research identifies that while item-level framing drives high variance, a persistent ``lab signal'' accounts for significant behavioral clustering. These findings demonstrate that in ``locked-in'' provider ecosystems, latent biases are not merely static errors but compounding variables that risk creating recursive ideological echo chambers in multi-layered AI architectures.",
      "authors": [
        "Dusan Bosnjakovic"
      ],
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "published": "2026-02-19T06:56:01Z",
      "updated": "2026-02-19T06:56:01Z",
      "pdf_url": "https://arxiv.org/pdf/2602.17127v1",
      "abs_url": "http://arxiv.org/abs/2602.17127v1",
      "summary": "论文提出一种新框架，利用心理测量理论审计LLM的潜在偏差，发现供应商级别的行为特征。",
      "key_contributions": [
        "提出一种基于心理测量理论的LLM潜在偏差审计框架",
        "使用强制选择排序小品和语义正交诱饵量化LLM的偏差",
        "发现LLM中存在显著的“实验室信号”，揭示潜在偏差的供应商级别行为特征"
      ],
      "methodology": "利用心理测量理论，通过强制选择排序小品和统计模型（MixedLM, ICC）量化LLM的优化偏差、谄媚和现状合法化等倾向。",
      "tags": [
        "LLM Bias",
        "Alignment",
        "Psychometrics",
        "Auditing",
        "Generative AI"
      ],
      "assigned_category": "agent",
      "relevance_score": 8,
      "relevance_reason": "该论文研究了LLM在多智能体系统中的潜在偏差问题，这对于构建可靠的AI Agent至关重要。",
      "analyzed_at": "2026-02-20T06:58:52.343867",
      "llm_provider": "gemini",
      "llm_model": "gemini-2.0-flash"
    }
  ],
  "fetch_time": "2026-02-20T06:58:52.344125"
}